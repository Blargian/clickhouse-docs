---
title: 'Настройки сессии'
sidebar_label: 'Настройки сессии'
slug: /operations/settings/settings
toc_max_heading_level: 2
description: 'Настройки, которые находятся в таблице ``system.settings``.'
---

import ExperimentalBadge from '@theme/badges/ExperimentalBadge';
import BetaBadge from '@theme/badges/BetaBadge';
import CloudAvailableBadge from '@theme/badges/CloudAvailableBadge';

<!-- Autogenerated -->
Все нижеуказанные настройки также доступны в таблице [system.settings](/docs/operations/system-tables/settings). Эти настройки автогенерируются из [источника](https://github.com/ClickHouse/ClickHouse/blob/master/src/Core/Settings.cpp).
## add_http_cors_header {#add_http_cors_header} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Добавить заголовок http CORS.
## additional_result_filter {#additional_result_filter} 

Дополнительное выражение фильтра для применения к результату запроса `SELECT`.
Эта настройка не применяется к любому подзапросу.

**Пример**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SElECT * FROM table_1;
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
```sql
SELECT *
FROM table_1
SETTINGS additional_result_filter = 'x != 2'
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
## additional_table_filters {#additional_table_filters} 

|Тип|По умолчанию|
|---|---|
|`Map`|`{}`|

Дополнительное выражение фильтра, которое применяется после чтения из указанной таблицы.

**Пример**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SELECT * FROM table_1;
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
```sql
SELECT *
FROM table_1
SETTINGS additional_table_filters = {'table_1': 'x != 2'}
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
## aggregate_functions_null_for_empty {#aggregate_functions_null_for_empty} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает переписывание всех агрегатных функций в запросе, добавляя суффикс [-OrNull](/sql-reference/aggregate-functions/combinators#-ornull) к ним. Включите его для совместимости со стандартом SQL.
Это реализовано через переписывание запроса (аналогично настройке [count_distinct_implementation](#count_distinct_implementation)), чтобы получить согласованные результаты для распределенных запросов.

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

**Пример**

Рассмотрим следующий запрос с агрегатными функциями:
```sql
SELECT SUM(-1), MAX(0) FROM system.one WHERE 0;
```

С `aggregate_functions_null_for_empty = 0` он даст:
```text
┌─SUM(-1)─┬─MAX(0)─┐
│       0 │      0 │
└─────────┴────────┘
```

С `aggregate_functions_null_for_empty = 1` результат будет:
```text
┌─SUMOrNull(-1)─┬─MAXOrNull(0)─┐
│          NULL │         NULL │
└───────────────┴──────────────┘
```
## aggregation_in_order_max_block_bytes {#aggregation_in_order_max_block_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`50000000`|

Максимальный размер блока в байтах, накапливаемого во время агрегации в порядке основного ключа. Меньший размер блока позволяет параллелить более финальную стадию слияния агрегации.
## aggregation_memory_efficient_merge_threads {#aggregation_memory_efficient_merge_threads} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Количество потоков для объединения промежуточных результатов агрегации в режиме эффективного использования памяти. При увеличении потребляется больше памяти. 0 означает - то же самое, что и 'max_threads'.
## allow_aggregate_partitions_independently {#allow_aggregate_partitions_independently} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить независимую агрегацию партиций на отдельных потоках, когда ключ партиционирования соответствует ключу группировки. Это полезно, когда количество партиций близко к количеству ядер, а партиции имеют примерно одинаковый размер.
## allow_archive_path_syntax {#allow_archive_path_syntax} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Движки/файлы S3 будут разбирать пути с '::' как `<archive> :: <file>\` если архив имеет правильное расширение.
## allow_asynchronous_read_from_io_pool_for_merge_tree {#allow_asynchronous_read_from_io_pool_for_merge_tree} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать фоновый пул ввода-вывода для чтения из таблиц MergeTree. Эта настройка может повысить производительность для запросов, зависящих от ввода-вывода.
## allow_changing_replica_until_first_data_packet {#allow_changing_replica_until_first_data_packet} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если это включено, в задерганных запросах мы можем начать новое соединение до получения первого пакета данных, даже если мы уже сделали некоторый прогресс
(но прогресс не обновлен в течение времени `receive_data_timeout`), иначе мы отключаем изменение реплики после первого раза, когда мы достигли прогресса.
## allow_create_index_without_type {#allow_create_index_without_type} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить запрос CREATE INDEX без TYPE. Запрос будет проигнорирован. Сделано для тестов совместимости SQL.
## allow_custom_error_code_in_throwif {#allow_custom_error_code_in_throwif} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить пользовательский код ошибки в функции throwIf(). Если true, выброшенные исключения могут иметь неожиданные коды ошибок.
## allow_ddl {#allow_ddl} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если установлено в true, пользователю разрешено выполнять DDL запросы.
## allow_deprecated_database_ordinary {#allow_deprecated_database_ordinary} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить создание баз данных со устаревшим обычным движком.
## allow_deprecated_error_prone_window_functions {#allow_deprecated_error_prone_window_functions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить использование устаревших потенциально ошибочных оконных функций (neighbor, runningAccumulate, runningDifferenceStartingWithFirstValue, runningDifference).
## allow_deprecated_snowflake_conversion_functions {#allow_deprecated_snowflake_conversion_functions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Функции `snowflakeToDateTime`, `snowflakeToDateTime64`, `dateTimeToSnowflake` и `dateTime64ToSnowflake` устарели и выключены по умолчанию.
Пожалуйста, используйте функции `snowflakeIDToDateTime`, `snowflakeIDToDateTime64`, `dateTimeToSnowflakeID` и `dateTime64ToSnowflakeID` вместо этого.

Чтобы повторно включить устаревшие функции (например, в переходный период), пожалуйста, установите эту настройку в `true`.
## allow_deprecated_syntax_for_merge_tree {#allow_deprecated_syntax_for_merge_tree} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить создание *MergeTree таблиц с устаревшим синтаксисом определения движка.
## allow_distributed_ddl {#allow_distributed_ddl} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если это установлено в true, пользователю разрешено выполнять распределенные DDL запросы.
## allow_drop_detached {#allow_drop_detached} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить запросы ALTER TABLE ... DROP DETACHED PART[ITION] ...
## allow_execute_multiif_columnar {#allow_execute_multiif_columnar} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить выполнение функции multiIf в столбцовом формате.
## allow_experimental_analyzer {#allow_experimental_analyzer} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить новый анализатор запросов.
## allow_experimental_codecs {#allow_experimental_codecs} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если установлено в true, разрешить указание экспериментальных кодеков сжатия (но у нас их еще нет, и эта опция ничего не делает).
## allow_experimental_database_glue_catalog {#allow_experimental_database_glue_catalog} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить экспериментальный движок базы данных DataLakeCatalog с catalog_type = 'glue'.
## allow_experimental_database_iceberg {#allow_experimental_database_iceberg} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить экспериментальный движок базы данных DataLakeCatalog с catalog_type = 'iceberg'.
## allow_experimental_database_materialized_postgresql {#allow_experimental_database_materialized_postgresql} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить создание базы данных с Engine=MaterializedPostgreSQL(...).
## allow_experimental_database_unity_catalog {#allow_experimental_database_unity_catalog} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить экспериментальный движок базы данных DataLakeCatalog с catalog_type = 'unity'.
## allow_experimental_dynamic_type {#allow_experimental_dynamic_type} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает создание типа данных [Dynamic](../../sql-reference/data-types/dynamic.md).
## allow_experimental_full_text_index {#allow_experimental_full_text_index} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если установлено в true, разрешить использовать экспериментальный полнотекстовый индекс.
## allow_experimental_funnel_functions {#allow_experimental_funnel_functions} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить экспериментальные функции для анализа воронки.
## allow_experimental_hash_functions {#allow_experimental_hash_functions} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить экспериментальные хеш-функции.
## allow_experimental_inverted_index {#allow_experimental_inverted_index} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если установлено в true, разрешить использовать экспериментальный обратный индекс.
## allow_experimental_join_condition {#allow_experimental_join_condition} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Поддержка соединения с неравенствующими условиями, которые включают столбцы как из левой, так и из правой таблицы. Например, `t1.y < t2.y`.
## allow_experimental_join_right_table_sorting {#allow_experimental_join_right_table_sorting} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если установлено в true и выполнены условия `join_to_sort_minimum_perkey_rows` и `join_to_sort_maximum_table_rows`, перенастройте правую таблицу по ключу для повышения производительности в левом или внутреннем хеш-соединении.
## allow_experimental_json_type {#allow_experimental_json_type} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает создание типа данных [JSON](../../sql-reference/data-types/newjson.md).
## allow_experimental_kafka_offsets_storage_in_keeper {#allow_experimental_kafka_offsets_storage_in_keeper} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить экспериментальную функцию для хранения смещений, связанных с Kafka, в ClickHouse Keeper. Когда включено, можно указать путь ClickHouse Keeper и имя реплики для движка таблицы Kafka. В результате вместо обычного движка Kafka будет использоваться новый тип движка хранения, который в первую очередь хранит зафиксированные смещения в ClickHouse Keeper.
## allow_experimental_kusto_dialect {#allow_experimental_kusto_dialect} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить язык запросов Kusto (KQL) - альтернативу SQL.
## allow_experimental_live_view {#allow_experimental_live_view} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает создание устаревшего LIVE VIEW.

Возможные значения:

- 0 — Работа с живыми представлениями отключена.
- 1 — Работа с живыми представлениями включена.
## allow_experimental_materialized_postgresql_table {#allow_experimental_materialized_postgresql_table} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает использовать движок таблицы MaterializedPostgreSQL. Отключен по умолчанию, потому что эта функция экспериментальная.
## allow_experimental_nlp_functions {#allow_experimental_nlp_functions} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить экспериментальные функции для обработки естественного языка.
## allow_experimental_object_type {#allow_experimental_object_type} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить устаревший тип данных Object.
## allow_experimental_parallel_reading_from_replicas {#allow_experimental_parallel_reading_from_replicas} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Использовать до `max_parallel_replicas` количество реплик из каждой шард для выполнения запроса SELECT. Чтение будет параллелизовано и координировано динамически. 0 - отключено, 1 - включено, молча отключить в случае сбоя, 2 - включено, выбросить исключение в случае сбоя.
## allow_experimental_prql_dialect {#allow_experimental_prql_dialect} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить PRQL - альтернативу SQL.
## allow_experimental_query_deduplication {#allow_experimental_query_deduplication} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Экспериментальная дедупликация данных для запросов SELECT на основе UUID частей.
## allow_experimental_shared_set_join {#allow_experimental_shared_set_join} 

<ExperimentalBadge/>

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Влияет только на ClickHouse Cloud. Разрешить создание ShareSet и SharedJoin.
## allow_experimental_statistics {#allow_experimental_statistics} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Позволяет определять столбцы со [статистикой](../../engines/table-engines/mergetree-family/mergetree.md/#table_engine-mergetree-creating-a-table) и [манипулировать статистикой](../../engines/table-engines/mergetree-family/mergetree.md/#column-statistics).
## allow_experimental_time_series_table {#allow_experimental_time_series_table} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает создание таблиц с использованием движка таблицы [TimeSeries](../../engines/table-engines/integrations/time-series.md).

Возможные значения:

- 0 — движок таблицы [TimeSeries](../../engines/table-engines/integrations/time-series.md) отключен.
- 1 — движок таблицы [TimeSeries](../../engines/table-engines/integrations/time-series.md) включен.
## allow_experimental_ts_to_grid_aggregate_function {#allow_experimental_ts_to_grid_aggregate_function} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Экспериментальная агрегатная функция tsToGrid для повторной выборки временных рядов, похожих на Prometheus. Только для Cloud.
## allow_experimental_variant_type {#allow_experimental_variant_type} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает создание типа данных [Variant](../../sql-reference/data-types/variant.md).
## allow_experimental_vector_similarity_index {#allow_experimental_vector_similarity_index} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить экспериментальный индекс векторного сходства.
## allow_experimental_window_view {#allow_experimental_window_view} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить WINDOW VIEW. Недостаточно зрелый.
## allow_general_join_planning {#allow_general_join_planning} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Позволяет более общий алгоритм планирования соединения, который может обрабатывать более сложные условия, но работает только с хеш-соединениями. Если хеш-соединение не включено, то используется обычный алгоритм планирования соединения независимо от значения этой настройки.
## allow_get_client_http_header {#allow_get_client_http_header} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает использовать функцию `getClientHTTPHeader`, которая позволяет получить значение текущего заголовка HTTP-запроса. По умолчанию не включена по соображениям безопасности, поскольку некоторые заголовки, такие как `Cookie`, могут содержать конфиденциальную информацию. Обратите внимание, что заголовки `X-ClickHouse-*` и `Authentication` всегда ограничены и не могут быть получены с помощью этой функции.
## allow_hyperscan {#allow_hyperscan} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить функции, использующие библиотеку Hyperscan. Отключите, чтобы избежать потенциально долгих времен компиляции и чрезмерного использования ресурсов.
## allow_introspection_functions {#allow_introspection_functions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает [функции интроспекции](../../sql-reference/functions/introspection.md) для профилирования запросов.

Возможные значения:

- 1 — Функции интроспекции включены.
- 0 — Функции интроспекции отключены.

**Смотрите также**

- [Профилировщик запросов с выборкой](../../operations/optimizing-performance/sampling-query-profiler.md)
- Системная таблица [trace_log](/operations/system-tables/trace_log).
## allow_materialized_view_with_bad_select {#allow_materialized_view_with_bad_select} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить CREATE MATERIALIZED VIEW с запросом SELECT, который ссылается на несуществующие таблицы или столбцы. Он все еще должен быть синтаксически корректным. Не применяется к обновляемым МВ. Не применяется, если схема МВ должна быть выведена из SELECT запроса (т.е. если CREATE не имеет списка столбцов и нет TO таблицы). Может использоваться для создания МВ до создания его исходной таблицы.
## allow_named_collection_override_by_default {#allow_named_collection_override_by_default} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить переопределение полей именованных коллекций по умолчанию.
## allow_non_metadata_alters {#allow_non_metadata_alters} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить выполнение изменений, которые затрагивают не только метаданные таблиц, но и данные на диске.
## allow_nonconst_timezone_arguments {#allow_nonconst_timezone_arguments} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить не константные аргументы часового пояса в некоторых функциях, связанных со временем, таких как toTimeZone(), fromUnixTimestamp*(), snowflakeToDateTime*().
## allow_nondeterministic_mutations {#allow_nondeterministic_mutations} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Пользовательская настройка, которая позволяет мутациям в реплицированных таблицах использовать недетерминированные функции, такие как `dictGet`.

Учитывая, что, например, словари могут быть не синхронизированы по узлам, мутации, которые извлекают значения из них, по умолчанию запрещены для реплицированных таблиц. Включение этой настройки позволяет это поведение, возлагая на пользователя ответственность за обеспечение синхронизации данных на всех узлах.

**Пример**

```xml
<profiles>
    <default>
        <allow_nondeterministic_mutations>1</allow_nondeterministic_mutations>

        <!-- ... -->
    </default>

    <!-- ... -->

</profiles>
```
## allow_nondeterministic_optimize_skip_unused_shards {#allow_nondeterministic_optimize_skip_unused_shards} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить недетерминированные (такие как `rand` или `dictGet`, так как последняя имеет некоторые нюансы с обновлениями) функции в ключе шардирования.

Возможные значения:

- 0 — Запрещено.
- 1 — Разрешено.
## allow_not_comparable_types_in_comparison_functions {#allow_not_comparable_types_in_comparison_functions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает или ограничивает использование несравнимых типов (таких как JSON/Object/AggregateFunction) в функциях сравнения `equal/less/greater/etc`.
## allow_not_comparable_types_in_order_by {#allow_not_comparable_types_in_order_by} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает или ограничивает использование несравнимых типов (таких как JSON/Object/AggregateFunction) в ключах ORDER BY.
## allow_prefetched_read_pool_for_local_filesystem {#allow_prefetched_read_pool_for_local_filesystem} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Предпочитать предварительно загруженный пул потоков, если все части находятся на локальной файловой системе.
## allow_prefetched_read_pool_for_remote_filesystem {#allow_prefetched_read_pool_for_remote_filesystem} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Предпочитать предварительно загруженный пул потоков, если все части находятся на удаленной файловой системе.
## allow_push_predicate_ast_for_distributed_subqueries {#allow_push_predicate_ast_for_distributed_subqueries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает продвигать предикат на уровне AST для распределенных подзапросов с включенным анализатором.
## allow_push_predicate_when_subquery_contains_with {#allow_push_predicate_when_subquery_contains_with} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает продвигать предикат, когда подзапрос содержит WITH клаузу.
## allow_reorder_prewhere_conditions {#allow_reorder_prewhere_conditions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

При перемещении условий из WHERE в PREWHERE разрешить их перестановку для оптимизации фильтрации.
## allow_settings_after_format_in_insert {#allow_settings_after_format_in_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Контролирует, разрешены ли `SETTINGS` после `FORMAT` в запросах `INSERT`. Рекомендуется не использовать это, так как это может интерпретировать часть `SETTINGS` как значения.

Пример:

```sql
INSERT INTO FUNCTION null('foo String') SETTINGS max_threads=1 VALUES ('bar');
```

Но следующий запрос будет работать только с `allow_settings_after_format_in_insert`:

```sql
SET allow_settings_after_format_in_insert=1;
INSERT INTO FUNCTION null('foo String') VALUES ('bar') SETTINGS max_threads=1;
```

Возможные значения:

- 0 — Запрещено.
- 1 — Разрешено.

:::note
Используйте эту настройку только для обратной совместимости, если ваши случаи использования зависят от старого синтаксиса.
:::
## allow_simdjson {#allow_simdjson} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить использование библиотеки simdjson в функциях 'JSON*', если доступны инструкции AVX2. Если отключено, будет использоваться rapidjson.
## allow_statistics_optimize {#allow_statistics_optimize} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает использование статистики для оптимизации запросов.
## allow_suspicious_codecs {#allow_suspicious_codecs} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если установлено в true, разрешить указание бессмысленных кодеков сжатия.
## allow_suspicious_fixed_string_types {#allow_suspicious_fixed_string_types} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

В команде CREATE TABLE разрешает создание столбцов типа FixedString(n) с n > 256. FixedString с длиной >= 256 является подозрительным и, скорее всего, указывает на неправильное использование.
## allow_suspicious_indices {#allow_suspicious_indices} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Отклонить первичные/вторичные индексы и ключи сортировки с идентичными выражениями.
## allow_suspicious_low_cardinality_types {#allow_suspicious_low_cardinality_types} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает или ограничивает использование [LowCardinality](../../sql-reference/data-types/lowcardinality.md) с типами данных с фиксированным размером 8 байт или меньше: числовые типы данных и `FixedString(8_bytes_or_less)`.

Для небольших фиксированных значений использование `LowCardinality` обычно неэффективно, поскольку ClickHouse хранит числовой индекс для каждой строки. В результате:

- Использование дискового пространства может увеличиваться.
- Потребление оперативной памяти может быть выше, в зависимости от размера словаря.
- Некоторые функции могут работать медленнее из-за дополнительных операций кодирования/декодирования.

Время слияния в таблицах с движками [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) может увеличиваться по всем вышеописанным причинам.

Возможные значения:

- 1 — Использование `LowCardinality` не ограничено.
- 0 — Использование `LowCardinality` ограничено.
## allow_suspicious_primary_key {#allow_suspicious_primary_key} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить подозрительные `PRIMARY KEY`/`ORDER BY` для MergeTree (т.е. SimpleAggregateFunction).
## allow_suspicious_ttl_expressions {#allow_suspicious_ttl_expressions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Отклонить выражения TTL, которые не зависят от каких-либо столбцов таблицы. Это почти всегда указывает на ошибку пользователя.
## allow_suspicious_types_in_group_by {#allow_suspicious_types_in_group_by} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает или ограничивает использование типов [Variant](../../sql-reference/data-types/variant.md) и [Dynamic](../../sql-reference/data-types/dynamic.md) в ключах GROUP BY.
## allow_suspicious_types_in_order_by {#allow_suspicious_types_in_order_by} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает или ограничивает использование типов [Variant](../../sql-reference/data-types/variant.md) и [Dynamic](../../sql-reference/data-types/dynamic.md) в ключах ORDER BY.
## allow_suspicious_variant_types {#allow_suspicious_variant_types} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

В команде CREATE TABLE позволяет указать тип Variant с похожими вариантными типами (например, с различными числовыми или датированными типами). Включение этой настройки может ввести некоторую неопределенность при работе со значениями с похожими типами.
## allow_unrestricted_reads_from_keeper {#allow_unrestricted_reads_from_keeper} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить неограниченные (без условия на путь) чтения из системной таблицы zookeeper, может быть полезно, но не безопасно для zookeeper.
## alter_move_to_space_execute_async {#alter_move_to_space_execute_async} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Выполнять ALTER TABLE MOVE ... TO [DISK|VOLUME] асинхронно.
## alter_partition_verbose_result {#alter_partition_verbose_result} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает отображение информации о частях, к которым успешно применены операции с партициями и частями.
Применимо к [ATTACH PARTITION|PART](/sql-reference/statements/alter/partition#attach-partitionpart) и к [FREEZE PARTITION](/sql-reference/statements/alter/partition#freeze-partition).

Возможные значения:

- 0 — отключить подробность.
- 1 — включить подробность.

**Пример**

```sql
CREATE TABLE test(a Int64, d Date, s String) ENGINE = MergeTree PARTITION BY toYYYYMDECLARE(d) ORDER BY a;
INSERT INTO test VALUES(1, '2021-01-01', '');
INSERT INTO test VALUES(1, '2021-01-01', '');
ALTER TABLE test DETACH PARTITION ID '202101';

ALTER TABLE test ATTACH PARTITION ID '202101' SETTINGS alter_partition_verbose_result = 1;

┌─command_type─────┬─partition_id─┬─part_name────┬─old_part_name─┐
│ ATTACH PARTITION │ 202101       │ 202101_7_7_0 │ 202101_5_5_0  │
│ ATTACH PARTITION │ 202101       │ 202101_8_8_0 │ 202101_6_6_0  │
└──────────────────┴──────────────┴──────────────┴───────────────┘

ALTER TABLE test FREEZE SETTINGS alter_partition_verbose_result = 1;

┌─command_type─┬─partition_id─┬─part_name────┬─backup_name─┬─backup_path───────────────────┬─part_backup_path────────────────────────────────────────────┐
│ FREEZE ALL   │ 202101       │ 202101_7_7_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_7_7_0 │
│ FREEZE ALL   │ 202101       │ 202101_8_8_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_8_8_0 │
└──────────────┴──────────────┴──────────────┴─────────────┴───────────────────────────────┴─────────────────────────────────────────────────────────────┘
```
## alter_sync {#alter_sync} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1`|

Позволяет настроить ожидание выполнения действий на репликах в результатах [ALTER](../../sql-reference/statements/alter/index.md), [OPTIMIZE](../../sql-reference/statements/optimize.md) или [TRUNCATE](../../sql-reference/statements/truncate.md).

Возможные значения:

- 0 — Не ждать.
- 1 — Ждать своей реализации.
- 2 — Ждать всех.

Cloud значение по умолчанию: `0`.

:::note
`alter_sync` применяется только к `Replicated` таблицам, он ничего не делает для изменений не `Replicated` таблиц.
:::
## analyze_index_with_space_filling_curves {#analyze_index_with_space_filling_curves} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если у таблицы есть заполняющая кривую в своем индексе, например, `ORDER BY mortonEncode(x, y)` или `ORDER BY hilbertEncode(x, y)`, и в запросе есть условия на его аргументы, например, `x >= 10 AND x <= 20 AND y >= 20 AND y <= 30`, используйте заполняющую кривую для анализа индекса.
## analyzer_compatibility_join_using_top_level_identifier {#analyzer_compatibility_join_using_top_level_identifier} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Заставляет решать идентификатор в JOIN USING из проекции (например, в `SELECT a + 1 AS b FROM t1 JOIN t2 USING (b)` соединение будет выполнено по `t1.a + 1 = t2.b`, а не по `t1.b = t2.b`).
## any_join_distinct_right_table_keys {#any_join_distinct_right_table_keys} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает наследуемое поведение сервера ClickHouse в операциях `ANY INNER|LEFT JOIN`.

:::note
Используйте эту настройку только для обратной совместимости, если ваши случаи использования зависят от наследуемого поведения `JOIN`.
:::

Когда включено наследуемое поведение:

- Результаты операций `t1 ANY LEFT JOIN t2` и `t2 ANY RIGHT JOIN t1` не равны, потому что ClickHouse использует логику с множественным отображением ключей с левой на правую таблицу.
- Результаты операций `ANY INNER JOIN` содержат все строки из левой таблицы, как операции `SEMI LEFT JOIN`.

Когда наследуемое поведение отключено:

- Результаты операций `t1 ANY LEFT JOIN t2` и `t2 ANY RIGHT JOIN t1` равны, потому что ClickHouse использует логику, обеспечивающую одно-ко-многим отображение ключей в операциях `ANY RIGHT JOIN`.
- Результаты операций `ANY INNER JOIN` содержат одну строку на ключ из обеих левых и правых таблиц.

Возможные значения:

- 0 — Наследуемое поведение отключено.
- 1 — Наследуемое поведение включено.

Смотрите также:

- [Строгость JOIN](/sql-reference/statements/select/join#settings).
## apply_deleted_mask {#apply_deleted_mask} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает фильтрацию строк, удаленных с помощью легковесного DELETE. Если отключено, запрос сможет прочитать эти строки. Это полезно для отладки и сценариев "восстановления".
## apply_mutations_on_fly {#apply_mutations_on_fly} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если да, мутации (UPDATE и DELETE), которые не материализованы в части данных, будут применяться при SELECT.
## apply_settings_from_server {#apply_settings_from_server} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Должен ли клиент принимать настройки от сервера.

Это затрагивает только операции, выполняемые на стороне клиента, в частности, парсинг входных данных INSERT и форматирование результата запроса. Большинство выполнения запроса происходит на сервере и не затрагивается этой настройкой.

Обычно эта настройка устанавливается в профиле пользователя (users.xml или запросы, такие как `ALTER USER`), а не через клиент (аргументы командной строки клиента, запрос `SET` или секция `SETTINGS` запроса `SELECT`). Через клиент ее можно изменить на false, но не можно изменить на true (поскольку сервер не отправит настройки, если профиль пользователя имеет `apply_settings_from_server = false`).

Обратите внимание, что изначально (24.12) была серверная настройка (`send_settings_to_client`), но позднее она была заменена этой клиентской настройкой для лучшей удобочитаемости.
## asterisk_include_alias_columns {#asterisk_include_alias_columns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить [ALIAS](../../sql-reference/statements/create/table.md/#alias) столбцы для запросов с подстановочными знаками (`SELECT *`).

Возможные значения:

- 0 - отключено
- 1 - включено
## asterisk_include_materialized_columns {#asterisk_include_materialized_columns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включите [MATERIALIZED](/sql-reference/statements/create/view#materialized-view) колонки для запроса с подстановочным знаком (`SELECT *`).

Возможные значения:

- 0 - отключено
- 1 - включено
## async_insert {#async_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если установлено в true, данные из запроса INSERT хранятся в очереди и позже сбрасываются в таблицу в фоновом режиме. Если wait_for_async_insert равно false, запрос INSERT обрабатывается почти мгновенно, в противном случае клиент будет ждать, пока данные не будут сброшены в таблицу.
## async_insert_busy_timeout_decrease_rate {#async_insert_busy_timeout_decrease_rate} 

|Тип|По умолчанию|
|---|---|
|`Double`|`0.2`|

Экспоненциальная скорость роста, с которой уменьшается адаптивный таймаут асинхронной вставки.
## async_insert_busy_timeout_increase_rate {#async_insert_busy_timeout_increase_rate} 

|Тип|По умолчанию|
|---|---|
|`Double`|`0.2`|

Экспоненциальная скорость роста, с которой увеличивается адаптивный таймаут асинхронной вставки.
## async_insert_busy_timeout_max_ms {#async_insert_busy_timeout_max_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`200`|

Максимальное время ожидания перед сбросом собранных данных за запрос с момента появления первых данных.
## async_insert_busy_timeout_min_ms {#async_insert_busy_timeout_min_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`50`|

Если автонастройка включена через async_insert_use_adaptive_busy_timeout, минимальное время ожидания перед сбросом собранных данных за запрос с момента появления первых данных. Оно также служит начальным значением для адаптивного алгоритма.
## async_insert_deduplicate {#async_insert_deduplicate} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Для асинхронных запросов INSERT в реплицированной таблице указывает, что должна проводиться дедупликация вставляемых блоков.
## async_insert_max_data_size {#async_insert_max_data_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10485760`|

Максимальный размер в байтах неподобранных данных, собранных за запрос перед вставкой.
## async_insert_max_query_number {#async_insert_max_query_number} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`450`|

Максимальное количество запросов на вставку перед вставкой.
## async_insert_poll_timeout_ms {#async_insert_poll_timeout_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`10`|

Таймаут для опроса данных из очереди асинхронной вставки.
## async_insert_use_adaptive_busy_timeout {#async_insert_use_adaptive_busy_timeout} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если установлено в true, использовать адаптивный таймаут при асинхронных вставках.
## async_query_sending_for_remote {#async_query_sending_for_remote} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает создание асинхронных соединений и отправку запросов при выполнении удаленного запроса.

Включено по умолчанию.
## async_socket_for_remote {#async_socket_for_remote} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает асинхронное чтение из сокета при выполнении удаленного запроса.

Включено по умолчанию.
## azure_allow_parallel_part_upload {#azure_allow_parallel_part_upload} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Используйте несколько потоков для загрузки нескольких частей в Azure.
## azure_check_objects_after_upload {#azure_check_objects_after_upload} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Проверьте каждый загруженный объект в хранилище блобов Azure, чтобы убедиться, что загрузка прошла успешно.
## azure_create_new_file_on_insert {#azure_create_new_file_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает создание нового файла при каждой вставке в таблицы Azure engine.
## azure_ignore_file_doesnt_exist {#azure_ignore_file_doesnt_exist} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорировать отсутствие файла, если он не существует, при чтении определенных ключей.

Возможные значения:
- 1 — `SELECT` возвращает пустой результат.
- 0 — `SELECT` вызывает исключение.
## azure_list_object_keys_size {#azure_list_object_keys_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Максимальное количество файлов, которые могут быть возвращены в пакетном запросе ListObject.
## azure_max_blocks_in_multipart_upload {#azure_max_blocks_in_multipart_upload} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`50000`|

Максимальное количество блоков в загрузке нескольких частей для Azure.
## azure_max_inflight_parts_for_one_file {#azure_max_inflight_parts_for_one_file} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`20`|

Максимальное количество одновременно загружаемых частей в запросе на загрузку нескольких частей. 0 означает неограниченное.
## azure_max_single_part_copy_size {#azure_max_single_part_copy_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`268435456`|

Максимальный размер объекта для копирования с использованием копирования одной части в хранилище блобов Azure.
## azure_max_single_part_upload_size {#azure_max_single_part_upload_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`104857600`|

Максимальный размер объекта для загрузки с использованием загрузки одной части в хранилище блобов Azure.
## azure_max_single_read_retries {#azure_max_single_read_retries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`4`|

Максимальное количество повторных попыток во время чтения из хранилища блобов Azure.
## azure_max_unexpected_write_error_retries {#azure_max_unexpected_write_error_retries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`4`|

Максимальное количество повторных попыток в случае неожиданных ошибок при записи в хранилище блобов Azure.
## azure_max_upload_part_size {#azure_max_upload_part_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5368709120`|

Максимальный размер части для загрузки при загрузке нескольких частей в хранилище блобов Azure.
## azure_min_upload_part_size {#azure_min_upload_part_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`16777216`|

Минимальный размер части для загрузки при загрузке нескольких частей в хранилище блобов Azure.
## azure_sdk_max_retries {#azure_sdk_max_retries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10`|

Максимальное количество повторных попыток в Azure SDK.
## azure_sdk_retry_initial_backoff_ms {#azure_sdk_retry_initial_backoff_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10`|

Минимальное время ожидания между повторными попытками в Azure SDK.
## azure_sdk_retry_max_backoff_ms {#azure_sdk_retry_max_backoff_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Максимальное время ожидания между повторными попытками в Azure SDK.
## azure_skip_empty_files {#azure_skip_empty_files} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает пропуск пустых файлов в движке S3.

Возможные значения:
- 0 — `SELECT` вызывает исключение, если пустой файл не совместим с запрашиваемым форматом.
- 1 — `SELECT` возвращает пустой результат для пустого файла.
## azure_strict_upload_part_size {#azure_strict_upload_part_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Точный размер части для загрузки при загрузке нескольких частей в хранилище блобов Azure.
## azure_throw_on_zero_files_match {#azure_throw_on_zero_files_match} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Выдавать ошибку, если соответствуют нулю файлов в соответствии с правилами расширения glob.

Возможные значения:
- 1 — `SELECT` вызывает исключение.
- 0 — `SELECT` возвращает пустой результат.
## azure_truncate_on_insert {#azure_truncate_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает обрезку перед вставкой в таблицы Azure engine.
## azure_upload_part_size_multiply_factor {#azure_upload_part_size_multiply_factor} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`2`|

Умножьте azure_min_upload_part_size на этот коэффициент каждый раз, когда azure_multiply_parts_count_threshold части были загружены из одной записи в хранилище блобов Azure.
## azure_upload_part_size_multiply_parts_count_threshold {#azure_upload_part_size_multiply_parts_count_threshold} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`500`|

Каждый раз, когда это количество частей загружается в хранилище блобов Azure, azure_min_upload_part_size умножается на azure_upload_part_size_multiply_factor.
## backup_restore_batch_size_for_keeper_multi {#backup_restore_batch_size_for_keeper_multi} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Максимальный размер партии для много запросов к [Zoo]Keeper во время резервного копирования или восстановления.
## backup_restore_batch_size_for_keeper_multiread {#backup_restore_batch_size_for_keeper_multiread} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10000`|

Максимальный размер партии для многочтений запроса к [Zoo]Keeper во время резервного копирования или восстановления.
## backup_restore_failure_after_host_disconnected_for_seconds {#backup_restore_failure_after_host_disconnected_for_seconds} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3600`|

Если хост во время операции BACKUP ON CLUSTER или RESTORE ON CLUSTER не восстанавливает свой эпhemerный узел 'alive' в ZooKeeper в течение этого времени, то вся операция резервного копирования или восстановления считается неудачной.
Это значение должно быть больше любого разумного времени для хоста, чтобы повторно подключиться к ZooKeeper после сбоя.
Ноль означает неограниченное.
## backup_restore_finish_timeout_after_error_sec {#backup_restore_finish_timeout_after_error_sec} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`180`|

Как долго инициатор должен ждать, чтобы другие хосты отреагировали на узел 'error' и остановили свою работу над текущей операцией BACKUP ON CLUSTER или RESTORE ON CLUSTER.
## backup_restore_keeper_fault_injection_probability {#backup_restore_keeper_fault_injection_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Приблизительная вероятность сбоя для запроса Keeper во время резервного копирования или восстановления. Допустимое значение находится в интервале [0.0f, 1.0f].
## backup_restore_keeper_fault_injection_seed {#backup_restore_keeper_fault_injection_seed} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

0 - случайное начальное значение, иначе значение настройки.
## backup_restore_keeper_max_retries {#backup_restore_keeper_max_retries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Максимальное количество повторных попыток для операций с [Zoo]Keeper в процессе операции BACKUP или RESTORE.
Должно быть достаточно большим, чтобы вся операция не завершилась неудачей из-за временной ошибки [Zoo]Keeper.
## backup_restore_keeper_max_retries_while_handling_error {#backup_restore_keeper_max_retries_while_handling_error} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`20`|

Максимальное количество повторных попыток для операций с [Zoo]Keeper во время обработки ошибки операции BACKUP ON CLUSTER или RESTORE ON CLUSTER.
## backup_restore_keeper_max_retries_while_initializing {#backup_restore_keeper_max_retries_while_initializing} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`20`|

Максимальное количество повторных попыток для операций с [Zoo]Keeper во время инициализации операции BACKUP ON CLUSTER или RESTORE ON CLUSTER.
## backup_restore_keeper_retry_initial_backoff_ms {#backup_restore_keeper_retry_initial_backoff_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100`|

Начальный таймаут ожидания для операций с [Zoo]Keeper во время резервного копирования или восстановления.
## backup_restore_keeper_retry_max_backoff_ms {#backup_restore_keeper_retry_max_backoff_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5000`|

Максимальный таймаут ожидания для операций с [Zoo]Keeper во время резервного копирования или восстановления.
## backup_restore_keeper_value_max_size {#backup_restore_keeper_value_max_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1048576`|

Максимальный размер данных узла [Zoo]Keeper во время резервного копирования.
## backup_restore_s3_retry_attempts {#backup_restore_s3_retry_attempts} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Настройка для Aws::Client::RetryStrategy, Aws::Client выполняет повторные попытки сам, 0 означает отсутствие повторных попыток. Это происходит только для резервного копирования/восстановления.
## cache_warmer_threads {#cache_warmer_threads} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`4`|

Имеет эффект только в ClickHouse Cloud. Количество фоновых потоков для спекулятивной загрузки новых частей данных в кеш файла, когда [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch) включен. Ноль для отключения.
## calculate_text_stack_trace {#calculate_text_stack_trace} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Вычислить текстовый стек трассировки в случае исключений во время выполнения запроса. Это значение по умолчанию. Требует поиска символов, что может замедлить тесты на неудачи, когда выполняется большое количество неверных запросов. В обычных случаях вы не должны отключать эту опцию.
## cancel_http_readonly_queries_on_client_close {#cancel_http_readonly_queries_on_client_close} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Отменяет HTTP-запросы только для чтения (например, SELECT), когда клиент закрывает соединение, не дожидаясь ответа.

Значение по умолчанию в облаке: `1`.
## cast_ipv4_ipv6_default_on_conversion_error {#cast_ipv4_ipv6_default_on_conversion_error} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Оператор CAST в IPv4, оператор CAST в IPV6, функции toIPv4, toIPv6 вернут значение по умолчанию вместо возникновения исключения при ошибке преобразования.
## cast_keep_nullable {#cast_keep_nullable} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает сохранение типа данных `Nullable` в операциях [CAST](/sql-reference/functions/type-conversion-functions#cast).

Когда настройка включена, а аргумент функции `CAST` является `Nullable`, результат также преобразуется в тип `Nullable`. Когда настройка отключена, результат всегда имеет именно указанный целевой тип.

Возможные значения:

- 0 — Результат `CAST` имеет точно указанный целевой тип.
- 1 — Если тип аргумента `Nullable`, результат `CAST` преобразуется в `Nullable(ЦелевойТипДанных)`.

**Примеры**

Следующий запрос приводит к получению результата с точно указанным целевым типом:

```sql
SET cast_keep_nullable = 0;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

Результат:

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Int32                                             │
└───┴───────────────────────────────────────────────────┘
```

Следующий запрос приводит к модификации типа в `Nullable`:

```sql
SET cast_keep_nullable = 1;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

Результат:

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Nullable(Int32)                                   │
└───┴───────────────────────────────────────────────────┘
```

**См. также**

- [CAST](/sql-reference/functions/type-conversion-functions#cast) функция.
## cast_string_to_dynamic_use_inference {#cast_string_to_dynamic_use_inference} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать вывод типов при преобразовании строки в динамический.
## check_query_single_value_result {#check_query_single_value_result} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Определяет уровень детализации результата запроса [CHECK TABLE](/sql-reference/statements/check-table) для движков семейства `MergeTree`.

Возможные значения:

- 0 — запрос показывает статус проверки для каждой отдельной части данных таблицы.
- 1 — запрос показывает общий статус проверки таблицы.
## check_referential_table_dependencies {#check_referential_table_dependencies} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Проверяет, что запрос DDL (например, DROP TABLE или RENAME) не нарушит референциальные зависимости.
## check_table_dependencies {#check_table_dependencies} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Проверяет, что запрос DDL (например, DROP TABLE или RENAME) не нарушит зависимости.
## checksum_on_read {#checksum_on_read} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Проверять контрольные суммы при чтении. Это включено по умолчанию и всегда должно быть включено в производственной среде. Пожалуйста, не ожидайте никаких преимуществ от отключения этой настройки. Она может использоваться только для экспериментов и бенчмарков. Настройка применима только для таблиц семейства `MergeTree`. Контрольные суммы всегда проверяются для других движков таблиц и при получении данных по сети.
## cloud_mode {#cloud_mode} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Облачный режим.
## cloud_mode_database_engine {#cloud_mode_database_engine} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1`|

Движок базы данных, разрешенный в облаке. 1 - переписать DDL для использования реплицированной базы данных, 2 - переписать DDL для использования совместной базы данных.
## cloud_mode_engine {#cloud_mode_engine} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1`|

Семейство движков, разрешенных в облаке.

- 0 - разрешить все
- 1 - переписать DDL для использования *ReplicatedMergeTree
- 2 - переписать DDL для использования SharedMergeTree
- 3 - переписать DDL для использования SharedMergeTree, кроме случаев, когда явно указан удаленный диск

UInt64 для минимизации публичной части.
## cluster_for_parallel_replicas {#cluster_for_parallel_replicas} 

<BetaBadge/>

Кластер для шардов, в котором находится текущий сервер.
## collect_hash_table_stats_during_aggregation {#collect_hash_table_stats_during_aggregation} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает сбор статистики хеш-таблицы для оптимизации распределения памяти.
## collect_hash_table_stats_during_joins {#collect_hash_table_stats_during_joins} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает сбор статистики хеш-таблицы для оптимизации распределения памяти.
## compatibility {#compatibility} 

Настройка `compatibility` заставляет ClickHouse использовать настройки по умолчанию предыдущей версии ClickHouse, где предыдущая версия указывается как настройка.

Если настройки установлены на нестандартные значения, то эти настройки учитываются (лишь настройки, которые не были изменены, подвержены влиянию настройки `compatibility`).

Эта настройка принимает номер версии ClickHouse в виде строки, например, `22.3`, `22.8`. Пустое значение означает, что эта настройка отключена.

По умолчанию отключена.

:::note
В ClickHouse Cloud настройка совместимости должна быть установлена поддержкой ClickHouse Cloud. Пожалуйста, [откройте заявку](https://clickhouse.cloud/support), чтобы это установить.
:::
## compatibility_ignore_auto_increment_in_create_table {#compatibility_ignore_auto_increment_in_create_table} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорировать ключевое слово AUTO_INCREMENT в объявлении колонки, если true, иначе вернуть ошибку. Упрощает миграцию с MySQL.
## compatibility_ignore_collation_in_create_table {#compatibility_ignore_collation_in_create_table} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Совместимость игнорирует сортировку при создании таблицы.
## compile_aggregate_expressions {#compile_aggregate_expressions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает JIT-компиляцию агрегатных функций в нативный код. Включение этой настройки может улучшить производительность.

Возможные значения:

- 0 — Агрегация осуществляется без JIT-компиляции.
- 1 — Агрегация осуществляется с JIT-компиляцией.

**См. Также**

- [min_count_to_compile_aggregate_expression](#min_count_to_compile_aggregate_expression)
## compile_expressions {#compile_expressions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Компилировать некоторые скалярные функции и операторы в нативный код. Из-за ошибки в инфраструктуре компилятора LLVM на машинах AArch64 известно, что это может привести к разыменованию nullptr и, следовательно, к сбою сервера. Не включайте эту настройку.
## compile_sort_description {#compile_sort_description} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Компилировать описание сортировки в нативный код.
## connect_timeout {#connect_timeout} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`10`|

Таймаут подключения, если реплики отсутствуют.
## connect_timeout_with_failover_ms {#connect_timeout_with_failover_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`1000`|

Таймаут в миллисекундах для подключения к удаленному серверу для распределенного движка таблиц, если в определении кластера используются секции 'shard' и 'replica'.
Если неудачно, производится несколько попыток подключения к различным репликам.
## connect_timeout_with_failover_secure_ms {#connect_timeout_with_failover_secure_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`1000`|

Таймаут подключения для выбора первой здоровой реплики (для защищенных соединений).
## connection_pool_max_wait_ms {#connection_pool_max_wait_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`0`|

Время ожидания в миллисекундах для подключения, когда пул подключений полон.

Возможные значения:

- Положительное целое число.
- 0 — Неограниченный таймаут.
## connections_with_failover_max_tries {#connections_with_failover_max_tries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3`|

Максимальное количество попыток подключения к каждой реплике для распределенного движка таблиц.
## convert_query_to_cnf {#convert_query_to_cnf} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

При установке в `true` запрос `SELECT` будет преобразован в конъюнктивную нормальную форму (CNF). Есть сценарии, когда переписывание запроса в CNF может выполняться быстрее (просмотрите [проблему на Github](https://github.com/ClickHouse/ClickHouse/issues/11749) для объяснения).

Например, обратите внимание, что следующий запрос `SELECT` не модифицируется (поведение по умолчанию):

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = false;
```

Результат:

```response
┌─explain────────────────────────────────────────────────────────┐
│ SELECT x                                                       │
│ FROM                                                           │
│ (                                                              │
│     SELECT number AS x                                         │
│     FROM numbers(20)                                           │
│     WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15)) │
│ ) AS a                                                         │
│ WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))     │
│ SETTINGS convert_query_to_cnf = 0                              │
└────────────────────────────────────────────────────────────────┘
```

Давайте установим `convert_query_to_cnf` в `true` и посмотрим, что изменится:

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = true;
```

Обратите внимание, что условие `WHERE` переписывается в CNF, но результирующий набор одинаков - логика булевых выражений не изменилась:

```response
┌─explain───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SELECT x                                                                                                              │
│ FROM                                                                                                                  │
│ (                                                                                                                     │
│     SELECT number AS x                                                                                                │
│     FROM numbers(20)                                                                                                  │
│     WHERE ((x <= 15) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x >= 10) OR (x >= 1)) │
│ ) AS a                                                                                                                │
│ WHERE ((x >= 10) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x <= 15) OR (x <= 5))     │
│ SETTINGS convert_query_to_cnf = 1                                                                                     │
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

Возможные значения: true, false.
## count_distinct_implementation {#count_distinct_implementation} 

|Тип|По умолчанию|
|---|---|
|`String`|`uniqExact`|

Указывает, какая из функций `uniq*` должна использоваться для выполнения конструкции [COUNT(DISTINCT ...)](/sql-reference/aggregate-functions/reference/count).

Возможные значения:

- [uniq](/sql-reference/aggregate-functions/reference/uniq)
- [uniqCombined](/sql-reference/aggregate-functions/reference/uniqcombined)
- [uniqCombined64](/sql-reference/aggregate-functions/reference/uniqcombined64)
- [uniqHLL12](/sql-reference/aggregate-functions/reference/uniqhll12)
- [uniqExact](/sql-reference/aggregate-functions/reference/uniqexact).
## count_distinct_optimization {#count_distinct_optimization} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Переписывать count distinct в подзапрос группировки.
## create_if_not_exists {#create_if_not_exists} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить `IF NOT EXISTS` для оператора `CREATE` по умолчанию. Если эта настройка или `IF NOT EXISTS` указаны, и таблица с указанным именем уже существует, исключение не будет выдано.
## create_index_ignore_unique {#create_index_ignore_unique} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорировать уникальные ключевые слова в CREATE UNIQUE INDEX. Сделано для тестов на совместимость SQL.
## create_replicated_merge_tree_fault_injection_probability {#create_replicated_merge_tree_fault_injection_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Вероятность инъекции сбоя при создании таблицы после создания метаданных в ZooKeeper.
## create_table_empty_primary_key_by_default {#create_table_empty_primary_key_by_default} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Позволяет создавать таблицы *MergeTree с пустым первичным ключом, когда ORDER BY и PRIMARY KEY не указаны.
## cross_join_min_bytes_to_compress {#cross_join_min_bytes_to_compress} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1073741824`|

Минимальный размер блока для сжатия в CROSS JOIN. Нулевое значение означает - отключить этот порог. Этот блок сжимается, когда достигается любой из двух порогов (по строкам или по байтам).
## cross_join_min_rows_to_compress {#cross_join_min_rows_to_compress} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10000000`|

Минимальное количество строк для сжатия блока в CROSS JOIN. Нулевое значение означает - отключить этот порог. Этот блок сжимается, когда достигается любой из двух порогов (по строкам или по байтам).
## data_type_default_nullable {#data_type_default_nullable} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Позволяет типам данных без явных модификаторов [NULL или NOT NULL](/sql-reference/statements/create/table#null-or-not-null-modifiers) в определении колонки быть [Nullable](/sql-reference/data-types/nullable).

Возможные значения:

- 1 — Типы данных в определениях колонок по умолчанию устанавливаются в `Nullable`.
- 0 — Типы данных в определениях колонок по умолчанию устанавливаются как не `Nullable`.
## database_atomic_wait_for_drop_and_detach_synchronously {#database_atomic_wait_for_drop_and_detach_synchronously} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Добавляет модификатор `SYNC` ко всем запросам `DROP` и `DETACH`.

Возможные значения:

- 0 — Запросы выполняются с задержкой.
- 1 — Запросы выполняются без задержки.
## database_replicated_allow_explicit_uuid {#database_replicated_allow_explicit_uuid} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

0 - Не разрешать явно указывать UUID для таблиц в реплицированных базах данных. 1 - Разрешить. 2 - Разрешить, но игнорировать указанный UUID и генерировать случайный взамен.
## database_replicated_allow_heavy_create {#database_replicated_allow_heavy_create} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить выполнение долгосрочных DDL-запросов (CREATE AS SELECT и POPULATE) в реплицированном движке базы данных. Обратите внимание, что это может блокировать очередь DDL на длительное время.
## database_replicated_allow_only_replicated_engine {#database_replicated_allow_only_replicated_engine} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить создавать только реплицированные таблицы в базе данных с движком `Replicated`.
## database_replicated_allow_replicated_engine_arguments {#database_replicated_allow_replicated_engine_arguments} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

0 - Не разрешать явно указывать путь ZooKeeper и имя реплики для таблиц *MergeTree в реплицированных базах данных. 1 - Разрешить. 2 - Разрешить, но игнорировать указанный путь и использовать вместо него путь по умолчанию. 3 - Разрешить и не записывать предупреждение в журнал.
## database_replicated_always_detach_permanently {#database_replicated_always_detach_permanently} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Выполнять DETACH TABLE как DETACH TABLE PERMANENTLY, если движок базы данных `Replicated`.
## database_replicated_enforce_synchronous_settings {#database_replicated_enforce_synchronous_settings} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Принуждает синхронное ожидание для некоторых запросов (см. также database_atomic_wait_for_drop_and_detach_synchronously, mutations_sync, alter_sync). Не рекомендуется включать эти настройки.
## database_replicated_initial_query_timeout_sec {#database_replicated_initial_query_timeout_sec} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`300`|

Устанавливает, как долго начальный DDL запрос должен ждать, пока реплицированная база данных обработает предыдущие записи очереди DDL в секундах.

Возможные значения:

- Положительное целое число.
- 0 — Неограниченно.
## decimal_check_overflow {#decimal_check_overflow} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Проверять переполнение при арфметических/сравнительных операциях с десятичными значениями.
## deduplicate_blocks_in_dependent_materialized_views {#deduplicate_blocks_in_dependent_materialized_views} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает проверку дедупликации для материализованных представлений, которые получают данные из таблиц `Replicated*`.

Возможные значения:

      0 — Отключено.
      1 — Включено.

Использование

По умолчанию дедупликация не выполняется для материализованных представлений, а производится в источнике, в основной таблице.
Если вставленный блок пропускается из-за дедупликации в основной таблице, то вставка в прикрепленные материализованные представления не произойдет. Это поведение существует, чтобы позволить вставку высоко агрегированных данных в материализованные представления, для случаев, когда вставленные блоки одинаковы после агрегации материализованного представления, но происходят из разных вставок в основную таблицу.
В то же время это поведение "ломает" идемпотентность `INSERT`. Если вставка в основную таблицу прошла успешно, а вставка в материализованное представление не удалась (например, из-за сбоя связи с ClickHouse Keeper), клиент получит ошибку и может повторить операцию. Однако материализованное представление не получит вторую вставку, потому что она будет отброшена дедупликацией в основной (исходной) таблице. Настройка `deduplicate_blocks_in_dependent_materialized_views` позволяет изменить это поведение. При повторной попытке материализованное представление получит повторную вставку и проверит дедупликацию самостоятельно, игнорируя результат проверки для основной таблицы, и вставит строки, потерянные из-за первой ошибки.
## default_materialized_view_sql_security {#default_materialized_view_sql_security} 

|Тип|По умолчанию|
|---|---|
|`SQLSecurityType`|`DEFINER`|

Позволяет установить значение по умолчанию для опции SQL SECURITY при создании материализованного представления. [Дополнительная информация о SQL безопасности](../../sql-reference/statements/create/view.md/#sql_security).

Значение по умолчанию: `DEFINER`.

## default_max_bytes_in_join {#default_max_bytes_in_join} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000000`|

Максимальный размер таблицы правой стороны, если ограничение требуется, но `max_bytes_in_join` не установлено.

## default_normal_view_sql_security {#default_normal_view_sql_security} 

|Тип|По умолчанию|
|---|---|
|`SQLSecurityType`|`INVOKER`|

Позволяет установить значение по умолчанию для опции `SQL SECURITY` при создании обычного представления. [Дополнительная информация о SQL безопасности](../../sql-reference/statements/create/view.md/#sql_security).

Значение по умолчанию: `INVOKER`.

## default_table_engine {#default_table_engine} 

|Тип|По умолчанию|
|---|---|
|`DefaultTableEngine`|`MergeTree`|

Движок таблиц по умолчанию, используемый при отсутствии `ENGINE` в операторе `CREATE`.

Возможные значения:

- строка, представляющая любое допустимое имя движка таблицы

Значение по умолчанию в облаке: `SharedMergeTree`.

**Пример**

Запрос:

```sql
SET default_table_engine = 'Log';

SELECT name, value, changed FROM system.settings WHERE name = 'default_table_engine';
```

Результат:

```response
┌─name─────────────────┬─value─┬─changed─┐
│ default_table_engine │ Log   │       1 │
└──────────────────────┴───────┴─────────┘
```

В этом примере любая новая таблица, которая не указывает `Engine`, будет использовать движок таблицы `Log`:

Запрос:

```sql
CREATE TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TABLE my_table;
```

Результат:

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```

## default_temporary_table_engine {#default_temporary_table_engine} 

|Тип|По умолчанию|
|---|---|
|`DefaultTableEngine`|`Memory`|

То же, что и [default_table_engine](#default_table_engine), но для временных таблиц.

В этом примере любая новая временная таблица, которая не указывает `Engine`, будет использовать движок таблицы `Log`:

Запрос:

```sql
SET default_temporary_table_engine = 'Log';

CREATE TEMPORARY TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TEMPORARY TABLE my_table;
```

Результат:

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TEMPORARY TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```

## default_view_definer {#default_view_definer} 

|Тип|По умолчанию|
|---|---|
|`String`|`CURRENT_USER`|

Позволяет установить значение по умолчанию для опции `DEFINER` при создании представления. [Дополнительная информация о SQL безопасности](../../sql-reference/statements/create/view.md/#sql_security).

Значение по умолчанию: `CURRENT_USER`.

## describe_compact_output {#describe_compact_output} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если true, включает только имена колонок и типы в результат запроса DESCRIBE.

## describe_extend_object_types {#describe_extend_object_types} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Определяет конкретный тип столбцов типа Object в запросе DESCRIBE.

## describe_include_subcolumns {#describe_include_subcolumns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает описание субколонок для запроса [DESCRIBE](../../sql-reference/statements/describe-table.md). Например, элементы [Tuple](../../sql-reference/data-types/tuple.md) или субколонки типа [Map](/sql-reference/data-types/map#reading-subcolumns-of-map), [Nullable](../../sql-reference/data-types/nullable.md/#finding-null) или [Array](../../sql-reference/data-types/array.md/#array-size).

Возможные значения:

- 0 — Субколонки не включены в запросы `DESCRIBE`.
- 1 — Субколонки включены в запросы `DESCRIBE`.

**Пример**

Смотрите пример для оператора [DESCRIBE](../../sql-reference/statements/describe-table.md).

## describe_include_virtual_columns {#describe_include_virtual_columns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если true, виртуальные колонки таблицы будут включены в результат запроса DESCRIBE.

## dialect {#dialect} 

|Тип|По умолчанию|
|---|---|
|`Dialect`|`clickhouse`|

Какой диалект будет использоваться для разбора запроса.

## dictionary_validate_primary_key_type {#dictionary_validate_primary_key_type} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Проверяет тип первичного ключа для словарей. По умолчанию тип id для простых макетов будет неявно преобразован в UInt64.

## distinct_overflow_mode {#distinct_overflow_mode} 

|Тип|По умолчанию|
|---|---|
|`OverflowMode`|`throw`|

Определяет, что происходит, когда количество данных превышает один из лимитов.

Возможные значения:
- `throw`: выбросить исключение (по умолчанию).
- `break`: остановить выполнение запроса и вернуть частичный результат, как будто исходные данные закончились.

## distributed_aggregation_memory_efficient {#distributed_aggregation_memory_efficient} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включен ли режим экономии памяти распределенной агрегации.

## distributed_background_insert_batch {#distributed_background_insert_batch} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает/выключает отправку вставленных данных пакетами.

Когда отправка пакетами включена, движок таблиц [Distributed](../../engines/table-engines/special/distributed.md) пытается отправить несколько файлов вставленных данных за одну операцию вместо того, чтобы отправлять их по отдельности. Пакетная отправка улучшает работу кластера за счет более эффективного использования ресурсов сервера и сети.

Возможные значения:

- 1 — Включено.
- 0 — Выключено.

## distributed_background_insert_max_sleep_time_ms {#distributed_background_insert_max_sleep_time_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`30000`|

Максимальный интервал для движка таблиц [Distributed](../../engines/table-engines/special/distributed.md) для отправки данных. Ограничивает экспоненциальный рост интервала, установленного в настройке [distributed_background_insert_sleep_time_ms](#distributed_background_insert_sleep_time_ms).

Возможные значения:

- Положительное целое число миллисекунд.

## distributed_background_insert_sleep_time_ms {#distributed_background_insert_sleep_time_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`100`|

Базовый интервал для движка таблиц [Distributed](../../engines/table-engines/special/distributed.md) для отправки данных. Фактический интервал увеличивается экспоненциально в случае ошибок.

Возможные значения:

- Положительное целое число миллисекунд.

## distributed_background_insert_split_batch_on_failure {#distributed_background_insert_split_batch_on_failure} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает/выключает разделение пакетов при ошибках.

Иногда отправка конкретного пакета на удаленный шард может завершиться неудачей из-за сложного конвейера после (например, `MATERIALIZED VIEW` с `GROUP BY`) из-за `Memory limit exceeded` или подобных ошибок. В этом случае повторная попытка не поможет (и это заблокирует распределенные отправки для таблицы), но отправка файлов из этого пакета по одному может привести к успешной вставке.

Поэтому установка этой настройки в `1` отключит пакетирование для таких пакетов (например, временно отключит `distributed_background_insert_batch` для неудачных пакетов).

Возможные значения:

- 1 — Включено.
- 0 — Выключено.

:::note
Эта настройка также влияет на поврежденные пакеты (которые могут появиться из-за ненормального завершения работы сервера (машины) и отсутствия `fsync_after_insert`/`fsync_directories` для движка таблиц [Distributed](../../engines/table-engines/special/distributed.md)).
:::

:::note
Не следует полагаться на автоматическое разделение пакетов, так как это может негативно сказаться на производительности.
:::

## distributed_background_insert_timeout {#distributed_background_insert_timeout} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Таймаут для запроса вставки в распределенный. Настройка используется только с включенным insert_distributed_sync. Нулевое значение означает отсутствие таймаута.

## distributed_cache_bypass_connection_pool {#distributed_cache_bypass_connection_pool} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Имеет эффекты только в ClickHouse Cloud. Позволяет обойти пул соединений распределенного кэша.

## distributed_cache_connect_max_tries {#distributed_cache_connect_max_tries} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`20`|

Имеет эффекты только в ClickHouse Cloud. Количество попыток подключения к распределенному кэшу в случае неудачи.

## distributed_cache_data_packet_ack_window {#distributed_cache_data_packet_ack_window} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5`|

Имеет эффекты только в ClickHouse Cloud. Окно для отправки ACK для последовательности DataPacket в одном запросе чтения с распределенного кэша.

## distributed_cache_discard_connection_if_unread_data {#distributed_cache_discard_connection_if_unread_data} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Имеет эффекты только в ClickHouse Cloud. Отбросить соединение, если есть необработанные данные.

## distributed_cache_fetch_metrics_only_from_current_az {#distributed_cache_fetch_metrics_only_from_current_az} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Имеет эффекты только в ClickHouse Cloud. Получать метрики только из текущей зоны доступности в system.distributed_cache_metrics, system.distributed_cache_events.

## distributed_cache_log_mode {#distributed_cache_log_mode} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`DistributedCacheLogMode`|`on_error`|

Имеет эффекты только в ClickHouse Cloud. Режим записи в system.distributed_cache_log.

## distributed_cache_max_unacked_inflight_packets {#distributed_cache_max_unacked_inflight_packets} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10`|

Имеет эффекты только в ClickHouse Cloud. Максимальное количество неподтвержденных в пути пакетов в одном запросе чтения с распределенного кэша.

## distributed_cache_min_bytes_for_seek {#distributed_cache_min_bytes_for_seek} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Имеет эффекты только в ClickHouse Cloud. Минимальное количество байт для осуществления поиска в распределенном кэше.

## distributed_cache_pool_behaviour_on_limit {#distributed_cache_pool_behaviour_on_limit} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`DistributedCachePoolBehaviourOnLimit`|`wait`|

Имеет эффекты только в ClickHouse Cloud. Определяет поведение соединения кэширования при достижении лимита пула.

## distributed_cache_read_alignment {#distributed_cache_read_alignment} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Имеет эффекты только в ClickHouse Cloud. Настройка для тестовых целей, не изменяйте ее.

## distributed_cache_receive_response_wait_milliseconds {#distributed_cache_receive_response_wait_milliseconds} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`60000`|

Имеет эффекты только в ClickHouse Cloud. Время ожидания в миллисекундах для получения данных по запросу из распределенного кэша.

## distributed_cache_receive_timeout_milliseconds {#distributed_cache_receive_timeout_milliseconds} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10000`|

Имеет эффекты только в ClickHouse Cloud. Время ожидания в миллисекундах для получения ответа любого вида из распределенного кэша.

## distributed_cache_throw_on_error {#distributed_cache_throw_on_error} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Имеет эффекты только в ClickHouse Cloud. Повторный выброс исключения, произошедшего во время общения с распределенным кэшем, или исключения, полученного от распределенного кэша. В противном случае возврат к пропуску распределенного кэша в случае ошибки.

## distributed_cache_wait_connection_from_pool_milliseconds {#distributed_cache_wait_connection_from_pool_milliseconds} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100`|

Имеет эффекты только в ClickHouse Cloud. Время ожидания в миллисекундах для получения соединения из пула соединений, если distributed_cache_pool_behaviour_on_limit выставлен на wait.

## distributed_connections_pool_size {#distributed_connections_pool_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1024`|

Максимальное количество одновременно открытых соединений с удаленными серверами для распределенной обработки всех запросов к одной таблице Distributed. Рекомендуется устанавливать значение не ниже количества серверов в кластере.

## distributed_ddl_entry_format_version {#distributed_ddl_entry_format_version} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5`|

Версия совместимости распределенных DDL (ON CLUSTER) запросов.

## distributed_ddl_output_mode {#distributed_ddl_output_mode} 

|Тип|По умолчанию|
|---|---|
|`DistributedDDLOutputMode`|`throw`|

Устанавливает формат результата запроса распределенного DDL.

Возможные значения:

- `throw` — Возвращает набор результатов с состоянием выполнения запроса для всех хостов, где запрос завершен. Если запрос не удался на некоторых хостах, будет повторно выброшено первое исключение. Если запрос не завершен еще на некоторых хостах и превышен [distributed_ddl_task_timeout](#distributed_ddl_task_timeout), будет выброшено исключение `TIMEOUT_EXCEEDED`.
- `none` — Аналогично throw, но запрос распределенного DDL не возвращает набор результатов.
- `null_status_on_timeout` — Возвращает `NULL` в качестве статуса выполнения в некоторых строках набора результатов вместо выброса `TIMEOUT_EXCEEDED`, если запрос не завершен на соответствующих хостах.
- `never_throw` — Не выбрасывать `TIMEOUT_EXCEEDED` и не повторно выбрасывать исключения, если запрос не удался на некоторых хостах.
- `none_only_active` - аналогично `none`, но не дожидается неактивных реплик базы данных `Replicated`. Примечание: с этим режимом невозможно понять, что запрос не был выполнен на некоторой реплике и будет выполнен в фоновом режиме.
- `null_status_on_timeout_only_active` — аналогично `null_status_on_timeout`, но не дожидается неактивных реплик базы данных `Replicated`.
- `throw_only_active` — аналогично `throw`, но не дожидается неактивных реплик базы данных `Replicated`.

Значение по умолчанию в облаке: `none`.

## distributed_ddl_task_timeout {#distributed_ddl_task_timeout} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`180`|

Устанавливает таймаут для ответов DDL запросов от всех хостов в кластере. Если DDL запрос не был выполнен на всех хостах, ответ будет содержать ошибку таймаута и запрос будет выполнен в асинхронном режиме. Отрицательное значение означает бесконечный таймаут.

Возможные значения:

- Положительное целое число.
- 0 — асинхронный режим.
- Отрицательное целое число — бесконечный таймаут.

## distributed_foreground_insert {#distributed_foreground_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или выключает синхронную вставку данных в таблицу [Distributed](/engines/table-engines/special/distributed).

По умолчанию, при вставке данных в таблицу `Distributed`, сервер ClickHouse отправляет данные на узлы кластера в фоновом режиме. Когда `distributed_foreground_insert=1`, данные обрабатываются синхронно, и операция `INSERT` завершается успешно только после того, как все данные сохранены на всех шардах (по крайней мере, одна реплика для каждого шард, если `internal_replication` равно true).

Возможные значения:

- 0 — Данные вставляются в фоновом режиме.
- 1 — Данные вставляются в синхронном режиме.

Значение по умолчанию в облаке: `1`.

**Смотрите также**

- [Движок Таблицы Distributed](/engines/table-engines/special/distributed)
- [Управление распределенными таблицами](/sql-reference/statements/system#managing-distributed-tables)

## distributed_group_by_no_merge {#distributed_group_by_no_merge} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Не объединять состояния агрегации с разных серверов для распределенной обработки запросов, можно использовать в случае, если точно известно, что на разных шардах находятся разные ключи.

Возможные значения:

- `0` — Отключено (финальная обработка запроса выполняется на узле-инициаторе).
- `1` - Не объединять состояния агрегации с разных серверов для распределенной обработки запросов (запрос полностью обрабатывается на шарде, инициатор только проксирует данные), можно использовать в случае, если точно известно, что на разных шардах находятся разные ключи.
- `2` - То же, что и `1`, но применяется `ORDER BY` и `LIMIT` (это невозможно, когда запрос полностью обрабатывается на удаленном узле, например, для `distributed_group_by_no_merge=1`) на инициаторе (можно использовать для запросов с `ORDER BY` и/или `LIMIT`).

**Пример**

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 1
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
│     0 │
└───────┘
```

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 2
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
└───────┘
```

## distributed_insert_skip_read_only_replicas {#distributed_insert_skip_read_only_replicas} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает пропуск реплик только для чтения для запросов INSERT в Distributed.

Возможные значения:

- 0 — INSERT выполняется как обычно, если он попадает на реплику только для чтения, он завершится с ошибкой.
- 1 — Инициатор пропустит реплики только для чтения перед отправкой данных на шарды.

## distributed_product_mode {#distributed_product_mode} 

|Тип|По умолчанию|
|---|---|
|`DistributedProductMode`|`deny`|

Изменяет поведение [распределенных подзапросов](../../sql-reference/operators/in.md).

ClickHouse применяет эту настройку, когда запрос содержит произведение распределенных таблиц, т.е. когда запрос для распределенной таблицы содержит подзапрос, который не является GLOBAL.

Ограничения:

- Применяется только для подзапросов IN и JOIN.
- Только если раздел FROM использует распределенную таблицу, содержащую более одного шарда.
- Если подзапрос касается распределенной таблицы, содержащей более одного шара.
- Не используется для функции, имеющей значение таблицы [remote](../../sql-reference/table-functions/remote.md).

Возможные значения:

- `deny` — Значение по умолчанию. Запрещает использование таких типов подзапросов (возвращает исключение "Double-distributed in/JOIN subqueries is denied").
- `local` — Заменяет базу данных и таблицу в подзапросе на локальные для целевого сервера (шара), оставляя обычные `IN`/`JOIN`.
- `global` — Заменяет запрос `IN`/`JOIN` на `GLOBAL IN`/`GLOBAL JOIN`.
- `allow` — Позволяет использование таких типов подзапросов.

## distributed_push_down_limit {#distributed_push_down_limit} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1`|

Включает или выключает применение [LIMIT](#limit) на каждом шарде отдельно.

Это позволит избежать:
- Отправки лишних строк по сети;
- Обработки строк превышающих лимит на инициаторе.

Начиная с версии 21.9 вы не сможете получить неточные результаты, так как `distributed_push_down_limit` изменяет выполнение запроса только в случае выполнения хотя бы одного из условий:
- [distributed_group_by_no_merge](#distributed_group_by_no_merge) > 0.
- Запрос **не имеет** `GROUP BY`/`DISTINCT`/`LIMIT BY`, но имеет `ORDER BY`/`LIMIT`.
- Запрос **имеет** `GROUP BY`/`DISTINCT`/`LIMIT BY` с `ORDER BY`/`LIMIT` и:
    - [optimize_skip_unused_shards](#optimize_skip_unused_shards) включен.
    - [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key) включен.

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

Смотрите также:

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)
- [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key)

## distributed_replica_error_cap {#distributed_replica_error_cap} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

- Тип: беззнаковое целое
- Значение по умолчанию: 1000

Количество ошибок каждой реплики ограничено этим значением, что предотвращает накопление слишком многих ошибок в одной реплике.

Смотрите также:

- [load_balancing](#load_balancing-round_robin)
- [Движок таблиц Distributed](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)

## distributed_replica_error_half_life {#distributed_replica_error_half_life} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`60`|

- Тип: секунды
- Значение по умолчанию: 60 секунд

Контролирует, как быстро ошибки в распределенных таблицах обнуляются. Если реплика недоступна в течение некоторого времени, накапливает 5 ошибок, и значение distributed_replica_error_half_life установлено на 1 секунду, тогда реплика считается нормальной через 3 секунды после последней ошибки.

Смотрите также:

- [load_balancing](#load_balancing-round_robin)
- [Движок таблиц Distributed](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)

## distributed_replica_max_ignored_errors {#distributed_replica_max_ignored_errors} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

- Тип: беззнаковое целое
- Значение по умолчанию: 0

Количество ошибок, которые будут проигнорированы при выборе реплик (в соответствии с алгоритмом `load_balancing`).

Смотрите также:

- [load_balancing](#load_balancing-round_robin)
- [Движок таблиц Distributed](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)

## do_not_merge_across_partitions_select_final {#do_not_merge_across_partitions_select_final} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Объединять части только в одной партиции в select final.

## empty_result_for_aggregation_by_constant_keys_on_empty_set {#empty_result_for_aggregation_by_constant_keys_on_empty_set} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Возвращает пустой результат при агрегации по постоянным ключам на пустом наборе.

## empty_result_for_aggregation_by_empty_set {#empty_result_for_aggregation_by_empty_set} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Возвращает пустой результат при агрегации без ключей на пустом наборе.

## enable_adaptive_memory_spill_scheduler {#enable_adaptive_memory_spill_scheduler} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Запускает процессор для адаптивного сброса данных во внешнее хранилище. В настоящее время поддерживается grace join.

## enable_blob_storage_log {#enable_blob_storage_log} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Записывает информацию о операциях блочного хранилища в таблицу system.blob_storage_log.

## enable_deflate_qpl_codec {#enable_deflate_qpl_codec} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если включено, можно использовать кодек DEFLATE_QPL для сжатия колонок.

## enable_early_constant_folding {#enable_early_constant_folding} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию запросов, где мы анализируем результаты функций и подзапросов и переписываем запрос, если там есть константы.

## enable_extended_results_for_datetime_functions {#enable_extended_results_for_datetime_functions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает возвращение результатов типа:
- `Date32` с расширенным диапазоном (по сравнению с типом `Date`) для функций [toStartOfYear](../../sql-reference/functions/date-time-functions.md/#tostartofyear), [toStartOfISOYear](../../sql-reference/functions/date-time-functions.md/#tostartofisoyear), [toStartOfQuarter](../../sql-reference/functions/date-time-functions.md/#tostartofquarter), [toStartOfMonth](../../sql-reference/functions/date-time-functions.md/#tostartofmonth), [toLastDayOfMonth](../../sql-reference/functions/date-time-functions.md/#tolastdayofmonth), [toStartOfWeek](../../sql-reference/functions/date-time-functions.md/#tostartofweek), [toLastDayOfWeek](../../sql-reference/functions/date-time-functions.md/#tolastdayofweek) и [toMonday](../../sql-reference/functions/date-time-functions.md/#tomonday).
- `DateTime64` с расширенным диапазоном (по сравнению с типом `DateTime`) для функций [toStartOfDay](../../sql-reference/functions/date-time-functions.md/#tostartofday), [toStartOfHour](../../sql-reference/functions/date-time-functions.md/#tostartofhour), [toStartOfMinute](../../sql-reference/functions/date-time-functions.md/#tostartofminute), [toStartOfFiveMinutes](../../sql-reference/functions/date-time-functions.md/#tostartoffiveminutes), [toStartOfTenMinutes](../../sql-reference/functions/date-time-functions.md/#tostartoftenminutes), [toStartOfFifteenMinutes](../../sql-reference/functions/date-time-functions.md/#tostartoffifteenminutes) и [timeSlot](../../sql-reference/functions/date-time-functions.md/#timeslot).

Возможные значения:

- 0 — Функции возвращают `Date` или `DateTime` для всех типов аргументов.
- 1 — Функции возвращают `Date32` или `DateTime64` для аргументов `Date32` или `DateTime64` и `Date` или `DateTime` в противном случае.

## enable_filesystem_cache {#enable_filesystem_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Используйте кэш для удаленной файловой системы. Эта настройка не включает/выключает кэш для дисков (это должно быть сделано через конфигурацию диска), но позволяет обойти кэш для некоторых запросов, если это необходимо.

## enable_filesystem_cache_log {#enable_filesystem_cache_log} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает записывать журнал кэширования файловой системы для каждого запроса.

## enable_filesystem_cache_on_write_operations {#enable_filesystem_cache_on_write_operations} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Запись в кэш при операциях записи. Для полноценной работы этой настройки необходимо также добавить её в конфигурацию диска.

## enable_filesystem_read_prefetches_log {#enable_filesystem_read_prefetches_log} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Запись в system.filesystem prefetch_log во время запроса. Следует использовать только для тестирования или отладки, не рекомендуется включать по умолчанию.

## enable_global_with_statement {#enable_global_with_statement} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Распространять операторы WITH на запросы UNION и все подзапросы.

## enable_hdfs_pread {#enable_hdfs_pread} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает операцию pread для файлов HDFS. По умолчанию используется `hdfsPread`. Если отключено, будут использоваться `hdfsRead` и `hdfsSeek` для чтения файлов hdfs.

## enable_http_compression {#enable_http_compression} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает сжатие данных в ответе на HTTP запрос.

Для получения дополнительной информации читайте [описание HTTP интерфейса](../../interfaces/http.md).

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

## enable_job_stack_trace {#enable_job_stack_trace} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Выводит трассировку стека создателя задания, когда задание приводит к исключению.

## enable_lightweight_delete {#enable_lightweight_delete} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает легковесные мутации удаления для таблиц mergetree.

## enable_memory_bound_merging_of_aggregation_results {#enable_memory_bound_merging_of_aggregation_results} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает стратегию слияния результатов агрегации с ограничением по памяти.

## enable_multiple_prewhere_read_steps {#enable_multiple_prewhere_read_steps} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Перемещает больше условий из WHERE в PREWHERE и выполняет чтение с диска и фильтрацию в нескольких этапах, если есть несколько условий, объединенных с AND.

## enable_named_columns_in_function_tuple {#enable_named_columns_in_function_tuple} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Генерирует именованные кортежи в функции tuple(), когда все имена уникальны и могут восприниматься как нецитируемые идентификаторы.

## enable_optimize_predicate_expression {#enable_optimize_predicate_expression} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает вытаскивание предикатов в запросах `SELECT`.

Вытаскивание предикатов может значительно снизить сетевой трафик для распределенных запросов.

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

Использование

Рассмотрите следующие запросы:

1.  `SELECT count() FROM test_table WHERE date = '2018-10-10'`
2.  `SELECT count() FROM (SELECT * FROM test_table) WHERE date = '2018-10-10'`

Если `enable_optimize_predicate_expression = 1`, то время выполнения этих запросов будет одинаковым, так как ClickHouse применяет `WHERE` к подзапросу во время его обработки.

Если `enable_optimize_predicate_expression = 0`, то время выполнения второго запроса будет значительно больше, поскольку условие `WHERE` применяется ко всем данным после завершения подзапроса.

## enable_optimize_predicate_expression_to_final_subquery {#enable_optimize_predicate_expression_to_final_subquery} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Позволяет проталкивать предикат к конечному подзапросу.

## enable_order_by_all {#enable_order_by_all} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает сортировку с синтаксисом `ORDER BY ALL`, см. [ORDER BY](../../sql-reference/statements/select/order-by.md).

Возможные значения:

- 0 — Отключить ORDER BY ALL.
- 1 — Включить ORDER BY ALL.

**Пример**

Запрос:

```sql
CREATE TABLE TAB(C1 Int, C2 Int, ALL Int) ENGINE=Memory();

INSERT INTO TAB VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM TAB ORDER BY ALL; -- возвращает ошибку, что ALL является неоднозначным

SELECT * FROM TAB ORDER BY ALL SETTINGS enable_order_by_all = 0;
```

Результат:

```text
┌─C1─┬─C2─┬─ALL─┐
│ 20 │ 20 │  10 │
│ 30 │ 10 │  20 │
│ 10 │ 20 │  30 │
└────┴─────┴───────┘
```

## enable_parsing_to_custom_serialization {#enable_parsing_to_custom_serialization} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если true, то данные могут быть разобраны непосредственно в колонки с пользовательским сериализацией (например, Sparse) в соответствии с подсказками для сериализации, полученными из таблицы.

## enable_positional_arguments {#enable_positional_arguments} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает поддержку позиционных аргументов для операторов [GROUP BY](/sql-reference/statements/select/group-by), [LIMIT BY](../../sql-reference/statements/select/limit-by.md), [ORDER BY](../../sql-reference/statements/select/order-by.md).

Возможные значения:

- 0 — Позиционные аргументы не поддерживаются.
- 1 — Позиционные аргументы поддерживаются: номера колонок могут использоваться вместо имен колонок.

**Пример**

Запрос:

```sql
CREATE TABLE positional_arguments(one Int, two Int, three Int) ENGINE=Memory();

INSERT INTO positional_arguments VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM positional_arguments ORDER BY 2,3;
```

Результат:

```text
┌─one─┬─two─┬─three─┐
│  30 │  10 │   20  │
│  20 │  20 │   10  │
│  10 │  20 │   30  │
└─────┴─────┴───────┘
```
## enable_reads_from_query_cache {#enable_reads_from_query_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если включено, результаты запросов `SELECT` извлекаются из [кэша запросов](../query-cache.md).

Возможные значения:

- 0 - Отключено
- 1 - Включено
## enable_s3_requests_logging {#enable_s3_requests_logging} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает очень явное логирование запросов к S3. Имеет смысл только для отладки.
## enable_scalar_subquery_optimization {#enable_scalar_subquery_optimization} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если установлено в true, предотвращает (де)сериализацию крупных скалярных значений в скалярных подзапросах и, возможно, избегает многократного выполнения одного и того же подзапроса.
## enable_sharing_sets_for_mutations {#enable_sharing_sets_for_mutations} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает совместное использование объектов набора, созданных для подзапросов IN, между различными задачами одной и той же мутации. Это снижает потребление памяти и использование CPU.
## enable_software_prefetch_in_aggregation {#enable_software_prefetch_in_aggregation} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает использование программного пре-fetch в агрегации.
## enable_unaligned_array_join {#enable_unaligned_array_join} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает ARRAY JOIN с несколькими массивами, которые имеют разные размеры. Когда эта настройка включена, массивы будут изменены по размеру к самому большому массиву.
## enable_url_encoding {#enable_url_encoding} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает включать/отключать декодирование/кодирование пути в uri в таблицах с движком [URL](../../engines/table-engines/special/url.md).

Включено по умолчанию.
## enable_vertical_final {#enable_vertical_final} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если включено, удаляет дублирующиеся строки во время FINAL, помечая строки как удаленные и фильтруя их позже вместо слияния строк.
## enable_writes_to_query_cache {#enable_writes_to_query_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если включено, результаты запросов `SELECT` сохраняются в [кэше запросов](../query-cache.md).

Возможные значения:

- 0 - Отключено
- 1 - Включено
## enable_zstd_qat_codec {#enable_zstd_qat_codec} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если включено, может использоваться кодек ZSTD_QAT для сжатия колонок.
## enforce_strict_identifier_format {#enforce_strict_identifier_format} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если включено, разрешены только идентификаторы, содержащие алфавитно-цифровые символы и символы подчеркивания.
## engine_file_allow_create_multiple_files {#engine_file_allow_create_multiple_files} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает создание нового файла при каждой вставке в таблицах с файловым движком, если формат имеет суффикс (`JSON`, `ORC`, `Parquet` и т.д.). Если включено, при каждой вставке будет создан новый файл с именем, следуя этому шаблону:

`data.Parquet` -> `data.1.Parquet` -> `data.2.Parquet`, и т.д.

Возможные значения:
- 0 — Запрос `INSERT` добавляет новые данные в конец файла.
- 1 — Запрос `INSERT` создает новый файл.
## engine_file_empty_if_not_exists {#engine_file_empty_if_not_exists} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает выбор данных из таблицы с файловым движком без файла.

Возможные значения:
- 0 — `SELECT` выдает исключение.
- 1 — `SELECT` возвращает пустой результат.
## engine_file_skip_empty_files {#engine_file_skip_empty_files} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает пропуск пустых файлов в таблицах с движком [File](../../engines/table-engines/special/file.md).

Возможные значения:
- 0 — `SELECT` выдает исключение, если пустой файл несовместим с запрашиваемым форматом.
- 1 — `SELECT` возвращает пустой результат для пустого файла.
## engine_file_truncate_on_insert {#engine_file_truncate_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает усечение перед вставкой в таблицах с движком [File](../../engines/table-engines/special/file.md).

Возможные значения:
- 0 — Запрос `INSERT` добавляет новые данные в конец файла.
- 1 — Запрос `INSERT` заменяет существующее содержание файла новыми данными.
## engine_url_skip_empty_files {#engine_url_skip_empty_files} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает пропуск пустых файлов в таблицах с движком [URL](../../engines/table-engines/special/url.md).

Возможные значения:
- 0 — `SELECT` выдает исключение, если пустой файл несовместим с запрашиваемым форматом.
- 1 — `SELECT` возвращает пустой результат для пустого файла.
## except_default_mode {#except_default_mode} 

|Тип|По умолчанию|
|---|---|
|`SetOperationMode`|`ALL`|

Устанавливает режим по умолчанию в запросе EXCEPT. Возможные значения: пустая строка, 'ALL', 'DISTINCT'. Если пусто, запрос без режима вызовет исключение.
## external_storage_connect_timeout_sec {#external_storage_connect_timeout_sec} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10`|

Тайм-аут соединения в секундах. В настоящее время поддерживается только для MySQL.
## external_storage_max_read_bytes {#external_storage_max_read_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Ограничивает максимальное количество байт, когда таблица с внешним движком должна сбросить данные истории. В настоящее время поддерживается только для движка таблиц MySQL, движка базы данных и словаря. Если равно 0, эта настройка отключена.
## external_storage_max_read_rows {#external_storage_max_read_rows} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Ограничивает максимальное количество строк, когда таблица с внешним движком должна сбросить данные истории. В настоящее время поддерживается только для движка таблиц MySQL, движка базы данных и словаря. Если равно 0, эта настройка отключена.
## external_storage_rw_timeout_sec {#external_storage_rw_timeout_sec} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`300`|

Тайм-аут чтения/записи в секундах. В настоящее время поддерживается только для MySQL.
## external_table_functions_use_nulls {#external_table_functions_use_nulls} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Определяет, как функции таблиц [mysql](../../sql-reference/table-functions/mysql.md), [postgresql](../../sql-reference/table-functions/postgresql.md) и [odbc](../../sql-reference/table-functions/odbc.md) используют Nullable колонки.

Возможные значения:

- 0 — Функция таблицы явно использует Nullable колонки.
- 1 — Функция таблицы неявно использует Nullable колонки.

**Использование**

Если настройка установлена в `0`, функция таблицы не создает Nullable колонки и вставляет значения по умолчанию вместо NULL. Это также применимо для значений NULL внутри массивов.
## external_table_strict_query {#external_table_strict_query} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если установлено true, преобразование выражения в локальный фильтр запрещено для запросов к внешним таблицам.
## extract_key_value_pairs_max_pairs_per_row {#extract_key_value_pairs_max_pairs_per_row} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Максимальное количество пар, которое может быть сгенерировано функцией `extractKeyValuePairs`. Используется как предосторожность против чрезмерного потребления памяти.
## extremes {#extremes} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Учитывать экстремальные значения (минимумы и максимумы в колонках результата запроса). Принимает 0 или 1. По умолчанию 0 (отключено).
Для получения дополнительной информации смотрите раздел "Экстремальные значения".
## fallback_to_stale_replicas_for_distributed_queries {#fallback_to_stale_replicas_for_distributed_queries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Принуждает запрос к устаревшей реплике, если обновленные данные недоступны. См. [Репликация](../../engines/table-engines/mergetree-family/replication.md).

ClickHouse выбирает наиболее актуальную из устаревших реплик таблицы.

Используется при выполнении `SELECT` из таблицы распределенной, указывающей на реплицированные таблицы.

По умолчанию 1 (включено).
## filesystem_cache_boundary_alignment {#filesystem_cache_boundary_alignment} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Выравнивание границ кэша файловой системы. Эта настройка применяется только к не-дисковым чтениям (например, для кэша удаленных движков таблиц / табличных функций, но не для конфигурации хранения таблиц MergeTree). Значение 0 означает отсутствие выравнивания.
## filesystem_cache_enable_background_download_during_fetch {#filesystem_cache_enable_background_download_during_fetch} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Имеет значение только в ClickHouse Cloud. Время ожидания для блокировки кэша для резервирования места в файловом кэше.
## filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage {#filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Имеет значение только в ClickHouse Cloud. Время ожидания для блокировки кэша для резервирования места в файловом кэше.
## filesystem_cache_max_download_size {#filesystem_cache_max_download_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`137438953472`|

Максимальный размер кэша удаленной файловой системы, который может быть загружен одним запросом.
## filesystem_cache_name {#filesystem_cache_name} 

Имя кэша файловой системы, которое следует использовать для статeless движков таблиц или озер данных.
## filesystem_cache_prefer_bigger_buffer_size {#filesystem_cache_prefer_bigger_buffer_size} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Предпочитайте больший размер буфера, если кэш файловой системы включен, чтобы избежать записи небольших сегментов файлов, что ухудшает производительность кэша. С другой стороны, включение этой настройки может увеличить потребление памяти.
## filesystem_cache_reserve_space_wait_lock_timeout_milliseconds {#filesystem_cache_reserve_space_wait_lock_timeout_milliseconds} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Время ожидания для блокировки кэша для резервирования места в файловом кэше.
## filesystem_cache_segments_batch_size {#filesystem_cache_segments_batch_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`20`|

Предельный размер отдельной партии сегментов файлов, которые буфер чтения может запросить из кэша. Слишком низкое значение приведет к чрезмерным запросам к кэшу, слишком большое может замедлить освобождение из кэша.
## filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit {#filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Пропустите загрузку с удаленной файловой системы, если превышен размер кэша запроса.
## filesystem_prefetch_max_memory_usage {#filesystem_prefetch_max_memory_usage} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1073741824`|

Максимальное использование памяти для предварительных загрузок.
## filesystem_prefetch_step_bytes {#filesystem_prefetch_step_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Шаг предварительной загрузки в байтах. Ноль означает `auto` — приблизительно лучший шаг предварительной загрузки будет автоматически определен, но может не быть на 100% лучшим. Фактическое значение может быть другим из-за настройки filesystem_prefetch_min_bytes_for_single_read_task.
## filesystem_prefetch_step_marks {#filesystem_prefetch_step_marks} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Шаг предварительной загрузки в метках. Ноль означает `auto` — приблизительно лучший шаг предварительной загрузки будет автоматически определен, но может не быть на 100% лучшим. Фактическое значение может быть другим из-за настройки filesystem_prefetch_min_bytes_for_single_read_task.
## filesystem_prefetches_limit {#filesystem_prefetches_limit} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`200`|

Максимальное количество предварительных загрузок. Ноль означает неограниченно. Рекомендуется установка `filesystem_prefetches_max_memory_usage`, если вы хотите ограничить количество предварительных загрузок.
## final {#final} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Автоматически применяет модификатор [FINAL](../../sql-reference/statements/select/from.md/#final-modifier) ко всем таблицам в запросе, к таблицам, где [FINAL](../../sql-reference/statements/select/from.md/#final-modifier) применим, включая объединенные таблицы и таблицы в подзапросах, и
распределенные таблицы.

Возможные значения:

- 0 - отключено
- 1 - включено

Пример:

```sql
CREATE TABLE test
(
    key Int64,
    some String
)
ENGINE = ReplacingMergeTree
ORDER BY key;

INSERT INTO test FORMAT Values (1, 'first');
INSERT INTO test FORMAT Values (1, 'second');

SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
┌─key─┬─some──┐
│   1 │ first │
└─────┴───────┘

SELECT * FROM test SETTINGS final = 1;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘

SET final = 1;
SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
```
## flatten_nested {#flatten_nested} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Устанавливает формат данных для колонок [nested](../../sql-reference/data-types/nested-data-structures/index.md).

Возможные значения:

- 1 — Вложенная колонка уплощается в отдельные массивы.
- 0 — Вложенная колонка остается единым массивом кортежей.

**Использование**

Если настройка установлена в `0`, возможно использование произвольного уровня вложенности.

**Примеры**

Запрос:

```sql
SET flatten_nested = 1;
CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

Результат:

```text
┌─statement───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n.a` Array(UInt32),
    `n.b` Array(UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

Запрос:

```sql
SET flatten_nested = 0;

CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

Результат:

```text
┌─statement──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n` Nested(a UInt32, b UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```
## force_aggregate_partitions_independently {#force_aggregate_partitions_independently} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Принуждает использование оптимизации, когда это применимо, но эвристика решила не использовать её.
## force_aggregation_in_order {#force_aggregation_in_order} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Эта настройка используется самим сервером для поддержки распределенных запросов. Не изменяйте её вручную, так как это приведет к нарушению нормальной работы. (Принуждает использование агрегации в порядке на удаленных узлах во время распределенной агрегации).
## force_data_skipping_indices {#force_data_skipping_indices} 

Отключает выполнение запроса, если переданные индексы пропуска данных не были использованы.

Рассмотрим следующий пример:

```sql
CREATE TABLE data
(
    key Int,
    d1 Int,
    d1_null Nullable(Int),
    INDEX d1_idx d1 TYPE minmax GRANULARITY 1,
    INDEX d1_null_idx assumeNotNull(d1_null) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

SELECT * FROM data_01515;
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices=''; -- запрос вызовет ошибку CANNOT_PARSE_TEXT.
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices='d1_idx'; -- запрос вызовет ошибку INDEX_NOT_USED.
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='d1_idx'; -- Ок.
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`'; -- Ок (пример полного парсера).
SELECT * FROM data_01515 WHERE d1 = 0 AND assumeNotNull(d1_null) = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- Ок.
```
## force_grouping_standard_compatibility {#force_grouping_standard_compatibility} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Заставляет функцию GROUPING возвращать 1, когда аргумент не используется в качестве ключа агрегации.
## force_index_by_date {#force_index_by_date} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Отключает выполнение запроса, если индекс не может быть использован по дате.

Работает с таблицами в семье MergeTree.

Если `force_index_by_date=1`, ClickHouse проверяет, есть ли в запросе условие по ключу даты, которое можно использовать для ограничения диапазонов данных. Если соответствующего условия нет, оно вызывает исключение. Однако оно не проверяет, сокращает ли условие объем данных, которые необходимо прочитать. Например, условие `Date != ' 2000-01-01 '` является допустимым, даже если оно соответствует всем данным в таблице (т.е. выполнение запроса требует полного сканирования). Для получения дополнительной информации о диапазонах данных в таблицах MergeTree см. [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md).
## force_optimize_projection {#force_optimize_projection} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает обязательное использование [проекций](../../engines/table-engines/mergetree-family/mergetree.md/#projections) в запросах `SELECT`, когда оптимизация проекций включена (см. настройку [optimize_use_projections](#optimize_use_projections)).

Возможные значения:

- 0 — Оптимизация проекций не обязательна.
- 1 — Оптимизация проекций обязательна.
## force_optimize_projection_name {#force_optimize_projection_name} 

Если установлено в непустую строку, проверьте, что эта проекция используется в запросе хотя бы один раз.

Возможные значения:

- строка: имя проекции, которая используется в запросе.
## force_optimize_skip_unused_shards {#force_optimize_skip_unused_shards} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Включает или отключает выполнение запроса, если [optimize_skip_unused_shards](#optimize_skip_unused_shards) включен и пропуск неиспользуемых шардов невозможен. Если пропуск невозможен и настройка включена, будет выброшено исключение.

Возможные значения:

- 0 — Отключено. ClickHouse не вызывает исключение.
- 1 — Включено. Выполнение запроса отключается только в том случае, если таблица имеет ключ шардирования.
- 2 — Включено. Выполнение запроса отключается независимо от того, определен ли ключ шардирования для таблицы.
## force_optimize_skip_unused_shards_nesting {#force_optimize_skip_unused_shards_nesting} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Управляет [`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards) (поэтому все еще требует [`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards)), в зависимости от уровня вложенности распределенного запроса (случай, когда у вас есть `Distributed` таблица, которая обращается к другой `Distributed` таблице).

Возможные значения:

- 0 - Отключено, `force_optimize_skip_unused_shards` всегда работает.
- 1 — Включает `force_optimize_skip_unused_shards` только для первого уровня.
- 2 — Включает `force_optimize_skip_unused_shards` до второго уровня.
## force_primary_key {#force_primary_key} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Отключает выполнение запроса, если индексирование по первичному ключу невозможно.

Работает с таблицами в семье MergeTree.

Если `force_primary_key=1`, ClickHouse проверяет, есть ли в запросе условие по первичному ключу, которое можно использовать для ограничения диапазонов данных. Если соответствующего условия нет, оно вызывает исключение. Однако оно не проверяет, сокращает ли условие объем данных, которые необходимо прочитать. Для получения дополнительной информации о диапазонах данных в таблицах MergeTree см. [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md).
## force_remove_data_recursively_on_drop {#force_remove_data_recursively_on_drop} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Рекурсивно удаляет данные при выполнении запроса DROP. Избегает ошибки 'Каталог не пуст', но может молча удалить открепленные данные.
## formatdatetime_f_prints_scale_number_of_digits {#formatdatetime_f_prints_scale_number_of_digits} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Форматировщик '%f' в функции 'formatDateTime' печатает только количество разрядов для масштабирования для DateTime64 вместо фиксированных 6 разрядов.
## formatdatetime_f_prints_single_zero {#formatdatetime_f_prints_single_zero} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Форматировщик '%f' в функции 'formatDateTime' печатает единственный ноль вместо шести нулей, если отформатированное значение не имеет дробных секунд.
## formatdatetime_format_without_leading_zeros {#formatdatetime_format_without_leading_zeros} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Форматировщики '%c', '%l' и '%k' в функции 'formatDateTime' печатают месяцы и часы без ведущих нулей.
## formatdatetime_parsedatetime_m_is_month_name {#formatdatetime_parsedatetime_m_is_month_name} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Форматировщик '%M' в функциях 'formatDateTime' и 'parseDateTime' печатает/парсит имя месяца вместо минут.
## fsync_metadata {#fsync_metadata} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает [fsync](http://pubs.opengroup.org/onlinepubs/9699919799/functions/fsync.html) при записи .sql файлов. Включено по умолчанию.

Имеет смысл отключить, если на сервере имеется миллионы маленьких таблиц, которые постоянно создаются и уничтожаются.
## function_implementation {#function_implementation} 

Выберите реализацию функции для конкретной цели или варианта (экспериментальный). Если пусто, включите все их.
## function_json_value_return_type_allow_complex {#function_json_value_return_type_allow_complex} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Управляет тем, разрешено ли возвращать сложный тип (например: структуру, массив, карту) для функции json_value.

```sql
SELECT JSON_VALUE('{"hello":{"world":"!"}}', '$.hello') settings function_json_value_return_type_allow_complex=true

┌─JSON_VALUE('{"hello":{"world":"!"}}', '$.hello')─┐
│ {"world":"!"}                                    │
└──────────────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

Возможные значения:

- true — Разрешить.
- false — Запретить.
## function_json_value_return_type_allow_nullable {#function_json_value_return_type_allow_nullable} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Контролирует, разрешено ли возвращать `NULL`, когда значение не существует для функции JSON_VALUE.

```sql
SELECT JSON_VALUE('{"hello":"world"}', '$.b') settings function_json_value_return_type_allow_nullable=true;

┌─JSON_VALUE('{"hello":"world"}', '$.b')─┐
│ ᴺᵁᴸᴸ                                   │
└────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

Возможные значения:

- true — Разрешить.
- false — Запретить.
## function_locate_has_mysql_compatible_argument_order {#function_locate_has_mysql_compatible_argument_order} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Контролирует порядок аргументов в функции [locate](../../sql-reference/functions/string-search-functions.md/#locate).

Возможные значения:

- 0 — Функция `locate` принимает аргументы `(haystack, needle[, start_pos])`.
- 1 — Функция `locate` принимает аргументы `(needle, haystack, [, start_pos])` (поведение, совместимое с MySQL).
## function_range_max_elements_in_block {#function_range_max_elements_in_block} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`500000000`|

Устанавливает предельное значение для объема данных, генерируемого функцией [range](/sql-reference/functions/array-functions#rangeend-rangestart--end--step). Определяет максимальное количество значений, создаваемых функцией на блок данных (сумма размеров массивов для каждой строки в блоке).

Возможные значения:

- Положительное целое число.

**См. также**

- [max_block_size](#max_block_size)
- [min_insert_block_size_rows](#min_insert_block_size_rows)
## function_sleep_max_microseconds_per_block {#function_sleep_max_microseconds_per_block} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3000000`|

Максимальное количество микросекунд, в течение которых функция `sleep` может спать для каждого блока. Если пользователь вызовет её с большим значением, будет выброшено исключение. Это предельное значение безопасности.
## function_visible_width_behavior {#function_visible_width_behavior} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1`|

Версия поведения `visibleWidth`. 0 - учитывает только количество кодовых точек; 1 - корректно считает символы с нулевой шириной и комбинирующими символами, считает полноширинные символы как два, оценивает ширину табуляции, считает символы удаления.
## geo_distance_returns_float64_on_float64_arguments {#geo_distance_returns_float64_on_float64_arguments} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если все четыре аргумента для функций `geoDistance`, `greatCircleDistance`, `greatCircleAngle` являются Float64, вернуть Float64 и использовать двойную точность для внутренних расчетов. В предыдущих версиях ClickHouse эти функции всегда возвращали Float32.
## glob_expansion_max_elements {#glob_expansion_max_elements} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Максимальное количество разрешенных адресов (Для внешних хранилищ, табличных функций и т.д.).
## grace_hash_join_initial_buckets {#grace_hash_join_initial_buckets} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`NonZeroUInt64`|`1`|

Начальное количество ведер для соединения grace hash.
## grace_hash_join_max_buckets {#grace_hash_join_max_buckets} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`NonZeroUInt64`|`1024`|

Предел по количеству ведер для соединения grace hash.
## group_by_overflow_mode {#group_by_overflow_mode} 

|Тип|По умолчанию|
|---|---|
|`OverflowModeGroupBy`|`throw`|

Устанавливает, что происходит, когда количество уникальных ключей для агрегации превышает предел:
- `throw`: выбросить исключение
- `break`: остановить выполнение запроса и вернуть частичный результат
- `any`: продолжить агрегацию для ключей, которые попали в набор, но не добавлять новые ключи в набор.

Использование значения 'any' позволяет вам выполнить приближение GROUP BY. Качество этого приближения зависит от статистической природы данных.
## group_by_two_level_threshold {#group_by_two_level_threshold} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100000`|

С какого количества ключей начинается агрегация двух уровней. 0 - порог не установлен.
## group_by_two_level_threshold_bytes {#group_by_two_level_threshold_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`50000000`|

С какого размера состояния агрегации в байтах начинается использование двух уровней агрегации. 0 - порог не установлен. Двухуровневая агрегация используется, когда хотя бы один из порогов срабатывает.
## group_by_use_nulls {#group_by_use_nulls} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Изменяет способ, которым [условие GROUP BY](/sql-reference/statements/select/group-by) обрабатывает типы ключей агрегации.
Когда используются спекifiers `ROLLUP`, `CUBE` или `GROUPING SETS`, некоторые ключи агрегации могут не использоваться для получения некоторых строк результата.
Столбцы для этих ключей заполняются либо значением по умолчанию, либо `NULL` в соответствующих строках в зависимости от этой настройки.

Возможные значения:

- 0 — Значение по умолчанию для типа ключа агрегации используется для получения отсутствующих значений.
- 1 — ClickHouse выполняет `GROUP BY` так же, как это указано в стандарте SQL. Типы ключей агрегации преобразуются в [Nullable](/sql-reference/data-types/nullable). Столбцы для соответствующих ключей агрегации заполняются [NULL](/sql-reference/syntax#null) для строк, которые не использовали его.

См. также:

- [Условие GROUP BY](/sql-reference/statements/select/group-by)
## h3togeo_lon_lat_result_order {#h3togeo_lon_lat_result_order} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Функция 'h3ToGeo' возвращает (lon, lat), если true, иначе (lat, lon).
## handshake_timeout_ms {#handshake_timeout_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`10000`|

Тайм-аут в миллисекундах для получения пакета Hello от реплик во время рукопожатия.
## hdfs_create_new_file_on_insert {#hdfs_create_new_file_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает создание нового файла при каждой вставке в таблицах HDFS. Если включено, при каждой вставке будет создан новый HDFS файл с именем по шаблону, аналогичному этому:

начальный: `data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz`, и т.д.

Возможные значения:
- 0 — Запрос `INSERT` добавляет новые данные в конец файла.
- 1 — Запрос `INSERT` создает новый файл.
## hdfs_ignore_file_doesnt_exist {#hdfs_ignore_file_doesnt_exist} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорирует отсутствие файла, если он не существует при чтении определенных ключей.

Возможные значения:
- 1 — `SELECT` возвращает пустой результат.
- 0 — `SELECT` выдает исключение.
## hdfs_replication {#hdfs_replication} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Фактическое количество репликаций может быть указано при создании файла hdfs.
## hdfs_skip_empty_files {#hdfs_skip_empty_files} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает пропуск пустых файлов в таблицах с движком [HDFS](../../engines/table-engines/integrations/hdfs.md).

Возможные значения:
- 0 — `SELECT` выдает исключение, если пустой файл несовместим с запрашиваемым форматом.
- 1 — `SELECT` возвращает пустой результат для пустого файла.
## hdfs_throw_on_zero_files_match {#hdfs_throw_on_zero_files_match} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Выбросить ошибку, если по правилам глобального расширения не найдено ноль файлов.

Возможные значения:
- 1 — `SELECT` выдает исключение.
- 0 — `SELECT` возвращает пустой результат.
## hdfs_truncate_on_insert {#hdfs_truncate_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает усечение перед вставкой в таблицах с движком hdfs. Если отключено, будет выдано исключение при попытке вставить, если файл в HDFS уже существует.

Возможные значения:
- 0 — Запрос `INSERT` добавляет новые данные в конец файла.
- 1 — Запрос `INSERT` заменяет существующее содержание файла новыми данными.
## hedged_connection_timeout_ms {#hedged_connection_timeout_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`50`|

Тайм-аут соединения для установления соединения с репликой для хеджированных запросов.
## hnsw_candidate_list_size_for_search {#hnsw_candidate_list_size_for_search} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`256`|

Размер динамического списка кандидатов при поиске в индексе векторного сходства, также известный как 'ef_search'.
## hsts_max_age {#hsts_max_age} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Срок действия для HSTS. 0 означает отключение HSTS.
## http_connection_timeout {#http_connection_timeout} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`1`|

Тайм-аут соединения HTTP (в секундах).

Возможные значения:

- Любое положительное целое число.
- 0 - Отключено (бесконечный тайм-аут).
## http_headers_progress_interval_ms {#http_headers_progress_interval_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100`|

Не отправлять HTTP заголовки X-ClickHouse-Progress чаще, чем через указанный интервал.
## http_make_head_request {#http_make_head_request} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Настройка `http_make_head_request` позволяет выполнять запрос `HEAD` при чтении данных по HTTP для получения информации о файле, который будет прочитан, такой как его размер. Поскольку она включена по умолчанию, может быть желательно отключить эту настройку в случаях, когда сервер не поддерживает запросы `HEAD`.

## http_max_field_name_size {#http_max_field_name_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`131072`|

Максимальная длина имени поля в HTTP заголовке

## http_max_field_value_size {#http_max_field_value_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`131072`|

Максимальная длина значения поля в HTTP заголовке

## http_max_fields {#http_max_fields} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000`|

Максимальное количество полей в HTTP заголовке

## http_max_multipart_form_data_size {#http_max_multipart_form_data_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1073741824`|

Ограничение на размер содержимого multipart/form-data. Эта настройка не может быть распознана из параметров URL и должна быть установлена в пользовательском профиле. Обратите внимание, что содержимое разбирается, и внешние таблицы создаются в памяти до начала выполнения запроса. И это единственное ограничение, которое имеет значение на этом этапе (ограничения по максимальному использованию памяти и максимальному времени выполнения не влияют на чтение данных формы HTTP).

## http_max_request_param_data_size {#http_max_request_param_data_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10485760`|

Ограничение на размер данных запроса, используемых в качестве параметра запроса в предопределённых HTTP запросах.

## http_max_tries {#http_max_tries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10`|

Максимальное количество попыток чтения через HTTP.

## http_max_uri_size {#http_max_uri_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1048576`|

Устанавливает максимальную длину URI HTTP запроса.

Возможные значения:

- Положительное целое число.

## http_native_compression_disable_checksumming_on_decompress {#http_native_compression_disable_checksumming_on_decompress} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает проверку контрольной суммы при распаковке данных HTTP POST от клиента. Используется только для формата сжатия ClickHouse (не используется с `gzip` или `deflate`).

Для получения дополнительной информации читайте [описание HTTP интерфейса](../../interfaces/http.md).

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

## http_receive_timeout {#http_receive_timeout} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`30`|

Тайм-аут приёмки HTTP (в секундах).

Возможные значения:

- Любое положительное целое число.
- 0 - Отключено (бессрочный тайм-аут).

## http_response_buffer_size {#http_response_buffer_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Количество байт, которые будут буферизоваться в памяти сервера перед отправкой HTTP ответа клиенту или сбросом на диск (когда включен http_wait_end_of_query).

## http_response_headers {#http_response_headers} 

|Тип|По умолчанию|
|---|---|
|`Map`|`{}`|

Позволяет добавлять или заменять HTTP заголовки, которые сервер вернёт в ответе с успешным результатом запроса. Это влияет только на HTTP интерфейс.

Если заголовок уже установлен по умолчанию, предоставленное значение его заменит. Если заголовок не был установлен по умолчанию, он будет добавлен в список заголовков. Заголовки, которые устанавливаются сервером по умолчанию и не перекрываются этой настройкой, останутся.

Настройка позволяет установить заголовок на постоянное значение. В данный момент нет способа установить заголовок на динамически рассчитанное значение.

Ни имена, ни значения не могут содержать управляющие символы ASCII.

Если вы реализуете прикладное программное обеспечение, позволяющее пользователям изменять настройки, но в то же время принимающее решения на основе возвращённых заголовков, рекомендуется ограничить эту настройку как только для чтения.

Пример: `SET http_response_headers = '{"Content-Type": "image/png"}'`

## http_retry_initial_backoff_ms {#http_retry_initial_backoff_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100`|

Минимум миллисекунд для задержки при повторной попытке чтения через HTTP.

## http_retry_max_backoff_ms {#http_retry_max_backoff_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10000`|

Максимум миллисекунд для задержки при повторной попытке чтения через HTTP.

## http_send_timeout {#http_send_timeout} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`30`|

Тайм-аут отправки HTTP (в секундах).

Возможные значения:

- Любое положительное целое число.
- 0 - Отключено (бессрочный тайм-аут).

:::note
Это применимо только к профилю по умолчанию. Перезагрузка сервера необходима для применения изменений.
:::

## http_skip_not_found_url_for_globs {#http_skip_not_found_url_for_globs} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Пропускать URL для глобов с ошибкой HTTP_NOT_FOUND.

## http_wait_end_of_query {#http_wait_end_of_query} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает буферизацию HTTP ответа на стороне сервера.

## http_write_exception_in_output_format {#http_write_exception_in_output_format} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Записывает исключение в выходном формате для получения допустимого вывода. Работает с форматами JSON и XML.

## http_zlib_compression_level {#http_zlib_compression_level} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`3`|

Устанавливает уровень сжатия данных в ответе на запрос HTTP, если [enable_http_compression = 1](#enable_http_compression).

Возможные значения: числа от 1 до 9.

## iceberg_snapshot_id {#iceberg_snapshot_id} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`0`|

Запрос к таблице Iceberg с использованием конкретного идентификатора снимка.

## iceberg_timestamp_ms {#iceberg_timestamp_ms} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`0`|

Запрос к таблице Iceberg с использованием снимка, который был актуален в конкретный момент времени.

## idle_connection_timeout {#idle_connection_timeout} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3600`|

Тайм-аут для закрытия неактивных TCP соединений после указанного количества секунд.

Возможные значения:

- Положительное целое число (0 - закрыть немедленно, через 0 секунд).

## ignore_cold_parts_seconds {#ignore_cold_parts_seconds} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Int64`|`0`|

Влияет только в ClickHouse Cloud. Исключает новые части данных из запросов SELECT, пока они либо не будут предварительно разогреты (см. [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)), либо не станут старыми на это количество секунд. Только для Replicated-/SharedMergeTree.

## ignore_data_skipping_indices {#ignore_data_skipping_indices} 

Игнорирует индексы пропуска, указанные, если они используются в запросе.

Рассмотрим следующий пример:

```sql
CREATE TABLE data
(
    key Int,
    x Int,
    y Int,
    INDEX x_idx x TYPE minmax GRANULARITY 1,
    INDEX y_idx y TYPE minmax GRANULARITY 1,
    INDEX xy_idx (x,y) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

INSERT INTO data VALUES (1, 2, 3);

SELECT * FROM data;
SELECT * FROM data SETTINGS ignore_data_skipping_indices=''; -- запрос вызовет ошибку CANNOT_PARSE_TEXT.
SELECT * FROM data SETTINGS ignore_data_skipping_indices='x_idx'; -- Ок.
SELECT * FROM data SETTINGS ignore_data_skipping_indices='na_idx'; -- Ок.

SELECT * FROM data WHERE x = 1 AND y = 1 SETTINGS ignore_data_skipping_indices='xy_idx',force_data_skipping_indices='xy_idx' ; -- запрос вызовет ошибку INDEX_NOT_USED, так как xy_idx явно игнорируется.
SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';
```

Запрос без игнорирования индексов:
```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2;

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
      Skip
        Name: xy_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
```

Игнорируя индекс `xy_idx`:
```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
```

Работает с таблицами в семействе MergeTree.

## ignore_drop_queries_probability {#ignore_drop_queries_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Если включено, сервер будет игнорировать все запросы DROP таблиц с заданной вероятностью (для Memory и JOIN движков будет заменять DROP на TRUNCATE). Используется для целей тестирования.

## ignore_materialized_views_with_dropped_target_table {#ignore_materialized_views_with_dropped_target_table} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорировать МВ с удаленной целевой таблицей при отправке данных во вьюхи.

## ignore_on_cluster_for_replicated_access_entities_queries {#ignore_on_cluster_for_replicated_access_entities_queries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорировать ON CLUSTER для управляющих запросов к реплицируемым сущностям доступа.

## ignore_on_cluster_for_replicated_named_collections_queries {#ignore_on_cluster_for_replicated_named_collections_queries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорировать ON CLUSTER для управляющих запросов к реплицируемым именованным коллекциям.

## ignore_on_cluster_for_replicated_udf_queries {#ignore_on_cluster_for_replicated_udf_queries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорировать ON CLUSTER для управляющих запросов к реплицируемым UDF.

## implicit_select {#implicit_select} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить написание простых запросов SELECT без ведущего ключевого слова SELECT, что делает их простыми для использования в стиле калькулятора, например, `1 + 2` становится допустимым запросом.

В `clickhouse-local` это включено по умолчанию и может быть явно отключено.

## implicit_transaction {#implicit_transaction} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если включено и не находится внутри транзакции, оборачивает запрос в полную транзакцию (начало + фиксация или откат).

## input_format_parallel_parsing {#input_format_parallel_parsing} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает параллельный парсинг форматов данных с сохранением порядка. Поддерживается только для форматов [TSV](../../interfaces/formats.md/#tabseparated), [TSKV](../../interfaces/formats.md/#tskv), [CSV](../../interfaces/formats.md/#csv) и [JSONEachRow](../../interfaces/formats.md/#jsoneachrow).

Возможные значения:

- 1 — Включено.
- 0 — Отключено.

## insert_allow_materialized_columns {#insert_allow_materialized_columns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если настройка включена, разрешает использование материализованных колонок в INSERT.

## insert_deduplicate {#insert_deduplicate} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает дедупликацию блоков при `INSERT` (для таблиц Replicated*).

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

По умолчанию блоки, вставляемые в реплицируемые таблицы с помощью оператора `INSERT`, дедуплицируются (см. [Репликация данных](../../engines/table-engines/mergetree-family/replication.md)). Для реплицируемых таблиц по умолчанию только 100 самых последних блоков для каждой партиции дедуплицируются (см. [replicated_deduplication_window](merge-tree-settings.md/#replicated-deduplication-window), [replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated-deduplication-window-seconds)). Для нереплицируемых таблиц см. [non_replicated_deduplication_window](merge-tree-settings.md/#non-replicated-deduplication-window).

## insert_deduplication_token {#insert_deduplication_token} 

Настройка позволяет пользователю предоставлять свою семантику дедупликации в MergeTree/ReplicatedMergeTree. Например, предоставив уникальное значение для настройки в каждом операторе INSERT, пользователь может избежать дедупликации одинаковых вставленных данных.

Возможные значения:

- Любая строка

`insert_deduplication_token` используется для дедупликации _только_ когда не пустое.

Для реплицируемых таблиц по умолчанию только 100 самых последних вставок для каждой партиции дедуплицируются (см. [replicated_deduplication_window](merge-tree-settings.md/#replicated-deduplication-window), [replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated-deduplication-window-seconds)). Для нереплицируемых таблиц см. [non_replicated_deduplication_window](merge-tree-settings.md/#non-replicated-deduplication-window).

:::note
`insert_deduplication_token` работает на уровне партиции (так же как и `insert_deduplication` контрольную сумму). Несколько партиций могут иметь одно и то же значение `insert_deduplication_token`.
:::

Пример:

```sql
CREATE TABLE test_table
( A Int64 )
ENGINE = MergeTree
ORDER BY A
SETTINGS non_replicated_deduplication_window = 100;

INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (1);

-- следующая вставка не будет дедуплицироваться, потому что insert_deduplication_token отличается
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test1' VALUES (1);

-- следующая вставка будет дедуплицирована, потому что insert_deduplication_token
-- совпадает с одним из предыдущих
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (2);

SELECT * FROM test_table

┌─A─┐
│ 1 │
└───┘
┌─A─┐
│ 1 │
└───┘
```

## insert_keeper_fault_injection_probability {#insert_keeper_fault_injection_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Приблизительная вероятность сбоя для запроса keeper во время вставки. Допустимое значение находится в интервале [0.0f, 1.0f].

## insert_keeper_fault_injection_seed {#insert_keeper_fault_injection_seed} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

0 - случайное семя, иначе значение настройки.

## insert_keeper_max_retries {#insert_keeper_max_retries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`20`|

Настройка устанавливает максимальное количество повторных попыток для запросов ClickHouse Keeper (или ZooKeeper) при вставке в реплицированный MergeTree. Учитываются только запросы Keeper, которые завершились неудачей из-за сетевой ошибки, таймаута сессии Keeper или таймаута запроса.

Возможные значения:

- Положительное целое число.
- 0 — Повторы отключены.

Значение по умолчанию в облаке: `20`.

Повторы запросов Keeper выполняются после некоторого таймаута. Таймаут контролируется следующими настройками: `insert_keeper_retry_initial_backoff_ms`, `insert_keeper_retry_max_backoff_ms`. Первая повторная попытка выполняется после таймаута `insert_keeper_retry_initial_backoff_ms`. Последующие таймауты будут рассчитываться следующим образом:
```
timeout = min(insert_keeper_retry_max_backoff_ms, latest_timeout * 2)
```

Например, если `insert_keeper_retry_initial_backoff_ms=100`, `insert_keeper_retry_max_backoff_ms=10000` и `insert_keeper_max_retries=8`, тогда таймауты будут `100, 200, 400, 800, 1600, 3200, 6400, 10000`.

Помимо отказоустойчивости, повторы также нацелены на обеспечение лучшего пользовательского опыта - они позволяют избежать возврата ошибки во время выполнения INSERT, если Keeper перезапускается, например, из-за обновления.

## insert_keeper_retry_initial_backoff_ms {#insert_keeper_retry_initial_backoff_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100`|

Начальный таймаут (в миллисекундах) для повторной попытки неудачного запроса Keeper во время выполнения запроса INSERT.

Возможные значения:

- Положительное целое число.
- 0 — Без таймаута.
## keeper_retry_max_backoff_ms {#keeper_retry_max_backoff_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5000`|

Максимальное время ожидания для общих операций Keeper
## least_greatest_legacy_null_behavior {#least_greatest_legacy_null_behavior} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если включено, функции 'least' и 'greatest' возвращают NULL, если один из их аргументов равен NULL.
## legacy_column_name_of_tuple_literal {#legacy_column_name_of_tuple_literal} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Список всех имен элементов больших литералов кортежей в их именах колонок вместо хеша. Эта настройка существует только по соображениям совместимости. Имеет смысл установить на 'true', при поэтапном обновлении кластера с версии ниже 21.7 на более высокую.
## lightweight_deletes_sync {#lightweight_deletes_sync} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`2`|

То же самое, что и [`mutations_sync`](#mutations_sync), но контролирует только выполнение легковесных удалений.

Возможные значения:

- 0 - Мутации выполняются асинхронно.
- 1 - Запрос ждет, пока легковесные удаления завершатся на текущем сервере.
- 2 - Запрос ждет, пока легковесные удаления завершатся на всех репликах (если они существуют).

**Смотрите также**

- [Синхронность запросов ALTER](../../sql-reference/statements/alter/index.md/#synchronicity-of-alter-queries)
- [Мутации](../../sql-reference/statements/alter/index.md/#mutations)
## limit {#limit} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Устанавливает максимальное количество строк для получения из результата запроса. Он регулирует значение, установленное в операторе [LIMIT](/sql-reference/statements/select/limit), таким образом, что лимит, указанный в запросе, не может превышать лимит, установленный этой настройкой.

Возможные значения:

- 0 — Количество строк не ограничено.
- Положительное целое число.
## live_view_heartbeat_interval {#live_view_heartbeat_interval} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Seconds`|`15`|

Интервал "сердцебиения" в секундах, чтобы указать, что живой запрос активен.
## load_balancing {#load_balancing} 

|Тип|По умолчанию|
|---|---|
|`LoadBalancing`|`random`|

Определяет алгоритм выбора реплик, который используется для распределенной обработки запросов.

ClickHouse поддерживает следующие алгоритмы выбора реплик:

- [Случайный](#load_balancing-random) (по умолчанию)
- [Ближайшее имя хоста](#load_balancing-nearest_hostname)
- [Расстояние Левенштейна имени хоста](#load_balancing-hostname_levenshtein_distance)
- [По порядку](#load_balancing-in_order)
- [Первый или случайный](#load_balancing-first_or_random)
- [Круговая очередность](#load_balancing-round_robin)

Смотрите также:

- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)
### Случайный (по умолчанию) {#load_balancing-random}

```sql
load_balancing = random
```

Количество ошибок учитывается для каждой реплики. Запрос отправляется на реплику с наименьшим количеством ошибок, а если таких несколько, то на любую из них.
Недостатки: Близость сервера не учитывается; если у реплик разные данные, вы также получите разные данные.
### Ближайшее имя хоста {#load_balancing-nearest_hostname}

```sql
load_balancing = nearest_hostname
```

Количество ошибок учитывается для каждой реплики. Каждые 5 минут количество ошибок делится на 2. Таким образом, количество ошибок рассчитывается за недавнее время с экспоненциальным сглаживанием. Если есть одна реплика с минимальным количеством ошибок (т.е. ошибки произошли недавно на других репликах), запрос отправляется на нее. Если есть несколько реплик с одинаковым минимальным количеством ошибок, запрос отправляется на реплику с именем хоста, наиболее похожим на имя сервера в конфигурационном файле (по количеству различных символов в идентичных позициях, до минимальной длины обоих имен хостов).

Например, example01-01-1 и example01-01-2 отличаются в одной позиции, в то время как example01-01-1 и example01-02-2 различны в двух местах.
Этот метод может показаться примитивным, но он не требует внешних данных о топологии сети, и он не сравнивает IP-адреса, что было бы сложно для наших IPv6-адресов.

Таким образом, если есть эквивалентные реплики, предпочтение отдается ближайшей по имени.
Можно также предположить, что при отправке запроса на один и тот же сервер, в отсутствие сбоев, распределенный запрос также будет проходить через одни и те же серверы. Поэтому, даже если на репликах размещены разные данные, запрос вернет в основном одинаковые результаты.
### Расстояние Левенштейна имени хоста {#load_balancing-hostname_levenshtein_distance}

```sql
load_balancing = hostname_levenshtein_distance
```

Так же, как и `nearest_hostname`, но сравнивает имена хостов по [расстоянию Левенштейна](https://en.wikipedia.org/wiki/Levenshtein_distance). Например:

```text
example-clickhouse-0-0 ample-clickhouse-0-0
1

example-clickhouse-0-0 example-clickhouse-1-10
2

example-clickhouse-0-0 example-clickhouse-12-0
3
```
### По порядку {#load_balancing-in_order}

```sql
load_balancing = in_order
```

Реплики с одинаковым количеством ошибок доступны в том порядке, в котором они указаны в конфигурации.
Этот метод подходит, когда вы точно знаете, какая реплика предпочтительнее.
### Первый или случайный {#load_balancing-first_or_random}

```sql
load_balancing = first_or_random
```

Этот алгоритм выбирает первую реплику в наборе или случайную реплику, если первая недоступна. Он эффективен в настройках кросс-репликации, но бесполезен в других конфигурациях.

Алгоритм `first_or_random` решает проблему алгоритма `in_order`. Если одна из реплик выходит из строя, следующая получает двойную нагрузку, в то время как оставшиеся обрабатывают обычное количество трафика. При использовании алгоритма `first_or_random` нагрузка равномерно распределяется между доступными репликами.

Можно явно определить, какая реплика будет первой, с помощью настройки `load_balancing_first_offset`. Это дает больший контроль для перераспределения нагрузки запросов между репликами.
### Круговая очередность {#load_balancing-round_robin}

```sql
load_balancing = round_robin
```

Этот алгоритм использует стратегию круговой очереди между репликами с одинаковым количеством ошибок (учитываются только запросы с политикой `round_robin`).
## load_balancing_first_offset {#load_balancing_first_offset} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Какая реплика предпочтительно посылать запрос, когда используется стратегия балансировки нагрузки FIRST_OR_RANDOM.
## load_marks_asynchronously {#load_marks_asynchronously} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Загружать метки MergeTree асинхронно.
## local_filesystem_read_method {#local_filesystem_read_method} 

|Тип|По умолчанию|
|---|---|
|`String`|`pread_threadpool`|

Метод чтения данных из локальной файловой системы, один из: read, pread, mmap, io_uring, pread_threadpool. Метод 'io_uring' является экспериментальным и не работает для Log, TinyLog, StripeLog, File, Set и Join и других таблиц с добавляемыми файлами при наличии одновременных чтений и записей.
## local_filesystem_read_prefetch {#local_filesystem_read_prefetch} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Должен ли использоваться предварительный выбор при чтении данных из локальной файловой системы.
## lock_acquire_timeout {#lock_acquire_timeout} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`120`|

Определяет, сколько секунд запрос блокировки будет ждать перед сбоем.

Тайм-аут блокировки используется для защиты от взаимных блокировок при выполнении операций чтения/записи с таблицами. Когда время тайм-аута истекает и запрос блокировки терпит неудачу, сервер ClickHouse выбрасывает исключение "Попытка блокировки завершилась тайм-аутом! Возможная взаимная блокировка предотвращена. Клиент должен повторить попытку." с кодом ошибки `DEADLOCK_AVOIDED`.

Возможные значения:

- Положительное целое число (в секундах).
- 0 — Нет тайм-аута для блокировки.
## log_comment {#log_comment} 

Определяет значение для поля `log_comment` таблицы [system.query_log](../system-tables/query_log.md) и текст комментария для журнальных записей сервера.

Это может быть использовано для повышения читаемости журналов сервера. Кроме того, это помогает выбрать запросы, относящиеся к тесту, из `system.query_log` после запуска [clickhouse-test](../../development/tests.md).

Возможные значения:

- Любая строка не длиннее [max_query_size](#max_query_size). Если значение max_query_size превышается, сервер выбрасывает исключение.

**Пример**

Запрос:

```sql
SET log_comment = 'log_comment test', log_queries = 1;
SELECT 1;
SYSTEM FLUSH LOGS;
SELECT type, query FROM system.query_log WHERE log_comment = 'log_comment test' AND event_date >= yesterday() ORDER BY event_time DESC LIMIT 2;
```

Результат:

```text
┌─type────────┬─query─────┐
│ QueryStart  │ SELECT 1; │
│ QueryFinish │ SELECT 1; │
└─────────────┴───────────┘
```
## log_formatted_queries {#log_formatted_queries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Позволяет логировать отформатированные запросы в системную таблицу [system.query_log](../../operations/system-tables/query_log.md) (заполняет колонку `formatted_query` в [system.query_log](../../operations/system-tables/query_log.md)).

Возможные значения:

- 0 — Отформатированные запросы не логируются в системной таблице.
- 1 — Отформатированные запросы логируются в системной таблице.
## log_processors_profiles {#log_processors_profiles} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Записывать время, которое процессор потратил во время выполнения/ожидания данных в таблице `system.processors_profile_log`.

Смотрите также:

- [`system.processors_profile_log`](../../operations/system-tables/processors_profile_log.md)
- [`EXPLAIN PIPELINE`](../../sql-reference/statements/explain.md/#explain-pipeline)
## log_profile_events {#log_profile_events} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Логировать статистику производительности запроса в query_log, query_thread_log и query_views_log.
## log_queries {#log_queries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Настройка ведения журнала запросов.

Запросы, посылаемые в ClickHouse с этой настройкой, записываются в соответствии с правилами параметра конфигурации сервера [query_log](../../operations/server-configuration-parameters/settings.md/#query_log).

Пример:

```text
log_queries=1
```
## log_queries_cut_to_length {#log_queries_cut_to_length} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100000`|

Если длина запроса превышает заданный порог (в байтах), то запрос обрезается при записи в журнал запросов. Также ограничивает длину печатаемого запроса в обычном текстовом журнале.
## log_queries_min_query_duration_ms {#log_queries_min_query_duration_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`0`|

Если включено (не ноль), запросы быстрее значения этой настройки не будут записываться (это можно рассматривать как `long_query_time` для [MySQL Slow Query Log](https://dev.mysql.com/doc/refman/5.7/slow-query-log.html)), и это, в основном, означает, что вы не найдете их в следующих таблицах:

- `system.query_log`
- `system.query_thread_log`

Только запросы с следующим типом попадут в журнал:

- `QUERY_FINISH`
- `EXCEPTION_WHILE_PROCESSING`

- Тип: миллисекунды
- Значение по умолчанию: 0 (любой запрос)
## log_queries_min_type {#log_queries_min_type} 

|Тип|По умолчанию|
|---|---|
|`LogQueriesType`|`QUERY_START`|

Минимальный тип `query_log` для записи в журнал.

Возможные значения:
- `QUERY_START` (`=1`)
- `QUERY_FINISH` (`=2`)
- `EXCEPTION_BEFORE_START` (`=3`)
- `EXCEPTION_WHILE_PROCESSING` (`=4`)

Можно использовать, чтобы ограничить, какие сущности попадут в `query_log`, скажем, если вы интересуетесь только ошибками, тогда вы можете использовать `EXCEPTION_WHILE_PROCESSING`:

```text
log_queries_min_type='EXCEPTION_WHILE_PROCESSING'
```
## log_queries_probability {#log_queries_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`1`|

Позволяет пользователю записывать в системные таблицы [query_log](../../operations/system-tables/query_log.md), [query_thread_log](../../operations/system-tables/query_thread_log.md) и [query_views_log](../../operations/system-tables/query_views_log.md) только выборку запросов, выбранных случайным образом с заданной вероятностью. Это помогает снизить нагрузку при большом объеме запросов в секунду.

Возможные значения:

- 0 — Запросы не записываются в системные таблицы.
- Положительное дробное число в диапазоне [0..1]. Например, если значение настройки равно `0.5`, примерно половина запросов записывается в системные таблицы.
- 1 — Все запросы записываются в системные таблицы.
## log_query_settings {#log_query_settings} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Логировать настройки запроса в query_log и журнале OpenTelemetry.
## log_query_threads {#log_query_threads} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Настройка ведения журнала потоков запросов.

Потоки запросов логируются в таблице [system.query_thread_log](../../operations/system-tables/query_thread_log.md). Эта настройка имеет эффект только тогда, когда [log_queries](#log_queries) истинно. Потоки запросов, выполняемые ClickHouse с этой настройкой, логируются в соответствии с правилами параметра конфигурации сервера [query_thread_log](/operations/server-configuration-parameters/settings#query_thread_log).

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

**Пример**

```text
log_query_threads=1
```
## log_query_views {#log_query_views} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Настройка ведения журнала представлений запросов.

Когда запрос, выполненный ClickHouse с этой включенной настройкой, имеет связанные представления (материализованные или живые представления), они записываются в параметре конфигурации сервера [query_views_log](/operations/server-configuration-parameters/settings#query_views_log).

Пример:

```text
log_query_views=1
```
## low_cardinality_allow_in_native_format {#low_cardinality_allow_in_native_format} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает или ограничивает использование типа данных [LowCardinality](../../sql-reference/data-types/lowcardinality.md) с форматом [Native](../../interfaces/formats.md/#native).

Если использование `LowCardinality` ограничено, сервер ClickHouse преобразует колонки `LowCardinality` в обыкновенные для `SELECT` запросов и преобразует обыкновенные колонки в колонки `LowCardinality` для `INSERT` запросов.

Эта настройка требуется в основном для сторонних клиентов, которые не поддерживают тип данных `LowCardinality`.

Возможные значения:

- 1 — Использование `LowCardinality` не ограничено.
- 0 — Использование `LowCardinality` ограничено.
## low_cardinality_max_dictionary_size {#low_cardinality_max_dictionary_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`8192`|

Устанавливает максимальный размер в строках общего глобального словаря для типа данных [LowCardinality](../../sql-reference/data-types/lowcardinality.md), который может быть записан в файловую систему хранения. Эта настройка предотвращает проблемы с ОЗУ в случае неограниченного роста словаря. Все данные, которые не могут быть закодированы из-за ограничения максимального размера словаря, ClickHouse записывает обычным способом.

Возможные значения:

- Любое положительное целое число.
## low_cardinality_use_single_dictionary_for_part {#low_cardinality_use_single_dictionary_for_part} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или выключает использование одного словаря для части данных.

По умолчанию сервер ClickHouse контролирует размер словарей и, если словарь переполняется, сервер начинает записывать следующий. Чтобы запретить создание нескольких словарей, установите `low_cardinality_use_single_dictionary_for_part = 1`.

Возможные значения:

- 1 — Создание нескольких словарей для части данных запрещено.
- 0 — Создание нескольких словарей для части данных не запрещено.
## low_priority_query_wait_time_ms {#low_priority_query_wait_time_ms} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`1000`|

Время ожидания в миллисекундах, когда запрос с низким приоритетом встречает запрос с высоким приоритетом.
## materialize_skip_indexes_on_insert {#materialize_skip_indexes_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Строятся ли индекс-пропуски и сохраняются ли они при вставках. Если отключено, индексы-пропуски будут построены и сохранены во время объединений или с помощью явного MATERIALIZE INDEX.
## materialize_statistics_on_insert {#materialize_statistics_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Строятся ли и вставляются ли статистические данные при вставках. Если отключено, статистика будет построена и сохранена во время объединений или с помощью явного MATERIALIZE STATISTICS.
## materialize_ttl_after_modify {#materialize_ttl_after_modify} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Применить TTL для старых данных после запроса ALTER MODIFY TTL.
## materialized_views_ignore_errors {#materialized_views_ignore_errors} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Позволяет игнорировать ошибки для MATERIALIZED VIEW и доставлять оригинальный блок в таблицу независимо от MVs.
## max_analyze_depth {#max_analyze_depth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5000`|

Максимальное число анализов, выполняемых интерпретатором.
## max_ast_depth {#max_ast_depth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Максимальная глубина вложенности синтаксического дерева запроса. Если превышена, выбрасывается исключение.

:::note
На данный момент это не проверяется во время разбора, а только после разбора запроса.
Это означает, что слишком глубокое синтаксическое дерево может быть создано во время разбора,
но запрос завершится с ошибкой.
:::
## max_ast_elements {#max_ast_elements} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`50000`|

Максимальное количество элементов в синтаксическом дереве запроса. Если превышено, выбрасывается исключение.

:::note
На данный момент это не проверяется во время разбора, а только после разбора запроса.
Это означает, что слишком глубокое синтаксическое дерево может быть создано во время разбора,
но запрос завершится с ошибкой.
:::
## max_autoincrement_series {#max_autoincrement_series} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Лимит на количество серий, созданных функцией `generateSeriesID`.

Поскольку каждая серия представляет собой узел в Keeper, рекомендуется не иметь более нескольких миллионов из них.
## max_backup_bandwidth {#max_backup_bandwidth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальная скорость чтения в байтах в секунду для конкретной резервной копии на сервере. Ноль означает неограниченно.
## max_block_size {#max_block_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`65409`|

В ClickHouse данные обрабатываются блоками, которые являются множествами частей колонок. Внутренние циклы обработки для одного блока эффективны, но при обработке каждого блока есть заметные затраты.

Настройка `max_block_size` указывает рекомендованное максимальное количество строк для включения в один блок при загрузке данных из таблиц. Блоки размером `max_block_size` не всегда загружаются из таблицы: если ClickHouse определяет, что необходимо извлечь меньше данных, обрабатывается меньший блок.

Размер блока не должен быть слишком маленьким, чтобы избежать заметных затрат при обработке каждого блока. Он также не должен быть слишком большим, чтобы гарантировать, что запросы с оператором LIMIT выполняются быстро после обработки первого блока. При настройке `max_block_size` цель должна заключаться в том, чтобы избежать избыточного использования памяти при извлечении большого количества колонок в нескольких потоках и сохранить хотя бы некоторую локальность кэша.
## max_bytes_before_external_group_by {#max_bytes_before_external_group_by} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Облачное значение по умолчанию: половина объема памяти на каждую реплику.

Включает или отключает выполнение операторов `GROUP BY` в внешней памяти.
(Смотрите [GROUP BY в внешней памяти](/sql-reference/statements/select/group-by#group-by-in-external-memory))

Возможные значения:

- Максимальный объем ОЗУ (в байтах), который может использовать одно [GROUP BY](/sql-reference/statements/select/group-by) операция.
- `0` — `GROUP BY` в внешней памяти отключен.

:::note
Если использование памяти во время операций GROUP BY превышает этот порог в байтах,
активируйте режим "внешней агрегации" (сброс данных на диск).

Рекомендуемое значение — половина доступной системной памяти.
:::
## max_bytes_before_external_sort {#max_bytes_before_external_sort} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Облачное значение по умолчанию: половина объема памяти на каждую реплику.

Включает или отключает выполнение операторов `ORDER BY` в внешней памяти. Смотрите [Детали реализации ORDER BY](../../sql-reference/statements/select/order-by.md#implementation-details)
Если использование памяти во время операции ORDER BY превышает этот порог в байтах, активируется режим "внешней сортировки" (сброс данных на диск).

Возможные значения:

- Максимальный объем ОЗУ (в байтах), который может быть использован одной [ORDER BY](../../sql-reference/statements/select/order-by.md) операцией.
  Рекомендуемое значение — половина доступной системной памяти
- `0` — `ORDER BY` в внешней памяти отключен.
## max_bytes_before_remerge_sort {#max_bytes_before_remerge_sort} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000000`|

В случае ORDER BY с LIMIT, когда использование памяти превышает указанный порог, выполните дополнительные операции слияния блоков перед окончательным слиянием, чтобы сохранить только верхние LIMIT строки.
## max_bytes_in_distinct {#max_bytes_in_distinct} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество байт состояния (в необработанных байтах) в памяти, которое используется хеш-таблицей при использовании DISTINCT.
## max_bytes_in_join {#max_bytes_in_join} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальный размер в количестве байт хеш-таблицы, используемой при соединении таблиц.

Эта настройка применяется к операциям [SELECT ... JOIN](/sql-reference/statements/select/join)
и к [движку таблицы Join](/engines/table-engines/special/join).

Если запрос содержит соединения, ClickHouse проверяет эту настройку для каждого промежуточного результата.

ClickHouse может выполнить различные действия, когда лимит достигнут. Используйте настройки [join_overflow_mode](/operations/settings/settings#join_overflow_mode), чтобы выбрать действие.

Возможные значения:

- Положительное целое число.
- 0 — Контроль памяти отключен.
## max_bytes_in_set {#max_bytes_in_set} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество байт (необработанных данных), используемое множеством в операторе IN, созданном из подзапроса.
## max_bytes_ratio_before_external_group_by {#max_bytes_ratio_before_external_group_by} 

|Тип|По умолчанию|
|---|---|
|`Double`|`0.5`|

Соотношение доступной памяти, разрешенной для `GROUP BY`. Как только оно будет достигнуто,
внешняя память используется для агрегации.

Например, если установлено значение `0.6`, `GROUP BY` позволит использовать 60% доступной памяти
(для сервера/пользователя/слияний) в начале выполнения, после чего он
начнет использовать внешнюю агрегацию.
## max_bytes_ratio_before_external_sort {#max_bytes_ratio_before_external_sort} 

|Тип|По умолчанию|
|---|---|
|`Double`|`0.5`|

Соотношение доступной памяти, разрешенной для `ORDER BY`. Как только оно будет достигнуто,
используется внешняя сортировка.

Например, если установлено значение `0.6`, `ORDER BY` позволит использовать `60%` доступной памяти
(для сервера/пользователя/слияний) в начале выполнения, после чего
он начнет использовать внешнюю сортировку.
## max_bytes_to_read {#max_bytes_to_read} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество байт (необработанных данных), которые могут быть прочитаны из таблицы при выполнении запроса.
Ограничение проверяется для каждого обрабатываемого блока данных, применяется только к
самому глубокому выражению таблицы и при чтении с удаленного сервера, проверяется только на
удаленном сервере.
## max_bytes_to_read_leaf {#max_bytes_to_read_leaf} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество байт (необработанных данных), которые могут быть прочитаны из локальной
таблицы на узле-листе при выполнении распределенного запроса. В то время как распределенные запросы
могут инициировать несколько подзапросов к каждому шарду (листьев) - это ограничение будет
проверяться только на этапе чтения на узлах-листах и будет игнорироваться на стадии слияния результатов на корневом узле.

Например, кластер состоит из 2 шардов, и каждый шард содержит таблицу с
100 байтами данных. Распределенный запрос, который должен прочитать все данные
из обеих таблиц с установкой `max_bytes_to_read=150`, завершится с ошибкой, так как в сумме это
будет 200 байт. Запрос с `max_bytes_to_read_leaf=150` завершится успешно, так как
узлы-листья прочитают максимум 100 байт.

Ограничение проверяется для каждого обрабатываемого блока данных.

:::note
Эта настройка нестабильна с `prefer_localhost_replica=1`.
:::
## max_bytes_to_sort {#max_bytes_to_sort} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество байт перед сортировкой. Если больше указанного количества
необработанных байт должно быть обработано для операции ORDER BY, поведение будет
определяться `sort_overflow_mode`, который по умолчанию установлен в `throw`.
## max_bytes_to_transfer {#max_bytes_to_transfer} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество байт (необработанных данных), которые могут быть переданы удаленному
серверу или сохранены во временной таблице, когда выполняется GLOBAL IN/JOIN.


## max_execution_time {#max_execution_time} 

|Тип|По умолчанию|
|---|---|
|`Секунды`|`0`|

Максимальное время выполнения запроса в секундах.

Параметр `max_execution_time` может быть немного запутанным. Он работает на основе интерполяции относительно скорости выполнения текущего запроса (это поведение контролируется параметром [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed)).

ClickHouse прервет запрос, если предполагаемое время выполнения превысит указанное `max_execution_time`. По умолчанию `timeout_before_checking_execution_speed` установлен на 10 секунд. Это означает, что через 10 секунд выполнения запроса ClickHouse начнет оценивать общее время выполнения. Если, например, `max_execution_time` установлен на 3600 секунд (1 час), ClickHouse завершит запрос, если оцененное время превысит этот лимит в 3600 секунд. Если вы установите `timeout_before_checking_execution_speed` в 0, ClickHouse будет использовать реальное время в качестве основы для `max_execution_time`.

Если время выполнения запроса превышает указанное количество секунд, поведение будет определяться параметром `timeout_overflow_mode`, который по умолчанию установлен на `throw`.

:::note
Тайм-аут проверяется, и запрос может быть остановлен только в определенных местах во время обработки данных. В настоящее время он не может быть остановлен во время слияния состояний агрегации или во время анализа запроса, и фактическое время выполнения будет больше, чем значение этой настройки.
:::
## max_execution_time_leaf {#max_execution_time_leaf} 

|Тип|По умолчанию|
|---|---|
|`Секунды`|`0`|

Семантически аналогично [`max_execution_time`](#max_execution_time), но применяется только на конечных узлах для распределенных или удаленных запросов.

Например, если мы хотим ограничить время выполнения на конечном узле до `10s`, но не имеем ограничения на начальном узле, вместо того чтобы иметь `max_execution_time` в настройках вложенного подзапроса:

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t SETTINGS max_execution_time = 10));
```

Мы можем использовать `max_execution_time_leaf` в качестве настроек запроса:

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t)) SETTINGS max_execution_time_leaf = 10;
```
## max_expanded_ast_elements {#max_expanded_ast_elements} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`500000`|

Максимальный размер синтаксического дерева запроса в количестве узлов после расширения псевдонимов и звездочки.
## max_fetch_partition_retries_count {#max_fetch_partition_retries_count} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5`|

Количество попыток при получении партиции с другого узла.
## max_final_threads {#max_final_threads} 

|Тип|По умолчанию|
|---|---|
|`MaxThreads`|`'auto(14)'`|

Устанавливает максимальное количество параллельных потоков для фазы чтения данных запроса `SELECT` с модификатором [FINAL](/sql-reference/statements/select/from#final-modifier).

Возможные значения:

- Положительное целое число.
- 0 или 1 — Отключено. Запросы `SELECT` выполняются в одном потоке.
## max_http_get_redirects {#max_http_get_redirects} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество переходов HTTP GET редиректов, разрешенных. Обеспечивает дополнительные меры безопасности для предотвращения перенаправления ваших запросов на неожиданные сервисы с помощью вредоносного сервера.

Существуют случаи, когда внешний сервер перенаправляет на другой адрес, но этот адрес выглядит как внутренний в инфраструктуре компании, и отправив HTTP-запрос на внутренний сервер, вы могли бы запросить внутренний API из внутренней сети, минуя аутентификацию, или даже запрашивать другие сервисы, такие как Redis или Memcached. Когда у вас нет внутренней инфраструктуры (включая что-то, работащее на вашем localhost), или вы доверяете серверу, безопасно разрешать редиректы. Однако помните, если URL использует HTTP вместо HTTPS, и вы должны доверять не только удаленному серверу, но и вашему интернет-провайдеру и каждой сети посередине.
## max_hyperscan_regexp_length {#max_hyperscan_regexp_length} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Определяет максимальную длину для каждого регулярного выражения в [функциях множественного совпадения hyperscan](/sql-reference/functions/string-search-functions#multimatchany).

Возможные значения:

- Положительное целое число.
- 0 - Длина не ограничена.

**Пример**

Запрос:

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 3;
```

Результат:

```text
┌─multiMatchAny('abcd', ['ab', 'bcd', 'c', 'd'])─┐
│                                              1 │
└────────────────────────────────────────────────┘
```

Запрос:

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 2;
```

Результат:

```text
Exception: Длина регулярного выражения слишком большая.
```

**См. Также**

- [max_hyperscan_regexp_total_length](#max_hyperscan_regexp_total_length)
## max_hyperscan_regexp_total_length {#max_hyperscan_regexp_total_length} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Устанавливает максимальную общую длину всех регулярных выражений в каждой [функции множественного совпадения hyperscan](/sql-reference/functions/string-search-functions#multimatchany).

Возможные значения:

- Положительное целое число.
- 0 - Длина не ограничена.

**Пример**

Запрос:

```sql
SELECT multiMatchAny('abcd', ['a','b','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

Результат:

```text
┌─multiMatchAny('abcd', ['a', 'b', 'c', 'd'])─┐
│                                           1 │
└─────────────────────────────────────────────┘
```

Запрос:

```sql
SELECT multiMatchAny('abcd', ['ab','bc','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

Результат:

```text
Exception: Общая длина регулярных выражений слишком большая.
```

**См. Также**

- [max_hyperscan_regexp_length](#max_hyperscan_regexp_length)
## max_insert_block_size {#max_insert_block_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1048449`|

Размер блоков (в количестве строк), которые формируются для вставки в таблицу. Эта настройка применяется только в тех случаях, когда сервер формирует блоки. Например, для INSERT через HTTP интерфейс сервер анализирует формат данных и формирует блоки указанного размера. Но при использовании clickhouse-client клиент сам разбирает данные, и настройка `max_insert_block_size` на сервере не влияет на размер вставляемых блоков. Настройка также не имеет значения при использовании INSERT SELECT, так как данные вставляются с использованием тех же блоков, которые формируются после SELECT.

По умолчанию значение немного больше, чем `max_block_size`. Причина в том, что определенные движки таблиц (`*MergeTree`) формируют часть данных на диске для каждого вставленного блока, что является довольно крупной сущностью. Аналогично, таблицы `*MergeTree` сортируют данные во время вставки, и достаточно большой размер блока позволяет сортировать больше данных в RAM. 
## max_insert_delayed_streams_for_parallel_write {#max_insert_delayed_streams_for_parallel_write} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество потоков (колонок), для задержки финальной сброса части. По умолчанию - авто (100 в случае, если базовое хранилище поддерживает параллельную запись, например S3, и отключено в противном случае).
## max_insert_threads {#max_insert_threads} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество потоков для выполнения запроса `INSERT SELECT`.

Возможные значения:

- 0 (или 1) — `INSERT SELECT` без параллельного выполнения.
- Положительное целое число, большее 1.

Облачное значение по умолчанию: от `2` до `4`, в зависимости от размера сервиса.

Параллельный `INSERT SELECT` имеет эффект только если часть `SELECT` выполняется параллельно, см. настройку [max_threads](#max_threads). Более высокие значения приведут к более высокому использованию памяти.
## max_joined_block_size_rows {#max_joined_block_size_rows} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`65409`|

Максимальный размер блока для результата JOIN (если алгоритм соединения это поддерживает). 0 означает неограниченно.
## max_limit_for_ann_queries {#max_limit_for_ann_queries} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000`|

Запросы SELECT с LIMIT больше этого параметра не могут использовать индексы векторного сходства. Помогает предотвратить переполнение памяти в индексах векторного сходства.
## max_live_view_insert_blocks_before_refresh {#max_live_view_insert_blocks_before_refresh} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`64`|

Ограничивает максимальное количество вставленных блоков, после которых сливаемые блоки сбрасываются и запрос повторно выполняется.
## max_local_read_bandwidth {#max_local_read_bandwidth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальная скорость локальных чтений в байтах в секунду.
## max_local_write_bandwidth {#max_local_write_bandwidth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальная скорость локальных записей в байтах в секунду.
## max_memory_usage {#max_memory_usage} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Облачное значение по умолчанию: зависит от объема RAM на реплике.

Максимальный объем RAM, который можно использовать для выполнения запроса на одном сервере. Значение `0` означает неограничено.

Эта настройка не учитывает объем доступной памяти или общий объем памяти на машине. Ограничение применяется к одному запросу на одном сервере.

Вы можете использовать `SHOW PROCESSLIST`, чтобы увидеть текущее потребление памяти для каждого запроса. Пиковое потребление памяти отслеживается для каждого запроса и записывается в журнал.

Использование памяти не отслеживается полностью для состояний следующих агрегатных функций с аргументами `String` и `Array`:
- `min`
- `max`
- `any`
- `anyLast`
- `argMin`
- `argMax`

Потребление памяти также ограничено параметрами [`max_memory_usage_for_user`](/operations/settings/settings#max_memory_usage_for_user) и [`max_server_memory_usage`](/operations/server-configuration-parameters/settings#max_server_memory_usage).
## max_memory_usage_for_user {#max_memory_usage_for_user} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальный объем RAM для выполнения запросов пользователя на одном сервере. Значение 0 означает неограничено.

По умолчанию объем не ограничен (`max_memory_usage_for_user = 0`).

Смотрите также описание [`max_memory_usage`](/operations/settings/settings#max_memory_usage).

Например, если вы хотите установить `max_memory_usage_for_user` на 1000 байт для пользователя с именем `clickhouse_read`, вы можете использовать оператор

```sql
ALTER USER clickhouse_read SETTINGS max_memory_usage_for_user = 1000;
```

Вы можете проверить, что это сработало, выйдя из вашего клиента, снова войдя, а затем используйте функцию `getSetting`:

```sql
SELECT getSetting('max_memory_usage_for_user');
```
## max_network_bandwidth {#max_network_bandwidth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Ограничивает скорость обмена данными по сети в байтах в секунду. Эта настройка применяется к каждому запросу.

Возможные значения:

- Положительное целое число.
- 0 — Управление пропускной способностью отключено.
## max_network_bandwidth_for_all_users {#max_network_bandwidth_for_all_users} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Ограничивает скорость, с которой данные обмениваются по сети в байтах в секунду. Эта настройка применяется ко всем одновременно выполняемым запросам на сервере.

Возможные значения:

- Положительное целое число.
- 0 — Управление скоростью данных отключено.
## max_network_bandwidth_for_user {#max_network_bandwidth_for_user} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Ограничивает скорость обмена данными по сети в байтах в секунду. Эта настройка применяется ко всем одновременно выполняемым запросам, выполняемым одним пользователем.

Возможные значения:

- Положительное целое число.
- 0 — Управление скоростью данных отключено.
## max_network_bytes {#max_network_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Ограничивает объем данных (в байтах), который принимается или передается по сети при выполнении запроса. Эта настройка применяется к каждому отдельному запросу.

Возможные значения:

- Положительное целое число.
- 0 — Управление объемом данных отключено.
## max_number_of_partitions_for_independent_aggregation {#max_number_of_partitions_for_independent_aggregation} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`128`|

Максимальное количество партиций в таблице для применения оптимизации.
## max_parallel_replicas {#max_parallel_replicas} 

|Тип|По умолчанию|
|---|---|
|`NonZeroUInt64`|`1000`|

Максимальное количество реплик для каждой шард, когда выполняется запрос.

Возможные значения:

- Положительное целое число.

**Дополнительная информация**

Эти параметры будут давать разные результаты в зависимости от используемых настроек.

:::note
Эта настройка будет давать некорректные результаты, когда используются соединения или подзапросы, и все таблицы не соответствуют определенным требованиям. См. [Распределенные подзапросы и max_parallel_replicas](/operations/settings/settings#max_parallel_replicas) для получения дополнительных деталей.
:::
### Параллельная обработка с использованием ключа `SAMPLE`

Запрос может обрабатываться быстрее, если он выполняется на нескольких серверах параллельно. Однако производительность запроса может ухудшиться в следующих случаях:

- Положение ключа выборки в ключе партиционирования не позволяет эффективно сканировать диапазон.
- Добавление ключа выборки к таблице делает фильтрацию по другим колонкам менее эффективной.
- Ключ выборки является выражением, которое дорого рассчитывать.
- Распределение задержки кластера имеет длинный хвост, так что запрос большего количества серверов увеличивает общую задержку запроса.
### Параллельная обработка с использованием [parallel_replicas_custom_key](#parallel_replicas_custom_key)

Эта настройка полезна для любой реплицированной таблицы.
## max_parser_backtracks {#max_parser_backtracks} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000`|

Максимальное количество возвратов парсера (как много раз он пробует разные альтернативы в процессе рекурсивного спуска парсинга).
## max_parser_depth {#max_parser_depth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Ограничивает максимальную глубину рекурсии в рекурсивном спускаемом парсере. Позволяет контролировать размер стека.

Возможные значения:

- Положительное целое число.
- 0 — Глубина рекурсии не ограничена.
## max_parsing_threads {#max_parsing_threads} 

|Тип|По умолчанию|
|---|---|
|`MaxThreads`|`'auto(14)'`|

Максимальное количество потоков для разбора данных в входных форматах, которые поддерживают параллельный разбор. По умолчанию это определяется автоматически.
## max_partition_size_to_drop {#max_partition_size_to_drop} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`50000000000`|

Ограничение на удаление партиций за время выполнения запроса. Значение 0 означает, что вы можете удалять партиции без каких-либо ограничений.

Облачное значение по умолчанию: 1 ТБ.

:::note
Эта настройка запроса перезаписывает соответствующую серверную настройку, см. [max_partition_size_to_drop](/operations/server-configuration-parameters/settings#max_partition_size_to_drop)
:::
## max_partitions_per_insert_block {#max_partitions_per_insert_block} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100`|

Ограничивает максимальное количество партиций в одном вставляемом блоке, и выбрасывает исключение, если блок содержит слишком много партиций.

- Положительное целое число.
- `0` — Неограниченное количество партиций.

**Детали**

При вставке данных ClickHouse вычисляет количество партиций в вставляемом блоке. Если количество партиций превышает `max_partitions_per_insert_block`, ClickHouse либо записывает предупреждение, либо выбрасывает исключение в зависимости от `throw_on_max_partitions_per_insert_block`. Исключения имеют следующий текст:

> "Слишком много партиций для одного INSERT блока (`partitions_count` партиций, лимит - " + toString(max_partitions) + "). Лимит контролируется настройкой `max_partitions_per_insert_block`. Большое количество партиций является общим заблуждением. Это приведет к серьезному отрицательному влиянию на производительность, включая медленный запуск сервера, медленные запросы INSERT и медленные запросы SELECT. Рекомендуемое общее количество партиций для таблицы - менее 1000..10000. Обратите внимание, что партиционирование не предназначено для ускорения запросов SELECT (ORDER BY ключа достаточно, чтобы сделать диапазонные запросы быстрыми). Партиции предназначены для манипуляции данными (DROP PARTITION и т. д.)."

:::note
Эта настройка является порогом безопасности, потому что использование большого количества партиций является общим заблуждением.
:::
## max_partitions_to_read {#max_partitions_to_read} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`-1`|

Ограничивает максимальное количество партиций, которые могут быть доступны в одном запросе.

Значение настройки, указанное при создании таблицы, может быть переопределено через уровень настройки запроса.

Возможные значения:

- Положительное целое число.
- `-1` - неограничено (по умолчанию).

:::note
Вы также можете указать настройку MergeTree [`max_partitions_to_read`](/operations/settings/settings#max_partitions_to_read) в настройках таблиц.
:::
## max_parts_to_move {#max_parts_to_move} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Ограничивает количество частей, которые могут быть перемещены в одном запросе. Ноль означает неограниченно.
## max_query_size {#max_query_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`262144`|

Максимальное количество байтов строки запроса, обрабатываемой SQL парсером. Данные в предлоге VALUES запросов INSERT обрабатываются отдельным парсером потока (который потребляет O(1) RAM) и не затрагиваются этим ограничением.

:::note
`max_query_size` не может быть установлен внутри SQL-запроса (например, `SELECT now() SETTINGS max_query_size=10000`), потому что ClickHouse нужно выделить буфер для разбора запроса, и размер этого буфера определяется настройкой `max_query_size`, которую необходимо настроить до выполнения запроса.
:::
## max_read_buffer_size {#max_read_buffer_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1048576`|

Максимальный размер буфера для чтения с файловой системы.
## max_read_buffer_size_local_fs {#max_read_buffer_size_local_fs} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`131072`|

Максимальный размер буфера для чтения с локальной файловой системы. Если установить в 0, будет использоваться max_read_buffer_size.
## max_read_buffer_size_remote_fs {#max_read_buffer_size_remote_fs} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальный размер буфера для чтения с удаленной файловой системы. Если установить в 0, будет использоваться max_read_buffer_size.
## max_recursive_cte_evaluation_depth {#max_recursive_cte_evaluation_depth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Максимальный лимит на глубину оценки рекурсивных CTE.
## max_remote_read_network_bandwidth {#max_remote_read_network_bandwidth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальная скорость обмена данными по сети в байтах в секунду для чтения.
## max_remote_write_network_bandwidth {#max_remote_write_network_bandwidth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальная скорость обмена данными по сети в байтах в секунду для записи.
## max_replica_delay_for_distributed_queries {#max_replica_delay_for_distributed_queries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`300`|

Отключает отстающие реплики для распределенных запросов. См. [Репликация](../../engines/table-engines/mergetree-family/replication.md).

Устанавливает время в секундах. Если задержка реплики больше или равна установленному значению, эта реплика не используется.

Возможные значения:

- Положительное целое число.
- 0 — Задержки реплик не проверяются.

Чтобы предотвратить использование любой реплики с ненулевой задержкой, установите этот параметр на 1.

Используется при выполнении `SELECT` из распределенной таблицы, указывающей на реплицированные таблицы.
## max_result_bytes {#max_result_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Ограничивает размер результата в байтах (не сжатый). Запрос остановится после обработки блока данных, если достигнут порог, но он не обрежет последний блок результата, поэтому размер результата может быть больше порога.

**Предостережения**

Размер результата в памяти учитывается для этого порога. Даже если размер результата мал, он может ссылаться на большие структуры данных в памяти, представляя словари колонок LowCardinality и Arenas колонок AggregateFunction, поэтому порог может быть превышен, несмотря на малый размер результата.

:::warning
Эта настройка является довольно низкоуровневой и должна использоваться с осторожностью.
:::
## max_result_rows {#max_result_rows} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Облачное значение по умолчанию: `0`.

Ограничивает количество строк в результате. Также проверяется для подзапросов и на удаленных серверах при выполнении частей распределенного запроса. Ограничение не применяется, когда значение равно `0`.

Запрос остановится после обработки блока данных, если достигнут порог, но он не обрежет последний блок результата, поэтому размер результата может быть больше порога.
## max_rows_in_distinct {#max_rows_in_distinct} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество различных строк при использовании DISTINCT.
## max_rows_in_join {#max_rows_in_join} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Ограничивает количество строк в хеш-таблице, используемой при соединении таблиц.

Эта настройка применяется к операциям [SELECT ... JOIN](/sql-reference/statements/select/join) и к движку таблиц [Join](/engines/table-engines/special/join).

Если запрос содержит несколько соединений, ClickHouse проверяет эту настройку для каждого промежуточного результата.

ClickHouse может продолжить с различными действиями, когда лимит достигнут. Используйте настройку [`join_overflow_mode`](/operations/settings/settings#join_overflow_mode), чтобы выбрать действие.

Возможные значения:

- Положительное целое число.
- `0` — Неограниченное количество строк.
## max_rows_in_set {#max_rows_in_set} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество строк для набора данных в операторе IN, сформированном из подзапроса.
## max_rows_in_set_to_optimize_join {#max_rows_in_set_to_optimize_join} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальный размер набора для фильтрации соединенных таблиц по наборам строк друг друга перед соединением.

Возможные значения:

- 0 — Отключить.
- Любое положительное целое число.
## max_rows_to_group_by {#max_rows_to_group_by} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество уникальных ключей, полученных из агрегации. Эта настройка позволяет ограничить использование памяти при агрегации.

Если агрегация во время GROUP BY генерирует более указанного количества строк (уникальных ключей GROUP BY), поведение будет определяться режимом `group_by_overflow_mode`, который по умолчанию установлен на `throw`, но также может быть переключен в приближенный режим GROUP BY.
## max_rows_to_read {#max_rows_to_read} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество строк, которые можно прочитать из таблицы при выполнении запроса. Ограничение проверяется для каждого обработанного чанка данных, применяется только к самой глубокой таблице выражения и при чтении с удаленного сервера, проверяется только на удаленном сервере.
## max_rows_to_read_leaf {#max_rows_to_read_leaf} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество строк, которые можно прочитать из локальной таблицы на конечном узле при выполнении распределенного запроса. В то время как распределенные запросы могут выдать несколько подзапросов к каждому шард (лист) - это ограничение будет проверяться только на этапе чтения на листовых узлах и игнорироваться на этапе слияния результатов на корневом узле.

Например, кластер состоит из 2 шард, и каждая шард содержит таблицу с 100 строками. Распределенный запрос, который должен прочитать все данные из обеих таблиц с настройкой `max_rows_to_read=150`, завершится ошибкой, так как всего будет 200 строк. Запрос с `max_rows_to_read_leaf=150` будет успешным, так как листовые узлы будут читать максимум 100 строк.

Ограничение проверяется для каждого обработанного чанка данных.

:::note
Эта настройка нестабильна с `prefer_localhost_replica=1`.
:::
## max_rows_to_sort {#max_rows_to_sort} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество строк до сортировки. Это позволяет ограничить использование памяти при сортировке. Если необходимо обработать более указанного количества записей для операции ORDER BY, поведение будет определяться `sort_overflow_mode`, который по умолчанию установлен на `throw`.
## max_rows_to_transfer {#max_rows_to_transfer} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальный размер (в строках), который может быть передан на удаленный сервер или сохранен во временной таблице, когда выполняется раздел GLOBAL IN/JOIN.
## max_sessions_for_user {#max_sessions_for_user} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество одновременных сессий для аутентифицированного пользователя на сервере ClickHouse.

Пример:

```xml
<profiles>
    <single_session_profile>
        <max_sessions_for_user>1</max_sessions_for_user>
    </single_session_profile>
    <two_sessions_profile>
        <max_sessions_for_user>2</max_sessions_for_user>
    </two_sessions_profile>
    <unlimited_sessions_profile>
        <max_sessions_for_user>0</max_sessions_for_user>
    </unlimited_sessions_profile>
</profiles>
<users>
    <!-- Пользователь Алиса может подключаться к серверу ClickHouse не более одного раза одновременно. -->
    <Alice>
        <profile>single_session_user</profile>
    </Alice>
    <!-- Пользователь Боб может использовать 2 одновременные сессии. -->
    <Bob>
        <profile>two_sessions_profile</profile>
    </Bob>
    <!-- Пользователь Чарльз может использовать произвольное количество одновременных сессий. -->
    <Charles>
        <profile>unlimited_sessions_profile</profile>
    </Charles>
</users>
```

Возможные значения:
- Положительное целое число.
- `0` - бесконечное количество одновременных сессий (по умолчанию).
## max_size_to_preallocate_for_aggregation {#max_size_to_preallocate_for_aggregation} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000000000`|

На сколько элементов разрешается предварительно выделять место во всех хеш-таблицах в целом перед агрегацией.
## max_size_to_preallocate_for_joins {#max_size_to_preallocate_for_joins} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000000000`|

На сколько элементов разрешается предварительно выделять место во всех хеш-таблицах в целом перед соединениями.
## max_streams_for_merge_tree_reading {#max_streams_for_merge_tree_reading} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Если не ноль, ограничьте количество потоков чтения для таблицы MergeTree.
## max_streams_multiplier_for_merge_tables {#max_streams_multiplier_for_merge_tables} 

|Тип|По умолчанию|
|---|---|
|`Float`|`5`|

Запрашивает больше потоков при чтении из таблицы Merge. Потоки будут распределены по таблицам, которые использует таблица Merge. Это позволяет более равномерно распределить работу между потоками и особенно полезно, когда объединенные таблицы различаются по размеру.
## max_streams_to_max_threads_ratio {#max_streams_to_max_threads_ratio} 

|Тип|По умолчанию|
|---|---|
|`Float`|`1`|

Позволяет использовать больше источников, чем количество потоков - для более равномерного распределения работы между потоками. Предполагается, что это временное решение, поскольку в будущем будет возможно сделать количество источников равным количеству потоков, но для каждого источника динамически выбирать доступную работу для себя.
## max_subquery_depth {#max_subquery_depth} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100`|

Если запрос содержит более указанного количества вложенных подзапросов, выбрасывает исключение.

:::tip
Это позволяет провести проверку, чтобы защитить пользователей вашего кластера от написания чрезмерно сложных запросов.
:::
## max_table_size_to_drop {#max_table_size_to_drop} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`50000000000`|

Ограничение на удаление таблиц за время выполнения запроса. Значение 0 означает, что вы можете удалять все таблицы без каких-либо ограничений.

Облачное значение по умолчанию: 1 ТБ.

:::note
Эта настройка запроса перезаписывает соответствующую серверную настройку, см. [max_table_size_to_drop](/operations/server-configuration-parameters/settings#max_table_size_to_drop)
:::
## max_temporary_columns {#max_temporary_columns} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество временных колонок, которые должны храниться в RAM одновременно при выполнении запроса, включая постоянные колонки. Если запрос создает больше указанного количества временных колонок в памяти в результате промежуточных вычислений, тогда выбрасывается исключение.

:::tip
Эта настройка полезна для предотвращения чрезмерно сложных запросов.
:::

Значение `0` означает неограничено.
## max_temporary_data_on_disk_size_for_query {#max_temporary_data_on_disk_size_for_query} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество данных, потребляемых временными файлами на диске в байтах для всех одновременно выполняемых запросов.

Возможные значения:

- Положительное целое число.
- `0` — неограничено (по умолчанию).
## max_temporary_data_on_disk_size_for_user {#max_temporary_data_on_disk_size_for_user} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество данных, потребляемых временными файлами на диске в байтах для всех одновременно выполняемых пользовательских запросов.

Возможные значения:

- Положительное целое число.
- `0` — неограничено (по умолчанию).
## max_temporary_non_const_columns {#max_temporary_non_const_columns} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Как и `max_temporary_columns`, максимальное количество временных колонок, которые должны храниться в RAM одновременно при выполнении запроса, но без учета постоянных колонок.

:::note
Постоянные колонки формируются довольно часто при выполнении запроса, но требуют примерно нулевых вычислительных ресурсов.
:::
## max_threads {#max_threads} 

|Тип|По умолчанию|
|---|---|
|`MaxThreads`|`'auto(14)'`|

Максимальное количество потоков для обработки запросов, исключая потоки для извлечения данных с удаленных серверов (см. параметр 'max_distributed_connections').

Этот параметр применяется к потокам, которые выполняют одни и те же этапы пайплайна обработки запросов параллельно. Например, при чтении из таблицы, если возможно одновременно оценивать выражения с функциями, фильтровать с WHERE и производить предагрегацию для GROUP BY, используя по крайней мере 'max_threads' количество потоков, то будут использоваться 'max_threads'.

Для запросов, которые быстро завершаются из-за LIMIT, вы можете установить более низкое значение 'max_threads'. Например, если необходимое количество записей находится в каждом блоке, и max_threads = 8, то будет извлечено 8 блоков, хотя одной записи было бы достаточно.

Чем меньше значение `max_threads`, тем меньше потребляется памяти.
## max_threads_for_indexes {#max_threads_for_indexes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество потоков для обработки индексов.
## max_untracked_memory {#max_untracked_memory} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`4194304`|

Небольшие аллокации и деаллокации группируются в локальную переменную потока и отслеживаются или профилируются только тогда, когда их количество (в абсолютном значении) становится больше указанного значения. Если значение превышает 'memory_profiler_step', оно будет эффективно снижено до 'memory_profiler_step'.
## memory_overcommit_ratio_denominator {#memory_overcommit_ratio_denominator} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1073741824`|

Он представляет собой мягкий лимит памяти, когда достигнут жесткий лимит на глобальном уровне. Это значение используется для вычисления коэффициента перерасхода для запроса. Ноль означает пропуск запроса. Узнайте больше о [перерасходе памяти](memory-overcommit.md).

## memory_overcommit_ratio_denominator_for_user {#memory_overcommit_ratio_denominator_for_user} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1073741824`|

Он представляет собой мягкий лимит памяти, когда достигнут жесткий лимит на уровне пользователя. Это значение используется для вычисления коэффициента перерасхода для запроса. Ноль означает пропуск запроса. Узнайте больше о [перерасходе памяти](memory-overcommit.md).

## memory_profiler_sample_max_allocation_size {#memory_profiler_sample_max_allocation_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Собирает случайные выделения памяти размером меньше или равным указанному значению с вероятностью, равной `memory_profiler_sample_probability`. 0 означает отключение. Возможно, вы захотите установить 'max_untracked_memory' в 0, чтобы этот предел работал должным образом.

## memory_profiler_sample_min_allocation_size {#memory_profiler_sample_min_allocation_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Собирает случайные выделения памяти размером больше или равным указанному значению с вероятностью, равной `memory_profiler_sample_probability`. 0 означает отключение. Возможно, вы захотите установить 'max_untracked_memory' в 0, чтобы этот предел работал должным образом.

## memory_profiler_sample_probability {#memory_profiler_sample_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Собирает случайные выделения и освобождения памяти и записывает их в system.trace_log с 'MemorySample' trace_type. Вероятность относится к каждому выделению/освобождению вне зависимости от размера выделения (можно изменить с помощью `memory_profiler_sample_min_allocation_size` и `memory_profiler_sample_max_allocation_size`). Обратите внимание, что выборка происходит только тогда, когда объем неучтенной памяти превышает 'max_untracked_memory'. Возможно, вам потребуется установить 'max_untracked_memory' в 0 для более тонкой выборки.

## memory_profiler_step {#memory_profiler_step} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`4194304`|

Устанавливает шаг анализатора памяти. Каждый раз, когда использование памяти запросом становится больше каждого следующего шага в байтах, анализатор памяти будет собирать стек вызовов выделения и записывать его в [trace_log](/operations/system-tables/trace_log).

Возможные значения:

- Положительное целое число в байтах.

- 0 для отключения анализатора памяти.

## memory_tracker_fault_probability {#memory_tracker_fault_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Для тестирования `безопасности исключений` - выбрасывать исключение каждый раз, когда вы выделяете память с заданной вероятностью.

## memory_usage_overcommit_max_wait_microseconds {#memory_usage_overcommit_max_wait_microseconds} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5000000`|

Максимальное время, которое поток будет ждать, чтобы память была освобождена в случае перерасхода памяти на уровне пользователя. Если время ожидания истечет и память не будет освобождена, будет выброшено исключение. Узнайте больше о [перерасходе памяти](memory-overcommit.md).

## merge_table_max_tables_to_look_for_schema_inference {#merge_table_max_tables_to_look_for_schema_inference} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

При создании `Merge` таблицы без явной схемы или при использовании табличной функции `merge`, схема выводится как объединение не более указанного количества соответствующих таблиц. Если будет большее количество таблиц, схема будет выведена из первого указанного количества таблиц.

## merge_tree_coarse_index_granularity {#merge_tree_coarse_index_granularity} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`8`|

При поиске данных ClickHouse проверяет метки данных в файловом индексе. Если ClickHouse обнаруживает, что необходимые ключи находятся в некотором диапазоне, он делит этот диапазон на `merge_tree_coarse_index_granularity` поддиапазонов и выполняет поиск необходимых ключей там рекурсивно.

Возможные значения:

- Любое положительное четное целое число.

## merge_tree_compact_parts_min_granules_to_multibuffer_read {#merge_tree_compact_parts_min_granules_to_multibuffer_read} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`16`|

Действительно только в ClickHouse Cloud. Число гранул в полосе компактной части таблиц MergeTree, чтобы использовать многобуферный считыватель, который поддерживает параллельное чтение и предварительную выборку. При чтении из удаленной файловой системы использование многобуферного считывателя увеличивает количество запросов на чтение. 

## merge_tree_determine_task_size_by_prewhere_columns {#merge_tree_determine_task_size_by_prewhere_columns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать только размер колонок prewhere для определения размера задачи чтения. 

## merge_tree_max_bytes_to_use_cache {#merge_tree_max_bytes_to_use_cache} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`2013265920`|

Если ClickHouse должен прочитать более `merge_tree_max_bytes_to_use_cache` байт в одном запросе, он не использует кэш некорректированных блоков.

Кэш некорректированных блоков хранит данные, извлеченные для запросов. ClickHouse использует этот кэш для ускорения ответов на повторяемые небольшие запросы. Эта настройка защищает кэш от разрушения запросами, которые читают большой объем данных. Настройка сервера [uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) определяет размер кэша некорректированных блоков.

Возможные значения:

- Любое положительное целое число.

## merge_tree_max_rows_to_use_cache {#merge_tree_max_rows_to_use_cache} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1048576`|

Если ClickHouse должен прочитать более `merge_tree_max_rows_to_use_cache` строк в одном запросе, он не использует кэш некорректированных блоков.

Кэш некорректированных блоков хранит данные, извлеченные для запросов. ClickHouse использует этот кэш для ускорения ответов на повторяемые небольшие запросы. Эта настройка защищает кэш от разрушения запросами, которые читают большой объем данных. Настройка сервера [uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) определяет размер кэша некорректированных блоков.

Возможные значения:

- Любое положительное целое число.

## merge_tree_min_bytes_for_concurrent_read {#merge_tree_min_bytes_for_concurrent_read} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`251658240`|

Если количество байт, которые необходимо прочитать из одного файла таблицы [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md), превышает `merge_tree_min_bytes_for_concurrent_read`, то ClickHouse пытается параллельно читать из этого файла в нескольких потоках.

Возможное значение:

- Положительное целое число.

## merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem {#merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Минимальное количество байт для чтения из одного файла перед тем, как движок [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) сможет параллелизовать чтение при чтении из удаленной файловой системы. Мы не рекомендуем использовать эту настройку.

Возможные значения:

- Положительное целое число.

## merge_tree_min_bytes_for_seek {#merge_tree_min_bytes_for_seek} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Если расстояние между двумя блоками данных, которые необходимо прочитать в одном файле, составляет менее `merge_tree_min_bytes_for_seek` байтов, то ClickHouse последовательно читает диапазон файла, который содержит оба блока, избегая тем самым дополнительных поисков.

Возможные значения:

- Любое положительное целое число.

## merge_tree_min_bytes_per_task_for_remote_reading {#merge_tree_min_bytes_per_task_for_remote_reading} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`2097152`|

Минимальное количество байт для чтения на задачу.

## merge_tree_min_read_task_size {#merge_tree_min_read_task_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`8`|

Жесткий нижний предел размера задачи (даже когда количество гранул низкое и количество доступных потоков высокое, мы не будем выделять меньшие задачи).

## merge_tree_min_rows_for_concurrent_read {#merge_tree_min_rows_for_concurrent_read} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`163840`|

Если количество строк, которые нужно прочитать из файла таблицы [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md), превышает `merge_tree_min_rows_for_concurrent_read`, то ClickHouse пытается выполнить параллельное чтение из этого файла в нескольких потоках.

Возможные значения:

- Положительное целое число.

## merge_tree_min_rows_for_concurrent_read_for_remote_filesystem {#merge_tree_min_rows_for_concurrent_read_for_remote_filesystem} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Минимальное количество строк для чтения из одного файла перед тем, как движок [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) сможет параллелизовать чтение при чтении из удаленной файловой системы. Мы не рекомендуем использовать эту настройку.

Возможные значения:

- Положительное целое число.

## merge_tree_min_rows_for_seek {#merge_tree_min_rows_for_seek} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Если расстояние между двумя блоками данных, которые нужно прочитать в одном файле, составляет менее `merge_tree_min_rows_for_seek` строк, то ClickHouse не ищет по файлу, а читает данные последовательно.

Возможные значения:

- Любое положительное целое число.

## merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability {#merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Для тестирования `PartsSplitter` - разделяет диапазоны чтения на пересекающиеся и непересекающиеся каждый раз, когда вы читаете из MergeTree с заданной вероятностью.

## merge_tree_use_const_size_tasks_for_remote_reading {#merge_tree_use_const_size_tasks_for_remote_reading} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать задачи фиксированного размера для чтения из удаленной таблицы.

## merge_tree_use_deserialization_prefixes_cache {#merge_tree_use_deserialization_prefixes_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает кэширование метаданных колонок из префиксов файла при чтении из широких частей в MergeTree.

## merge_tree_use_prefixes_deserialization_thread_pool {#merge_tree_use_prefixes_deserialization_thread_pool} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает использование пула потоков для параллельного чтения префиксов в широких частях MergeTree. Размер этого пула потоков контролируется серверной настройкой `max_prefixes_deserialization_thread_pool_size`.

## merge_tree_use_v1_object_and_dynamic_serialization {#merge_tree_use_v1_object_and_dynamic_serialization} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Когда включено, версия сериализации V1 типов JSON и Dynamic будет использоваться в MergeTree вместо V2. Изменение этой настройки вступает в силу только после перезапуска сервера.

## metrics_perf_events_enabled {#metrics_perf_events_enabled} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если включено, некоторые из событий производительности будут измеряться во время выполнения запросов.

## metrics_perf_events_list {#metrics_perf_events_list} 

Список показателей производительности, разделенных запятыми, которые будут измеряться во время выполнения запросов. Пустой означает все события. Смотрите PerfEventInfo в источниках для доступных событий.

## min_bytes_to_use_direct_io {#min_bytes_to_use_direct_io} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Минимальный объем данных, необходимый для использования прямого ввода-вывода к диску хранилища.

ClickHouse использует эту настройку при чтении данных из таблиц. Если общий объем хранимых данных для чтения превышает `min_bytes_to_use_direct_io` байт, ClickHouse читает данные с диска хранилища с опцией `O_DIRECT`.

Возможные значения:

- 0 — Прямой ввод-вывод отключен.
- Положительное целое число.

## min_bytes_to_use_mmap_io {#min_bytes_to_use_mmap_io} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Это экспериментальная настройка. Устанавливает минимальный объем памяти для чтения больших файлов без копирования данных из ядра в пространство пользователя. Рекомендуемый предел составляет около 64 МБ, потому что [mmap/munmap](https://en.wikipedia.org/wiki/Mmap) работает медленно. Это имеет смысл только для больших файлов и помогает только в том случае, если данные находятся в кэше страниц.

Возможные значения:

- Положительное целое число.
- 0 — Большие файлы читаются только с копированием данных из ядра в пространство пользователя.

## min_chunk_bytes_for_parallel_parsing {#min_chunk_bytes_for_parallel_parsing} 

|Тип|По умолчанию|
|---|---|
|`NonZeroUInt64`|`10485760`|

- Тип: беззнаковое целое
- Значение по умолчанию: 1 МБ

Минимальный размер чанка в байтах, который каждый поток будет парсить параллельно.

## min_compress_block_size {#min_compress_block_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`65536`|

Для таблиц [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md). Чтобы уменьшить задержку при обработке запросов, блок компрессируется при записи следующей метки, если его размер составляет не менее `min_compress_block_size`. По умолчанию 65,536.

Фактический размер блока, если необработанные данные меньше `max_compress_block_size`, не меньше этого значения и не меньше объема данных для одной метки.

Рассмотрим пример. Предположим, что `index_granularity` был установлен на 8192 во время создания таблицы.

Мы записываем колонку типа UInt32 (4 байта на значение). При записи 8192 строк общее будет 32 КБ данных. Поскольку min_compress_block_size = 65,536, сжатый блок будет сформирован для каждых двух меток.

Мы записываем колонку URL с типом String (средний размер 60 байт на значение). При записи 8192 строк среднее значение будет чуть менее 500 КБ данных. Поскольку это больше 65,536, сжатый блок будет сформирован для каждой метки. В этом случае, при чтении данных с диска в диапазоне одной метки, дополнительные данные не будут разжаты.

:::note
Это настройка экспертного уровня, и вам не следует изменять ее, если вы только начинаете работать с ClickHouse.
:::

## min_count_to_compile_aggregate_expression {#min_count_to_compile_aggregate_expression} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3`|

Минимальное количество идентичных агрегатных выражений, чтобы запустить JIT-компиляцию. Работает только если включена настройка [compile_aggregate_expressions](#compile_aggregate_expressions).

Возможные значения:

- Положительное целое число.
- 0 — Идентичные агрегатные выражения всегда JIT-компилируются.

## min_count_to_compile_expression {#min_count_to_compile_expression} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3`|

Минимальное количество выполнения одного и того же выражения, прежде чем оно будет скомпилировано.

## min_count_to_compile_sort_description {#min_count_to_compile_sort_description} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3`|

Количество идентичных описаний сортировки, прежде чем они будут JIT-компилированы.

## min_execution_speed {#min_execution_speed} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Минимальная скорость выполнения в строках в секунду. Проверяется на каждом блоке данных, когда истечет
[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed). Если скорость выполнения ниже, будет выброшено исключение.

## min_execution_speed_bytes {#min_execution_speed_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Минимальное количество байт выполнения в секунду. Проверяется на каждом блоке данных, когда истечет
[`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed). Если скорость выполнения ниже, будет выброшено исключение.

## min_external_sort_block_bytes {#min_external_sort_block_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`104857600`|

Минимальный размер блока в байтах для внешней сортировки, который будет сброшен на диск, чтобы избежать слишком большого количества файлов.

## min_external_table_block_size_bytes {#min_external_table_block_size_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`268402944`|

Сжимает блоки, переданные во внешнюю таблицу до указанного размера в байтах, если блоки недостаточно велики.

## min_external_table_block_size_rows {#min_external_table_block_size_rows} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1048449`|

Сжимает блоки, переданные во внешнюю таблицу, до указанного размера в строках, если блоки недостаточно велики.

## min_free_disk_bytes_to_perform_insert {#min_free_disk_bytes_to_perform_insert} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Минимальное количество свободного места на диске в байтах, чтобы выполнить вставку.

## min_free_disk_ratio_to_perform_insert {#min_free_disk_ratio_to_perform_insert} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Минимальное отношение свободного дискового пространства для выполнения вставки.

## min_free_disk_space_for_temporary_data {#min_free_disk_space_for_temporary_data} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Минимальное дисковое пространство, которое нужно сохранить во время записи временных данных, используемых в внешней сортировке и агрегации.

## min_hit_rate_to_use_consecutive_keys_optimization {#min_hit_rate_to_use_consecutive_keys_optimization} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0.5`|

Минимальная частота попаданий кэша, которая используется для оптимизации последовательных ключей в агрегировании, чтобы она оставалась включенной.

## min_insert_block_size_bytes {#min_insert_block_size_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`268402944`|

Устанавливает минимальное количество байт в блоке, который может быть вставлен в таблицу с помощью запроса `INSERT`. Более мелкие блоки сжимаются в более крупные.

Возможные значения:

- Положительное целое число.
- 0 — Сжатие отключено.

## min_insert_block_size_bytes_for_materialized_views {#min_insert_block_size_bytes_for_materialized_views} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Устанавливает минимальное количество байт в блоке, который может быть вставлен в таблицу с помощью запроса `INSERT`. Более мелкие блоки сжимаются в более крупные. Эта настройка применяется только для блоков, вставленных в [материализованное представление](../../sql-reference/statements/create/view.md). Настройка этой опции позволяет контролировать сжатие блоков при загрузке в материализованное представление и избегать чрезмерного использования памяти.

Возможные значения:

- Любое положительное целое число.
- 0 — Сжатие отключено.

**См. также**

- [min_insert_block_size_bytes](#min_insert_block_size_bytes)

## min_insert_block_size_rows {#min_insert_block_size_rows} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1048449`|

Устанавливает минимальное количество строк в блоке, которые могут быть вставлены в таблицу с помощью запроса `INSERT`. Более мелкие блоки сжимаются в более крупные.

Возможные значения:

- Положительное целое число.
- 0 — Сжатие отключено.

## min_insert_block_size_rows_for_materialized_views {#min_insert_block_size_rows_for_materialized_views} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Устанавливает минимальное количество строк в блоке, которые могут быть вставлены в таблицу с помощью запроса `INSERT`. Более мелкие блоки сжимаются в более крупные. Эта настройка применяется только для блоков, вставленных в [материализованное представление](../../sql-reference/statements/create/view.md). Настройка этой опции позволяет контролировать сжатие блоков при загрузке в материализованное представление и избегать чрезмерного использования памяти.

Возможные значения:

- Любое положительное целое число.
- 0 — Сжатие отключено.

**См. также**

- [min_insert_block_size_rows](#min_insert_block_size_rows)

## min_joined_block_size_bytes {#min_joined_block_size_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`524288`|

Минимальный размер блока для результата JOIN (если алгоритм соединения поддерживает это). 0 означает неограниченный.

## mongodb_throw_on_unsupported_query {#mongodb_throw_on_unsupported_query} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если включено, таблицы MongoDB вернут ошибку, когда запрос MongoDB не может быть построен. В противном случае ClickHouse считывает полную таблицу и обрабатывает ее локально. Эта опция не применяется, когда 'allow_experimental_analyzer=0'.

## move_all_conditions_to_prewhere {#move_all_conditions_to_prewhere} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Переместить все подходящие условия из WHERE в PREWHERE.

## move_primary_key_columns_to_end_of_prewhere {#move_primary_key_columns_to_end_of_prewhere} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Переместить условия PREWHERE, содержащие колонки первичного ключа, в конец цепочки AND. Вероятно, эти условия учитываются при анализе первичного ключа и, таким образом, не будут способствовать фильтрации PREWHERE.

## multiple_joins_try_to_keep_original_names {#multiple_joins_try_to_keep_original_names} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Не добавлять псевдонимы в список выражений верхнего уровня при переписывании нескольких соединений.

## mutations_execute_nondeterministic_on_initiator {#mutations_execute_nondeterministic_on_initiator} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если true, постоянные недетерминированные функции (например, функция `now()`) выполняются на инициаторе и заменяются на литералы в запросах `UPDATE` и `DELETE`. Это помогает поддерживать данные синхронизированными на репликах во время выполнения мутаций с постоянными недетерминированными функциями. Значение по умолчанию: `false`.

## mutations_execute_subqueries_on_initiator {#mutations_execute_subqueries_on_initiator} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если true, скалярные подзапросы выполняются на инициаторе и заменяются на литералы в запросах `UPDATE` и `DELETE`. Значение по умолчанию: `false`.

## mutations_max_literal_size_to_replace {#mutations_max_literal_size_to_replace} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`16384`|

Максимальный размер сериализованного литерала в байтах для замены в запросах `UPDATE` и `DELETE`. Действует только если включена хотя бы одна из двух вышеуказанных настроек. Значение по умолчанию: 16384 (16 KiB).

## mutations_sync {#mutations_sync} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Позволяет выполнять запросы `ALTER TABLE ... UPDATE|DELETE|MATERIALIZE INDEX|MATERIALIZE PROJECTION|MATERIALIZE COLUMN|MATERIALIZE STATISTICS` ([мутации](../../sql-reference/statements/alter/index.md/#mutations)) синхронно.

Возможные значения:

- 0 - Мутации выполняются асинхронно.
- 1 - Запрос ждет завершения всех мутаций на текущем сервере.
- 2 - Запрос ждет завершения всех мутаций на всех репликах (если они существуют).

## mysql_datatypes_support_level {#mysql_datatypes_support_level} 

Определяет, как типы MySQL преобразуются в соответствующие типы ClickHouse. Список, разделенный запятыми, в любой комбинации `decimal`, `datetime64`, `date2Date32` или `date2String`.
- `decimal`: преобразовать типы `NUMERIC` и `DECIMAL` в `Decimal`, когда это позволяет точность.
- `datetime64`: преобразовать типы `DATETIME` и `TIMESTAMP` в `DateTime64` вместо `DateTime`, когда точность не равна `0`.
- `date2Date32`: преобразовать `DATE` в `Date32` вместо `Date`. Имеет приоритет над `date2String`.
- `date2String`: преобразовать `DATE` в `String` вместо `Date`. Переопределяется `datetime64`.

## mysql_map_fixed_string_to_text_in_show_columns {#mysql_map_fixed_string_to_text_in_show_columns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Когда включено, тип данных ClickHouse [FixedString](../../sql-reference/data-types/fixedstring.md) будет отображаться как `TEXT` в [SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns).

Действует только при подключении через протокол MySQL.

- 0 - Используйте `BLOB`.
- 1 - Используйте `TEXT`.

## mysql_map_string_to_text_in_show_columns {#mysql_map_string_to_text_in_show_columns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Когда включено, тип данных ClickHouse [String](../../sql-reference/data-types/string.md) будет отображаться как `TEXT` в [SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns).

Действует только при подключении через протокол MySQL.

- 0 - Используйте `BLOB`.
- 1 - Используйте `TEXT`.

## mysql_max_rows_to_insert {#mysql_max_rows_to_insert} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`65536`|

Максимальное количество строк в пакетной вставке MySQL для движка хранения MySQL.

## network_compression_method {#network_compression_method} 

|Тип|По умолчанию|
|---|---|
|`String`|`LZ4`|

Устанавливает метод сжатия данных, который используется для связи между серверами и между сервером и [clickhouse-client](../../interfaces/cli.md).

Возможные значения:

- `LZ4` — устанавливает метод сжатия LZ4.
- `ZSTD` — устанавливает метод сжатия ZSTD.

**См. также**

- [network_zstd_compression_level](#network_zstd_compression_level)

## network_zstd_compression_level {#network_zstd_compression_level} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`1`|

Регулирует уровень сжатия ZSTD. Используется только когда [network_compression_method](#network_compression_method) установлен на `ZSTD`.

Возможные значения:

- Положительное целое число от 1 до 15.

## normalize_function_names {#normalize_function_names} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Нормализует имена функций до их канонических имен.

## number_of_mutations_to_delay {#number_of_mutations_to_delay} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Если в изменяемой таблице содержится как минимум столько же незавершенных мутаций, искусственно замедлить мутации таблицы. 0 - отключено.

## number_of_mutations_to_throw {#number_of_mutations_to_throw} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Если в изменяемой таблице содержится как минимум столько же незавершенных мутаций, выбросить исключение 'Слишком много мутаций ...'. 0 - отключено.

## odbc_bridge_connection_pool_size {#odbc_bridge_connection_pool_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`16`|

Размер пула соединений для каждой строки настроек соединения в ODBC мосту.

## odbc_bridge_use_connection_pooling {#odbc_bridge_use_connection_pooling} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать пул соединений в ODBC мосту. Если установлено значение false, новое соединение создается каждый раз.

## offset {#offset} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Устанавливает количество строк, которые следует пропустить перед началом возврата строк из запроса. Он корректирует смещение, заданное клаузой [OFFSET](/sql-reference/statements/select/offset), так что эти два значения суммируются.

Возможные значения:

- 0 — Никакие строки не пропускаются.
- Положительное целое число.

**Пример**

Входная таблица:

```sql
CREATE TABLE test (i UInt64) ENGINE = MergeTree() ORDER BY i;
INSERT INTO test SELECT number FROM numbers(500);
```

Запрос:

```sql
SET limit = 5;
SET offset = 7;
SELECT * FROM test LIMIT 10 OFFSET 100;
```
Результат:

```text
┌───i─┐
│ 107 │
│ 108 │
│ 109 │
└─────┘
```

## opentelemetry_start_trace_probability {#opentelemetry_start_trace_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Устанавливает вероятность того, что ClickHouse может запустить трассировку для выполненных запросов (если не предоставлен родительский [контекст трассировки](https://www.w3.org/TR/trace-context/)).

Возможные значения:

- 0 — Трассировка для всех выполненных запросов отключена (если не предоставлен родительский контекст трассировки).
- Положительное число с плавающей запятой в диапазоне [0..1]. Например, если значение настройки равно `0.5`, ClickHouse может запустить трассировку в среднем для половины запросов.
- 1 — Трассировка для всех выполненных запросов включена.

## opentelemetry_trace_processors {#opentelemetry_trace_processors} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Собирать OpenTelemetry диапазоны для процессоров.

## optimize_aggregation_in_order {#optimize_aggregation_in_order} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает оптимизацию [GROUP BY](/sql-reference/statements/select/group-by) в запросах [SELECT](../../sql-reference/statements/select/index.md) для агрегирования данных в соответствующем порядке в таблицах [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md).

Возможные значения:

- 0 — Оптимизация `GROUP BY` отключена.
- 1 — Оптимизация `GROUP BY` включена.

**См. также**

- [Оптимизация GROUP BY](/sql-reference/statements/select/group-by#group-by-optimization-depending-on-table-sorting-key)

## optimize_aggregators_of_group_by_keys {#optimize_aggregators_of_group_by_keys} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Устраняет агрегаторы min/max/any/anyLast ключей GROUP BY в разделе SELECT.

## optimize_and_compare_chain {#optimize_and_compare_chain} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Заполняет константное сравнение в цепочках AND для усиления возможностей фильтрации. Поддерживает операторы `<`, `<=`, `>`, `>=`, `=` и их комбинации. Например, `(a < b) AND (b < c) AND (c < 5)` будет `(a < b) AND (b < c) AND (c < 5) AND (b < 5) AND (a < 5)`.

## optimize_append_index {#optimize_append_index} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Используйте [ограничения](../../sql-reference/statements/create/table.md/#constraints), чтобы добавить условие индекса. По умолчанию `false`.

Возможные значения:

- true, false.

## optimize_arithmetic_operations_in_aggregate_functions {#optimize_arithmetic_operations_in_aggregate_functions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Переместить арифметические операции за пределы агрегатных функций.

## optimize_count_from_files {#optimize_count_from_files} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает оптимизацию подсчета количества строк из файлов в разных входных форматах. Применяется к таблицам/движкам функции `file`/`s3`/`url`/`hdfs`/`azureBlobStorage`.

Возможные значения:

- 0 — Оптимизация отключена.
- 1 — Оптимизация включена.

## optimize_distinct_in_order {#optimize_distinct_in_order} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включить оптимизацию DISTINCT, если некоторые колонки в DISTINCT формируют префикс сортировки. Например, префикс ключа сортировки в дереве объединения или операторе ORDER BY.
## optimize_distributed_group_by_sharding_key {#optimize_distributed_group_by_sharding_key} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Оптимизирует запросы `GROUP BY sharding_key`, избегая затратной агрегации на инициирующем сервере (что снизит использование памяти для запроса на инициирующем сервере).

Поддерживаются следующие типы запросов (и все их комбинации):

- `SELECT DISTINCT [..., ]sharding_key[, ...] FROM dist`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...]`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] ORDER BY x`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1 BY x`

Не поддерживаются следующие типы запросов (поддержка некоторых из них может быть добавлена позже):

- `SELECT ... GROUP BY sharding_key[, ...] WITH TOTALS`
- `SELECT ... GROUP BY sharding_key[, ...] WITH ROLLUP`
- `SELECT ... GROUP BY sharding_key[, ...] WITH CUBE`
- `SELECT ... GROUP BY sharding_key[, ...] SETTINGS extremes=1`

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

Смотрите также:

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [distributed_push_down_limit](#distributed_push_down_limit)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)

:::note
На данный момент это требует `optimize_skip_unused_shards` (причина в том, что однажды это может быть включено по умолчанию, и оно будет работать корректно только если данные были вставлены через распределённую таблицу, т.е. данные распределены в соответствии с sharding_key).
:::
## optimize_extract_common_expressions {#optimize_extract_common_expressions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает извлечение общих выражений из дизъюнкций в WHERE, PREWHERE, ON, HAVING и QUALIFY выражениях. Логическое выражение, такое как `(A AND B) OR (A AND C)`, может быть переписано как `A AND (B OR C)`, что может помочь использовать:
- индексы в простых фильтрах
- оптимизацию перекрёстного к внутреннему соединению
## optimize_functions_to_subcolumns {#optimize_functions_to_subcolumns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает оптимизацию, преобразуя некоторые функции для чтения субколонок. Это уменьшает количество данных для чтения.

Эти функции могут быть преобразованы:

- [length](/sql-reference/functions/array-functions#length) для чтения субколонки [size0](../../sql-reference/data-types/array.md/#array-size).
- [empty](/sql-reference/functions/array-functions#empty) для чтения субколонки [size0](../../sql-reference/data-types/array.md/#array-size).
- [notEmpty](/sql-reference/functions/array-functions#notempty) для чтения субколонки [size0](../../sql-reference/data-types/array.md/#array-size).
- [isNull](/sql-reference/functions/functions-for-nulls#isnull) для чтения субколонки [null](../../sql-reference/data-types/nullable.md/#finding-null).
- [isNotNull](/sql-reference/functions/functions-for-nulls#isnotnull) для чтения субколонки [null](../../sql-reference/data-types/nullable.md/#finding-null).
- [count](/sql-reference/aggregate-functions/reference/count) для чтения субколонки [null](../../sql-reference/data-types/nullable.md/#finding-null).
- [mapKeys](/sql-reference/functions/tuple-map-functions#mapkeys) для чтения субколонки [keys](/sql-reference/data-types/map#reading-subcolumns-of-map).
- [mapValues](/sql-reference/functions/tuple-map-functions#mapvalues) для чтения субколонки [values](/sql-reference/data-types/map#reading-subcolumns-of-map).

Возможные значения:

- 0 — Оптимизация отключена.
- 1 — Оптимизация включена.
## optimize_group_by_constant_keys {#optimize_group_by_constant_keys} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Оптимизирует GROUP BY, когда все ключи в блоке постоянные.
## optimize_group_by_function_keys {#optimize_group_by_function_keys} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Устраняет функции других ключей в секции GROUP BY.
## optimize_if_chain_to_multiif {#optimize_if_chain_to_multiif} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Заменяет цепочки if(cond1, then1, if(cond2, ...)) на multiIf. В настоящее время это не выгодно для числовых типов.
## optimize_if_transform_strings_to_enum {#optimize_if_transform_strings_to_enum} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Заменяет аргументы строкового типа в If и Transform на enum. Отключено по умолчанию, так как это может привести к несогласованному изменению в распределённом запросе, что приведёт к его сбою.
## optimize_injective_functions_in_group_by {#optimize_injective_functions_in_group_by} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Заменяет инъективные функции их аргументами в секции GROUP BY.
## optimize_injective_functions_inside_uniq {#optimize_injective_functions_inside_uniq} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Удаляет инъективные функции с одним аргументом внутри функций uniq*().
## optimize_min_equality_disjunction_chain_length {#optimize_min_equality_disjunction_chain_length} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3`|

Минимальная длина выражения `expr = x1 OR ... expr = xN` для оптимизации.
## optimize_min_inequality_conjunction_chain_length {#optimize_min_inequality_conjunction_chain_length} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3`|

Минимальная длина выражения `expr <> x1 AND ... expr <> xN` для оптимизации.
## optimize_move_to_prewhere {#optimize_move_to_prewhere} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает автоматическую оптимизацию [PREWHERE](../../sql-reference/statements/select/prewhere.md) в [SELECT](../../sql-reference/statements/select/index.md) запросах.

Работает только для [*MergeTree](../../engines/table-engines/mergetree-family/index.md) таблиц.

Возможные значения:

- 0 — Автоматическая оптимизация `PREWHERE` отключена.
- 1 — Автоматическая оптимизация `PREWHERE` включена.
## optimize_move_to_prewhere_if_final {#optimize_move_to_prewhere_if_final} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает автоматическую оптимизацию [PREWHERE](../../sql-reference/statements/select/prewhere.md) в [SELECT](../../sql-reference/statements/select/index.md) запросах с модификатором [FINAL](/sql-reference/statements/select/from#final-modifier).

Работает только для [*MergeTree](../../engines/table-engines/mergetree-family/index.md) таблиц.

Возможные значения:

- 0 — Автоматическая оптимизация `PREWHERE` в `SELECT` запросах с модификатором `FINAL` отключена.
- 1 — Автоматическая оптимизация `PREWHERE` в `SELECT` запросах с модификатором `FINAL` включена.

**Смотрите также**

- Настройка [optimize_move_to_prewhere](#optimize_move_to_prewhere).
## optimize_multiif_to_if {#optimize_multiif_to_if} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Заменяет 'multiIf' с единственным условием на 'if'.
## optimize_normalize_count_variants {#optimize_normalize_count_variants} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Переписывает агрегатные функции, которые семантически эквивалентны count(), как count().
## optimize_on_insert {#optimize_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает преобразование данных перед вставкой, как если бы слияние было выполнено над этим блоком (в соответствии с движком таблицы).

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

**Пример**

Разница между включённым и отключённым:

Запрос:

```sql
SET optimize_on_insert = 1;

CREATE TABLE test1 (`FirstTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY FirstTable;

INSERT INTO test1 SELECT number % 2 FROM numbers(5);

SELECT * FROM test1;

SET optimize_on_insert = 0;

CREATE TABLE test2 (`SecondTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY SecondTable;

INSERT INTO test2 SELECT number % 2 FROM numbers(5);

SELECT * FROM test2;
```

Результат:

```text
┌─FirstTable─┐
│          0 │
│          1 │
└────────────┘

┌─SecondTable─┐
│           0 │
│           0 │
│           0 │
│           1 │
│           1 │
└─────────────┘
```

Обратите внимание, что эта настройка влияет на поведение [материализованного представления](/sql-reference/statements/create/view#materialized-view).
## optimize_or_like_chain {#optimize_or_like_chain} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Оптимизирует множество OR LIKE в multiMatchAny. Эта оптимизация не должна быть включена по умолчанию, так как она нарушает анализ индекса в некоторых случаях.
## optimize_read_in_order {#optimize_read_in_order} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию [ORDER BY](/sql-reference/statements/select/order-by#optimization-of-data-reading) в [SELECT](../../sql-reference/statements/select/index.md) запросах для чтения данных из [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) таблиц.

Возможные значения:

- 0 — Оптимизация `ORDER BY` отключена.
- 1 — Оптимизация `ORDER BY` включена.

**Смотрите также**

- [Клауза ORDER BY](/sql-reference/statements/select/order-by#optimization-of-data-reading).
## optimize_read_in_window_order {#optimize_read_in_window_order} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию ORDER BY в окне для чтения данных в соответствующем порядке в таблицах MergeTree.
## optimize_redundant_functions_in_order_by {#optimize_redundant_functions_in_order_by} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Удаляет функции из ORDER BY, если их аргумент также присутствует в ORDER BY.
## optimize_respect_aliases {#optimize_respect_aliases} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если установлено в true, будет учтён псевдоним в WHERE/GROUP BY/ORDER BY, что поможет с обрезкой партиций/вторичными индексами/оптимизацией агрегации/оптимизацией чтения в порядке/оптимизацией тривиального счёта.
## optimize_rewrite_aggregate_function_with_if {#optimize_rewrite_aggregate_function_with_if} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Переписывает агрегатные функции с выражением if в качестве аргумента, когда они логически эквивалентны.
Например, `avg(if(cond, col, null))` может быть переписано как `avgOrNullIf(cond, col)`. Это может улучшить производительность.

:::note
Поддерживается только с анализатором (`enable_analyzer = 1`).
:::
## optimize_rewrite_array_exists_to_has {#optimize_rewrite_array_exists_to_has} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Переписывает функции arrayExists() в has(), когда они логически эквивалентны. Например, arrayExists(x -> x = 1, arr) может быть переписано в has(arr, 1).
## optimize_rewrite_sum_if_to_count_if {#optimize_rewrite_sum_if_to_count_if} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Переписывает функции sumIf() и sum(if()) в функцию countIf(), когда они логически эквивалентны.
## optimize_skip_merged_partitions {#optimize_skip_merged_partitions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает оптимизацию для запроса [OPTIMIZE TABLE ... FINAL](../../sql-reference/statements/optimize.md), если существует только одна часть с уровнем > 0 и у неё нет истёкшего TTL.

- `OPTIMIZE TABLE ... FINAL SETTINGS optimize_skip_merged_partitions=1`

По умолчанию запрос `OPTIMIZE TABLE ... FINAL` переписывает одну часть, даже если существует всего одна часть.

Возможные значения:

- 1 - Включить оптимизацию.
- 0 - Отключить оптимизацию.
## optimize_skip_unused_shards {#optimize_skip_unused_shards} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает пропуск неиспользуемых шардов для [SELECT](../../sql-reference/statements/select/index.md) запросов, которые имеют условие шардирования в `WHERE/PREWHERE` (при условии что данные распределены по ключу шардирования, иначе запрос будет давать некорректный результат).

Возможные значения:

- 0 — Отключено.
- 1 — Включено.
## optimize_skip_unused_shards_limit {#optimize_skip_unused_shards_limit} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Лимит для числа значений ключа шардирования, отключает `optimize_skip_unused_shards`, если лимит превышен.

Слишком большое количество значений может потребовать значительных затрат на обработку, в то время как польза может быть сомнительной, так как если у вас огромное число значений в `IN (...)`, то, скорее всего, запрос будет отправлен на все шарды в любом случае.
## optimize_skip_unused_shards_nesting {#optimize_skip_unused_shards_nesting} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Управляет [`optimize_skip_unused_shards`](#optimize_skip_unused_shards) (поэтому всё ещё требует [`optimize_skip_unused_shards`](#optimize_skip_unused_shards)) в зависимости от уровня вложенности распределённого запроса (случай, когда у вас есть `Distributed` таблица, которая смотрит на другую `Distributed` таблицу).

Возможные значения:

- 0 — Отключено, `optimize_skip_unused_shards` всегда работает.
- 1 — Включает `optimize_skip_unused_shards` только для первого уровня.
- 2 — Включает `optimize_skip_unused_shards` до второго уровня.
## optimize_skip_unused_shards_rewrite_in {#optimize_skip_unused_shards_rewrite_in} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Переписывает IN в запросе для удалённых шардов, исключая значения, которые не принадлежат шару (требуется optimize_skip_unused_shards).

Возможные значения:

- 0 — Отключено.
- 1 — Включено.
## optimize_sorting_by_input_stream_properties {#optimize_sorting_by_input_stream_properties} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Оптимизирует сортировку по свойствам входного потока.
## optimize_substitute_columns {#optimize_substitute_columns} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использует [ограничения](../../sql-reference/statements/create/table.md/#constraints) для замены колонок. По умолчанию установлено `false`.

Возможные значения:

- true, false
## optimize_syntax_fuse_functions {#optimize_syntax_fuse_functions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает слияние агрегатных функций с идентичным аргументом. Он переписывает запрос, содержащий по меньшей мере две агрегатные функции из [sum](/sql-reference/aggregate-functions/reference/sum), [count](/sql-reference/aggregate-functions/reference/count) или [avg](/sql-reference/aggregate-functions/reference/avg) с идентичным аргументом на [sumCount](/sql-reference/aggregate-functions/reference/sumcount).

Возможные значения:

- 0 — Функции с идентичным аргументом не сливаются.
- 1 — Функции с идентичным аргументом сливаются.

**Пример**

Запрос:

```sql
CREATE TABLE fuse_tbl(a Int8, b Int8) Engine = Log;
SET optimize_syntax_fuse_functions = 1;
EXPLAIN SYNTAX SELECT sum(a), sum(b), count(b), avg(b) from fuse_tbl FORMAT TSV;
```

Результат:

```text
SELECT
    sum(a),
    sumCount(b).1,
    sumCount(b).2,
    (sumCount(b).1) / (sumCount(b).2)
FROM fuse_tbl
```
## optimize_throw_if_noop {#optimize_throw_if_noop} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает выбрасывание исключения, если запрос [OPTIMIZE](../../sql-reference/statements/optimize.md) не произвёл слияние.

По умолчанию `OPTIMIZE` возвращает успешно, даже если он ничего не сделал. Эта настройка позволяет вам различать эти ситуации и получить причину в сообщении об исключении.

Возможные значения:

- 1 — Включено выбрасывание исключения.
- 0 — Отключено выбрасывание исключения.
## optimize_time_filter_with_preimage {#optimize_time_filter_with_preimage} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Оптимизирует предикаты Date и DateTime путём преобразования функций в эквивалентные сравнения без преобразований (например, `toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31'`).
## optimize_trivial_approximate_count_query {#optimize_trivial_approximate_count_query} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использует приблизительное значение для тривиальной оптимизации счёта для хранилищ, которые поддерживают такую оценку, например, EmbeddedRocksDB.

Возможные значения:

   - 0 — Оптимизация отключена.
   - 1 — Оптимизация включена.
## optimize_trivial_count_query {#optimize_trivial_count_query} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает оптимизацию тривиального запроса `SELECT count() FROM table` с использованием метаданных из MergeTree. Если вам нужно использовать безопасность на уровне строк, отключите эту настройку.

Возможные значения:

   - 0 — Оптимизация отключена.
   - 1 — Оптимизация включена.

Смотрите также:

- [optimize_functions_to_subcolumns](#optimize_functions_to_subcolumns)
## optimize_trivial_insert_select {#optimize_trivial_insert_select} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Оптимизирует тривиальный запрос 'INSERT INTO table SELECT ... FROM TABLES'.
## optimize_uniq_to_count {#optimize_uniq_to_count} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Переписывает uniq и его варианты (кроме uniqUpTo) в count, если подзапрос имеет оператор distinct или group by.
## optimize_use_implicit_projections {#optimize_use_implicit_projections} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Автоматически выбирает неявные проекции для выполнения запроса SELECT.
## optimize_use_projections {#optimize_use_projections} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает оптимизацию [проекций](../../engines/table-engines/mergetree-family/mergetree.md/#projections) при обработке запросов `SELECT`.

Возможные значения:

- 0 — Оптимизация проекций отключена.
- 1 — Оптимизация проекций включена.
## optimize_using_constraints {#optimize_using_constraints} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использует [ограничения](../../sql-reference/statements/create/table.md/#constraints) для оптимизации запросов. По умолчанию установлено `false`.

Возможные значения:

- true, false
## os_thread_priority {#os_thread_priority} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`0`|

Устанавливает приоритет ([nice](https://en.wikipedia.org/wiki/Nice_(Unix))) для потоков, которые выполняют запросы. Планировщик ОС учитывает этот приоритет при выборе следующего потока для запуска на каждом доступном ядре CPU.

:::note
Для использования этой настройки необходимо установить возможность `CAP_SYS_NICE`. Пакет `clickhouse-server` настраивает её во время установки. Некоторые виртуальные среды не позволяют установить возможность `CAP_SYS_NICE`. В этом случае `clickhouse-server` выводит сообщение об этом в начале.
:::

Возможные значения:

- Значения можно устанавливать в диапазоне `[-20, 19]`.

Низкие значения означают более высокий приоритет. Потоки с низкими значениями приоритета `nice` выполняются чаще, чем потоки с высокими значениями. Высокие значения предпочтительны для долгосрочных неинтерактивных запросов, так как это позволяет им быстро отказаться от ресурсов в пользу коротких интерактивных запросов, когда они поступают.
## output_format_compression_level {#output_format_compression_level} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`3`|

Уровень сжатия по умолчанию, если вывод запроса сжат. Настройка применяется, когда запрос `SELECT` имеет `INTO OUTFILE` или когда осуществляется запись в табличные функции `file`, `url`, `hdfs`, `s3` или `azureBlobStorage`.

Возможные значения: от `1` до `22`.
## output_format_compression_zstd_window_log {#output_format_compression_zstd_window_log} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Может быть использован, когда метод сжатия вывода - `zstd`. Если больше `0`, эта настройка явно задаёт размер окна сжатия (степень `2`) и включает режим длинного диапазона для сжатия zstd. Это может помочь достичь лучшего коэффициента сжатия.

Возможные значения: неотрицательные числа. Обратите внимание, что если значение слишком мало или слишком велико, `zstdlib` выбросит исключение. Типичные значения находятся в диапазоне от `20` (размер окна = `1MB`) до `30` (размер окна = `1GB`).
## output_format_parallel_formatting {#output_format_parallel_formatting} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает параллельное форматирование данных для форматов. Поддерживаются только для форматов [TSV](../../interfaces/formats.md/#tabseparated), [TSKV](../../interfaces/formats.md/#tskv), [CSV](../../interfaces/formats.md/#csv) и [JSONEachRow](../../interfaces/formats.md/#jsoneachrow).

Возможные значения:

- 1 — Включено.
- 0 — Отключено.
## page_cache_inject_eviction {#page_cache_inject_eviction} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Кэш страниц пользовательского пространства иногда будет случайно аннулировать некоторые страницы. Предназначен для тестирования.
## parallel_distributed_insert_select {#parallel_distributed_insert_select} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Включает параллельный распределённый запрос `INSERT ... SELECT`.

Если мы выполняем запросы `INSERT INTO distributed_table_a SELECT ... FROM distributed_table_b` и обе таблицы используют один и тот же кластер, и обе таблицы либо [реплицированы](../../engines/table-engines/mergetree-family/replication.md), либо не реплицированы, то этот запрос обрабатывается локально на каждом шарде.

Возможные значения:

- 0 — Отключено.
- 1 — `SELECT` будет выполняться на каждом шарде из основной таблицы распределённого движка.
- 2 — `SELECT` и `INSERT` будут выполняться на каждом шарде из/в основную таблицу распределённого движка.
## parallel_replica_offset {#parallel_replica_offset} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Это внутренняя настройка, которую не следует использовать напрямую, и она представляет собой реализацию «параллельных реплик». Эта настройка будет автоматически установлена инициирующим сервером для распределённых запросов на индекс реплики, участвующей в обработке запроса среди параллельных реплик.
## parallel_replicas_allow_in_with_subquery {#parallel_replicas_allow_in_with_subquery} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если true, подзапрос для IN будет выполняться на каждой вспомогательной реплике.
## parallel_replicas_count {#parallel_replicas_count} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Это внутренняя настройка, которую не следует использовать напрямую, и она представляет собой реализацию «параллельных реплик». Эта настройка будет автоматически установлена инициирующим сервером для распределённых запросов на количество параллельных реплик, участвующих в обработке запроса.
## parallel_replicas_custom_key {#parallel_replicas_custom_key} 

<BetaBadge/>

Произвольное целочисленное выражение, которое может быть использовано для распределения работы между репликами для конкретной таблицы. Значение может быть любым целочисленным выражением.

Предпочтительны простые выражения, использующие первичные ключи.

Если эта настройка используется в кластере, который состоит из одного шара с несколькими репликами, эти реплики будут преобразованы в виртуальные шары. В противном случае она будет вести себя так же, как для ключа `SAMPLE`, будет использовать несколько реплик каждого шарда.
## parallel_replicas_custom_key_range_lower {#parallel_replicas_custom_key_range_lower} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Позволяет фильтру типа `range` равномерно распределить работу между репликами на основе пользовательского диапазона `[parallel_replicas_custom_key_range_lower, INT_MAX]`.

При использовании совместно с [parallel_replicas_custom_key_range_upper](#parallel_replicas_custom_key_range_upper) позволяет фильтру равномерно распределить работу между репликами для диапазона `[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]`.

Примечание: Эта настройка не приведёт к фильтрации дополнительных данных во время обработки запроса, она просто изменяет точки, в которых диапазонный фильтр разбивает диапазон `[0, INT_MAX]` для параллельной обработки.
## parallel_replicas_custom_key_range_upper {#parallel_replicas_custom_key_range_upper} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Позволяет фильтру типа `range` равномерно распределить работу между репликами на основе пользовательского диапазона `[0, parallel_replicas_custom_key_range_upper]`. Значение 0 отключает верхнюю границу, устанавливая её на максимальное значение пользовательского ключевого выражения.

При использовании совместно с [parallel_replicas_custom_key_range_lower](#parallel_replicas_custom_key_range_lower) позволяет фильтру равномерно распределить работу между репликами для диапазона `[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]`.

Примечание: Эта настройка не приведёт к фильтрации дополнительных данных во время обработки запроса, она просто изменяет точки, в которых диапазонный фильтр разбивает диапазон `[0, INT_MAX]` для параллельной обработки.
## parallel_replicas_for_cluster_engines {#parallel_replicas_for_cluster_engines} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Заменяет движки табличных функций их -Cluster аналогами.
## parallel_replicas_for_non_replicated_merge_tree {#parallel_replicas_for_non_replicated_merge_tree} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если true, ClickHouse будет использовать алгоритм параллельных реплик также для нереплицированных таблиц MergeTree.
## parallel_replicas_index_analysis_only_on_coordinator {#parallel_replicas_index_analysis_only_on_coordinator} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Анализ индекса выполняется только на реплике-координаторе и пропускается на других репликах. Эффективно только с включённым parallel_replicas_local_plan.
## parallel_replicas_local_plan {#parallel_replicas_local_plan} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Строит локальный план для локальной реплики.
## parallel_replicas_mark_segment_size {#parallel_replicas_mark_segment_size} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Части виртуально делятся на сегменты, которые распределяются между репликами для параллельного чтения. Эта настройка контролирует размер этих сегментов. Не рекомендуется изменять, пока вы не уверены в том, что делаете. Значение должно находиться в диапазоне [128; 16384].
## parallel_replicas_min_number_of_rows_per_replica {#parallel_replicas_min_number_of_rows_per_replica} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Ограничивает количество реплик, используемых в запросе до (оценочное число строк для чтения / min_number_of_rows_per_replica). Максимум всё ещё ограничен 'max_parallel_replicas'.
## parallel_replicas_mode {#parallel_replicas_mode} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`ParallelReplicasMode`|`read_tasks`|

Тип фильтра, который использовать с пользовательским ключом для параллельных реплик. По умолчанию - использовать операцию модуляции на пользовательском ключе, диапазон - использовать диапазонный фильтр на пользовательском ключе, используя все возможные значения для типа значения пользовательского ключа.
## parallel_replicas_only_with_analyzer {#parallel_replicas_only_with_analyzer} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Анализатор должен быть включен для использования параллельных реплик. При отключённом анализаторе выполнение запроса сводится к локальному выполнению, даже если включено параллельное чтение с реплик. Использование параллельных реплик без включённого анализатора не поддерживается.
## parallel_replicas_prefer_local_join {#parallel_replicas_prefer_local_join} 

<BetaBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если true и JOIN может быть выполнен с алгоритмом параллельных реплик, и все хранилища правой части JOIN - это *MergeTree, будет использоваться локальный JOIN вместо ГЛОБАЛЬНОГО JOIN.
## parallel_view_processing {#parallel_view_processing} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает одновременную отправку запросов к прикреплённым представлениям вместо последовательного.
## parallelize_output_from_storages {#parallelize_output_from_storages} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Параллелизует вывод на этапе чтения из хранилища. Это позволяет параллелизации обработки запроса сразу после чтения из хранилища, если это возможно.
## parsedatetime_parse_without_leading_zeros {#parsedatetime_parse_without_leading_zeros} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Форматтеры '%c', '%l' и '%k' в функции 'parseDateTime' парсят месяцы и часы без ведущих нулей.
## partial_merge_join_left_table_buffer_bytes {#partial_merge_join_left_table_buffer_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Если не 0, группирует блоки левой таблицы в более крупные для левой таблицы в частичном слиянии. Использует до 2x указанной памяти на каждый поток соединения.
## partial_merge_join_rows_in_right_blocks {#partial_merge_join_rows_in_right_blocks} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`65536`|

Ограничивает размеры данных в правом соединении в алгоритме частичного слияния для запросов [JOIN](../../sql-reference/statements/select/join.md).

Сервер ClickHouse:

1.  Делит данные правого соединения на блоки с максимумом указанного количества строк.
2.  Индексирует каждый блок его минимальными и максимальными значениями.
3.  Сбрасывает подготовленные блоки на диск, если это возможно.

Возможные значения:

- Любое положительное целое число. Рекомендуемый диапазон значений: \[1000, 100000\].
## partial_result_on_first_cancel {#partial_result_on_first_cancel} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешает запросу вернуть частичный результат после отмены.
## parts_to_delay_insert {#parts_to_delay_insert} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Если в целевой таблице есть хотя бы столько активных частей в одной партиции, искусственно замедляет вставку в таблицу.
## parts_to_throw_insert {#parts_to_throw_insert} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Если в единственной партиции целевой таблицы активных частей больше чем это число, выбрасывает исключение 'Слишком много частей ...'.
## periodic_live_view_refresh {#periodic_live_view_refresh} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`60`|

Интервал, после которого периодически обновляемое live представление будет принудительно обновлено.
## poll_interval {#poll_interval} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10`|

Блокирует цикл ожидания запроса на сервере на указанное количество секунд.
## postgresql_connection_attempt_timeout {#postgresql_connection_attempt_timeout} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`2`|

Тайм-аут подключения в секундах для одной попытки подключения к конечной точке PostgreSQL.
Значение передаётся как параметр `connect_timeout` в URL подключения.
## postgresql_connection_pool_auto_close_connection {#postgresql_connection_pool_auto_close_connection} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Закрывает соединение перед возвратом соединения в пул.
## postgresql_connection_pool_retries {#postgresql_connection_pool_retries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`2`|

Количество попыток push/pop в пуле соединений для движка таблицы PostgreSQL и движка базы данных.
## postgresql_connection_pool_size {#postgresql_connection_pool_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`16`|

Размер пула соединений для движка таблицы PostgreSQL и движка базы данных.
## postgresql_connection_pool_wait_timeout {#postgresql_connection_pool_wait_timeout} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5000`|

Тайм-аут push/pop пула соединений при пустом пуле для движка таблицы PostgreSQL и движка базы данных. По умолчанию он будет блокировать при пустом пуле.
## postgresql_fault_injection_probability {#postgresql_fault_injection_probability} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0`|

Приблизительная вероятность сбоя внутренних (для репликации) запросов PostgreSQL. Допустимое значение находится в интервале [0.0f, 1.0f].
## prefer_column_name_to_alias {#prefer_column_name_to_alias} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает использование оригинальных названий колонок вместо алиасов в выражениях и предложениях запросов. Это особенно важно, когда алиас совпадает с названием колонки, см. [Алиасы выражений](/sql-reference/syntax#notes-on-usage). Включите эту настройку, чтобы сделать правила синтаксиса алиасов в ClickHouse более совместимыми с большинством других движков баз данных.

Возможные значения:

- 0 — Название колонки заменяется алиасом.
- 1 — Название колонки не заменяется алиасом.

**Пример**

Разница между включённым и выключенным:

Запрос:

```sql
SET prefer_column_name_to_alias = 0;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

Результат:

```text
Получено исключение от сервера (версия 21.5.1):
Код: 184. DB::Exception: Получено от localhost:9000. DB::Exception: Агрегатная функция avg(number) найдена внутри другой агрегатной функции в запросе: Во время обработки avg(number) AS number.
```

Запрос:

```sql
SET prefer_column_name_to_alias = 1;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

Результат:

```text
┌─number─┬─max(number)─┐
│    4.5 │           9 │
└────────┴─────────────┘
```
## prefer_external_sort_block_bytes {#prefer_external_sort_block_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`16744704`|

Предпочитать максимальные байты блока для внешней сортировки, уменьшить использование памяти во время слияния.
## prefer_global_in_and_join {#prefer_global_in_and_join} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает замену операторов `IN`/`JOIN` на `GLOBAL IN`/`GLOBAL JOIN`.

Возможные значения:

- 0 — Отключено. Операторы `IN`/`JOIN` не заменяются на `GLOBAL IN`/`GLOBAL JOIN`.
- 1 — Включено. Операторы `IN`/`JOIN` заменяются на `GLOBAL IN`/`GLOBAL JOIN`.

**Использование**

Хотя `SET distributed_product_mode=global` может изменить поведение запросов для распределённых таблиц, он не подходит для локальных таблиц или таблиц из внешних ресурсов. Здесь и вступает в действие настройка `prefer_global_in_and_join`.

Например, у нас есть узлы обслуживания запросов, которые содержат локальные таблицы, не подходящие для распределения. Нам нужно рассеять их данные на лету во время распределённой обработки с помощью ключевого слова `GLOBAL` — `GLOBAL IN`/`GLOBAL JOIN`.

Другой случай использования `prefer_global_in_and_join` — доступ к таблицам, созданным внешними движками. Эта настройка помогает сократить количество вызовов к внешним источникам при объединении таких таблиц: только один вызов за запрос.

**Смотрите также:**

- [Распределённые подзапросы](/sql-reference/operators/in#distributed-subqueries) для получения дополнительной информации о том, как использовать `GLOBAL IN`/`GLOBAL JOIN`
## prefer_localhost_replica {#prefer_localhost_replica} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает/выключает предпочтительное использование локальной реплики при обработке распределённых запросов.

Возможные значения:

- 1 — ClickHouse всегда отправляет запрос на локальную реплику, если она существует.
- 0 — ClickHouse использует стратегию балансировки, указанную в настройке [load_balancing](#load_balancing).

:::note
Отключите эту настройку, если вы используете [max_parallel_replicas](#max_parallel_replicas) без [parallel_replicas_custom_key](#parallel_replicas_custom_key).
Если [parallel_replicas_custom_key](#parallel_replicas_custom_key) установлен, отключите эту настройку только если она используется в кластере с несколькими шардерами, содержащими несколько реплик.
Если она используется в кластере с одним шардером и несколькими репликами, отключение этой настройки приведёт к негативным последствиям.
:::
## prefer_warmed_unmerged_parts_seconds {#prefer_warmed_unmerged_parts_seconds} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Int64`|`0`|

Эта настройка имеет действие только в ClickHouse Cloud. Если объединённая часть моложе этого количества секунд и не разогрета, (см. [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)), но все её исходные части доступны и разогреты, SELECT запросы будут читать из этих частей. Только для Replicated-/SharedMergeTree. Обратите внимание, что это проверяет только то, обработал ли CacheWarmer часть; если часть была извлечена в кэш чем-то другим, она всё равно будет считаться холодной, пока CacheWarmer не дойдёт до неё; если она была разогрета, а затем выгнана из кэша, она всё равно будет считаться тёплой.
## preferred_block_size_bytes {#preferred_block_size_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000`|

Эта настройка регулирует размер блока данных для обработки запросов и представляет собой дополнительную тонкую настройку более грубой настройки 'max_block_size'. Если колонки большие, и при 'max_block_size' строки размер блока, вероятно, будет больше указанного количества байт, его размер будет снижен для лучшей локальности кэша CPU.
## preferred_max_column_in_block_size_bytes {#preferred_max_column_in_block_size_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Предел максимального размера колонки в блоке при чтении. Помогает уменьшить количество промахов кэша. Должен быть близок к размеру кэша L2.
## preferred_optimize_projection_name {#preferred_optimize_projection_name} 

Если установлено в непустую строку, ClickHouse будет пытаться применить указанную проекцию в запросе.

Возможные значения:

- строка: название предпочтительной проекции
## prefetch_buffer_size {#prefetch_buffer_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1048576`|

Максимальный размер буфера предзагрузки для чтения из файловой системы.
## print_pretty_type_names {#print_pretty_type_names} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Позволяет выводить глубоко вложенные названия типов в красивом виде с отступами в запросе `DESCRIBE` и в функции `toTypeName()`.

Пример:

```sql
CREATE TABLE test (a Tuple(b String, c Tuple(d Nullable(UInt64), e Array(UInt32), f Array(Tuple(g String, h Map(String, Array(Tuple(i String, j UInt64))))), k Date), l Nullable(String))) ENGINE=Memory;
DESCRIBE TABLE test FORMAT TSVRaw SETTINGS print_pretty_type_names=1;
```

```
a   Tuple(
    b String,
    c Tuple(
        d Nullable(UInt64),
        e Array(UInt32),
        f Array(Tuple(
            g String,
            h Map(
                String,
                Array(Tuple(
                    i String,
                    j UInt64
                ))
            )
        )),
        k Date
    ),
    l Nullable(String)
)
```
## priority {#priority} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Приоритет запроса. 1 - наивысший, более высокое значение - более низкий приоритет; 0 - не использовать приоритеты.
## push_external_roles_in_interserver_queries {#push_external_roles_in_interserver_queries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включить передачу пользовательских ролей от инициатора к другим узлам во время выполнения запроса.
## query_cache_compress_entries {#query_cache_compress_entries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Сжимать записи в [кэше запросов](../query-cache.md). Уменьшает потребление памяти кэша запросов за счёт более медленного вставки / считывания из него.

Возможные значения:

- 0 - Отключено
- 1 - Включено
## query_cache_max_entries {#query_cache_max_entries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество результатов запросов, которые текущий пользователь может хранить в [кэше запросов](../query-cache.md). 0 означает неограниченное количество.

Возможные значения:

- Положительное целое число >= 0.
## query_cache_max_size_in_bytes {#query_cache_max_size_in_bytes} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество памяти (в байтах), которое текущий пользователь может выделить в [кэше запросов](../query-cache.md). 0 означает неограниченное.

Возможные значения:

- Положительное целое число >= 0.
## query_cache_min_query_duration {#query_cache_min_query_duration} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`0`|

Минимальная продолжительность в миллисекундах, в течение которой запрос должен выполняться, чтобы его результат был сохранён в [кэше запросов](../query-cache.md).

Возможные значения:

- Положительное целое число >= 0.
## query_cache_min_query_runs {#query_cache_min_query_runs} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Минимальное количество раз, которое запрос `SELECT` должен выполняться, прежде чем его результат будет сохранён в [кэше запросов](../query-cache.md).

Возможные значения:

- Положительное целое число >= 0.
## query_cache_nondeterministic_function_handling {#query_cache_nondeterministic_function_handling} 

|Тип|По умолчанию|
|---|---|
|`QueryResultCacheNondeterministicFunctionHandling`|`throw`|

Управляет тем, как [кэш запросов](../query-cache.md) обрабатывает запросы `SELECT` с недетерминированными функциями, такими как `rand()` или `now()`.

Возможные значения:

- `'throw'` - Генерировать исключение и не кэшировать результат запроса.
- `'save'` - Кэшировать результат запроса.
- `'ignore'` - Не кэшировать результат запроса и не генерировать исключение.
## query_cache_share_between_users {#query_cache_share_between_users} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если включено, результат запросов `SELECT`, кэшированных в [кэше запросов](../query-cache.md), может быть прочитан другими пользователями.
Не рекомендуется включать эту настройку по соображениям безопасности.

Возможные значения:

- 0 - Отключено
- 1 - Включено
## query_cache_squash_partial_results {#query_cache_squash_partial_results} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Сжимать частичные результатирующие блоки в блоки размера [max_block_size](#max_block_size). Уменьшает производительность вставок в [кэш запросов](../query-cache.md), но улучшает сжимаемость записей кэша (см. [query_cache_compress-entries](#query_cache_compress_entries)).

Возможные значения:

- 0 - Отключено
- 1 - Включено
## query_cache_system_table_handling {#query_cache_system_table_handling} 

|Тип|По умолчанию|
|---|---|
|`QueryResultCacheSystemTableHandling`|`throw`|

Управляет тем, как [кэш запросов](../query-cache.md) обрабатывает запросы `SELECT` к системным таблицам, т.е. к таблицам в базах данных `system.*` и `information_schema.*`.

Возможные значения:

- `'throw'` - Генерировать исключение и не кэшировать результат запроса.
- `'save'` - Кэшировать результат запроса.
- `'ignore'` - Не кэшировать результат запроса и не генерировать исключение.
## query_cache_tag {#query_cache_tag} 

Строка, которая действует как метка для записей [кэша запросов](../query-cache.md).
Одни и те же запросы с разными метками рассматриваются кэшем запросов как разные.

Возможные значения:

- Любая строка
## query_cache_ttl {#query_cache_ttl} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`60`|

После этого времени в секундах записи в [кэше запросов](../query-cache.md) становятся устаревшими.

Возможные значения:

- Положительное целое число >= 0.
## query_metric_log_interval {#query_metric_log_interval} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`-1`|

Интервал в миллисекундах, с которым собирается [query_metric_log](../../operations/system-tables/query_metric_log.md) для отдельных запросов.

Если установлено на любое отрицательное значение, будет использоваться значение `collect_interval_milliseconds` из настройки [query_metric_log](/operations/server-configuration-parameters/settings#query_metric_log) или по умолчанию 1000, если оно отсутствует.

Чтобы отключить сбор отдельного запроса, установите `query_metric_log_interval` в 0.

Значение по умолчанию: -1
## query_plan_aggregation_in_order {#query_plan_aggregation_in_order} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию плана запроса агрегации в порядке.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_convert_join_to_in {#query_plan_convert_join_to_in} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить преобразование JOIN в подзапрос с IN, если выходные колонки связаны только с левой таблицей.
## query_plan_convert_outer_join_to_inner_join {#query_plan_convert_outer_join_to_inner_join} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить преобразование OUTER JOIN в INNER JOIN, если фильтр после JOIN всегда фильтрует значения по умолчанию.
## query_plan_enable_multithreading_after_window_functions {#query_plan_enable_multithreading_after_window_functions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включить многопоточность после оценки оконных функций для обеспечения параллельной потоковой обработки.
## query_plan_enable_optimizations {#query_plan_enable_optimizations} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию запросов на уровне плана запроса.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить все оптимизации на уровне плана запроса
- 1 - Включить оптимизации на уровне плана запроса (но отдельные оптимизации могут быть отключены через их индивидуальные настройки)
## query_plan_execute_functions_after_sorting {#query_plan_execute_functions_after_sorting} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая перемещает выражения после шагов сортировки.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_filter_push_down {#query_plan_filter_push_down} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая перемещает фильтры вниз в плане выполнения.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_join_shard_by_pk_ranges {#query_plan_join_shard_by_pk_ranges} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Применить шардирование для JOIN, если ключи объединения содержат префикс PRIMARY KEY для обеих таблиц. Поддерживается для алгоритмов hash, parallel_hash и full_sorting_merge.
## query_plan_join_swap_table {#query_plan_join_swap_table} 

|Тип|По умолчанию|
|---|---|
|`BoolAuto`|`auto`|

    Определить, какая сторона соединения должна быть таблицей построения (также называемой внутренней, той, которая вставляется в хеш-таблицу для хеш-объединения) в плане запроса. Эта настройка поддерживается только для `ALL` строгости объединения с клаузой `JOIN ON`. Возможные значения:
    - 'auto': Позволить планировщику решить, какую таблицу использовать в качестве таблицы построения.
    - 'false': Никогда не менять таблицы (правая таблица является таблицей построения).
    - 'true': Всегда менять таблицы (левая таблица является таблицей построения).
## query_plan_lift_up_array_join {#query_plan_lift_up_array_join} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая перемещает ARRAY JOIN вверх в плане выполнения.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_lift_up_union {#query_plan_lift_up_union} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая перемещает более крупные поддеревья плана запроса в объединение, чтобы включить дальнейшие оптимизации.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_max_limit_for_lazy_materialization {#query_plan_max_limit_for_lazy_materialization} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10`|

Контролирует максимальное предельное значение, позволяющее использовать план запроса для оптимизации ленивого материализования. Если ноль, нет предела.
## query_plan_max_optimizations_to_apply {#query_plan_max_optimizations_to_apply} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10000`|

Ограничивает общее количество оптимизаций, применяемых к плану запроса, см. настройку [query_plan_enable_optimizations](#query_plan_enable_optimizations).
Полезно для предотвращения длительного времени оптимизации сложных запросов.
В запросе EXPLAIN PLAN прекращается применение оптимизаций после достижения этого предела и возвращается план как есть.
Для обычного выполнения запроса, если фактическое количество оптимизаций превышает эту настройку, выбрасывается исключение.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::
## query_plan_merge_expressions {#query_plan_merge_expressions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая сливает последовательные фильтры.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_merge_filters {#query_plan_merge_filters} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить слияние фильтров в плане запроса.
## query_plan_optimize_lazy_materialization {#query_plan_optimize_lazy_materialization} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать план запроса для оптимизации ленивого материализования.
## query_plan_optimize_prewhere {#query_plan_optimize_prewhere} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить перемещение фильтра в выражение PREWHERE для поддерживаемых хранилищ.
## query_plan_push_down_limit {#query_plan_push_down_limit} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая перемещает LIMIT вниз в плане выполнения.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_read_in_order {#query_plan_read_in_order} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию чтения в порядке на уровне плана запроса.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_remove_redundant_distinct {#query_plan_remove_redundant_distinct} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая удаляет избыточные DISTINCT шаги.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_remove_redundant_sorting {#query_plan_remove_redundant_sorting} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая удаляет избыточные сортировочные шаги, например, в подзапросах.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_reuse_storage_ordering_for_window_functions {#query_plan_reuse_storage_ordering_for_window_functions} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая использует сортировку хранилища при сортировке для оконных функций.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_split_filter {#query_plan_split_filter} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Включает оптимизацию на уровне плана запроса, которая разбивает фильтры на выражения.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_try_use_vector_search {#query_plan_try_use_vector_search} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает оптимизацию на уровне плана запроса, которая пытается использовать индекс векторного сходства.
Действует только если установка [query_plan_enable_optimizations](#query_plan_enable_optimizations) равна 1.

:::note
Это настройка для экспертов, которая должна использоваться только для отладки разработчиками. В будущем настройка может измениться несовместимыми способами или быть удалена.
:::

Возможные значения:

- 0 - Отключить
- 1 - Включить
## query_plan_use_new_logical_join_step {#query_plan_use_new_logical_join_step} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать новый логический шаг объединения в плане запроса.
## query_profiler_cpu_time_period_ns {#query_profiler_cpu_time_period_ns} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000000`|

Устанавливает период для таймера процессора [профилировщика запросов](../../operations/optimizing-performance/sampling-query-profiler.md). Этот таймер считает только время CPU.

Возможные значения:

- Положительное целое число в наносекундах.

    Рекомендуемые значения:

            - 10000000 (100 раз в секунду) наносекунд и больше для одиночных запросов.
            - 1000000000 (раз в секунду) для профилирования по всему кластеру.

- 0 для отключения таймера.

**Временно отключено в ClickHouse Cloud.**

Смотрите также:

- Системная таблица [trace_log](/operations/system-tables/trace_log)
## query_profiler_real_time_period_ns {#query_profiler_real_time_period_ns} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000000000`|

Устанавливает период для реального таймера [профилировщика запросов](../../operations/optimizing-performance/sampling-query-profiler.md). Реальный таймер считает время по часам.

Возможные значения:

- Положительное целое число в наносекундах.

    Рекомендуемые значения:

            - 10000000 (100 раз в секунду) наносекунд и меньше для одиночных запросов.
            - 1000000000 (раз в секунду) для профилирования по всему кластеру.

- 0 для отключения таймера.

**Временно отключено в ClickHouse Cloud.**

Смотрите также:

- Системная таблица [trace_log](/operations/system-tables/trace_log)
## queue_max_wait_ms {#queue_max_wait_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`0`|

Время ожидания в очереди запросов, если количество параллельных запросов превышает максимальное.
## rabbitmq_max_wait_ms {#rabbitmq_max_wait_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`5000`|

Время ожидания для чтения из RabbitMQ перед повторной попыткой.
## read_backoff_max_throughput {#read_backoff_max_throughput} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1048576`|

Настройки, чтобы уменьшить количество потоков в случае медленных чтений. Подсчитывать события, когда полоса пропускания чтения составляет меньше указанного количества байт в секунду.
## read_backoff_min_concurrency {#read_backoff_min_concurrency} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1`|

Настройки, чтобы попытаться удерживать минимальное количество потоков в случае медленных чтений.
## read_backoff_min_events {#read_backoff_min_events} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`2`|

Настройки, чтобы уменьшить количество потоков в случае медленных чтений. Количество событий, после которого количество потоков будет уменьшено.
## read_backoff_min_interval_between_events_ms {#read_backoff_min_interval_between_events_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`1000`|

Настройки, чтобы уменьшить количество потоков в случае медленных чтений. Не учитывать событие, если предыдущее прошло менее определённого количества времени.
## read_backoff_min_latency_ms {#read_backoff_min_latency_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`1000`|

Настройка, чтобы уменьшить количество потоков в случае медленных чтений. Учитывать только чтения, которые заняли как минимум это время.
## read_from_filesystem_cache_if_exists_otherwise_bypass_cache {#read_from_filesystem_cache_if_exists_otherwise_bypass_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Позволяет использовать кэш файловой системы в пассивном режиме - извлекать выгоду из существующих записей кэша, но не добавлять новые записи в кэш. Если вы установите эту настройку для тяжелых ad-hoc запросов и оставите её отключенной для коротких запросов в реальном времени, это позволит избежать тростников кэша из-за слишком тяжелых запросов и улучшить общую эффективность системы.
## read_from_page_cache_if_exists_otherwise_bypass_cache {#read_from_page_cache_if_exists_otherwise_bypass_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать кэш страниц в пользовательском пространстве в пассивном режиме, аналогично read_from_filesystem_cache_if_exists_otherwise_bypass_cache.
## read_in_order_two_level_merge_threshold {#read_in_order_two_level_merge_threshold} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100`|

Минимальное количество частей для чтения, чтобы выполнить предварительный этап слияния во время многопоточной чтения в порядке первичного ключа.
## read_in_order_use_buffering {#read_in_order_use_buffering} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать буферизацию перед слиянием при чтении в порядке первичного ключа. Это увеличивает параллелизм выполнения запросов.
## read_in_order_use_virtual_row {#read_in_order_use_virtual_row} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать виртуальную строку при чтении в порядке первичного ключа или его монотонной функции. Это полезно при поиске по нескольким частям, так как касаются только актуальные.
## read_overflow_mode {#read_overflow_mode} 

|Тип|По умолчанию|
|---|---|
|`OverflowMode`|`throw`|

Что делать, когда предел превышен.
## read_overflow_mode_leaf {#read_overflow_mode_leaf} 

|Тип|По умолчанию|
|---|---|
|`OverflowMode`|`throw`|

Устанавливает, что происходит, когда объём читаемых данных превышает один из ограничений листа.

Возможные опции:
- `throw`: выбросить исключение (по умолчанию).
- `break`: прекратить выполнение запроса и вернуть частичный результат.
## read_priority {#read_priority} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`0`|

Приоритет чтения данных из локальной файловой системы или удалённой файловой системы. Поддерживается только для метода 'pread_threadpool' для локальной файловой системы и для метода `threadpool` для удалённой файловой системы.
## read_through_distributed_cache {#read_through_distributed_cache} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Эта настройка имеет действие только в ClickHouse Cloud. Позволяет чтение из распределённого кэша.
## readonly {#readonly} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

0 - отсутствие ограничений на только чтение. 1 - только запросы на чтение, а также изменение явно разрешенных настроек. 2 - только запросы на чтение, а также изменение настроек, кроме настройки 'readonly'.
## receive_data_timeout_ms {#receive_data_timeout_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`2000`|

Таймаут подключения для получения первого пакета данных или пакета с положительным прогрессом от реплики.
## receive_timeout {#receive_timeout} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`300`|

Таймаут для получения данных из сети, в секундах. Если в этом интервале не были получены байты, будет выброшено исключение. Если вы установите эту настройку на клиенте, тайм-аут 'send_timeout' для сокета также будет установлен на соответствующем конце подключения на сервере.
## regexp_max_matches_per_row {#regexp_max_matches_per_row} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Устанавливает максимальное количество совпадений для одного регулярного выражения на строку. Используйте это, чтобы защититься от перегрузки памяти при использовании жадного регулярного выражения в функции [extractAllGroupsHorizontal](/sql-reference/functions/string-search-functions#extractallgroupshorizontal).

Возможные значения:

- Положительное целое число.
## reject_expensive_hyperscan_regexps {#reject_expensive_hyperscan_regexps} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Отклонять шаблоны, которые, вероятно, будут дорогостоящими для оценки с помощью hyperscan (из-за взрыва состояния NFA).
## remerge_sort_lowered_memory_bytes_ratio {#remerge_sort_lowered_memory_bytes_ratio} 

|Тип|По умолчанию|
|---|---|
|`Float`|`2`|

Если использование памяти после повторного слияния не снижено на это соотношение, повторное слияние будет отключено.
## remote_filesystem_read_method {#remote_filesystem_read_method} 

|Тип|По умолчанию|
|---|---|
|`String`|`threadpool`|

Метод чтения данных из удалённой файловой системы, один из: read, threadpool.
## remote_filesystem_read_prefetch {#remote_filesystem_read_prefetch} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Следует использовать предварительную загрузку при чтении данных из удалённой файловой системы.
## remote_fs_read_backoff_max_tries {#remote_fs_read_backoff_max_tries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5`|

Максимальное количество попыток чтения с откатом.
## remote_fs_read_max_backoff_ms {#remote_fs_read_max_backoff_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10000`|

Максимальное время ожидания при попытке чтения данных для удалённого диска.
## remote_read_min_bytes_for_seek {#remote_read_min_bytes_for_seek} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`4194304`|

Минимальные байты, необходимые для удалённого чтения (url, s3) для выполнения поиска, вместо чтения с игнорированием.
## rename_files_after_processing {#rename_files_after_processing} 

- **Тип:** Строка

- **Значение по умолчанию:** Пустая строка

Эта настройка позволяет задать шаблон переименования для файлов, обработанных функцией таблицы `file`. Когда опция установлена, все файлы, прочитанные функцией таблицы `file`, будут переименованы в соответствии с указанным шаблоном с заполнителями, только если обработка файлов была успешной.
### Заполнители

- `%a` — Полное имя оригинального файла (например, "sample.csv").
- `%f` — Имя оригинального файла без расширения (например, "sample").
- `%e` — Оригинальное расширение файла с точкой (например, ".csv").
- `%t` — Время (в микросекундах).
- `%%` — Знак процента ("%").
### Пример
- Опция: `--rename_files_after_processing="processed_%f_%t%e"`

- Запрос: `SELECT * FROM file('sample.csv')`

Если чтение `sample.csv` прошло успешно, файл будет переименован в `processed_sample_1683473210851438.csv`.

## replace_running_query {#replace_running_query} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

При использовании HTTP интерфейса параметр 'query_id' может быть передан. Это любая строка, которая служит идентификатором запроса. Если в это время существует запрос от того же пользователя с тем же 'query_id', поведение зависит от параметра 'replace_running_query'.

`0` (по умолчанию) – Генерирует исключение (не позволяет запросу выполняться, если запрос с тем же 'query_id' уже выполняется).

`1` – Отменяет старый запрос и начинает выполнение нового.

Установите этот параметр в 1 для реализации предложений по условиям сегментации. После ввода следующего символа, если старый запрос еще не завершен, он должен быть отменен.

## replace_running_query_max_wait_ms {#replace_running_query_max_wait_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`5000`|

Время ожидания завершения выполнения запроса с тем же `query_id`, когда активен параметр [replace_running_query](#replace_running_query).

Возможные значения:

- Положительное целое число.
- 0 — Генерирует исключение, которое не позволяет запустить новый запрос, если сервер уже выполняет запрос с тем же `query_id`.

## replication_wait_for_inactive_replica_timeout {#replication_wait_for_inactive_replica_timeout} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`120`|

Указывает, как долго (в секундах) ждать, пока не выполнится [ALTER](../../sql-reference/statements/alter/index.md), [OPTIMIZE](../../sql-reference/statements/optimize.md) или [TRUNCATE](../../sql-reference/statements/truncate.md) запросы для неактивных реплик.

Возможные значения:

- 0 — Не ждать.
- Отрицательное целое число — Ждать неограниченное время.
- Положительное целое число — Количество секунд ожидания.

## restore_replace_external_dictionary_source_to_null {#restore_replace_external_dictionary_source_to_null} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Заменяет источники внешних словарей на Null при восстановлении. Полезно для тестирования.

## restore_replace_external_engines_to_null {#restore_replace_external_engines_to_null} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Для тестирования. Заменяет все внешние движки на Null, чтобы не инициировать внешние соединения.

## restore_replace_external_table_functions_to_null {#restore_replace_external_table_functions_to_null} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Для тестирования. Заменяет все внешние табличные функции на Null, чтобы не инициировать внешние соединения.

## restore_replicated_merge_tree_to_shared_merge_tree {#restore_replicated_merge_tree_to_shared_merge_tree} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Заменяет движок таблицы с Replicated*MergeTree -> Shared*MergeTree во время ВОССТАНОВЛЕНИЯ.

## result_overflow_mode {#result_overflow_mode} 

|Тип|По умолчанию|
|---|---|
|`OverflowMode`|`throw`|

Значение по умолчанию для облака: `throw`

Устанавливает, что делать, если объем результата превышает один из лимитов.

Возможные значения:
- `throw`: выбросить исключение (по умолчанию).
- `break`: остановить выполнение запроса и вернуть частичный результат, как будто исходные данные закончились.

Использование 'break' похоже на использование LIMIT. `Break` прерывает выполнение только на уровне блока. Это означает, что количество возвращаемых строк больше чем [`max_result_rows`](/operations/settings/settings#max_result_rows), кратное [`max_block_size`](/operations/settings/settings#max_block_size) и зависит от [`max_threads`](/operations/settings/settings#max_threads).

**Пример**

```sql title="Запрос"
SET max_threads = 3, max_block_size = 3333;
SET max_result_rows = 3334, result_overflow_mode = 'break';

SELECT *
FROM numbers_mt(100000)
FORMAT Null;
```

```text title="Результат"
6666 rows in set. ...
```

## rewrite_count_distinct_if_with_count_distinct_implementation {#rewrite_count_distinct_if_with_count_distinct_implementation} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Позволяет переписывать `countDistinctIf` с настройкой [count_distinct_implementation](#count_distinct_implementation).

Возможные значения:

- true — Разрешить.
- false — Запретить.

## s3_allow_multipart_copy {#s3_allow_multipart_copy} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешить многосоставное копирование в S3.

## s3_allow_parallel_part_upload {#s3_allow_parallel_part_upload} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать несколько потоков для загрузки многосоставных частей в S3. Это может привести к немного большему использованию памяти.

## s3_check_objects_after_upload {#s3_check_objects_after_upload} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Проверять каждый загруженный объект в S3 с запросом head, чтобы убедиться, что загрузка прошла успешно.

## s3_connect_timeout_ms {#s3_connect_timeout_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Таймаут подключения к хостам с дисками S3.

## s3_create_new_file_on_insert {#s3_create_new_file_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает создание нового файла при каждой вставке в таблицы движка S3. Если включено, при каждой вставке будет создан новый объект S3 с ключом, аналогично следующему шаблону:

начальный: `data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz` и т. д.

Возможные значения:
- 0 — Запрос `INSERT` создает новый файл или завершается ошибкой, если файл существует и не установлен s3_truncate_on_insert.
- 1 — Запрос `INSERT` создает новый файл при каждой вставке, используя суффикс (со второго) при условии, что s3_truncate_on_insert не установлен.

Смотрите более подробную информацию [здесь](/integrations/s3#inserting-data).

## s3_disable_checksum {#s3_disable_checksum} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Не вычислять контрольную сумму при отправке файла в S3. Это ускоряет записи, избегая избыточных проходов по файлу. Это в основном безопасно, поскольку данные таблиц MergeTree все равно проверяются ClickHouse, а при доступе к S3 через HTTPS уровень TLS уже обеспечивает целостность при передаче по сети. В то время как дополнительные контрольные суммы в S3 обеспечивают дополнительную защиту.

## s3_ignore_file_doesnt_exist {#s3_ignore_file_doesnt_exist} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорировать отсутствие файла, если он не существует, при чтении определенных ключей.

Возможные значения:
- 1 — Запрос `SELECT` возвращает пустой результат.
- 0 — Запрос `SELECT` генерирует исключение.

## s3_list_object_keys_size {#s3_list_object_keys_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Максимальное количество файлов, которые могут быть возвращены в пакете по запросу ListObject.

## s3_max_connections {#s3_max_connections} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1024`|

Максимальное количество подключений на сервер.

## s3_max_get_burst {#s3_max_get_burst} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество запросов, которые могут быть выданы одновременно до достижения лимита запросов в секунду. По умолчанию (0) равно `s3_max_get_rps`.

## s3_max_get_rps {#s3_max_get_rps} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Лимит на частоту GET-запросов S3 в секунду до снижения скорости. Ноль означает неограниченно.

## s3_max_inflight_parts_for_one_file {#s3_max_inflight_parts_for_one_file} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`20`|

Максимальное количество загружаемых одновременно частей в запросе многосоставной загрузки. 0 означает неограниченно.

## s3_max_part_number {#s3_max_part_number} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10000`|

Максимальный номер части для загрузки в S3.

## s3_max_put_burst {#s3_max_put_burst} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальное количество запросов, которые могут быть выданы одновременно до достижения лимита запросов в секунду. По умолчанию (0) равно `s3_max_put_rps`.

## s3_max_put_rps {#s3_max_put_rps} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Лимит на частоту PUT-запросов S3 в секунду до снижения скорости. Ноль означает неограниченно.

## s3_max_redirects {#s3_max_redirects} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`10`|

Максимальное количество перенаправлений S3.

## s3_max_single_operation_copy_size {#s3_max_single_operation_copy_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`33554432`|

Максимальный размер для копирования в одной операции в S3. Эта настройка используется только если s3_allow_multipart_copy установлено на true.

## s3_max_single_part_upload_size {#s3_max_single_part_upload_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`33554432`|

Максимальный размер объекта для загрузки с использованием одночастной загрузки в S3.

## s3_max_single_read_retries {#s3_max_single_read_retries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`4`|

Максимальное количество попыток при одном чтении из S3.

## s3_max_unexpected_write_error_retries {#s3_max_unexpected_write_error_retries} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`4`|

Максимальное количество попыток в случае неожиданных ошибок при записи в S3.

## s3_max_upload_part_size {#s3_max_upload_part_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`5368709120`|

Максимальный размер части для загрузки во время многосоставной загрузки в S3.

## s3_min_upload_part_size {#s3_min_upload_part_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`16777216`|

Минимальный размер части для загрузки во время многосоставной загрузки в S3.

## s3_request_timeout_ms {#s3_request_timeout_ms} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`30000`|

Таймаут бездействия для передачи и получения данных в S3. Ошибка, если одной TCP операции чтения или записи не удается выполнить в течение этого времени.

## s3_retry_attempts {#s3_retry_attempts} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`100`|

Настройка для Aws::Client::RetryStrategy, Aws::Client выполняет повторные попытки самостоятельно, 0 означает отсутствие повторных попыток.

## s3_skip_empty_files {#s3_skip_empty_files} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает пропуск пустых файлов в таблицах движка [S3](../../engines/table-engines/integrations/s3.md).

Возможные значения:
- 0 — Запрос `SELECT` генерирует исключение, если пустой файл несовместим с запрашиваемым форматом.
- 1 — Запрос `SELECT` возвращает пустой результат для пустого файла.

## s3_strict_upload_part_size {#s3_strict_upload_part_size} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Точный размер части для загрузки во время многосоставной загрузки в S3 (некоторые реализации не поддерживают части переменного размера).

## s3_throw_on_zero_files_match {#s3_throw_on_zero_files_match} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Генерировать ошибку, когда запрос ListObjects не может найти ни одного файла.

## s3_truncate_on_insert {#s3_truncate_on_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает обрезку перед вставками в таблицы движка S3. Если отключено, генерируется исключение при попытках вставки, если объект S3 уже существует.

Возможные значения:
- 0 — Запрос `INSERT` создает новый файл или завершается ошибкой, если файл существует и s3_create_new_file_on_insert не установлен.
- 1 — Запрос `INSERT` заменяет существующее содержимое файла новыми данными.

Смотрите более подробную информацию [здесь](/integrations/s3#inserting-data).

## s3_upload_part_size_multiply_factor {#s3_upload_part_size_multiply_factor} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`2`|

Умножает s3_min_upload_part_size на этот коэффициент каждый раз, когда s3_multiply_parts_count_threshold частей загружается с одной записи в S3.

## s3_upload_part_size_multiply_parts_count_threshold {#s3_upload_part_size_multiply_parts_count_threshold} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`500`|

Каждый раз, когда это количество частей загружается в S3, s3_min_upload_part_size умножается на s3_upload_part_size_multiply_factor.

## s3_use_adaptive_timeouts {#s3_use_adaptive_timeouts} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Когда установлено значение `true`, для всех запросов S3 первые две попытки выполняются с низкими таймаутами отправки и получения. Когда установлено значение `false`, все попытки выполняются с идентичными таймаутами.

## s3_validate_request_settings {#s3_validate_request_settings} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает валидацию настроек запросов S3.

Возможные значения:
- 1 — валидировать настройки.
- 0 — не валидировать настройки.

## s3queue_default_zookeeper_path {#s3queue_default_zookeeper_path} 

|Тип|По умолчанию|
|---|---|
|`String`|`/clickhouse/s3queue/`|

Префикс пути по умолчанию для Zookeeper для движка S3Queue.

## s3queue_enable_logging_to_s3queue_log {#s3queue_enable_logging_to_s3queue_log} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает запись в system.s3queue_log. Значение может быть переопределено для каждой таблицы с помощью настроек таблицы.

## s3queue_migrate_old_metadata_to_buckets {#s3queue_migrate_old_metadata_to_buckets} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Миграция старой структуры метаданных таблицы S3Queue на новую.

## schema_inference_cache_require_modification_time_for_url {#schema_inference_cache_require_modification_time_for_url} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать схему из кэша для URL с проверкой времени последнего изменения (для URL с заголовком Last-Modified).

## schema_inference_use_cache_for_azure {#schema_inference_use_cache_for_azure} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать кэш в выводе схемы при использовании табличной функции Azure.

## schema_inference_use_cache_for_file {#schema_inference_use_cache_for_file} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать кэш в выводе схемы при использовании табличной функции файла.

## schema_inference_use_cache_for_hdfs {#schema_inference_use_cache_for_hdfs} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать кэш в выводе схемы при использовании табличной функции HDFS.

## schema_inference_use_cache_for_s3 {#schema_inference_use_cache_for_s3} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать кэш в выводе схемы при использовании табличной функции S3.

## schema_inference_use_cache_for_url {#schema_inference_use_cache_for_url} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать кэш в выводе схемы при использовании табличной функции URL.

## select_sequential_consistency {#select_sequential_consistency} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

:::note
Эта настройка имеет различные поведения для SharedMergeTree и ReplicatedMergeTree. Посмотрите [последовательность SharedMergeTree](/cloud/reference/shared-merge-tree#consistency) для получения дополнительной информации о поведении `select_sequential_consistency` в SharedMergeTree.
:::

Включает или отключает последовательную согласованность для запросов `SELECT`. Требует, чтобы `insert_quorum_parallel` был отключен (включен по умолчанию).

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

Использование

Когда последовательная согласованность включена, ClickHouse позволяет клиенту выполнять запрос `SELECT` только для тех реплик, которые содержат данные от всех предыдущих запросов `INSERT`, выполненных с `insert_quorum`. Если клиент ссылается на частичную реплику, ClickHouse создаст исключение. Запрос SELECT не будет включать данные, которые еще не были записаны в кворум реплик.

Когда `insert_quorum_parallel` включен (по умолчанию), тогда `select_sequential_consistency` не работает. Это связано с тем, что параллельные запросы `INSERT` могут быть записаны в разные наборы кворумных реплик, поэтому нет гарантии, что одна реплика примет все записи.

Смотрите также:

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)

## send_logs_level {#send_logs_level} 

|Тип|По умолчанию|
|---|---|
|`LogsLevel`|`fatal`|

Отправляет текстовые логи сервера с указанным минимальным уровнем клиенту. Допустимые значения: 'trace', 'debug', 'information', 'warning', 'error', 'fatal', 'none'.

## send_logs_source_regexp {#send_logs_source_regexp} 

Отправляет текстовые логи сервера с указанным регулярным выражением для сопоставления имени источника лога. Пустое значение означает все источники. 

## send_progress_in_http_headers {#send_progress_in_http_headers} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает заголовки HTTP-ответов `X-ClickHouse-Progress` в ответах `clickhouse-server`.

Для получения дополнительной информации читайте описание [HTTP интерфейса](../../interfaces/http.md).

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

## send_timeout {#send_timeout} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`300`|

Таймаут для отправки данных в сеть, в секундах. Если клиенту нужно отправить данные, но он не может отправить ни одного байта в этот интервал, создается исключение. Если вы установите эту настройку на клиенте, таймаут 'receive_timeout' для сокета также будет установлен на соответствующем конце соединения на сервере.

## session_timezone {#session_timezone} 

<BetaBadge/>

Устанавливает неявный часовой пояс текущей сессии или запроса. Неявный часовой пояс — это часовой пояс, который применяется к значениям типа DateTime/DateTime64, у которых явно не указан часовой пояс. Эта настройка имеет приоритет перед глобально настроенным (уровня сервера) неявным часовым поясом. Значение '' (пустая строка) означает, что неявный часовой пояс текущей сессии или запроса равен [серверному часовому поясу](../server-configuration-parameters/settings.md/#timezone).

Вы можете использовать функции `timeZone()` и `serverTimeZone()`, чтобы получить часовой пояс сессии и серверный часовой пояс.

Возможные значения:

- Любое имя часового пояса из `system.time_zones`, например, `Europe/Berlin`, `UTC` или `Zulu`.

Примеры:

```sql
SELECT timeZone(), serverTimeZone() FORMAT CSV

"Europe/Berlin","Europe/Berlin"
```

```sql
SELECT timeZone(), serverTimeZone() SETTINGS session_timezone = 'Asia/Novosibirsk' FORMAT CSV

"Asia/Novosibirsk","Europe/Berlin"
```

Назначение часового пояса сессии 'America/Denver' внутреннему DateTime без явно указанного часового пояса:

```sql
SELECT toDateTime64(toDateTime64('1999-12-12 23:23:23.123', 3), 3, 'Europe/Zurich') SETTINGS session_timezone = 'America/Denver' FORMAT TSV

1999-12-13 07:23:23.123
```

:::warning
Не все функции, которые разбирают DateTime/DateTime64, учитывают `session_timezone`. Это может привести к тонким ошибкам. 
Смотрите следующий пример и объяснение.
:::

```sql
CREATE TABLE test_tz (`d` DateTime('UTC')) ENGINE = Memory AS SELECT toDateTime('2000-01-01 00:00:00', 'UTC');

SELECT *, timeZone() FROM test_tz WHERE d = toDateTime('2000-01-01 00:00:00') SETTINGS session_timezone = 'Asia/Novosibirsk'
0 rows in set.

SELECT *, timeZone() FROM test_tz WHERE d = '2000-01-01 00:00:00' SETTINGS session_timezone = 'Asia/Novosibirsk'
┌───────────────────d─┬─timeZone()───────┐
│ 2000-01-01 00:00:00 │ Asia/Novosibirsk │
└─────────────────────┴──────────────────┘
```

Это происходит из-за различных конвейеров разбора:

- `toDateTime()` без явно указанного часового пояса, используемого в первом запросе `SELECT`, учитывает настройку `session_timezone` и глобальный часовой пояс.
- Во втором запросе DateTime разбирается из строки и наследует тип и часовой пояс существующего столбца `d`. Таким образом, установка `session_timezone` и глобального часового пояса не учитывается.

**Смотрите также**

- [timezone](../server-configuration-parameters/settings.md/#timezone)

## set_overflow_mode {#set_overflow_mode} 

|Тип|По умолчанию|
|---|---|
|`OverflowMode`|`throw`|

Устанавливает, что происходит, когда объем данных превышает один из лимитов.

Возможные значения:
- `throw`: выбросить исключение (по умолчанию).
- `break`: остановить выполнение запроса и вернуть частичный результат, как будто исходные данные закончились.

## shared_merge_tree_sync_parts_on_partition_operations {#shared_merge_tree_sync_parts_on_partition_operations} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Автоматически синхронизирует набор частей данных после операций MOVE|REPLACE|ATTACH в таблицах SMT. Только в облаке.

## short_circuit_function_evaluation {#short_circuit_function_evaluation} 

|Тип|По умолчанию|
|---|---|
|`ShortCircuitFunctionEvaluation`|`enable`|

Позволяет вычислять функции [if](../../sql-reference/functions/conditional-functions.md/#if), [multiIf](../../sql-reference/functions/conditional-functions.md/#multiif), [and](/sql-reference/functions/logical-functions#and) и [or](/sql-reference/functions/logical-functions#or) согласно [схеме короткого замыкания](https://en.wikipedia.org/wiki/Short-circuit_evaluation). Это помогает оптимизировать выполнение сложных выражений в этих функциях и предотвращает возможные исключения (например, деление на ноль, когда это не ожидается).

Возможные значения:

- `enable` — Включает оценку функций с коротким замыканием для функций, которые к этому подходят (могут выбросить исключение или являются вычислительно тяжелыми).
- `force_enable` — Включает оценку функций с коротким замыканием для всех функций.
- `disable` — Отключает оценку функций с коротким замыканием.

## short_circuit_function_evaluation_for_nulls {#short_circuit_function_evaluation_for_nulls} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Оптимизирует оценку функций, которые возвращают NULL, когда любой аргумент равен NULL. Когда процент значений NULL в аргументах функции превышает short_circuit_function_evaluation_for_nulls_threshold, система пропускает оценку функции строка за строкой. Вместо этого она немедленно возвращает NULL для всех строк, избегая ненужных вычислений.

## short_circuit_function_evaluation_for_nulls_threshold {#short_circuit_function_evaluation_for_nulls_threshold} 

|Тип|По умолчанию|
|---|---|
|`Double`|`1`|

Пороговое соотношение значений NULL для выполнения функций с Nullable аргументами только по строкам с ненулевыми значениями во всех аргументах. Применяется, когда включена настройка short_circuit_function_evaluation_for_nulls. Когда соотношение строк, содержащих значения NULL, к общему количеству строк превышает этот порог, строки, содержащие значения NULL, не будут оцениваться.

## show_table_uuid_in_table_create_query_if_not_nil {#show_table_uuid_in_table_create_query_if_not_nil} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Устанавливает отображение запроса `SHOW TABLE`.

Возможные значения:

- 0 — Запрос будет отображаться без UUID таблицы.
- 1 — Запрос будет отображаться с UUID таблицы.

## single_join_prefer_left_table {#single_join_prefer_left_table} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Для одиночного JOIN в случае неоднозначности идентификаторов предпочтение отдается левой таблице.

## skip_redundant_aliases_in_udf {#skip_redundant_aliases_in_udf} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Избыточные алиасы не используются (не заменяются) в пользовательских функциях для упрощения их использования.

Возможные значения:

- 1 — Алиасы пропускаются (заменяются) в UDF.
- 0 — Алиасы не пропускаются (заменяются) в UDF.

**Пример**

Разница между включенной и выключенной настройками:

Запрос:

```sql
SET skip_redundant_aliases_in_udf = 0;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

Результат:

```text
SELECT ((4 + 2) + 1 AS y, y + 2)
```

Запрос:

```sql
SET skip_redundant_aliases_in_udf = 1;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

Результат:

```text
SELECT ((4 + 2) + 1, ((4 + 2) + 1) + 2)
```

## skip_unavailable_shards {#skip_unavailable_shards} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает безмолвный пропуск недоступных шардов.

Шард считается недоступным, если все его реплики недоступны. Реплика недоступна в следующих случаях:

- ClickHouse не может подключиться к реплике по любой причине.

При подключении к реплике ClickHouse делает несколько попыток. Если все эти попытки терпят неудачу, реплика считается недоступной.

- Реплику нельзя разрешить через DNS.

Еслиhostname реплики не может быть разрешено через DNS, это может указывать на следующие ситуации:

- У реплики нет записи DNS. Это может произойти в системах с динамическим DNS, например, [Kubernetes](https://kubernetes.io), где узлы могут быть неразрешимы во время времени простоя, и это не ошибка.

- Ошибка конфигурации. В конфигурационном файле ClickHouse содержится неверное имя хоста.

Возможные значения:

- 1 — включен пропуск.

Если шард недоступен, ClickHouse возвращает результат на основе частичных данных и не сообщает о проблемах с доступностью узла.

- 0 — пропуск отключен.

Если шард недоступен, ClickHouse генерирует исключение.

## sleep_after_receiving_query_ms {#sleep_after_receiving_query_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`0`|

Время ожидания после получения запроса в TCPHandler.

## sleep_in_send_data_ms {#sleep_in_send_data_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`0`|

Время ожидания при отправке данных в TCPHandler.

## sleep_in_send_tables_status_ms {#sleep_in_send_tables_status_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`0`|

Время ожидания при отправке статуса таблиц в ответе в TCPHandler.

## sort_overflow_mode {#sort_overflow_mode} 

|Тип|По умолчанию|
|---|---|
|`OverflowMode`|`throw`|

Устанавливает, что происходит, если количество строк, полученных перед сортировкой, превышает один из лимитов.

Возможные значения:
- `throw`: выбросить исключение.
- `break`: остановить выполнение запроса и вернуть частичный результат.

## split_intersecting_parts_ranges_into_layers_final {#split_intersecting_parts_ranges_into_layers_final} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разделение пересекающихся диапазонов частей на слои в процессе финальной оптимизации.

## split_parts_ranges_into_intersecting_and_non_intersecting_final {#split_parts_ranges_into_intersecting_and_non_intersecting_final} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разделение диапазонов частей на пересекающиеся и непересекающиеся во время финальной оптимизации.

## splitby_max_substrings_includes_remaining_string {#splitby_max_substrings_includes_remaining_string} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Управляет тем, следует ли функции [splitBy*()](../../sql-reference/functions/splitting-merging-functions.md) включать оставшуюся строку в последнем элементе результирующего массива, если аргумент `max_substrings` > 0.

Возможные значения:

- `0` - Оставшаяся строка не будет включена в последний элемент результирующего массива.
- `1` - Оставшаяся строка будет включена в последний элемент результирующего массива. Это поведение функции [`split()`](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.split.html) Spark и метода ['string.split()'](https://docs.python.org/3/library/stdtypes.html#str.split) Python.

## stop_refreshable_materialized_views_on_startup {#stop_refreshable_materialized_views_on_startup} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

При запуске сервера отключает планирование обновляемых материализованных представлений, как при SYSTEM STOP VIEWS. Вы можете вручную запустить их позже с помощью команды `SYSTEM START VIEWS` или `SYSTEM START VIEW <name>`. Также это относится к вновь созданным представлениям. Не влияет на не обновляемые материализованные представления.

## storage_file_read_method {#storage_file_read_method} 

|Тип|По умолчанию|
|---|---|
|`LocalFSReadMethod`|`pread`|

Метод чтения данных из файлов хранилища, один из: `read`, `pread`, `mmap`. Метод mmap не применяется к clickhouse-server (предназначен для clickhouse-local).

## storage_system_stack_trace_pipe_read_timeout_ms {#storage_system_stack_trace_pipe_read_timeout_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`100`|

Максимальное время для чтения из трубы для получения информации от потоков при запросе таблицы `system.stack_trace`. Эта настройка используется для тестирования и не предназначена для изменения пользователями.

## stream_flush_interval_ms {#stream_flush_interval_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`7500`|

Работает для таблиц с потоковой передачей в случае таймаута или когда поток генерирует [max_insert_block_size](#max_insert_block_size) строк.

Значение по умолчанию составляет 7500.

Чем меньше значение, тем чаще данные сбрасываются в таблицу. Установка значения слишком низким приводит к плохой производительности.

## stream_like_engine_allow_direct_select {#stream_like_engine_allow_direct_select} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Разрешить прямой запрос SELECT для движков Kafka, RabbitMQ, FileLog, Redis Streams и NATS. Если прикреплены материализованные представления, запрос SELECT не допускается, даже если эта настройка включена.

## stream_like_engine_insert_queue {#stream_like_engine_insert_queue} 

Когда движок, подобный потоку, читает из нескольких очередей, пользователю нужно будет выбрать одну очередь для вставки при записи. Используется для Redis Streams и NATS.

## stream_poll_timeout_ms {#stream_poll_timeout_ms} 

|Тип|По умолчанию|
|---|---|
|`Milliseconds`|`500`|

Таймаут для опроса данных из/в потоковые хранилища.

## system_events_show_zero_values {#system_events_show_zero_values} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Позволяет выбирать события с нулевыми значениями из [`system.events`](../../operations/system-tables/events.md).

Некоторые системы мониторинга требуют передачи всех значений метрик для каждой контрольной точки, даже если значение метрики равно нулю.

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

**Примеры**

Запрос

```sql
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

Результат

```text
Ok.
```

Запрос
```sql
SET system_events_show_zero_values = 1;
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

Результат

```text
┌─event────────────────────┬─value─┬─description───────────────────────────────────────────┐
│ QueryMemoryLimitExceeded │     0 │ Количество случаев, когда лимит памяти был превышен для запроса. │
└──────────────────────────┴───────┴───────────────────────────────────────────────────────┘
```

## table_function_remote_max_addresses {#table_function_remote_max_addresses} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`1000`|

Устанавливает максимальное количество адресов, генерируемых из шаблонов для функции [remote](../../sql-reference/table-functions/remote.md).

Возможные значения:

- Положительное целое число.

## tcp_keep_alive_timeout {#tcp_keep_alive_timeout} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`290`|

Время в секундах, в течение которого соединение должно оставаться бездействующим, прежде чем TCP начнет отправлять keepalive-запросы.

## temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds {#temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`600000`|

Время ожидания для блокировки кэша для резервирования пространства для временных данных в файловой системе.

## temporary_files_codec {#temporary_files_codec} 

|Тип|По умолчанию|
|---|---|
|`String`|`LZ4`|

Устанавливает кодек сжатия для временных файлов, используемых в операциях сортировки и объединения на диске.

Возможные значения:

- LZ4 — Применяется сжатие [LZ4](https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)).
- NONE — Сжатие не применяется.
## throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert {#throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Выбросить исключение при выполнении запроса INSERT, если настройка `deduplicate_blocks_in_dependent_materialized_views` включена вместе с `async_insert`. Это гарантирует корректность, поскольку эти функции не могут работать вместе.

## throw_if_no_data_to_insert {#throw_if_no_data_to_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Разрешает или запрещает пустые INSERT, по умолчанию включено (вызывает ошибку при пустом вставке). Применяется только к INSERT, выполняемым с помощью [`clickhouse-client`](/interfaces/cli) или используя [gRPC интерфейс](/interfaces/grpc).

## throw_on_error_from_cache_on_write_operations {#throw_on_error_from_cache_on_write_operations} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Игнорировать ошибку из кэша при кэшировании операций записи (INSERT, слияния).

## throw_on_max_partitions_per_insert_block {#throw_on_max_partitions_per_insert_block} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Позволяет контролировать поведение, когда достигнуто значение `max_partitions_per_insert_block`.

Возможные значения:
- `true`  - Когда блок вставки достигает `max_partitions_per_insert_block`, происходит выброс исключения.
- `false` - Логирует предупреждение, когда достигается `max_partitions_per_insert_block`.

:::tip
Это может быть полезно, если вы пытаетесь понять влияние на пользователей при изменении [`max_partitions_per_insert_block`](/operations/settings/settings#max_partitions_per_insert_block).
:::

## throw_on_unsupported_query_inside_transaction {#throw_on_unsupported_query_inside_transaction} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Выбросить исключение, если используется неподдерживаемый запрос внутри транзакции.

## timeout_before_checking_execution_speed {#timeout_before_checking_execution_speed} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`10`|

Проверяет, что скорость выполнения не слишком мала (не менее `min_execution_speed`), после истечения указанного времени в секундах.

## timeout_overflow_mode {#timeout_overflow_mode} 

|Тип|По умолчанию|
|---|---|
|`OverflowMode`|`throw`|

Устанавливает, что делать, если запрос выполняется дольше, чем `max_execution_time` или оцениваемое время выполнения больше, чем `max_estimated_execution_time`.

Возможные значения:
- `throw`: выбросить исключение (по умолчанию).
- `break`: остановить выполнение запроса и вернуть частичный результат, как если бы исходные данные закончились.

## timeout_overflow_mode_leaf {#timeout_overflow_mode_leaf} 

|Тип|По умолчанию|
|---|---|
|`OverflowMode`|`throw`|

Устанавливает, что происходит, когда запрос в узле-листье выполняется дольше, чем `max_execution_time_leaf`.

Возможные значения:
- `throw`: выбросить исключение (по умолчанию).
- `break`: остановить выполнение запроса и вернуть частичный результат, как если бы исходные данные закончились.

## totals_auto_threshold {#totals_auto_threshold} 

|Тип|По умолчанию|
|---|---|
|`Float`|`0.5`|

Порог для `totals_mode = 'auto'`. Смотрите раздел "Модификатор WITH TOTALS".

## totals_mode {#totals_mode} 

|Тип|По умолчанию|
|---|---|
|`TotalsMode`|`after_having_exclusive`|

Как рассчитывать ИТОГИ, когда присутствует HAVING, а также когда присутствуют max_rows_to_group_by и group_by_overflow_mode = 'any'. Смотрите раздел "Модификатор WITH TOTALS".

## trace_profile_events {#trace_profile_events} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает или отключает сбор трассировок стеков при каждом обновлении событий профилирования вместе с именем события профилирования и значением инкремента и отправкой их в [trace_log](/operations/system-tables/trace_log).

Возможные значения:

- 1 — Включено трассирование событий профилирования.
- 0 — Отключено трассирование событий профилирования.

## transfer_overflow_mode {#transfer_overflow_mode} 

|Тип|По умолчанию|
|---|---|
|`OverflowMode`|`throw`|

Устанавливает, что происходит, когда объем данных превышает один из лимитов.

Возможные значения:
- `throw`: выбросить исключение (по умолчанию).
- `break`: остановить выполнение запроса и вернуть частичный результат, как если бы исходные данные закончились.

## transform_null_in {#transform_null_in} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включает равенство значений [NULL](/sql-reference/syntax#null) для оператора [IN](../../sql-reference/operators/in.md).

По умолчанию, значения `NULL` не могут быть сравнены, потому что `NULL` означает неопределенное значение. Таким образом, сравнение `expr = NULL` должно всегда возвращать `false`. С этой настройкой `NULL = NULL` возвращает `true` для оператора `IN`.

Возможные значения:

- 0 — Сравнение значений `NULL` в операторе `IN` возвращает `false`.
- 1 — Сравнение значений `NULL` в операторе `IN` возвращает `true`.

**Пример**

Рассмотрим таблицу `null_in`:

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
│    3 │     3 │
└──────┴───────┘
```

Запрос:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 0;
```

Результат:

```text
┌──idx─┬────i─┐
│    1 │    1 │
└──────┴──────┘
```

Запрос:

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 1;
```

Результат:

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
└──────┴───────┘
```

**Смотрите также**

- [Обработка NULL в операторах IN](/sql-reference/operators/in#null-processing)

## traverse_shadow_remote_data_paths {#traverse_shadow_remote_data_paths} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Обходит замороженные данные (теневая директория) в дополнение к фактическим данным таблицы при выполнении запроса `system.remote_data_paths`.

## union_default_mode {#union_default_mode} 

Устанавливает режим для объединения результатов запросов `SELECT`. Настройка используется только в случае совместного использования с [UNION](../../sql-reference/statements/select/union.md), не указывая явно `UNION ALL` или `UNION DISTINCT`.

Возможные значения:

- `'DISTINCT'` — ClickHouse выводит строки в результате объединения запросов, убирая дублирующиеся строки.
- `'ALL'` — ClickHouse выводит все строки в результате объединения запросов, включая дублирующиеся строки.
- `''` — ClickHouse генерирует исключение при использовании с `UNION`.

Смотрите примеры в [UNION](../../sql-reference/statements/select/union.md).

## unknown_packet_in_send_data {#unknown_packet_in_send_data} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Отправить неизвестный пакет вместо N-го пакета данных.

## use_async_executor_for_materialized_views {#use_async_executor_for_materialized_views} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать асинхронное и потенциально многопоточное выполнение запросов к материализованным представлениям, что может ускорить обработку представлений во время INSERT, но также потребляет больше памяти.

## use_cache_for_count_from_files {#use_cache_for_count_from_files} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает кэширование количества строк при подсчете из файлов в табличных функциях `file`/`s3`/`url`/`hdfs`/`azureBlobStorage`.

По умолчанию включено.

## use_client_time_zone {#use_client_time_zone} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать временную зону клиента для интерпретации строковых значений DateTime, вместо временной зоны сервера.

## use_compact_format_in_distributed_parts_names {#use_compact_format_in_distributed_parts_names} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использует компактный формат для хранения блоков для фоновых INSERT в таблицы с движком `Distributed`.

Возможные значения:

- 0 — Используется формат `user[:password]@host:port#default_database`.
- 1 — Используется формат директории `[shard{shard_index}[_replica{replica_index}]]`.

:::note
- При `use_compact_format_in_distributed_parts_names=0` изменения из определения кластера не будут применены для фонового INSERT.
- При `use_compact_format_in_distributed_parts_names=1` изменение порядка узлов в определении кластера изменит `shard_index`/`replica_index`, так что будьте внимательны.
:::

## use_concurrency_control {#use_concurrency_control} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Учитывать контроль параллелизма сервера (см. глобальные настройки сервера `concurrent_threads_soft_limit_num` и `concurrent_threads_soft_limit_ratio_to_cores`). Если отключено, разрешает использование большего числа потоков, даже если сервер перегружен (не рекомендуется для нормального использования, нужно в основном для тестов).

## use_hedged_requests {#use_hedged_requests} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает логику хеджирования запросов для удаленных запросов. Это позволяет устанавливать много соединений с разными репликами для запроса. Новое соединение устанавливается в случае, если существующие соединения с репликами не были установлены в течение `hedged_connection_timeout` или данные не были получены в течение `receive_data_timeout`. Запрос использует первое соединение, которое отправит непустой пакет прогресса (или пакет данных, если `allow_changing_replica_until_first_data_packet`); другие соединения отменяются. Поддерживаются запросы с `max_parallel_replicas > 1`.

По умолчанию включено.

Отключено по умолчанию в Cloud.

## use_hive_partitioning {#use_hive_partitioning} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

При включении ClickHouse будет обнаруживать партиционирование в стиле Hive в пути (`/name=value/`) в файлообразных табличных движках [File](/sql-reference/table-functions/file#hive-style-partitioning)/[S3](/sql-reference/table-functions/s3#hive-style-partitioning)/[URL](/sql-reference/table-functions/url#hive-style-partitioning)/[HDFS](/sql-reference/table-functions/hdfs#hive-style-partitioning)/[AzureBlobStorage](/sql-reference/table-functions/azureBlobStorage#hive-style-partitioning) и позволит использовать партиционные колонки как виртуальные колонки в запросе. Эти виртуальные колонки будут иметь такие же имена, как и в партиционированном пути, но начиная с `_`.

## use_iceberg_partition_pruning {#use_iceberg_partition_pruning} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать обрезку партиций Iceberg для таблиц Iceberg.

## use_index_for_in_with_subqueries {#use_index_for_in_with_subqueries} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Попробуйте использовать индекс, если с правой стороны оператора IN находится подзапрос или табличное выражение.

## use_index_for_in_with_subqueries_max_values {#use_index_for_in_with_subqueries_max_values} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`0`|

Максимальный размер множества с правой стороны оператора IN для использования табличного индекса для фильтрации. Позволяет избежать снижения производительности и большего использования памяти из-за подготовки дополнительных структур данных для больших запросов. Ноль означает отсутствие предела.

## use_json_alias_for_old_object_type {#use_json_alias_for_old_object_type} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

При включении будет использоваться псевдоним типа `JSON` для создания старого типа [Object('json')](../../sql-reference/data-types/json.md) вместо нового типа [JSON](../../sql-reference/data-types/newjson.md).

## use_page_cache_for_disks_without_file_cache {#use_page_cache_for_disks_without_file_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать кэш страниц пользовательского пространства для удаленных дисков, у которых не включен кэш файловой системы.

## use_page_cache_with_distributed_cache {#use_page_cache_with_distributed_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать кэш страниц пользовательского пространства, когда используется распределенный кэш.

## use_query_cache {#use_query_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если включено, запросы `SELECT` могут использовать [кэш запросов](../query-cache.md). Параметры [enable_reads_from_query_cache](#enable_reads_from_query_cache) и [enable_writes_to_query_cache](#enable_writes_to_query_cache) более подробно контролируют, как используется кэш.

Возможные значения:

- 0 - Отключено
- 1 - Включено

## use_query_condition_cache {#use_query_condition_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Включить [кэш условий запроса](/operations/query-condition-cache). Кэш хранит диапазоны гранул в частях данных, которые не удовлетворяют условию в предложении `WHERE`, и повторно использует эту информацию в качестве эпhemerного индекса для последующих запросов.

Возможные значения:

- 0 - Отключено
- 1 - Включено

## use_skip_indexes {#use_skip_indexes} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Использовать индексы пропуска данных во время выполнения запроса.

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

## use_skip_indexes_if_final {#use_skip_indexes_if_final} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Контролирует, используются ли индексы пропуска при выполнении запроса с модификатором FINAL.

По умолчанию эта настройка отключена, потому что индексы пропуска могут исключать строки (гранулы), содержащие последние данные, что может привести к неправильным результатам. При включении индексы пропуска применяются даже с модификатором FINAL, потенциально улучшая производительность, но с риском пропуска недавних обновлений.

Возможные значения:

- 0 — Отключено.
- 1 — Включено.

## use_structure_from_insertion_table_in_table_functions {#use_structure_from_insertion_table_in_table_functions} 

|Тип|По умолчанию|
|---|---|
|`UInt64`|`2`|

Использовать структуру из вставляемой таблицы вместо вывода схемы из данных. Возможные значения: 0 - отключено, 1 - включено, 2 - авто.

## use_uncompressed_cache {#use_uncompressed_cache} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Использовать кэш не сжатых блоков. Принимает 0 или 1. По умолчанию 0 (отключено). Использование не сжатого кэша (только для таблиц из семейства MergeTree) может значительно снизить задержку и повысить производительность при работе с большим количеством коротких запросов. Включите эту настройку для пользователей, которые отправляют частые короткие запросы. Также обратите внимание на параметр конфигурации [uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) (устанавливается только в файле конфигурации) – размер кэша не сжатых блоков. По умолчанию это 8 ГиБ. Не сжатый кэш заполняется по мере необходимости, и наименее используемые данные автоматически удаляются.

Для запросов, читающих хотя бы довольно большой объем данных (миллион строк и более), не сжатый кэш автоматически отключается, чтобы сэкономить место для действительно небольших запросов. Это означает, что вы можете оставить настройку 'use_uncompressed_cache' всегда установленной на 1.

## use_variant_as_common_type {#use_variant_as_common_type} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Позволяет использовать тип `Variant` в качестве возвращаемого типа для функций [if](../../sql-reference/functions/conditional-functions.md/#if)/[multiIf](../../sql-reference/functions/conditional-functions.md/#multiif)/[array](../../sql-reference/functions/array-functions.md)/[map](../../sql-reference/functions/tuple-map-functions.md), когда нет общего типа для аргументных типов.

Пример:

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(if(number % 2, number, range(number))) as variant_type FROM numbers(1);
SELECT if(number % 2, number, range(number)) as variant FROM numbers(5);
```

```text
┌─variant_type───────────────────┐
│ Variant(Array(UInt64), UInt64) │
└────────────────────────────────┘
┌─variant───┐
│ []        │
│ 1         │
│ [0,1]     │
│ 3         │
│ [0,1,2,3] │
└───────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL)) AS variant_type FROM numbers(1);
SELECT multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL) AS variant FROM numbers(4);
```

```text
─variant_type─────────────────────────┐
│ Variant(Array(UInt8), String, UInt8) │
└──────────────────────────────────────┘

┌─variant───────┐
│ 42            │
│ [1,2,3]       │
│ Hello, World! │
│ ᴺᵁᴸᴸ          │
└───────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(array(range(number), number, 'str_' || toString(number))) as array_of_variants_type from numbers(1);
SELECT array(range(number), number, 'str_' || toString(number)) as array_of_variants FROM numbers(3);
```

```text
┌─array_of_variants_type────────────────────────┐
│ Array(Variant(Array(UInt64), String, UInt64)) │
└───────────────────────────────────────────────┘

┌─array_of_variants─┐
│ [[],0,'str_0']    │
│ [[0],1,'str_1']   │
│ [[0,1],2,'str_2'] │
└───────────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(map('a', range(number), 'b', number, 'c', 'str_' || toString(number))) as map_of_variants_type from numbers(1);
SELECT map('a', range(number), 'b', number, 'c', 'str_' || toString(number)) as map_of_variants FROM numbers(3);
```

```text
┌─map_of_variants_type────────────────────────────────┐
│ Map(String, Variant(Array(UInt64), String, UInt64)) │
└─────────────────────────────────────────────────────┘

┌─map_of_variants───────────────┐
│ {'a':[],'b':0,'c':'str_0'}    │
│ {'a':[0],'b':1,'c':'str_1'}   │
│ {'a':[0,1],'b':2,'c':'str_2'} │
└───────────────────────────────┘
```

## use_with_fill_by_sorting_prefix {#use_with_fill_by_sorting_prefix} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Столбцы перед колонками WITH FILL в предложении ORDER BY формируют префикс сортировки. Строки с различными значениями в префиксе сортировки заполняются независимо.

## validate_enum_literals_in_operators {#validate_enum_literals_in_operators} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Если включено, проверять литералы перечислений в операторах, таких как `IN`, `NOT IN`, `==`, `!=` на соответствие типу перечисления и выбрасывать исключение, если литерал не является допустимым значением перечисления.

## validate_mutation_query {#validate_mutation_query} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Проверять запросы на мутации перед их принятием. Мутации выполняются в фоновом режиме, и выполнение недопустимого запроса приведет к зависанию мутаций, требуя ручного вмешательства.

Изменяйте эту настройку только в случае, если вы столкнетесь с ошибкой, несовместимой с обратной совместимостью.

## validate_polygons {#validate_polygons} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Включает или отключает выброс исключения в функции [pointInPolygon](/sql-reference/functions/geo/coordinates#pointinpolygon), если многоугольник самопересекается или самотангенциален.

Возможные значения:

- 0 — Выброс исключения отключен. `pointInPolygon` принимает недопустимые многоугольники и возвращает, возможно, неправильные результаты для них.
- 1 — Выброс исключения включен.

## wait_changes_become_visible_after_commit_mode {#wait_changes_become_visible_after_commit_mode} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`TransactionsWaitCSNMode`|`wait_unknown`|

Ожидать, пока зафиксированные изменения фактически станут видимыми в последнем снимке.

## wait_for_async_insert {#wait_for_async_insert} 

|Тип|По умолчанию|
|---|---|
|`Bool`|`1`|

Если true, ждать завершения обработки асинхронной вставки.

## wait_for_async_insert_timeout {#wait_for_async_insert_timeout} 

|Тип|По умолчанию|
|---|---|
|`Seconds`|`120`|

Тайм-аут ожидания завершения обработки асинхронной вставки.

## wait_for_window_view_fire_signal_timeout {#wait_for_window_view_fire_signal_timeout} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Seconds`|`10`|

Тайм-аут ожидания сигнала срабатывания оконного представления при обработке событий времени.

## window_view_clean_interval {#window_view_clean_interval} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Seconds`|`60`|

Интервал очистки оконного представления в секундах для освобождения устаревших данных.

## window_view_heartbeat_interval {#window_view_heartbeat_interval} 

<ExperimentalBadge/>

|Тип|По умолчанию|
|---|---|
|`Seconds`|`15`|

Интервал heartbeat в секундах, чтобы указать, что наблюдаемый запрос активен.

## workload {#workload} 

|Тип|По умолчанию|
|---|---|
|`String`|`default`|

Имя рабочей нагрузки, используемой для доступа к ресурсам.

## write_through_distributed_cache {#write_through_distributed_cache} 

<CloudAvailableBadge/>

|Тип|По умолчанию|
|---|---|
|`Bool`|`0`|

Эта настройка действует только в ClickHouse Cloud. Разрешает запись в распределенный кэш (запись в s3 также будет выполнена через распределенный кэш).

## zstd_window_log_max {#zstd_window_log_max} 

|Тип|По умолчанию|
|---|---|
|`Int64`|`0`|

Позволяет выбрать максимальный лог окна ZSTD (не будет использоваться для семейства MergeTree).
