---
sidebar_label: 'Интеграция Kafka с ClickHouse'
sidebar_position: 1
slug: /integrations/kafka
description: 'Введение в Kafka с ClickHouse'
title: 'Интеграция Kafka с ClickHouse'
---


# Интеграция Kafka с ClickHouse

[Apache Kafka](https://kafka.apache.org/) — это открытая распределенная платформа стриминга событий, используемая тысячами компаний для высокопроизводительных конвейеров данных, стриминговой аналитики, интеграции данных и критически важных приложений. В большинстве случаев, связанных с Kafka и ClickHouse, пользователи желают вставить данные из Kafka в ClickHouse. Ниже мы описываем несколько вариантов для обоих случаев использования, определяя плюсы и минусы каждого подхода.

## Выбор варианта {#choosing-an-option}

При интеграции Kafka с ClickHouse вам нужно будет принять ранние архитектурные решения о высокоуровневом подходе. Мы описываем наиболее распространенные стратегии ниже:

### ClickPipes для Kafka (ClickHouse Cloud) {#clickpipes-for-kafka-clickhouse-cloud}
* [**ClickPipes**](../clickpipes/kafka.md) предлагает самый простой и интуитивно понятный способ загрузки данных в ClickHouse Cloud. В настоящее время поддерживаются Apache Kafka, Confluent Cloud и Amazon MSK, а в ближайшее время появится много других источников данных.

### Подключение Kafka третьих сторон на облачной базе {#3rd-party-cloud-based-kafka-connectivity}
* [**Confluent Cloud**](./confluent/index.md) - платформа Confluent предоставляет возможность загрузки и [работы ClickHouse Connector Sink на Confluent Cloud](./confluent/custom-connector.md) или использования [HTTP Sink Connector для платформы Confluent](./confluent/kafka-connect-http.md), который интегрирует Apache Kafka с API через HTTP или HTTPS.

* [**Amazon MSK**](./msk/index.md) - поддерживает фреймворк Amazon MSK Connect для передачи данных из кластеров Apache Kafka во внешние системы, такие как ClickHouse. Вы можете установить ClickHouse Kafka Connect на Amazon MSK.

* [**Redpanda Cloud**](https://cloud.redpanda.com/) - Redpanda это потоковая платформа данных, совместимая с API Kafka, которая может использоваться в качестве верхнего источника данных для ClickHouse. Облачная платформа Redpanda Cloud интегрируется с ClickHouse через протокол Kafka, обеспечивая прием данных в реальном времени для рабочих нагрузок стриминговой аналитики.

### Подключение управляемого Kafka {#self-managed-kafka-connectivity}
* [**Kafka Connect**](./kafka-clickhouse-connect-sink.md) - Kafka Connect является бесплатным, открытым компонентом Apache Kafka, который работает как централизованный узел данных для простой интеграции данных между Kafka и другими системами данных. Коннекторы предоставляют простой способ масштабируемой и надежной передачи данных из и в Kafka. Source Connectors вставляют данные в темы Kafka из других систем, в то время как Sink Connectors передают данные из тем Kafka в другие хранилища данных, такие как ClickHouse.
* [**Vector**](./kafka-vector.md) - Vector является нейтральным вендором конвейером данных. С возможностью чтения из Kafka и отправки событий в ClickHouse, это представляет собой надежный вариант интеграции.
* [**JDBC Connect Sink**](./kafka-connect-jdbc.md) - Коннектор JDBC Sink для Kafka Connect позволяет экспортировать данные из тем Kafka в любую реляционную базу данных с JDBC драйвером.
* **Пользовательский код** - Пользовательский код с использованием соответствующих клиентских библиотек для Kafka и ClickHouse может быть уместен в случаях, когда требуется пользовательская обработка событий. Это выходит за рамки данной документации.
* [**Движок таблицы Kafka**](./kafka-table-engine.md) предоставляет нативную интеграцию ClickHouse (не доступна на ClickHouse Cloud). Этот движок таблицы **извлекает** данные из исходной системы. Это требует, чтобы ClickHouse имел прямой доступ к Kafka.
* [**Движок таблицы Kafka с именованными коллекциями**](./kafka-table-engine-named-collections.md) - Использование именованных коллекций предоставляет нативную интеграцию ClickHouse с Kafka. Этот подход позволяет защищенные соединения с несколькими кластерами Kafka, централизуя управление конфигурацией и улучшая масштабируемость и безопасность.

### Выбор подхода {#choosing-an-approach}
Решение сводится к нескольким ключевым моментам:

* **Подключение** - Движок таблицы Kafka должен иметь возможность извлекать данные из Kafka, если ClickHouse является конечным пунктом. Это требует двустороннего подключения. Если существует сетевое разделение, например, ClickHouse находится в облаке, а Kafka управляется самостоятельно, вы можете быть осторожны с удалением этого по причинам соблюдения норм и безопасности. (Этот подход в настоящее время не поддерживается в ClickHouse Cloud.) Движок таблицы Kafka использует ресурсы внутри самого ClickHouse, используя потоки для потребителей. Нагрузка на ресурсы ClickHouse может быть невозможна из-за ограничений ресурсов, или ваши архитекторы могут предпочесть разделение обязанностей. В этом случае инструменты, такие как Kafka Connect, которые работают как отдельный процесс и могут быть развернуты на другом оборудовании, могут быть предпочтительны. Это позволяет процессу, ответственному за извлечение данных из Kafka, масштабироваться независимо от ClickHouse.

* **Хостинг в облаке** - Облачные провайдеры могут устанавливать ограничения на компоненты Kafka, доступные на их платформе. Следуйте руководству, чтобы изучить рекомендованные варианты для каждого облачного провайдера.

* **Внешнее обогащение** - Хотя сообщения могут быть обработаны перед вставкой в ClickHouse с использованием функций в операторе select материализованного представления, пользователи могут предпочесть переместить сложное обогащение за пределы ClickHouse.

* **Направление потока данных** - Vector поддерживает только передачу данных из Kafka в ClickHouse.

## Предположения {#assumptions}

Пользовательские руководства, указанные выше, предполагают следующее:

* Вы знакомы с основами Kafka, такими как продюсеры, потребители и темы.
* У вас есть подготовленная тема для этих примеров. Мы предполагаем, что все данные хранятся в Kafka в формате JSON, хотя принципы остаются теми же при использовании Avro.
* В наших примерах мы используем отличный [kcat](https://github.com/edenhill/kcat) (ранее kafkacat) для публикации и потребления данных Kafka.
* Хотя мы ссылаемся на некоторые python-скрипты для загрузки тестовых данных, не стесняйтесь адаптировать примеры под свой набор данных.
* Вы в целом знакомы с материализованными представлениями ClickHouse.
