---
slug: /migrations/postgresql/overview
title: 'Миграция с PostgreSQL на ClickHouse'
description: 'Руководство по миграции с PostgreSQL на ClickHouse'
keywords: ['postgres', 'postgresql', 'миграция', 'миграция']
---

## Почему стоит использовать ClickHouse вместо Postgres? {#why-use-clickhouse-over-postgres}

TLDR: Потому что ClickHouse разработан для быстрой аналитики, в частности для запросов `GROUP BY`, как OLAP база данных, в то время как Postgres — это OLTP база данных, предназначенная для транзакционных нагрузок.

OLTP, или базы данных для онлайн-транзакционной обработки, предназначены для управления транзакционной информацией. Основная цель этих баз данных, классическим примером которой является Postgres, заключается в том, чтобы инженер мог подать пакет обновлений в базу данных и быть уверенным, что он — в полном объеме — либо выполнится, либо будет отменен. Эти типы транзакционных гарантий с ACID-свойствами являются главной задачей баз данных OLTP и огромным преимуществом Postgres. Учитывая эти требования, OLTP базы данных обычно сталкиваются с ограничениями производительности при использовании для аналитических запросов по большим наборам данных.

OLAP, или базы данных для онлайн-аналитической обработки, предназначены для удовлетворения этих потребностей — управления аналитическими нагрузками. Основная цель этих баз данных заключается в том, чтобы инженеры могли эффективно запрашивать и агрегировать огромные наборы данных. Системы OLAP в реальном времени, такие как ClickHouse, позволяют проводить этот анализ по мере поступления данных в реальном времени.

Смотрите [здесь](/migrations/postgresql/appendix#postgres-vs-clickhouse-equivalent-and-different-concepts) для более глубокого сравнения ClickHouse и PostgreSQL.

Чтобы увидеть потенциальные различия в производительности между ClickHouse и Postgres при аналитических запросах, смотрите [Переписывание запросов PostgreSQL в ClickHouse](/migrations/postgresql/rewriting-queries).

## Стратегии миграции {#migration-strategies}

При миграции с PostgreSQL на ClickHouse правильная стратегия зависит от вашего случая использования, инфраструктуры и требований к данным. В общем, для большинства современных случаев использования наиболее подходящим подходом является изменение данных в реальном времени (CDC), в то время как ручная загрузка больших объемов данных с последующими периодическими обновлениями подходит для более простых сценариев или одноразовых миграций.

Ниже описаны две основные стратегии миграции: **CDC в реальном времени** и **Ручная загрузка больших объемов данных + Периодические обновления**.

### Репликация в реальном времени (CDC) {#real-time-replication-cdc}

Изменение данных в реальном времени (CDC) — это процесс, при котором таблицы синхронизируются между двумя базами данных. Это наиболее эффективный подход для большинства миграций с PostgreSQL, но он более сложный, поскольку обрабатывает вставки, обновления и удаления из PostgreSQL в ClickHouse в режиме практически реального времени. Он идеально подходит для случаев использования, где важна аналитика в реальном времени.

CDC в реальном времени можно реализовать в ClickHouse с помощью [ClickPipes](/integrations/clickpipes/postgres/deduplication), если вы используете ClickHouse Cloud, или [PeerDB](https://github.com/PeerDB-io/peerdb), если вы запускаете ClickHouse локально. Эти решения берут на себя сложности синхронизации данных в реальном времени, включая начальную загрузку, путем захвата вставок, обновлений и удалений из PostgreSQL и их репликации в ClickHouse. Этот подход обеспечивает актуальность и точность данных в ClickHouse без необходимости ручного вмешательства.

### Ручная загрузка больших объемов данных + периодические обновления {#manual-bulk-load-periodic-updates}

В некоторых случаях более простой подход, как ручная загрузка больших объемов данных с последующими периодическими обновлениями, может быть достаточным. Эта стратегия идеально подходит для одноразовых миграций или ситуаций, когда репликация в реальном времени не требуется. Она включает загрузку данных из PostgreSQL в ClickHouse большими партиями, либо через прямые SQL команды `INSERT`, либо путем экспорта и импорта файлов CSV. После начальной миграции вы можете периодически обновлять данные в ClickHouse, синхронизируя изменения из PostgreSQL с регулярными интервалами.

Процесс загрузки больших объемов данных прост и гибок, но имеет недостаток отсутствия обновлений в реальном времени. Как только начальные данные находятся в ClickHouse, обновления не будут отражены немедленно, поэтому вы должны запланировать периодические обновления, чтобы синхронизировать изменения из PostgreSQL. Этот подход хорошо подходит для менее чувствительных к времени случаев использования, но вводит задержку между изменениями данных в PostgreSQL и моментом, когда эти изменения появляются в ClickHouse.

### Какую стратегию выбрать? {#which-strategy-to-choose}

Для большинства приложений, которые требуют свежих, актуальных данных в ClickHouse, CDC в реальном времени через ClickPipes является рекомендуемым подходом. Он обеспечивает непрерывную синхронизацию данных с минимальными настройками и обслуживанием. С другой стороны, ручная загрузка больших объемов данных с периодическими обновлениями является жизнеспособным вариантом для более простых одноразовых миграций или рабочих нагрузок, где обновления в реальном времени не критичны.

---

**[Начните руководство по миграции PostgreSQL здесь](/migrations/postgresql/dataset).**
