---
slug: /engines/table-engines/special/buffer
sidebar_position: 120
sidebar_label:  バッファ
title: "バッファテーブルエンジン"
description: "データを書き込むためにRAMにバッファリングし、定期的に別のテーブルにフラッシュします。読み取り操作中は、バッファと他のテーブルから同時にデータが読み取られます。"
---

# バッファテーブルエンジン

データを書き込むためにRAMにバッファリングし、定期的に別のテーブルにフラッシュします。読み取り操作中は、バッファと他のテーブルから同時にデータが読み取られます。

:::note
バッファテーブルエンジンの推奨代替は、[非同期挿入](/guides/best-practices/asyncinserts.md)を有効にすることです。
:::

``` sql
Buffer(database, table, num_layers, min_time, max_time, min_rows, max_rows, min_bytes, max_bytes [,flush_time [,flush_rows [,flush_bytes]]])
```

### エンジンパラメータ: {#engine-parameters}

#### database {#database}

`database` – データベース名。`currentDatabase()`または文字列を返す他の定数式を使用できます。

#### table {#table}

`table` – データをフラッシュする対象のテーブル。

#### num_layers {#num_layers}

`num_layers` – パラレリズムレイヤー。物理的には、テーブルは`num_layers`の独立したバッファとして表されます。

#### min_time, max_time, min_rows, max_rows, min_bytes, and max_bytes {#min_time-max_time-min_rows-max_rows-min_bytes-and-max_bytes}

バッファからデータをフラッシュする条件。

### オプションのエンジンパラメータ: {#optional-engine-parameters}

#### flush_time, flush_rows, and flush_bytes {#flush_time-flush_rows-and-flush_bytes}

バッファからデータをバックグラウンドでフラッシュする条件（省略またはゼロの場合は`flush*`パラメータなし）。

全ての`min*`条件が満たされるか、少なくとも1つの`max*`条件が満たされると、データがバッファからフラッシュされて宛先テーブルに書き込まれます。

また、少なくとも1つの`flush*`条件が満たされると、バックグラウンドでフラッシュが開始されます。これは`max*`とは異なり、`flush*`を使用することで、バッファテーブルへの`INSERT`クエリの遅延を回避するためにバックグラウンドフラッシュを別々に設定できます。

#### min_time, max_time, and flush_time {#min_time-max_time-and-flush_time}

バッファへの最初の書き込みからの経過時間の条件（秒）。

#### min_rows, max_rows, and flush_rows {#min_rows-max_rows-and-flush_rows}

バッファ内の行数に関する条件。

#### min_bytes, max_bytes, and flush_bytes {#min_bytes-max_bytes-and-flush_bytes}

バッファ内のバイト数に関する条件。

書き込み操作中、データは1つ以上のランダムなバッファ（`num_layers`で設定された）に挿入されます。また、挿入するデータ部分が十分に大きい（`max_rows`または`max_bytes`を超える）場合は、バッファをスキップして宛先テーブルに直接書き込まれます。

データをフラッシュする条件は、各`num_layers`バッファごとに別々に計算されます。例えば、`num_layers = 16`かつ`max_bytes = 100000000`の場合、最大RAM消費量は1.6GBです。

例:

``` sql
CREATE TABLE merge.hits_buffer AS merge.hits ENGINE = Buffer(merge, hits, 1, 10, 100, 10000, 1000000, 10000000, 100000000)
```

`merge.hits`と同じ構造を持つ`merge.hits_buffer`テーブルを作成し、バッファエンジンを使用します。このテーブルに書き込むと、データはRAMにバッファリングされ、後で`merge.hits`テーブルに書き込まれます。バッファは1つ作成され、以下のいずれかが発生した場合にデータがフラッシュされます：
- 最後のフラッシュから100秒が経過した（`max_time`）または
- 100万行が書き込まれた（`max_rows`）または
- 100MBのデータが書き込まれた（`max_bytes`）または
- 10秒が経過した（`min_time`）うえに、10,000行（`min_rows`）および10MB（`min_bytes`）のデータが書き込まれた

例えば、1行だけ書き込まれた場合、100秒後にフラッシュされますが、書き込まれた行数が多い場合、データはより早くフラッシュされます。

サーバーが停止されると、`DROP TABLE`または`DETACH TABLE`を実行することで、バッファリングされたデータも宛先テーブルにフラッシュされます。

データベースとテーブル名に空文字列を単一引用符で設定することができます。これは宛先テーブルが存在しないことを示します。この場合、データフラッシュ条件が満たされると、バッファは単にクリアされます。これはメモリ内にデータウィンドウを保持するのに便利です。

バッファテーブルから読み取る際、データはバッファおよび宛先テーブル（存在する場合）の両方から処理されます。
バッファテーブルはインデックスをサポートしていないことに注意してください。つまり、バッファ内のデータは完全にスキャンされ、大きなバッファでは遅くなる可能性があります。（従属テーブルのデータに対しては、そのサポートするインデックスが使用されます。）

バッファテーブルのカラムのセットが従属テーブルのカラムのセットと一致しない場合、両方のテーブルに存在するカラムのサブセットが挿入されます。

バッファテーブルのカラムの1つの型が従属テーブルの型と一致しない場合、エラーメッセージがサーバーログに記録され、バッファがクリアされます。
バッファがフラッシュされる際、従属テーブルが存在しない場合も同様です。

:::note
2021年10月26日以前のリリースでバッファテーブルに対してALTERを実行すると、`Block structure mismatch`エラーが発生します（見てください：[#15117](https://github.com/ClickHouse/ClickHouse/issues/15117) および [#30565](https://github.com/ClickHouse/ClickHouse/pull/30565)）。そのため、バッファテーブルを削除してから再作成するのが唯一のオプションです。バッファテーブルに対してALTERを実行しようとする前に、このエラーがあなたのリリースで修正されているか確認してください。
:::

サーバーが異常に再起動されると、バッファ内のデータは失われます。

`FINAL`および`SAMPLE`はバッファテーブルでは正しく機能しません。これらの条件は宛先テーブルに渡されますが、バッファ内のデータ処理には使用されません。これらの機能が必要な場合は、書き込みにはバッファテーブルのみを使用し、宛先テーブルからの読み取りを行うことをお勧めします。

バッファテーブルにデータを追加すると、バッファの1つがロックされます。これにより、テーブルからの読み取り操作が同時に行われている場合に遅延が発生します。

バッファテーブルに挿入されたデータは、従属テーブルに異なる順序で異なるブロックに保存される可能性があります。これにより、バッファテーブルをCollapsingMergeTreeに正しく書き込むのが難しくなります。問題を避けるために、`num_layers`を1に設定することができます。

宛先テーブルがレプリケートされている場合、バッファテーブルへの書き込み時にレプリケートされたテーブルの期待される特性が失われます。行の順序やデータ部分のサイズに対するランダムな変更がデータの重複排除を停止させるため、レプリケートテーブルへの「正確に一度」の書き込みが保証できなくなります。

これらの欠点により、バッファテーブルを使用するのは稀な場合に限ることをお勧めします。

バッファテーブルは、時間単位で多くのサーバーからの多くのINSERTを受け取る場合に使用されます。データを挿入する前にバッファリングできないため、INSERTが十分に速く実行されません。

バッファテーブルに対して1行ずつデータを挿入することは意味がないことに注意してください。これは毎秒数千行の速度しか得られず、大きなデータブロックを挿入すると毎秒100万行を超える速度が得られます。
