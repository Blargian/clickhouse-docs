---
slug: /shards
title: 'Шарды и реплики таблиц'
description: 'Что такое шарды и реплики таблиц в ClickHouse'
keywords: ['shard', 'shards', 'sharding', 'replica', 'replicas']
---

import image_01 from '@site/static/images/managing-data/core-concepts/shards_01.png'
import image_02 from '@site/static/images/managing-data/core-concepts/shards_02.png'
import image_03 from '@site/static/images/managing-data/core-concepts/shards_03.png'
import image_04 from '@site/static/images/managing-data/core-concepts/shards_04.png'
import image_05 from '@site/static/images/managing-data/core-concepts/shards_replicas_01.png'
import Image from '@theme/IdealImage';

<br/>
:::note
Эта тема не относится к ClickHouse Cloud, где [Параллельные реплики](/docs/deployment-guides/parallel-replicas) функционируют как несколько шардов в традиционных кластерах ClickHouse с распределением нагрузки, а объектное хранилище [заменяет](https://clickhouse.com/blog/clickhouse-cloud-boosts-performance-with-sharedmergetree-and-lightweight-updates#shared-object-storage-for-data-availability) реплики, обеспечивая высокую доступность и отказоустойчивость.
:::

## Что такое шарды таблиц в ClickHouse? {#what-are-table-shards-in-clickhouse}

В традиционных кластерах ClickHouse с [отсутствием разделяемых ресурсов](https://en.wikipedia.org/wiki/Shared-nothing_architecture) шардирование используется, когда ① данные слишком большие для одного сервера или ② один сервер слишком медленный для обработки данных. Следующая иллюстрация демонстрирует случай ①, где таблица [uk_price_paid_simple](/parts) превышает емкость одного компьютера:

<Image img={image_01} size="lg" alt='SHARDS'/>

<br/>

В таком случае данные могут быть распределены по нескольким серверам ClickHouse в виде шардов таблиц:

<Image img={image_02} size="lg" alt='SHARDS'/>

<br/>

Каждый шард удерживает подмножество данных и функционирует как обычная таблица ClickHouse, которую можно запрашивать независимо. Однако запросы будут обрабатывать только это подмножество, что может быть допустимым в зависимости от распределения данных. Обычно объединенная таблица [distributed](/docs/engines/table-engines/special/distributed) (часто на сервер) обеспечивает единый обзор полного набора данных. Она не хранит данные, а перенаправляет **SELECT** запросы ко всем шартам, собирает результаты и отправляет **INSERTS** для равномерного распределения данных.

## Создание распределенной таблицы {#distributed-table-creation}

Чтобы проиллюстрировать перенаправление **SELECT** запросов и маршрутизацию **INSERT**, рассмотрим пример таблицы [Что такое части таблиц](/parts), разделённой на два шарда на двух серверах ClickHouse. Сначала покажем DDL-оператор для создания соответствующей **Распределенной таблицы** для этой конфигурации:

```sql
CREATE TABLE uk.uk_price_paid_simple_dist ON CLUSTER test_cluster
(
    date Date,
    town LowCardinality(String),
    street LowCardinality(String),
    price UInt32
)
ENGINE = Distributed('test_cluster', 'uk', 'uk_price_paid_simple', rand())
```

Клаузула `ON CLUSTER` делает оператор DDL [распределенным оператором DDL](/docs/sql-reference/distributed-ddl), инструктируя ClickHouse создать таблицу на всех серверах, перечисленных в [определении кластера](/docs/architecture/horizontal-scaling#replication-and-sharding-configuration) `test_cluster`. Распределенный DDL требует дополнительный компонент [Keeper](https://clickhouse.com/clickhouse/keeper) в [архитектуре кластера](/docs/architecture/horizontal-scaling#architecture-diagram).

Для [параметров распределенного движка](/docs/engines/table-engines/special/distributed#distributed-parameters) указываем имя кластера (`test_cluster`), имя базы данных (`uk`) для целевой таблицы с шардингом, имя целевой таблицы с шардингом (`uk_price_paid_simple`) и **ключ шардирования** для маршрутизации INSERT. В этом примере мы используем функцию [rand](/sql-reference/functions/random-functions#rand) для случайного распределения строк по шартам. Однако может быть использовано любое выражение — даже сложные — в качестве ключа шардирования, в зависимости от конкретного случая. В следующем разделе будет иллюстрироваться, как работает маршрутизация INSERT.

## Маршрутизация INSERT {#insert-routing}

Диаграмма ниже иллюстрирует, как обрабатываются INSERT'ы в распределенную таблицу в ClickHouse:

<Image img={image_03} size="lg" alt='SHARDS'/>

<br/>

① INSERT (с одной строкой), нацеленный на распределенную таблицу, отправляется на сервер ClickHouse, который хранит таблицу, либо напрямую, либо через балансировщик нагрузки.

② Для каждой строки из INSERT (в нашем примере только одна) ClickHouse оценивает ключ шардирования (здесь — rand()), берет результат по модулю количество серверов шардов и использует это в качестве целевого ID сервера (ID начинаются с 0 и увеличиваются на 1). Строка затем перенаправляется и ③ вставляется в шард таблицы соответствующего сервера.

Следующий раздел объясняет, как работает перенаправление SELECT.

## Перенаправление SELECT {#select-forwarding}

Эта диаграмма показывает, как обрабатываются SELECT запросы с распределенной таблицей в ClickHouse:

<Image img={image_04} size="lg" alt='SHARDS'/>

<br/>

① SELECT запрос агрегации, нацеленный на распределенную таблицу, отправляется на соответствующий сервер ClickHouse, либо напрямую, либо через балансировщик нагрузки.

② Распределенная таблица перенаправляет запрос ко всем серверам, которые хранят шарды целевой таблицы, где каждый сервер ClickHouse вычисляет свой локальный результат агрегации **параллельно**.

Затем сервер ClickHouse, который изначально был нацелен на распределенную таблицу, ③ собирает все локальные результаты, ④ объединяет их в окончательный глобальный результат и ⑤ возвращает его отправителю запроса.

## Что такое реплики таблиц в ClickHouse? {#what-are-table-replicas-in-clickhouse}

Репликация в ClickHouse обеспечивает **целостность данных** и **переключение в случае сбоя**, поддерживая **копии данных шардов** на нескольких серверах. Поскольку аппаратные сбои неизбежны, репликация предотвращает потерю данных, обеспечивая, чтобы каждый шард имел несколько реплик. Записи могут направляться на любую реплику, либо напрямую, либо через [распределенную таблицу](#distributed-table-creation), которая выбирает реплику для операции. Изменения автоматически распространяются на другие реплики. В случае сбоя или обслуживания данные остаются доступными на других репликах, и как только сбойный хост восстанавливается, он автоматически синхронизируется, чтобы оставаться актуальным.

Обратите внимание, что репликация требует компонента [Keeper](https://clickhouse.com/clickhouse/keeper) в [архитектуре кластера](/docs/architecture/horizontal-scaling#architecture-diagram).

Следующая диаграмма иллюстрирует кластер ClickHouse из шести серверов, где два шарда таблицы `Shard-1` и `Shard-2`, представленные ранее, имеют по три реплики. Запрос отправляется в этот кластер:

<Image img={image_05} size="lg" alt='SHARDS'/>

<br/>

Обработка запроса работает аналогично настройкам без реплик, только одна реплика из каждого шард выполняет запрос.

> Реплики не только обеспечивают целостность данных и переключение в случае сбоя, но и повышают пропускную способность обработки запросов, позволяя нескольким запросам выполняться параллельно на разных репликах.

① Запрос, нацеленный на распределенную таблицу, отправляется на соответствующий сервер ClickHouse, либо напрямую, либо через балансировщик нагрузки.

② Распределенная таблица перенаправляет запрос к одной реплике из каждого шард, где каждый сервер ClickHouse, хранящий выбранную реплику, вычисляет свой локальный результат запроса параллельно.

Остальное работает [так же](#select-forwarding), как и в настройках без реплик, и не показано на диаграмме выше. Сервер ClickHouse, который изначально был нацелен на распределенную таблицу, собирает все локальные результаты, объединяет их в окончательный глобальный результат и возвращает его отправителю запроса.

Обратите внимание, что ClickHouse позволяет настраивать стратегию перенаправления запросов для ②. По умолчанию — в отличие от диаграммы выше — распределенная таблица [предпочитает](/docs/operations/settings/settings#prefer_localhost_replica) локальную реплику, если она доступна, но могут использоваться и другие стратегии балансировки нагрузки [по умолчанию](/docs/operations/settings/settings#load_balancing).

## Где найти дополнительную информацию {#where-to-find-more-information}

Для получения более подробной информации помимо этого обобщенного введения в шардов и реплик таблиц, ознакомьтесь с нашим [руководством по развертыванию и масштабированию](/docs/architecture/horizontal-scaling).

Мы также настоятельно рекомендуем это учебное видео для более глубокого погружения в шардов и реплик ClickHouse:

<iframe width="1024" height="576" src="https://www.youtube.com/embed/vBjCJtw_Ei0?si=WqopTrnti6usCMRs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
