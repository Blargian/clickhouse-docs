---
slug: /integrations/s3/performance
sidebar_position: 2
sidebar_label: 'Оптимизация производительности'
title: 'Оптимизация производительности вставки и чтения в S3'
description: 'Оптимизация производительности чтения и вставки в S3'
---

import Image from '@theme/IdealImage';
import InsertMechanics from '@site/static/images/integrations/data-ingestion/s3/insert_mechanics.png';
import Pull from '@site/static/images/integrations/data-ingestion/s3/pull.png';
import Merges from '@site/static/images/integrations/data-ingestion/s3/merges.png';
import ResourceUsage from '@site/static/images/integrations/data-ingestion/s3/resource_usage.png';
import InsertThreads from '@site/static/images/integrations/data-ingestion/s3/insert_threads.png';
import S3Cluster from '@site/static/images/integrations/data-ingestion/s3/s3Cluster.png';
import HardwareSize from '@site/static/images/integrations/data-ingestion/s3/hardware_size.png';

Этот раздел сосредоточен на оптимизации производительности при чтении и вставке данных из S3 с использованием [функций таблиц s3](/sql-reference/table-functions/s3).

:::info
**Урок, описанный в этом руководстве, может быть применен к другим реализациям объектного хранилища с их собственными специализированными функциями таблиц, таким как [GCS](/sql-reference/table-functions/gcs) и [Azure Blob storage](/sql-reference/table-functions/azureBlobStorage).**
:::

Перед настройкой потоков и блоков для улучшения производительности вставки мы рекомендуем пользователям понять механику вставок в S3. Если вы знакомы с механикой вставок или просто хотите краткие советы, пропустите к нашему примеру [ниже](/integrations/s3/performance#example-dataset).
## Механика вставки (одиночный узел) {#insert-mechanics-single-node}

Два основных фактора, помимо размера оборудования, влияют на производительность и использование ресурсов механики вставки данных ClickHouse (для одиночного узла): **размер блока вставки** и **параллелизм вставки**.
### Размер блока вставки {#insert-block-size}

<Image img={InsertMechanics} size="lg" border alt="Механика размера блока вставки в ClickHouse" />

При выполнении `INSERT INTO SELECT` ClickHouse получает некоторую часть данных и ① формирует (по крайней мере) один блок вставки в памяти (на каждую [ключ партиционирования](/engines/table-engines/mergetree-family/custom-partitioning-key)) из полученных данных. Данные блока сортируются, и применяются оптимизации, специфические для движка таблицы. Затем данные сжимаются и ② записываются в хранилище базы данных в виде новой части данных.

Размер блока вставки влияет как на [использование дискового ввода-вывода](https://en.wikipedia.org/wiki/Category:Disk_file_systems), так и на использование памяти сервера ClickHouse. Более крупные блоки вставки используют больше памяти, но создают более крупные и менее многочисленные исходные части. Чем меньше частей ClickHouse необходимо создать для загрузки большого объема данных, тем меньше требуются ввод-вывод диска и автоматические [фоновая агрегация](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges).

При использовании запроса `INSERT INTO SELECT` в сочетании с интеграционным движком таблицы или функцией таблицы данные забираются сервером ClickHouse:

<Image img={Pull} size="lg" border alt="Извлечение данных из внешних источников в ClickHouse" />

Пока данные полностью не загружены, сервер выполняет цикл:

```bash
① Извлекает и разбирает следующую порцию данных и формирует из нее блок данных в памяти (по одному на ключ партиционирования).

② Записывает блок в новую часть на хранилище.

Перейти к ①
```

В ① размер зависит от размера блока вставки, который можно контролировать с помощью двух настроек:

- [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) (по умолчанию: `1048545` миллионов строк)
- [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes) (по умолчанию: `256 MiB`)

Когда либо указанное количество строк собрано в блоке вставки, либо достигнуто заданное количество данных (в зависимости от того, что произойдет первым), это приведет к записи блока в новую часть. Вставочный цикл продолжается с шага ①.

Обратите внимание, что значение `min_insert_block_size_bytes` обозначает не сжатый размер блока в памяти (а не размер сжатой части на диске). Также обратите внимание, что созданные блоки и части редко точно содержат указанное количество строк или байтов, потому что ClickHouse потоково и [обрабатывает](https://clickhouse.com/company/events/query-performance-introspection) данные по-долговому-[блочному](/operations/settings/settings#max_block_size). Поэтому эти настройки указывают минимальные пороговые значения.
#### Будьте осторожны с агрегацией {#be-aware-of-merges}

Чем меньше установленный размер блока вставки, тем больше исходных частей создается для большой загрузки данных, и тем больше фоновой агрегации выполняется одновременно со приемом данных. Это может вызвать конкуренцию за ресурсы (CPU и память) и потребовать дополнительного времени (для достижения [здорового](/operations/settings/merge-tree-settings#parts_to_throw_insert) (3000) количества частей) после завершения загрузки.

:::important
Производительность запросов ClickHouse будет отрицательно затронута, если количество частей превысит [рекомендуемые пределы](/operations/settings/merge-tree-settings#parts_to_throw_insert).
:::

ClickHouse будет непрерывно [смешивать части](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse#data-needs-to-be-batched-for-optimal-performance) в более крупные части, пока они не [достигнут](/operations/settings/merge-tree-settings#max_bytes_to_merge_at_max_space_in_pool) сжатого размера ~150 GiB. Эта схема показывает, как сервер ClickHouse объединяет части:

<Image img={Merges} size="lg" border alt="Фоновая агрегация в ClickHouse" />

Один сервер ClickHouse использует несколько [фонов пулов агрегации](/operations/server-configuration-parameters/settings#background_pool_size) для выполнения параллельных [агрегаций частей](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges:~:text=to%20execute%20concurrent-,part%20merges,-.%20Each%20thread%20executes). Каждый поток выполняет цикл:

```bash
① Решает, какие части следует объединить в следующий раз, и загружает эти части в память как блоки.

② Смешивает загруженные блоки в памяти в более крупный блок.

③ Записывает объединенный блок в новую часть на диске.

Перейти к ①
```

Обратите внимание, что [увеличение](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#hardware-size) числа ядер CPU и размера RAM увеличивает пропускную способность фоновой агрегации.

Части, которые были объединены в более крупные части, помечаются как [неактивные](/operations/system-tables/parts) и в конце концов удаляются после [настраиваемого](/operations/settings/merge-tree-settings#old_parts_lifetime) количества минут. Со временем это создает дерево объединенных частей (отсюда название [`MergeTree`](/engines/table-engines/mergetree-family) таблицы).
### Параллелизм вставки {#insert-parallelism}

<Image img={ResourceUsage} size="lg" border alt="Использование ресурсов для параллелизма вставки" />

Сервер ClickHouse может обрабатывать и вставлять данные параллельно. Уровень параллелизма вставки влияет на пропускную способность и использование памяти сервера ClickHouse. Загрузка и обработка данных параллельно требует больше основной памяти, но увеличивает пропускную способность, так как данные обрабатываются быстрее.

Функции таблиц, такие как s3, позволяют указывать наборы имен файлов для загрузки с помощью шаблонов glob. Когда шаблон glob соответствует нескольким существующим файлам, ClickHouse может параллелизовать чтение этих файлов и вставлять данные параллельно в таблицу, используя параллельно выполняющиеся потоки вставки (на сервер):

<Image img={InsertThreads} size="lg" border alt="Параллельные потоки вставки в ClickHouse" />

Пока все данные из всех файлов обрабатываются, каждый поток вставки выполняет цикл:

```bash
① Получает следующую порцию не обработанных данных из файла (размер порции основан на заданном размере блока) и создает из нее блок данных в памяти.

② Записывает блок в новую часть на хранилище.

Перейти к ①. 
```

Количество таких параллельных потоков вставки можно настроить с помощью настройки [`max_insert_threads`](/operations/settings/settings#max_insert_threads). Значение по умолчанию равно `1` для открытого исходного кода ClickHouse и 4 для [ClickHouse Cloud](https://clickhouse.com/cloud).

С большим количеством файлов параллельная обработка несколькими потоками вставки работает хорошо. Она может полностью загрузить как доступные ядра CPU, так и пропускную способность сети (для параллельных загрузок файлов). В сценариях, когда будет загружено всего несколько крупных файлов, ClickHouse автоматически устанавливает высокий уровень параллелизма обработки данных и оптимизирует использование пропускной способности сети, создавая дополнительные потоки для чтения (загрузки) более различных диапазонов в крупных файлах параллельно.

Для функции и таблицы s3 параллельная загрузка отдельного файла определяется значениями [max_download_threads](https://clickhouse.com/codebrowser/ClickHouse/src/Core/Settings.h.html#DB::SettingsTraits::Data::max_download_threads) и [max_download_buffer_size](https://clickhouse.com/codebrowser/ClickHouse/src/Core/Settings.h.html#DB::SettingsTraits::Data::max_download_buffer_size). Файлы будут загружаться параллельно только в том случае, если их размер превышает `2 * max_download_buffer_size`. По умолчанию значение `max_download_buffer_size` установлено на 10 MiB. В некоторых случаях вы можете без опасения увеличить этот размер буфера до 50 МБ (`max_download_buffer_size=52428800`), с целью гарантировать, что каждый файл будет загружен только одним потоком. Это может уменьшить время, которое каждый поток тратит на вызовы S3, и таким образом снизить время ожидания S3. Более того, для файлов, которые слишком малы для параллельного чтения, чтобы увеличить пропускную способность, ClickHouse автоматически загружает данные, заранее считывая такие файлы асинхронно.
## Измерение производительности {#measuring-performance}

Оптимизация производительности запросов с использованием функций таблиц S3 требуется как при выполнении запросов к данным на месте, т.е. при ад-хок запросах, когда используется только вычисление ClickHouse, и данные остаются в S3 в своем оригинальном формате, так и при вставке данных из S3 в движок таблиц ClickHouse MergeTree. Если не указано другое, следующие рекомендации применимы к обоим сценариям.
## Влияние размера оборудования {#impact-of-hardware-size}

<Image img={HardwareSize} size="lg" border alt="Влияние размера оборудования на производительность ClickHouse" />

Количество доступных ядер CPU и размер RAM влияют на:

- поддерживаемый [начальный размер частей](#insert-block-size)
- возможный уровень [параллелизма вставки](#insert-parallelism)
- пропускную способность [фоновых агрегаций частей](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges)

и, следовательно, на общую пропускную способность загрузки.
## Региональная локализация {#region-locality}

Убедитесь, что ваши бакеты находятся в том же регионе, что и ваши экземпляры ClickHouse. Эта простая оптимизация может значительно улучшить производительность пропускной способности, особенно если вы разворачиваете свои экземпляры ClickHouse на инфраструктуре AWS.
## Форматы {#formats}

ClickHouse может читать файлы, хранящиеся в бакетах S3, в [поддерживаемых форматах](/interfaces/formats#formats-overview) с использованием функции `s3` и движка `S3`. Если читать «сырые» файлы, некоторые из этих форматов имеют явные преимущества:

* Форматы с закодированными именами колонок, такие как Native, Parquet, CSVWithNames и TabSeparatedWithNames, будут менее многословны для запроса, так как пользователю не потребуется указывать имя колонки в функции `s3`. Имена колонок позволяют извлечь эту информацию.
* Форматы будут различаться по производительности в отношении чтения и записи. Native и parquet представляют собой наиболее оптимальные форматы для производительности чтения, так как они уже ориентированы на столбцы и более компактны. Формат native также выигрывает от согласованности с тем, как ClickHouse хранит данные в памяти - тем самым уменьшая накладные расходы на обработку при потоковой передаче данных в ClickHouse.
* Размер блока часто влияет на задержку чтения больших файлов. Это очень заметно, если вы просто выбираете данные, например, возвращая первые N строк. В случае таких форматов, как CSV и TSV, файлы должны быть разобраны, чтобы вернуть набор строк. Форматы, такие как Native и Parquet, позволят быстрее выполнять выборку по этой причине.
* Каждый формат сжатия приносит свои плюсы и минусы, часто балансируя между уровнем сжатия для скорости и смещая производительность сжатия или распаковки. Если сжимать «сырые» файлы, такие как CSV или TSV, lz4 предлагает наиболее быструю производительность распаковки, жертвуя уровнем сжатия. Gzip, как правило, обеспечивает лучшее сжатие за счет немного медленных скоростей чтения. Xz идет дальше, обычно предлагая лучшее сжатие, но наиболее медленную производительность сжатия и распаковки. Если экспортируется, Gz и lz4 предлагают сопоставимые скорости сжатия. Учитывайте это в соотношении со скоростями подключения. Любые выгоды от более быстрого распаковки или сжатия будут легко нивелированы медленным подключением к вашим бакетам s3.
* Форматы, такие как native или parquet, обычно не оправдывают накладные расходы на сжатие. Любые экономии в размере данных, вероятно, будут минимальными, так как эти форматы изначально компактны. Время, затраченное на сжатие и распаковку, редко компенсирует время передачи по сети - особенно поскольку s3 глобально доступен с высокой пропускной способностью сети.
## Пример набора данных {#example-dataset}

Чтобы проиллюстрировать дальнейшие потенциальные оптимизации, мы будем использовать [посты из набора данных Stack Overflow](/data-modeling/schema-design#stack-overflow-dataset) - оптимизируя как производительность запроса, так и производительность вставки этих данных.

Этот набор данных состоит из 189 файлов Parquet, по одному на каждый месяц с июля 2008 года по март 2024 года.

Обратите внимание, что мы используем Parquet для производительности, следуя нашим [вышеописанным рекомендациям](#formats), выполняя все запросы на кластере ClickHouse, расположенном в том же регионе, что и бакет. Этот кластер имеет 3 узла, каждый с 32 ГБ памяти и 8 vCPU.

Без настройки мы демонстрируем производительность вставки этого набора данных в движок таблиц MergeTree, а также выполнения запроса на подсчет пользователей, задающих наибольшее количество вопросов. Оба этих запроса намеренно требуют полного сканирования данных.

```sql
-- Топ имена пользователей
SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5

┌─OwnerDisplayName─┬─num_posts─┐
│ user330315       │     10344 │
│ user4039065      │      5316 │
│ user149341       │      4102 │
│ user529758       │      3700 │
│ user3559349      │      3068 │
└──────────────────┴───────────┘

5 строк в наборе. Время выполнения: 3.013 сек. Обработано 59.82 миллионов строк, 24.03 ГБ (19.86 миллионов строк/с., 7.98 ГБ/с.)
Пиковое использование памяти: 603.64 МиБ.

-- Загрузка в таблицу posts
INSERT INTO posts SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')

0 строк в наборе. Время выполнения: 191.692 сек. Обработано 59.82 миллиона строк, 24.03 ГБ (312.06 тысяч строк/с., 125.37 МБ/с.)
```

В нашем примере мы возвращаем только несколько строк. Если требуется измерить производительность запросов `SELECT`, при возвращении больших объемов данных клиенту, либо используйте [null формат](/interfaces/formats/#null) для запросов, либо направляйте результаты на [`Null` engine](/engines/table-engines/special/null.md). Это должно предотвратить перегрузку клиента данными и насыщение сети.

:::info
При чтении из запросов начальный запрос может показаться медленнее, чем если тот же запрос повторяется. Это может быть связано как с кешированием S3, так и с [Кэшем вывода схемы ClickHouse](/operations/system-tables/schema_inference_cache). Это сохраняет выведенную схему файлов и означает, что шаг вывода можно пропустить при последующих обращениях, тем самым уменьшая время запроса.
:::
## Использование потоков для чтения {#using-threads-for-reads}

Производительность чтения из S3 будет линейно масштабироваться с количеством ядер, при условии, что вы не ограничены пропускной способностью сети или локальным ввода-вывода. Увеличение количества потоков также имеет комбинации накладных расходов на память, о которых пользователи должны знать. Следующие параметры можно изменить, чтобы потенциально улучшить производительность пропускной способности чтения:

* Обычно, значение по умолчанию для `max_threads` является достаточным, т.е. равное количеству ядер. Если количество памяти, используемой для запроса, велико, и это необходимо уменьшить, либо ограничение по результатам невелико, это значение можно установить ниже. Пользователи с достаточным количеством памяти могут попробовать увеличить это значение для возможного повышения пропускной способности чтения из S3. Обычно это полезно только на машинах с меньшим количеством ядер, т.е. < 10. Польза от дальнейшего параллелизма обычно уменьшается, поскольку другие ресурсы становятся узким местом, например, конкуренция между сетью и CPU.
* Версии ClickHouse до 22.3.1 параллелизовали чтение только по нескольким файлам при использовании функции `s3` или движка `S3`. Это требовало от пользователя гарантировать, что файлы были разбиты на кусочки на S3 и читались с использованием шаблона glob для достижения оптимальной производительности чтения. Поздние версии теперь параллелизуют загрузки внутри файла.
* В сценариях с низким количеством потоков пользователи могут извлечь выгоду, установив `remote_filesystem_read_method` в "read", чтобы инициировать синхронное чтение файлов из S3.
* Для функции и таблицы s3 параллельная загрузка отдельного файла определяется значениями [`max_download_threads`](/operations/settings/settings#max_download_threads) и [`max_download_buffer_size`](/operations/settings/settings#max_download_buffer_size). В то время как [`max_download_threads`](/operations/settings/settings#max_download_threads) управляет количеством используемых потоков, файлы будут загружаться параллельно только в том случае, если их размер превышает 2 * `max_download_buffer_size`. По умолчанию значение `max_download_buffer_size` установлено на 10 MiB. В некоторых случаях вы можете безопасно увеличить этот размер буфера до 50 MB (`max_download_buffer_size=52428800`), с целью обеспечения того, чтобы большие файлы были загружены только одним потоком. Это может сократить время, которое каждый поток тратит на вызовы S3, и, таким образом, уменьшить время ожидания S3. См. [этот блог](https://clickhouse.com/blog/clickhouse-1-trillion-row-challenge) для примера этого.

Перед внесением каких-либо изменений для улучшения производительности убедитесь, что вы корректно измеряете. Поскольку API вызовы S3 чувствительны к задержке и могут воздействовать на время клиента, используйте лог запросов для метрик производительности, т.е. `system.query_log`.

Рассмотрите наш предыдущий запрос, удвоение `max_threads` до `16` (по умолчанию `max_thread` равно количеству ядер на узле), улучшает производительность запроса чтения в 2 раза за счет большего использования памяти. Дальнейшее увеличение `max_threads` имеет уменьшенную отдачу, как показано.

```sql
SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5
SETTINGS max_threads = 16

┌─OwnerDisplayName─┬─num_posts─┐
│ user330315       │     10344 │
│ user4039065      │      5316 │
│ user149341       │      4102 │
│ user529758       │      3700 │
│ user3559349      │      3068 │
└──────────────────┴───────────┘

5 строк в наборе. Время выполнения: 1.505 сек. Обработано 59.82 миллионов строк, 24.03 ГБ (39.76 миллионов строк/с., 15.97 ГБ/с.)
Пиковое использование памяти: 178.58 МиБ.

SETTINGS max_threads = 32

5 строк в наборе. Время выполнения: 0.779 сек. Обработано 59.82 миллионов строк, 24.03 ГБ (76.81 миллиона строк/с., 30.86 ГБ/с.)
Пиковое использование памяти: 369.20 МиБ.

SETTINGS max_threads = 64

5 строк в наборе. Время выполнения: 0.674 сек. Обработано 59.82 миллионов строк, 24.03 ГБ (88.81 миллиона строк/с., 35.68 ГБ/с.)
Пиковое использование памяти: 639.99 МиБ.
```
## Настройка потоков и размера блока для вставок {#tuning-threads-and-block-size-for-inserts}

Чтобы достичь максимальной производительности инъекций, необходимо выбрать (1) размер блока вставки и (2) соответствующий уровень параллелизма вставки на основе (3) количества доступных ядер CPU и доступной памяти. В общем:

- Чем больше мы [настраиваем размер блока вставки](#insert-block-size), тем меньше частей ClickHouse придется создать, и тем меньше [дискового ввода-вывода](https://en.wikipedia.org/wiki/Category:Disk_file_systems) и [фоновая агрегация](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#more-parts--more-background-part-merges) требуется.  
- Чем выше мы настраиваем [число параллельных потоков вставки](#insert-parallelism), тем быстрее будут обрабатываться данные.

Существует противоречивый компромисс между этими двумя факторами производительности (плюс компромисс с фоновым слиянием частей). Количество доступной основной памяти серверов ClickHouse ограничено. Более крупные блоки используют больше основной памяти, что ограничивает количество параллельных потоков вставки, которые мы можем использовать. Напротив, большее количество параллельных потоков вставки требует больше основной памяти, так как количество потоков вставки определяет количество блоков вставки, созданных в памяти параллельно. Это ограничивает возможный размер блоков вставки. Кроме того, между потоками вставки и потоками фонового слияния может возникнуть конкуренция за ресурсы. Высокое количество настроенных потоков вставки (1) создает больше частей, которые требуют слияния и (2) отвлекает ядра CPU и пространство памяти от потоков фонового слияния.

Для подробного описания того, как поведение этих параметров влияет на производительность и ресурсы, мы рекомендуем [прочитать этот блог](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part2). Как описано в этом блоге, настройка может потребовать осторожного баланса двух параметров. Эта исчерпывающая проверка часто является непрактичной, поэтому в общем мы рекомендуем:

```bash
• max_insert_threads: выберите ~ половину доступных ядер CPU для потоков вставки (чтобы оставить достаточно выделенных ядер для фонового слияния)

• peak_memory_usage_in_bytes: выберите предполагаемый пик использования памяти; либо всю доступную RAM (если это изолированная вставка), либо половину или меньше (чтобы оставить место для других параллельных задач)

Затем:
min_insert_block_size_bytes = peak_memory_usage_in_bytes / (~3 * max_insert_threads)
```

С помощью этой формулы вы можете установить `min_insert_block_size_rows` в 0 (чтобы отключить порог на основе строк), в то время как `max_insert_threads` устанавливается на выбранное значение, а `min_insert_block_size_bytes` устанавливается на рассчитанный результат из приведенной выше формулы.

Используя эту формулу с нашим предыдущим примером Stack Overflow.

- `max_insert_threads=4` (8 ядер на узел)
- `peak_memory_usage_in_bytes` - 32 ГБ (100% ресурсов узла) или `34359738368` байт.
- `min_insert_block_size_bytes` = `34359738368/(3*4) = 2863311530`

```sql
INSERT INTO posts SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet') SETTINGS min_insert_block_size_rows=0, max_insert_threads=4, min_insert_block_size_bytes=2863311530

0 строк в наборе. Время выполнения: 128.566 сек. Обработано 59.82 миллионов строк, 24.03 ГБ (465.28 тысяч строк/с., 186.92 МБ/с.)
```

Как показано, настройка этих параметров улучшила производительность вставки более чем на `33%`. Мы оставляем это читателю, чтобы посмотреть, сможет ли он дальше улучшить производительность одиночного узла.
## Масштабирование с ресурсами и узлами {#scaling-with-resources-and-nodes}

Масштабирование с ресурсами и узлами применяется как к чтению, так и к запросам вставки.
### Вертикальное масштабирование {#vertical-scaling}

Все предыдущие настройки и запросы использовали только один узел в нашем кластере ClickHouse Cloud. Пользователи также часто имеют более одного доступного узла ClickHouse. Мы рекомендуем пользователям изначально масштабировать вертикально, улучшая пропускную способность S3 линейно с количеством ядер. Если мы повторим наши предыдущие вставочные и читательские запросы на большем узле ClickHouse Cloud с удвоенными ресурсами (64 ГБ, 16 vCPU) с соответствующими настройками, оба будут выполняться примерно в два раза быстрее.

```sql
INSERT INTO posts SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet') SETTINGS min_insert_block_size_rows=0, max_insert_threads=8, min_insert_block_size_bytes=2863311530

0 строк в наборе. Время выполнения: 67.294 сек. Обработано 59.82 миллионов строк, 24.03 ГБ (888.93 тысяч строк/с., 357.12 МБ/с.)

SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5
SETTINGS max_threads = 92

5 строк в наборе. Время выполнения: 0.421 сек. Обработано 59.82 миллионов строк, 24.03 ГБ (142.08 миллиона строк/с., 57.08 ГБ/с.)
```

:::note
Отдельные узлы также могут быть узким местом из-за сети и запросов S3 GET, что предотвращает линейное масштабирование производительности вверх.
:::
### Горизонтальное масштабирование {#horizontal-scaling}

В конечном итоге, горизонтальное масштабирование часто необходимо из-за доступности оборудования и экономической эффективности. В ClickHouse Cloud производственные кластеры имеют как минимум 3 узла. Пользователи также могут захотеть использовать все узлы для вставки.

Использование кластера для чтения из S3 требует использования функции `s3Cluster`, как описано в [Использование кластеров](/integrations/s3#utilizing-clusters). Это позволяет распределить чтение между узлами.

Сервер, который изначально получает запрос на вставку, сначала разрешает шаблон glob, а затем динамически распределяет обработку каждого соответствующего файла между собой и другими серверами.

<Image img={S3Cluster} size="lg" border alt="Функция s3Cluster в ClickHouse" />

Мы повторяем наш предыдущий запрос, перераспределяя рабочую нагрузку между 3 узлами, изменяя запрос для использования `s3Cluster`. Это выполняется автоматически в ClickHouse Cloud, ссылаясь на кластер `default`.

Как отмечается в [Использовании кластеров](/integrations/s3#utilizing-clusters), эта работа распределяется на уровне файлов. Чтобы воспользоваться этой функцией пользователям потребуется достаточное количество файлов, т.е. более количества узлов.


```sql
SELECT
    OwnerDisplayName,
    count() AS num_posts
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
WHERE OwnerDisplayName NOT IN ('', 'anon')
GROUP BY OwnerDisplayName
ORDER BY num_posts DESC
LIMIT 5
SETTINGS max_threads = 16

┌─OwnerDisplayName─┬─num_posts─┐
│ user330315       │     10344 │
│ user4039065      │      5316 │
│ user149341       │      4102 │
│ user529758       │      3700 │
│ user3559349      │      3068 │
└──────────────────┴───────────┘

5 строк в наборе. Время выполнения: 0.622 сек. Обработано 59.82 миллионов строк, 24.03 ГБ (96.13 миллиона строк/с., 38.62 ГБ/с.)
Пиковое использование памяти: 176.74 МиБ.
```

Аналогичным образом, наш запрос на вставку может быть распределен, используя улучшенные настройки, идентифицированные ранее для одиночного узла:

```sql
INSERT INTO posts SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet') SETTINGS min_insert_block_size_rows=0, max_insert_threads=4, min_insert_block_size_bytes=2863311530

0 строк в наборе. Время выполнения: 171.202 сек. Обработано 59.82 миллионов строк, 24.03 ГБ (349.41 тысячи строк/с., 140.37 МБ/с.)
```

Читатели заметят, что чтение файлов улучшило производительность запроса, но не вставки. По умолчанию, хотя чтения распределяются с использованием `s3Cluster`, вставки будут происходить против инициирующего узла. Это означает, что в то время как чтения происходят на каждом узле, итоговые строки будут направлены к инициатору для распределения. В сценариях с высоким пропуском это может оказаться узким местом. Чтобы это исправить, установите параметр `parallel_distributed_insert_select` для функции `s3cluster`.

Установка этого параметра в `parallel_distributed_insert_select=2` гарантирует, что `SELECT` и `INSERT` будут выполняться на каждом шардированном узле, от/к базовой таблицы распределенного движка.

```sql
INSERT INTO posts
SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows=0, max_insert_threads=4, min_insert_block_size_bytes=2863311530

0 строк в наборе. Время выполнения: 54.571 сек. Обработано 59.82 миллиона строк, 24.03 ГБ (1.10 миллиона строк/с., 440.38 МБ/с.)
Пиковое использование памяти: 11.75 ГиБ.
```

Как и ожидалось, это снижает производительность вставки в 3 раза.
## Дальнейшая настройка {#further-tuning}
### Отключение дедупликации {#disable-de-duplication}

Операции вставки иногда могут завершаться неудачно из-за ошибок, таких как тайм-ауты. Когда вставки происходят неудачно, данные могли быть успешно вставлены или нет. Чтобы позволить клиенту безопасно повторить вставки, по умолчанию в распределенных развертываниях, таких как ClickHouse Cloud, ClickHouse пытается определить, были ли данные уже успешно вставлены. Если вставленные данные помечены как дубликаты, ClickHouse не вставляет их в целевую таблицу. Однако пользователь все равно получит статус успешной операции, как будто данные были вставлены нормально.

Хотя такое поведение, которое накладывает накладные расходы на вставку, имеет смысл при загрузке данных от клиента или пакетно, оно может быть ненужным при выполнении `INSERT INTO SELECT` из объектного хранилища. Отключив эту функциональность во время вставки, мы можем улучшить производительность, как показано ниже:

```sql
INSERT INTO posts
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows = 0, max_insert_threads = 4, min_insert_block_size_bytes = 2863311530, insert_deduplicate = 0
SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows = 0, max_insert_threads = 4, min_insert_block_size_bytes = 2863311530, insert_deduplicate = 0

0 строк в наборе. Время выполнения: 52.992 сек. Обработано 59.82 миллиона строк, 24.03 ГБ (1.13 миллиона строк/с., 453.50 МБ/с.)
Пиковое использование памяти: 26.57 ГиБ.
```
### Оптимизация при вставке {#optimize-on-insert}

В ClickHouse настройка `optimize_on_insert` управляет тем, будет ли происходить слияние частей данных в процессе вставки. Когда эта функция включена (`optimize_on_insert = 1` по умолчанию), маленькие части сливаются в более крупные по мере их вставки, что улучшает производительность запросов за счет уменьшения числа частей, которые необходимо считать. Однако это слияние добавляет накладные расходы к процессу вставки, что может замедлить вставки с высокой пропускной способностью.

Отключение этой настройки (`optimize_on_insert = 0`) пропускает слияние во время вставок, позволяя данным записываться быстрее, особенно при частых маленьких вставках. Процесс слияния откладывается на фон, что позволяет улучшить производительность вставки, но временно увеличивает количество маленьких частей, что может замедлить запросы до завершения фонового слияния. Эта настройка идеальна, когда производительность вставки является приоритетом, и фоновый процесс слияния может эффективно обработать оптимизацию позже. Как показано ниже, отключение настройки может улучшить пропускную способность вставки:

```sql
SELECT *
FROM s3Cluster('default', 'https://datasets-documentation.s3.eu-west-3.amazonaws.com/stackoverflow/parquet/posts/by_month/*.parquet')
SETTINGS parallel_distributed_insert_select = 2, min_insert_block_size_rows = 0, max_insert_threads = 4, min_insert_block_size_bytes = 2863311530, insert_deduplicate = 0, optimize_on_insert = 0

0 rows in set. Elapsed: 49.688 sec. Processed 59.82 million rows, 24.03 GB (1.20 million rows/s., 483.66 MB/s.)
```
## Разные заметки {#misc-notes}

* Для сценариев с низким объемом памяти рассмотрите возможность снижения `max_insert_delayed_streams_for_parallel_write`, если вставляете в S3.
