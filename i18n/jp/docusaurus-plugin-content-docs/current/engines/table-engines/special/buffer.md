---
description: 'RAMに書き込むためのデータをバッファリングし、定期的に別のテーブルにフラッシュします。読み取り操作の際には、バッファと他のテーブルから同時にデータが読み取られます。'
sidebar_label: 'バッファ'
sidebar_position: 120
slug: /engines/table-engines/special/buffer
title: 'バッファテーブルエンジン'
---


# バッファテーブルエンジン

RAMに書き込むためのデータをバッファリングし、定期的に別のテーブルにフラッシュします。読み取り操作の際には、バッファと他のテーブルから同時にデータが読み取られます。

:::note
バッファテーブルエンジンの推奨代替手段は、[非同期挿入](/guides/best-practices/asyncinserts.md)を有効にすることです。
:::

```sql
Buffer(database, table, num_layers, min_time, max_time, min_rows, max_rows, min_bytes, max_bytes [,flush_time [,flush_rows [,flush_bytes]]])
```

### エンジンパラメータ: {#engine-parameters}

#### database {#database}

`database` – データベース名。`currentDatabase()`や文字列を返す他の定数表現を使用できます。

#### table {#table}

`table` – データをフラッシュするテーブル。

#### num_layers {#num_layers}

`num_layers` – 並列性の層。物理的にはテーブルは`num_layers`の独立したバッファとして表現されます。

#### min_time, max_time, min_rows, max_rows, min_bytes, and max_bytes {#min_time-max_time-min_rows-max_rows-min_bytes-and-max_bytes}

バッファからデータをフラッシュする条件。

### オプションのエンジンパラメータ: {#optional-engine-parameters}

#### flush_time, flush_rows, and flush_bytes {#flush_time-flush_rows-and-flush_bytes}

バックグラウンドでバッファからデータをフラッシュする条件（省略またはゼロは`flush*`パラメータなしを意味します）。

すべての`min*`条件が満たされるか、少なくとも1つの`max*`条件が満たされると、バッファからデータがフラッシュされて宛先テーブルに書き込まれます。

また、少なくとも1つの`flush*`条件が満たされると、バックグラウンドでフラッシュが開始されます。これは`max*`とは異なり、`flush*`を使用することで、Bufferテーブルへの`INSERT`クエリの遅延を回避するためにバックグラウンドフラッシュを別に構成できます。

#### min_time, max_time, and flush_time {#min_time-max_time-and-flush_time}

バッファへの最初の書き込みからの経過時間の条件（秒）。

#### min_rows, max_rows, and flush_rows {#min_rows-max_rows-and-flush_rows}

バッファ内の行数の条件。

#### min_bytes, max_bytes, and flush_bytes {#min_bytes-max_bytes-and-flush_bytes}

バッファ内のバイト数の条件。

書き込み操作中、データは1つまたは複数のランダムなバッファ（`num_layers`で構成）に挿入されます。あるいは、挿入するデータ部分が十分に大きい場合（`max_rows`または`max_bytes`を超える場合）、バッファを省略して宛先テーブルに直接書き込まれます。

データをフラッシュする条件は、各`num_layers`バッファごとに個別に計算されます。たとえば、`num_layers = 16`および`max_bytes = 100000000`の場合、最大RAM消費量は1.6 GBです。

例:

```sql
CREATE TABLE merge.hits_buffer AS merge.hits ENGINE = Buffer(merge, hits, 1, 10, 100, 10000, 1000000, 10000000, 100000000)
```

`merge.hits`と同じ構造を持つ`merge.hits_buffer`テーブルを作成し、バッファエンジンを使用しています。このテーブルに書き込むと、データはRAMにバッファリングされ、後に'relmerge.hits'テーブルに書き込まれます。単一のバッファが作成され、データがフラッシュされる条件は次のいずれかです：
- 最後のフラッシュから100秒が経過した場合（`max_time`）または
- 100万行が書き込まれた場合（`max_rows`）または
- 100 MBのデータが書き込まれた場合（`max_bytes`）または
- 10秒が経過し（`min_time`）、10,000行（`min_rows`）および10 MB（`min_bytes`）のデータが書き込まれた場合

たとえば、1行だけが書き込まれた場合、100秒後にそれがフラッシュされます。だが、多くの行が書き込まれた場合、データは早めにフラッシュされます。

サーバーが停止するとき、`DROP TABLE`または`DETACH TABLE`とともに、バッファされたデータも宛先テーブルにフラッシュされます。

データベース名とテーブル名に空文字列を単一引用符で囲んで設定できます。これは宛先テーブルが存在しないことを示します。この場合、データフラッシュ条件が満たされると、単にバッファがクリアされます。これはメモリにデータウィンドウを維持するのに役立つかもしれません。

バッファテーブルから読み取る際には、バッファと宛先テーブル（存在する場合）の両方からデータが処理されます。
バッファテーブルはインデックスをサポートしないことに注意してください。言い換えれば、バッファ内のデータは完全にスキャンされるため、大きなバッファでは遅くなる可能性があります。（従属テーブルのデータに対しては、それがサポートするインデックスが使用されます。）

バッファテーブルのカラムの集合が従属テーブルのカラムの集合と一致しない場合、両方のテーブルに存在するカラムのサブセットが挿入されます。

バッファテーブルのいずれかのカラムと従属テーブルのカラムの型が一致しない場合、エラーメッセージがサーバーログに記録され、バッファがクリアされます。
バッファがフラッシュされるときに従属テーブルが存在しない場合も同様です。

:::note
2021年10月26日以前に作成されたリリースでバッファテーブルにALTERを実行すると、`Block structure mismatch`エラーが発生します（[#15117](https://github.com/ClickHouse/ClickHouse/issues/15117)および[#30565](https://github.com/ClickHouse/ClickHouse/pull/30565）を参照）。そのため、バッファテーブルを削除してから再作成することが唯一のオプションです。バッファテーブルのALTERを実行する前に、このエラーが修正されていることを確認してください。
:::

サーバーが異常に再起動されると、バッファ内のデータは失われます。

`FINAL`および`SAMPLE`はバッファテーブルでは正しく機能しません。これらの条件は宛先テーブルに渡されますが、バッファ内のデータ処理には使用されません。これらの機能が必要な場合は、バッファテーブルには書き込みのみに使用し、宛先テーブルから読み取ることをお勧めします。

バッファテーブルにデータを追加する際、1つのバッファがロックされます。これにより、テーブルからの読み取り操作が同時に行われている場合、遅延が生じます。

バッファテーブルに挿入されたデータは、異なる順序や異なるブロックで従属テーブルに到達する場合があります。そのため、バッファテーブルは CollapsingMergeTree に書き込むための使用が難しいです。問題を避けるために、`num_layers`を1に設定することをお勧めします。

宛先テーブルがレプリケートされている場合、バッファテーブルへの書き込み時にレプリケートテーブルの期待される特性が失われます。行の順序やデータ部分のサイズのランダムな変更により、データの重複排除が機能しなくなり、信頼性のある「一度きり」のレプリケートテーブルへの書き込みが不可能になります。

これらの欠点により、バッファテーブルの使用は稀なケースでの利用を推奨するにとどまります。

バッファテーブルは、単位時間内に大量のサーバーから受信した多くのINSERTに遭遇し、挿入前にデータをバッファリングできない場合に使用されます。つまり、INSERTが十分に高速に実行できないということです。

バッファテーブルに対して、1行ずつデータを挿入することには意味がないことに注意してください。これでは、毎秒数千行の速度しか出ず、大きなデータブロックを挿入することで毎秒100万行を超える速度を出すことができます。
