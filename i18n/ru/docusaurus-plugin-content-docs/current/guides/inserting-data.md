---
title: 'Вставка данных в ClickHouse'
description: 'Как вставить данные в ClickHouse'
keywords: ['вставка', 'вставка данных', 'вставка в таблицу']
sidebar_label: 'Вставка данных в ClickHouse'
slug: /guides/inserting-data
---

import postgres_inserts from '@site/static/images/guides/postgres-inserts.png';
import Image from '@theme/IdealImage';

## Основной пример {#basic-example}

Вы можете использовать хорошо знакомую команду `INSERT INTO TABLE` с ClickHouse. Давайте вставим некоторые данные в таблицу, которую мы создали в начальном руководстве ["Создание таблиц в ClickHouse"](./creating-tables).

```sql
INSERT INTO helloworld.my_first_table (user_id, message, timestamp, metric) VALUES
    (101, 'Hello, ClickHouse!',                                 now(),       -1.0    ),
    (102, 'Insert a lot of rows per batch',                     yesterday(), 1.41421 ),
    (102, 'Sort your data based on your commonly-used queries', today(),     2.718   ),
    (101, 'Granules are the smallest chunks of data read',      now() + 5,   3.14159 )
```

Чтобы убедиться, что это сработало, мы выполним следующий запрос `SELECT`:

```sql
SELECT * FROM helloworld.my_first_table
```

Что возвращает:

```response
user_id message                                             timestamp           metric
101         Hello, ClickHouse!                                  2024-11-13 20:01:22     -1
101         Granules are the smallest chunks of data read           2024-11-13 20:01:27 3.14159
102         Insert a lot of rows per batch                          2024-11-12 00:00:00 1.41421
102         Sort your data based on your commonly-used queries  2024-11-13 00:00:00     2.718
```

## Вставка в ClickHouse против OLTP баз данных {#inserting-into-clickhouse-vs-oltp-databases}

Как OLAP (Online Analytical Processing) база данных, ClickHouse оптимизирован для высокой производительности и масштабируемости, позволяя потенциально вставлять миллионы строк в секунду.
Это достигается за счет сочетания высокопараллелизированной архитектуры и эффективного столбцового сжатия, но с компромиссом на моментальной согласованности.
Конкретнее, ClickHouse оптимизирован для операций только добавления и предлагает только гарантии конечной согласованности.

В отличие от этого, OLTP базы данных, такие как Postgres, специально оптимизированы для транзакционных вставок с полной совместимостью ACID, обеспечивая строгие гарантии согласованности и надежности.
PostgreSQL использует MVCC (Multi-Version Concurrency Control) для обработки параллельных транзакций, что включает поддержание нескольких версий данных.
Эти транзакции могут потенциально затрагивать небольшое количество строк за раз, с значительными накладными расходами из-за гарантий надежности, ограничивающими производительность вставки.

Чтобы добиться высокой производительности вставки при сохранении строгих гарантий согласованности, пользователи должны соблюдать простые правила, описанные ниже, при вставке данных в ClickHouse.
Соблюдение этих правил поможет избежать проблем, с которыми пользователи часто сталкиваются в первый раз, используя ClickHouse, и попыток воспроизвести стратегию вставки, которая работает для OLTP баз данных.

## Лучшие практики для вставок {#best-practices-for-inserts}

### Вставляйте большими партиями {#insert-in-large-batch-sizes}

По умолчанию каждая вставка, отправленная в ClickHouse, заставляет ClickHouse немедленно создать часть хранилища, содержащую данные из вставки, вместе с другими метаданными, которые должны быть сохранены.
Поэтому отправка меньшего количества вставок, каждая из которых содержит больше данных, по сравнению с отправкой большего количества вставок, каждая из которых содержит меньше данных, уменьшит количество необходимых записей.
В общем, мы рекомендуем вставлять данные довольно большими партиями, не менее 1,000 строк за раз, а в идеале от 10,000 до 100,000 строк.
(Дополнительные детали [здесь](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse#data-needs-to-be-batched-for-optimal-performance)).

Если большие партии невозможны, используйте асинхронные вставки, описанные ниже.

### Обеспечьте согласованные партии для идемпотентных повторов {#ensure-consistent-batches-for-idempotent-retries}

По умолчанию вставки в ClickHouse являются синхронными и идемпотентными (т.е. выполнение той же операции вставки несколько раз имеет тот же эффект, что и выполнение ее один раз).
Для таблиц семейства движка MergeTree ClickHouse, по умолчанию, автоматически [дедуплицирует вставки](https://clickhouse.com/blog/common-getting-started-issues-with-clickhouse#5-deduplication-at-insert-time).

Это означает, что вставки остаются устойчивыми в следующих случаях:

- 1. Если узел, получающий данные, имеет проблемы, запрос вставки завершится с таймаутом (или выдаст более конкретную ошибку) и не получит подтверждение.
- 2. Если данные были записаны узлом, но подтверждение не может быть возвращено отправителю запроса из-за сетевых перебоев, отправитель либо получит таймаут, либо сетевую ошибку.

С точки зрения клиента (i) и (ii) может быть трудно различить. Однако в обоих случаях неподтвержденную вставку можно немедленно повторить.
При условии, что повторный запрос вставки содержит те же данные в том же порядке, ClickHouse автоматически проигнорирует повторный запрос вставки, если (неподтвержденная) оригинальная вставка была успешной.

### Вставляйте в таблицу MergeTree или распределенную таблицу {#insert-to-a-mergetree-table-or-a-distributed-table}

Мы рекомендуем вставлять непосредственно в таблицу MergeTree (или Реплицированную таблицу), распределяя запросы между набором узлов, если данные шардированы, и устанавливая `internal_replication=true`.
Это позволит ClickHouse реплицировать данные на любые доступные репликационные шардирования и гарантирует, что данные будут в конечном итоге согласованными.

Если эта балансировка нагрузки со стороны клиента неудобна, пользователи могут вставлять через [распределенную таблицу](/engines/table-engines/special/distributed), которая затем распределит записи между узлами. Снова рекомендуется установить `internal_replication=true`.
Однако следует отметить, что этот подход имеет немного меньшую производительность, поскольку записи должны быть выполнены локально на узле с распределенной таблицей, а затем отправлены на шардирования.

### Используйте асинхронные вставки для небольших партий {#use-asynchronous-inserts-for-small-batches}

Есть сценарии, когда пакетная обработка на стороне клиента невозможна, например, в случае наблюдения с несколькими сотнями или тысячами одноцелевых агентов, отправляющих логи, метрики, трассировки и т.д.
В этом сценарии транспортировка данных в реальном времени имеет ключевое значение для быстрого выявления проблем и аномалий.
Более того, существует риск всплесков событий в наблюдаемых системах, которые могут потенциально вызвать крупные всплески памяти и связанные с этим проблемы при попытке буферизовать данные наблюдения на стороне клиента.
Если большие партии не могут быть вставлены, пользователи могут делегировать пакетирование ClickHouse, используя [асинхронные вставки](/cloud/bestpractices/asynchronous-inserts).

При включенных асинхронных вставках данные сначала вставляются в буфер, а затем записываются в хранилище базы данных позже в 3 этапа, как показано на диаграмме ниже:

<Image img={postgres_inserts} size="md" alt="Postgres inserts"/>

С включенными асинхронными вставками ClickHouse:

(1) получает запрос вставки асинхронно.
(2) сначала записывает данные запроса в буфер в памяти.
(3) сортирует и записывает данные как часть в хранилище базы данных, только когда происходит следующий сброс буфера.

Перед тем как буфер будет сброшен, данные других асинхронных запросов вставки от того же или других клиентов могут быть собраны в буфере.
Часть, созданная из сброса буфера, потенциально может содержать данные из нескольких асинхронных запросов вставки.
В общем, эти механизмы смещают пакетирование данных с клиентской стороны на серверную (экземпляр ClickHouse).

:::note
Обратите внимание, что данные не могут быть найдены по запросам до их сброса в хранилище базы данных и что сброс буфера настраиваемый.

Полные детали по настройке асинхронных вставок можно найти [здесь](/optimize/asynchronous-inserts#enabling-asynchronous-inserts), с углубленным анализом [здесь](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse).
:::


### Используйте официальные клиенты ClickHouse {#use-official-clickhouse-clients}

ClickHouse имеет клиентов на самых популярных языках программирования.
Они оптимизированы, чтобы гарантировать, что вставки выполняются корректно и нативно поддерживают асинхронные вставки либо напрямую, как например в [Go клиентах](/integrations/go#async-insert), либо косвенно, когда это разрешено в настройках запроса, пользователя или соединения.

Смотрите [Клиенты и драйверы](/interfaces/cli) для получения полного списка доступных клиентов и драйверов ClickHouse.

### Предпочитайте нативный формат {#prefer-the-native-format}

ClickHouse поддерживает множество [форматов ввода](/interfaces/formats) при вставке (и запросе).
Это значительное отличие от OLTP баз данных и упрощает загрузку данных из внешних источников - особенно в сочетании с [табличными функциями](/sql-reference/table-functions) и возможностью загружать данные из файлов на диске.
Эти форматы идеальны для выполнения загрузки данных "ad hoc" и для задач по обработке данных.

Для приложений, стремящихся достичь оптимальной производительности вставки, пользователи должны вставлять, используя [Нативный](/interfaces/formats/Native) формат.
Это поддерживается большинством клиентов (таких как Go и Python) и гарантирует, что серверу нужно выполнить минимальное количество работы, поскольку этот формат уже является столбцовым.
Таким образом, ответственность за преобразование данных в столбцовый формат ложится на клиентскую сторону. Это важно для эффективного масштабирования вставок.

В качестве альтернативы пользователи могут использовать [RowBinary формат](/interfaces/formats/RowBinary) (как используется Java клиентом), если предпочтительнее строковый формат - это, как правило, проще записывать, чем нативный формат.
Это более эффективно с точки зрения сжатия, сетевых накладных расходов и обработки на сервере, чем альтернативные строковые форматы, такие как [JSON](/interfaces/formats/JSON).
Формат [JSONEachRow](/interfaces/formats/JSONEachRow) может быть рассмотрен пользователями с более низкой пропускной способностью записи, стремящимися быстро интегрироваться. Пользователи должны осознавать, что этот формат будет иметь накладные расходы на CPU в ClickHouse для анализа.

### Используйте HTTP интерфейс {#use-the-http-interface}

В отличие от многих традиционных баз данных, ClickHouse поддерживает HTTP интерфейс.
Пользователи могут использовать его как для вставки, так и для запроса данных, используя любой из вышеупомянутых форматов.
Это часто предпочтительнее протокола ClickHouse, так как позволяет легко переключить трафик с помощью балансировщиков нагрузки.
Мы ожидаем небольших различий в производительности вставки с нативным протоколом, который имеет немного меньше накладных расходов.
Существующие клиенты используют любой из этих протоколов (в некоторых случаях оба, например, Go клиент).
Нативный протокол действительно позволяет легко отслеживать прогресс запроса.

Смотрите [HTTP интерфейс](/interfaces/http) для получения дополнительных деталей.

## Загрузка данных из Postgres {#loading-data-from-postgres}

Для загрузки данных из Postgres пользователи могут использовать:

- `PeerDB by ClickHouse`, инструмент ETL, специально разработанный для репликации баз данных PostgreSQL. Это доступно как в:
  - ClickHouse Cloud - доступно через наш [новый коннектор](/integrations/clickpipes/postgres) (Приватный предварительный просмотр) в ClickPipes, нашем управляемом сервисе загрузки. Заинтересованные пользователи [регистрируются здесь](https://clickpipes.peerdb.io/).
  - Самоуправляемый - через [проект с открытым исходным кодом](https://github.com/PeerDB-io/peerdb).
- [Движок таблиц PostgreSQL](/integrations/postgresql#using-the-postgresql-table-engine) для чтения данных напрямую, как показано в предыдущих примерах. Обычно подходит, если пакетная репликация на основе известного временного маркера, например, метки времени, достаточна или если это одноразовая миграция. Этот подход может масштабироваться до десятков миллионов строк. Пользователи, желающие мигрировать большие наборы данных, должны рассмотреть возможность множества запросов, каждый из которых обрабатывает часть данных. Временные таблицы могут использоваться для каждой части перед тем, как их партиции будут перемещены в финальную таблицу. Это позволяет повторно пытаться обработать неудачные запросы. Для получения дополнительных деталей о этой стратегии массовой загрузки смотрите здесь.
- Данные можно экспортировать из PostgreSQL в формате CSV. Эти данные затем могут быть вставлены в ClickHouse как из локальных файлов, так и через объектное хранилище с помощью табличных функций.

:::note Нужна помощь с вставкой больших наборов данных?
Если вам нужна помощь с вставкой больших наборов данных или вы столкнулись с какими-либо ошибками при импорте данных в ClickHouse Cloud, пожалуйста, свяжитесь с нами по адресу support@clickhouse.com, и мы можем помочь.
:::
