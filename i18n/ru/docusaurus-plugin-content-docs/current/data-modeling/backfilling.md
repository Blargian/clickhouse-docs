---
slug: /data-modeling/backfilling
title: 'Заполнение данных'
description: 'Как использовать заполнение больших наборов данных в ClickHouse'
keywords: ['материализованные представления', 'заполнение', 'вставка данных', 'устойчивая загрузка данных']
---

import nullTableMV from '@site/static/images/data-modeling/null_table_mv.png';
import Image from '@theme/IdealImage';

# Заполнение данных

Независимо от того, новый вы пользователь ClickHouse или отвечаете за существующее развертывание, пользователям неизбежно потребуется заполнить таблицы историческими данными. В некоторых случаях это относительно просто, но может усложниться, когда необходимо заполнить материализованные представления. Этот гид документирует некоторые процессы для этой задачи, которые пользователи могут применить к своему кейсу.

:::note
Этот гид предполагает, что пользователи уже знакомы с концепцией [Инкрементных материализованных представлений](/materialized-view/incremental-materialized-view) и [загрузки данных с использованием табличных функций, таких как s3 и gcs](/integrations/s3). Мы также рекомендуем пользователям прочитать наше руководство по [оптимизации производительности вставки из объектного хранилища](/integrations/s3/performance), советы из которого можно применить к вставкам в этом руководстве.
:::
## Пример набора данных {#example-dataset}

На протяжении этого руководства мы используем набор данных PyPI. Каждая строка в этом наборе данных представляет загрузку пакета Python с использованием инструмента, такого как `pip`.

Например, подмножество охватывает один день — `2024-12-17` и доступно публично по адресу `https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/`. Пользователи могут выполнять запросы:

```sql
SELECT count()
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/*.parquet')

┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

1 row in set. Elapsed: 32.726 sec. Processed 2.04 миллиарда строк, 170.05 KB (62.34 миллиона строк/с., 5.20 KB/с.)
Пиковое использование памяти: 239.50 MiB.
```

Полный набор данных для этого бакета содержит более 320 ГБ файлов parquet. В примерах ниже мы намеренно нацелимся на подмножества, используя шаблоны glob.

Мы предполагаем, что пользователь получает поток этих данных, например, из Kafka или объектного хранилища, для данных после этой даты. Схема для этих данных показана ниже:

```sql
DESCRIBE TABLE s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/*.parquet')
FORMAT PrettyCompactNoEscapesMonoBlock
SETTINGS describe_compact_output = 1

┌─name───────────────┬─type────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ timestamp │ Nullable(DateTime64(6))                                                                                                                 │
│ country_code       │ Nullable(String)                                                                                                                        │
│ url │ Nullable(String)                                                                                                                        │
│ project            │ Nullable(String)                                                                                                                        │
│ file │ Tuple(filename Nullable(String), project Nullable(String), version Nullable(String), type Nullable(String))                             │
│ installer          │ Tuple(name Nullable(String), version Nullable(String))                                                                                  │
│ python             │ Nullable(String)                                                                                                                        │
│ implementation     │ Tuple(name Nullable(String), version Nullable(String))                                                                                  │
│ distro             │ Tuple(name Nullable(String), version Nullable(String), id Nullable(String), libc Tuple(lib Nullable(String), version Nullable(String))) │
│ system │ Tuple(name Nullable(String), release Nullable(String))                                                                                  │
│ cpu                │ Nullable(String)                                                                                                                        │
│ openssl_version    │ Nullable(String)                                                                                                                        │
│ setuptools_version │ Nullable(String)                                                                                                                        │
│ rustc_version      │ Nullable(String)                                                                                                                        │
│ tls_protocol       │ Nullable(String)                                                                                                                        │
│ tls_cipher         │ Nullable(String)                                                                                                                        │
└────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

:::note
Полный набор данных PyPI, состоящий из более чем 1 триллиона строк, доступен в нашей публичной демо-среде [clickpy.clickhouse.com](https://clickpy.clickhouse.com). Для получения дополнительных деталей об этом наборе данных, включая то, как демо использует материализованные представления для повышения производительности и как данные пополняются ежедневно, см. [здесь](https://github.com/ClickHouse/clickpy).
:::
## Сценарии заполнения {#backfilling-scenarios}

Заполнение данных обычно требуется, когда поток данных принимается с определенного момента времени. Эти данные вставляются в таблицы ClickHouse с [инкрементными материализованными представлениями](/materialized-view/incremental-materialized-view), которые активируются при вставке блоков. Эти представления могут преобразовывать данные перед вставкой или вычислять агрегаты и отправлять результаты в целевые таблицы для дальнейшего использования в прикладных приложениях.

Мы постараемся охватить следующие сценарии:

1. **Заполнение данных с уже существующим приемом данных** — загружаются новые данные, и исторические данные необходимо заполнить. Эти исторические данные были определены.
2. **Добавление материализованных представлений к существующим таблицам** — необходимо добавить новые материализованные представления к настройке, для которой уже были заполнены исторические данные, и данные уже потоковы.

Мы предполагаем, что данные будут заполнены из объектного хранилища. В любом случае мы стремимся избежать пауз в вставке данных.

Рекомендуем заполнять исторические данные из объектного хранилища. Данные следует экспортировать в Parquet, если это возможно, для оптимальной производительности чтения и сжатия (уменьшение сетевой передачи). Предпочтительный размер файла составляет около 150 МБ, но ClickHouse поддерживает более [70 форматов файлов](/interfaces/formats) и способен обрабатывать файлы любого размера.
## Использование дублирующих таблиц и представлений {#using-duplicate-tables-and-views}

Для всех сценариев мы полагаемся на концепцию "дублирующих таблиц и представлений". Эти таблицы и представления представляют собой копии тех, которые используются для живого потокового данных и позволяют выполнять заполнение в изоляции с простым способом восстановления в случае сбоя. Например, у нас есть основная таблица `pypi` и материализованное представление, которое вычисляет количество загрузок по проекту Python:

```sql
CREATE TABLE pypi
(
    `timestamp` DateTime,
    `country_code` LowCardinality(String),
    `project` String,
    `type` LowCardinality(String),
    `installer` LowCardinality(String),
    `python_minor` LowCardinality(String),
    `system` LowCardinality(String),
    `on` String
)
ENGINE = MergeTree
ORDER BY (project, timestamp)

CREATE TABLE pypi_downloads
(
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY project

CREATE MATERIALIZED VIEW pypi_downloads_mv TO pypi_downloads
AS SELECT
 project,
    count() AS count
FROM pypi
GROUP BY project
```

Мы заполняем основную таблицу и сопутствующее представление подмножеством данных:

```sql
INSERT INTO pypi SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{000..100}.parquet')

0 rows in set. Elapsed: 15.702 sec. Processed 41.23 million rows, 3.94 GB (2.63 миллиона строк/с., 251.01 MB/с.)
Пиковое использование памяти: 977.49 MiB.

SELECT count() FROM pypi

┌──count()─┐
│ 20612750 │ -- 20.61 миллиона
└──────────┘

1 row in set. Elapsed: 0.004 sec.

SELECT sum(count)
FROM pypi_downloads


┌─sum(count)─┐
│   20612750 │ -- 20.61 миллиона
└────────────┘

1 row in set. Elapsed: 0.006 sec. Processed 96.15 тысяч строк, 769.23 KB (16.53 миллиона строк/с., 132.26 MB/с.)
Пиковое использование памяти: 682.38 KiB.
```

Предположим, мы хотим загрузить другое подмножество `{101..200}`. Хотя мы могли бы вставить напрямую в `pypi`, мы можем выполнить это заполнение в изоляции, создав дублирующие таблицы.

Если заполнение потерпит неудачу, это не повлияет на наши основные таблицы, и мы просто можем [усечь](/managing-data/truncate) наши дубликаты и повторить.

Чтобы создать новые копии этих представлений, мы можем использовать `CREATE TABLE AS` с суффиксом `_v2`:

```sql
CREATE TABLE pypi_v2 AS pypi

CREATE TABLE pypi_downloads_v2 AS pypi_downloads

CREATE MATERIALIZED VIEW pypi_downloads_mv_v2 TO pypi_downloads_v2
AS SELECT
 project,
    count() AS count
FROM pypi_v2
GROUP BY project
```

Мы заполняем это нашим 2-м подмножеством примерно того же размера и подтверждаем успешную загрузку.

```sql
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{101..200}.parquet')

0 rows in set. Elapsed: 17.545 sec. Processed 40.80 million rows, 3.90 GB (2.33 миллиона строк/с., 222.29 MB/с.)
Пиковое использование памяти: 991.50 MiB.

SELECT count()
FROM pypi_v2

┌──count()─┐
│ 20400020 │ -- 20.40 миллиона
└──────────┘

1 row in set. Elapsed: 0.004 sec.

SELECT sum(count)
FROM pypi_downloads_v2

┌─sum(count)─┐
│   20400020 │ -- 20.40 миллиона
└────────────┘

1 row in set. Elapsed: 0.006 sec. Processed 95.49 тысяч строк, 763.90 KB (14.81 миллиона строк/с., 118.45 MB/с.)
Пиковое использование памяти: 688.77 KiB.
```

Если мы ощутим сбой в любой момент в течение этой второй загрузки, мы можем просто [усечь](/managing-data/truncate) `pypi_v2` и `pypi_downloads_v2` и повторить загрузку данных.

С завершением загрузки данных мы можем переместить данные из наших дублирующих таблиц в основные таблицы, используя [`ALTER TABLE MOVE PARTITION`](/sql-reference/statements/alter/partition#move-partition-to-table) оператор.

```sql
ALTER TABLE pypi
 (MOVE PARTITION () FROM pypi_v2)

0 rows in set. Elapsed: 1.401 sec.

ALTER TABLE pypi_downloads
 (MOVE PARTITION () FROM pypi_downloads_v2)

0 rows in set. Elapsed: 0.389 sec.
```

:::note Имена разделов
Вышеуказанный вызов `MOVE PARTITION` использует имя раздела `()`. Это представляет единый раздел для этой таблицы (которая не разделена). Для таблиц, которые разделены, пользователям придется вызвать несколько `MOVE PARTITION` вызовов — по одному для каждого раздела. Имя текущих разделов можно определить из таблицы [`system.parts`](/operations/system-tables/parts), например, `SELECT DISTINCT partition FROM system.parts WHERE (table = 'pypi_v2')`.
:::

Теперь мы можем подтвердить, что `pypi` и `pypi_downloads` содержат полные данные. `pypi_downloads_v2` и `pypi_v2` можно безопасно удалить.

```sql
SELECT count()
FROM pypi

┌──count()─┐
│ 41012770 │ -- 41.01 миллиона
└──────────┘

1 row in set. Elapsed: 0.003 sec.

SELECT sum(count)
FROM pypi_downloads

┌─sum(count)─┐
│   41012770 │ -- 41.01 миллиона
└────────────┘

1 row in set. Elapsed: 0.007 sec. Processed 191.64 тысяч строк, 1.53 MB (27.34 миллиона строк/с., 218.74 MB/с.)

SELECT count()
FROM pypi_v2
```

Важно отметить, что операция `MOVE PARTITION` является легковесной (используя жесткие ссылки) и атомарной, т.е. она либо завершается неудачей, либо успехом без промежуточного состояния.

Мы активно используем этот процесс в наших сценариях заполнения ниже.

Обратите внимание, как этот процесс требует от пользователей выбирать размер каждой операции вставки.

Более крупные вставки, т.е. больше строк, будут означать меньшее количество `MOVE PARTITION` операций. Однако это должно быть сбалансировано с затратами в случае сбоя вставки, например, из-за прерывания сети, для восстановления. Пользователи могут дополнить этот процесс пакетированием файлов, чтобы снизить риск. Это можно выполнить любым из запросов диапазона, например, `WHERE timestamp BETWEEN 2024-12-17 09:00:00 AND 2024-12-17 10:00:00`, или используя шаблоны glob. Например,

```sql
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{101..200}.parquet')
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{201..300}.parquet')
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{301..400}.parquet')
-- продолжая до полной загрузки файлов ИЛИ выполнение вызова MOVE PARTITION
```

:::note
ClickPipes использует этот подход при загрузке данных из объектного хранилища, автоматически создавая дубликаты целевой таблицы и ее материализованных представлений и избегая необходимости пользователю выполнять вышеуказанные шаги. Также используя несколько рабочих потоков, каждый из которых обрабатывает разные подмножества (через шаблоны glob) и имеет свои дублирующие таблицы, данные могут загружаться быстро с семантикой exactly-once. Для тех, кто интересуется, дополнительные подробности можно найти [в этом блоге](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part3).
:::
## Сценарий 1: Заполнение данных с уже существующим приемом данных {#scenario-1-backfilling-data-with-existing-data-ingestion}

В этом сценарии мы предполагаем, что данные для заполнения находятся не в изолированном бакете и, следовательно, требуется фильтрация. Данные уже вставляются, и можно идентифицировать временную метку или монотонно увеличивающийся столбец, из которого необходимо заполнить исторические данные.

Этот процесс включает следующие шаги:

1. Определите контрольную точку — либо временную метку, либо значение столбца, с которого необходимо восстановить исторические данные.
2. Создайте дубликаты основной таблицы и целевых таблиц для материализованных представлений.
3. Создайте копии любых материализованных представлений, указывающих на целевые таблицы, созданные на шаге (2).
4. Вставьте в нашу дублирующую таблицу, созданную на шаге (2).
5. Переместите все разделы из дублирующих таблиц в их оригинальные версии. Удалите дублирующие таблицы.

Например, в наших данных PyPI предположим, что у нас уже есть загруженные данные. Мы можем определить минимальную временную метку, и, следовательно, нашу "контрольную точку".

```sql
SELECT min(timestamp)
FROM pypi

┌──────min(timestamp)─┐
│ 2024-12-17 09:00:00 │
└─────────────────────┘

1 row in set. Elapsed: 0.163 sec. Processed 1.34 миллиарда строк, 5.37 GB (8.24 миллиарда строк/с., 32.96 GB/с.)
Пиковое использование памяти: 227.84 MiB.
```

Из вышеизложенного мы знаем, что нам нужно загрузить данные до `2024-12-17 09:00:00`. Используя наш предыдущий процесс, мы создаем дублирующие таблицы и представления и загружаем подмножество, используя фильтр по временной метке.

```sql
CREATE TABLE pypi_v2 AS pypi

CREATE TABLE pypi_downloads_v2 AS pypi_downloads

CREATE MATERIALIZED VIEW pypi_downloads_mv_v2 TO pypi_downloads_v2
AS SELECT project, count() AS count
FROM pypi_v2
GROUP BY project

INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-*.parquet')
WHERE timestamp < '2024-12-17 09:00:00'

0 rows in set. Elapsed: 500.152 sec. Processed 2.74 миллиарда строк, 364.40 GB (5.47 миллионов строк/с., 728.59 MB/с.)
```
:::note
Фильтрация по временным меткам в Parquet может быть очень эффективной. ClickHouse будет читать только столбец временной метки, чтобы определить полные диапазоны данных для загрузки, минимизируя сетевой трафик. Индексы Parquet, такие как min-max, также могут быть использованы движком запросов ClickHouse.
:::

Как только эта вставка завершится, мы сможем переместить соответствующие разделы.

```sql
ALTER TABLE pypi
 (MOVE PARTITION () FROM pypi_v2)

ALTER TABLE pypi_downloads
 (MOVE PARTITION () FROM pypi_downloads_v2)
```

Если исторические данные находятся в изолированном бакете, вышеуказанный временной фильтр не требуется. Если временная или монотонная колонка недоступна, изолируйте свои исторические данные.

:::note Просто используйте ClickPipes в ClickHouse Cloud
Пользователям ClickHouse Cloud следует использовать ClickPipes для восстановления исторических резервных копий, если данные могут быть изолированы в собственном бакете (и фильтр не требуется). Параллелизуя загрузку с помощью нескольких рабочих, что уменьшает время загрузки, ClickPipes автоматизирует вышеуказанный процесс — создавая дублирующие таблицы как для основной таблицы, так и для материализованных представлений.
:::
## Сценарий 2: Добавление материализованных представлений к существующим таблицам {#scenario-2-adding-materialized-views-to-existing-tables}

Не uncommon, что новые материализованные представления необходимо добавлять к настройке, для которой уже были заполнены значительные данные и данные вставляются. Временная метка или монотонно увеличивающийся столбец, который можно использовать для идентификации точки в потоке, полезны здесь и позволяют избежать пауз в приеме данных. В примерах ниже мы предполагаем оба случая, предпочитая подходы, которые избегают пауз в вставке.

:::note Избегайте POPULATE
Мы не рекомендуем использовать команду [`POPULATE`](/sql-reference/statements/create/view#materialized-view) для заполнения материализованных представлений для чего-либо, кроме небольших наборов данных, когда прием приостанавливается. Этот оператор может пропустить строки, вставленные в исходную таблицу, с материализованным представлением, созданным после того, как заполнение хеш завершено. Кроме того, это заполнение выполняется по всем данным и подвержено прерыванию или ограничениям памяти для больших наборов данных.
:::
### Доступна временная метка или монотонно увеличивающийся столбец {#timestamp-or-monotonically-increasing-column-available}

В этом случае мы рекомендуем, чтобы новое материализованное представление включало фильтр, который ограничивает строки теми, которые превышают произвольные данные в будущем. Затем материализованное представление может быть заполнено с этой даты с использованием исторических данных из основной таблицы. Подход к заполнению зависит от размера данных и сложности связанного запроса.

Наш самый простой подход включает следующие шаги:

1. Создайте наше материализованное представление с фильтром, который учитывает только строки, превышающие произвольное время в ближайшем будущем.
2. Выполните запрос `INSERT INTO SELECT`, который вставляет в целевую таблицу нашего материализованного представления, считывая из исходной таблицы с агрегирующим запросом представления.

Это можно дополнительно улучшить, нацелившись на подмножества данных на этапе (2) и/или использовать дублирующую целевую таблицу для материализованного представления (присоедините разделы к оригиналу, как только вставка завершится) для упрощения восстановления после сбоя.

Рассмотрим следующее материализованное представление, которое вычисляет самые популярные проекты за час.

```sql
CREATE TABLE pypi_downloads_per_day
(
    `hour` DateTime,
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY (project, hour)


CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi
GROUP BY
    hour,
 project
```

Хотя мы можем добавить целевую таблицу, перед добавлением материализованного представления мы изменяем его `SELECT` предложение, чтобы включить фильтр, который учитывает только строки, превышающие произвольное время в ближайшем будущем — в этом случае мы предполагаем, что `2024-12-17 09:00:00` является ближайшим будущем.

```sql
CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project, count() AS count
FROM pypi WHERE timestamp >= '2024-12-17 09:00:00'
GROUP BY hour, project
```

Как только этот вид добавлен, мы можем заполнить все данные для материализованного представления до этой даты.

Простейший способ сделать это — просто выполнить запрос из материализованного представления на основной таблице с фильтром, который игнорирует недавно добавленные данные, вставляя результаты в целевую таблицу нашего представления через `INSERT INTO SELECT`. Например, для вышеуказанного представления:

```sql
INSERT INTO pypi_downloads_per_day SELECT
 toStartOfHour(timestamp) AS hour,
 project,
    count() AS count
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
GROUP BY
    hour,
 project

Ok.

0 rows in set. Elapsed: 2.830 sec. Processed 798.89 миллионов строк, 17.40 GB (282.28 миллиона строк/с., 6.15 GB/с.)
Пиковое использование памяти: 543.71 MiB.
```

:::note
В вышеуказанном примере наша целевая таблица является [SummingMergeTree](/engines/table-engines/mergetree-family/summingmergetree). В этом случае мы можем просто использовать наш оригинальный агрегирующий запрос. Для более сложных случаев использования, которые используют [AggregatingMergeTree](/engines/table-engines/mergetree-family/aggregatingmergetree), пользователи будут использовать функции `-State` для агрегатов. Пример этого можно найти [здесь](/integrations/s3/performance#be-aware-of-merges).
:::

В нашем случае это относительно легковесная агрегация, которая завершается менее чем за 3 секунды и использует менее 600MiB памяти. Для более сложных или долгосрочных агрегаций пользователи могут сделать этот процесс более устойчивым, используя ранее упомянутый подход с дублирующей таблицей, т.е. создайте целевую дублирующую таблицу, например `pypi_downloads_per_day_v2`, вставьте в нее и затем прикрепите получившиеся разделы к `pypi_downloads_per_day`.

Часто запрос материализованного представления может быть более сложным (что не редкость, иначе пользователи не стали бы использовать представления!) и потреблять ресурсы. В редких случаях ресурсы для запроса превышают возможности сервера. Это подчеркивает одно из преимуществ материализованных представлений ClickHouse — они инкрементальны и не обрабатывают весь набор данных за один раз!

В этом случае у пользователей есть несколько вариантов:

1. Измените ваш запрос для заполнения диапазонов, например, `WHERE timestamp BETWEEN 2024-12-17 08:00:00 AND 2024-12-17 09:00:00`, `WHERE timestamp BETWEEN 2024-12-17 07:00:00 AND 2024-12-17 08:00:00` и т.д.
2. Используйте [движок таблицы Null](/engines/table-engines/special/null) для заполнения материализованного представления. Это воспроизводит типичную инкрементальную подпитку материализованного представления, выполняя его запрос по блокам данных (конфигурируемого размера).

(1) представляет собой самый простой подход и часто является достаточным. Мы не включаем примеры для краткости.

Мы исследуем (2) более подробно ниже.
#### Использование движка таблицы Null для заполнения материализованных представлений {#using-a-null-table-engine-for-filling-materialized-views}

[Движок таблицы Null](/engines/table-engines/special/null) предоставляет движок хранения, который не сохраняет данные (думайте о нем как о `/dev/null` в мире движков таблиц). Хотя это кажется противоречивым, материализованные представления все равно выполняются на данных, вставленных в этот движок таблицы. Это позволяет строить материализованные представления, не сохраняя оригинальные данные, избегая ввода-вывода и сопутствующего хранения.

Важно, что любые материализованные представления, прикрепленные к движку таблицы, все равно выполняются по блокам данных, по мере их вставки — отправляя свои результаты в целевую таблицу. Эти блоки имеют конфигурируемый размер. Хотя более крупные блоки могут быть потенциально более эффективными (и быстрее в Processing), они расходуют больше ресурсов (прежде всего памяти). Использование этого движка таблицы означает, что мы можем создавать наше материализованное представление инкрементально, т.е. по одному блоку за раз, избегая необходимости удерживать всю агрегацию в памяти.

<Image img={nullTableMV} size="md" alt="Денормализация в ClickHouse"/>

<br />

Рассмотрим следующий пример:

```sql
CREATE TABLE pypi_v2
(
    `timestamp` DateTime,
    `project` String
)
ENGINE = Null

CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv_v2 TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi_v2
GROUP BY
    hour,
 project
```

Здесь мы создаем таблицу Null, `pypi_v2`, чтобы получать строки, которые будут использоваться для построения нашего материализованного представления. Обратите внимание, как мы ограничиваем схему только необходимыми столбцами. Наше материализованное представление выполняет агрегацию по строкам, вставленным в эту таблицу (по одному блоку за раз), отправляя результаты в нашу целевую таблицу `pypi_downloads_per_day`.

:::note
Мы использовали `pypi_downloads_per_day` как нашу целевую таблицу здесь. Для дополнительной устойчивости пользователи могут создать дублирующую таблицу, `pypi_downloads_per_day_v2`, и использовать ее как целевую таблицу представления, как показано в предыдущих примерах. По завершении вставки разделы в `pypi_downloads_per_day_v2` могут, в свою очередь, быть перемещены в `pypi_downloads_per_day.` Это позволит восстановить данные в случае, если наша вставка завершится неудачей из-за проблем памяти или сбоев сервера, т.е. мы просто усечем `pypi_downloads_per_day_v2`, настроим параметры и попробуем снова.
:::

Чтобы заполнить это материализованное представление, мы просто вставляем соответствующие данные для заполнения в `pypi_v2` из `pypi.`

```sql
INSERT INTO pypi_v2 SELECT timestamp, project FROM pypi WHERE timestamp < '2024-12-17 09:00:00'

0 rows in set. Elapsed: 27.325 sec. Processed 1.50 миллиарда строк, 33.48 GB (54.73 миллиона строк/с., 1.23 GB/с.)
Пиковое использование памяти: 639.47 MiB.
```

Обратите внимание, что наше использование памяти здесь составляет `639.47 MiB`.
##### Настройка производительности и ресурсов {#tuning-performance--resources}

Несколько факторов определят производительность и ресурсы, использованные в вышеупомянутом сценарии. Прежде чем пытаться настроить, мы рекомендуем читателям ознакомиться с механикой вставки, документированной подробно в разделе [Использование потоков для чтения](/integrations/s3/performance#using-threads-for-reads) руководства [Оптимизация для вставки и чтения в S3](/integrations/s3/performance). В кратком изложении:

- **Параллелизм чтения** — количество потоков, используемых для чтения. Контролируется через [`max_threads`](/operations/settings/settings#max_threads). В ClickHouse Cloud это определяется размером экземпляра, по умолчанию равным количеству vCPU. Увеличение этого значения может улучшить производительность чтения за счет большего использования памяти.
- **Параллелизм вставки** — количество потоков вставки, используемых для вставки. Контролируется через [`max_insert_threads`](/operations/settings/settings#max_insert_threads). В ClickHouse Cloud это определяется размером экземпляра (от 2 до 4) и устанавливается на 1 в OSS. Увеличение этого значения может улучшить производительность за счет большего использования памяти.
- **Размер блока вставки** — данные обрабатываются в цикле, где они извлекаются, разбираются и формируются в блоки вставки в памяти на основе [ключа разбиения](/engines/table-engines/mergetree-family/custom-partitioning-key). Эти блоки сортируются, оптимизируются, сжимаются и записываются в хранилище как новые [части данных](/parts). Размер блока вставки, контролируемый настройками [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) и [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes) (несжатый), влияет на использование памяти и ввод-вывод диска. Более крупные блоки используют больше памяти, но создают меньше частей, уменьшая ввод-вывод и фоновое слияние. Эти настройки представляют собой минимальные пороговые значения (первое, которое будет достигнуто, вызовет сброс).
- **Размер блока материализованного представления** — кроме механики для основной вставки, перед вставкой в материализованные представления блоки также упаковываются для более эффективной обработки. Размер этих блоков определяется настройками [`min_insert_block_size_bytes_for_materialized_views`](/operations/settings/settings#min_insert_block_size_bytes_for_materialized_views) и [`min_insert_block_size_rows_for_materialized_views`](/operations/settings/settings#min_insert_block_size_rows_for_materialized_views). Более крупные блоки позволяют более эффективную обработку за счет большего использования памяти. По умолчанию эти настройки возвращаются к значениям настроек исходной таблицы [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) и [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes), соответственно.

Для улучшения производительности пользователи могут следовать рекомендациям, изложенным в разделе [Настройка потоков и размера блока для вставок](/integrations/s3/performance#tuning-threads-and-block-size-for-inserts) руководства [Оптимизация для вставки и чтения в S3](/integrations/s3/performance). В большинстве случаев не должно быть необходимости изменить также `min_insert_block_size_bytes_for_materialized_views` и `min_insert_block_size_rows_for_materialized_views`, чтобы улучшить производительность. Если они изменяются, используйте те же лучшие практики, как описано для `min_insert_block_size_rows` и `min_insert_block_size_bytes`.

Чтобы минимизировать использование памяти, пользователи могут попробовать поэкспериментировать с этими настройками. Это неизбежно снизит производительность. Используя ранее указанный запрос, мы показываем ниже примеры.

Уменьшение `max_insert_threads` до 1 снижает нашу нагрузку на память.

```sql
INSERT INTO pypi_v2
SELECT
    timestamp,
 project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1

0 rows in set. Elapsed: 27.752 sec. Processed 1.50 миллиарда строк, 33.48 GB (53.89 миллиона строк/с., 1.21 GB/с.)
Пиковое использование памяти: 506.78 MiB.
```

Мы можем еще больше снизить память, установив настройку `max_threads` на 1.

```sql
INSERT INTO pypi_v2
SELECT timestamp, project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1, max_threads = 1

Ok.

0 rows in set. Elapsed: 43.907 sec. Processed 1.50 миллиарда строк, 33.48 GB (34.06 миллиона строк/с., 762.54 MB/с.)
Пиковое использование памяти: 272.53 MiB.
```

Наконец, мы можем еще больше снизить память, установив `min_insert_block_size_rows` на 0 (отключает его как фактор принятия решения по размеру блока) и `min_insert_block_size_bytes` на 10485760 (10MiB).

```sql
INSERT INTO pypi_v2
SELECT
    timestamp,
 project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1, max_threads = 1, min_insert_block_size_rows = 0, min_insert_block_size_bytes = 10485760

0 rows in set. Elapsed: 43.293 sec. Processed 1.50 миллиарда строк, 33.48 GB (34.54 миллиона строк/с., 773.36 MB/с.)
Пиковое использование памяти: 218.64 MiB.
```

Наконец, обратите внимание, что снижение размеров блока создает больше частей и вызывает большее давление на слияние. Как обсуждалось [здесь](/integrations/s3/performance#be-aware-of-merges), эти настройки следует изменять осторожно.
### Нет временной метки или монотонно увеличивающегося столбца {#no-timestamp-or-monotonically-increasing-column}

При вышеуказанных процессах от пользователей требуется наличие временной метки или монотонно увеличивающегося столбца. В некоторых случаях это просто недоступно. В этом случае мы рекомендуем следующий процесс, который использует многие из шагов, описанных ранее, но требует от пользователей приостановить прием данных.

1. Приостановите вставки в вашу основную таблицу.
2. Создайте дубликат вашей целевой таблицы с помощью синтаксиса `CREATE AS`.
3. Присоедините разделы из оригинальной целевой таблицы к дубликату с помощью [`ALTER TABLE ATTACH`](/sql-reference/statements/alter/partition#attach-partitionpart). **Примечание:** Эта операция присоединения отличается от ранее использованного перемещения. Используя жесткие ссылки, данные в оригинальной таблице сохраняются.
4. Создайте новые материализованные представления.
5. Перезапустите вставки. **Примечание:** Вставки будут обновлять только целевую таблицу, а не дубликат, который будет ссылаться только на оригинальные данные.
6. Заполните материализованное представление, применяя тот же процесс, что и выше для данных с временными метками, используя дубликат таблицы в качестве источника.

Рассмотрим следующий пример с использованием PyPI и нашим предыдущим новым материализованным представлением `pypi_downloads_per_day` (предположим, что мы не можем использовать временную метку):

```sql
SELECT count() FROM pypi

┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

1 row in set. Elapsed: 0.003 sec.

-- (1) Приостановите вставки
-- (2) Создайте дубликат нашей целевой таблицы

CREATE TABLE pypi_v2 AS pypi

SELECT count() FROM pypi_v2

┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

1 row in set. Elapsed: 0.004 sec.

-- (3) Присоедините разделы из оригинальной целевой таблицы к дубликату.

ALTER TABLE pypi_v2
 (ATTACH PARTITION tuple() FROM pypi)

-- (4) Создайте наши новые материализованные представления

CREATE TABLE pypi_downloads_per_day
(
    `hour` DateTime,
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY (project, hour)


CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi
GROUP BY
    hour,
 project

-- (4) Перезапустите вставки. Мы воспроизводим здесь вставку одной строки.

INSERT INTO pypi SELECT *
FROM pypi
LIMIT 1

SELECT count() FROM pypi

┌────count()─┐
│ 2039988138 │ -- 2.04 миллиарда
└────────────┘

1 row in set. Elapsed: 0.003 sec.

-- обратите внимание, что pypi_v2 содержит то же количество строк, что и раньше

SELECT count() FROM pypi_v2
┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

-- (5) Заполните представление, используя резервную копию pypi_v2

INSERT INTO pypi_downloads_per_day SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi_v2
GROUP BY
    hour,
 project

0 rows in set. Elapsed: 3.719 sec. Processed 2.04 миллиарда строк, 47.15 GB (548.57 миллионов строк/с., 12.68 GB/с.)

DROP TABLE pypi_v2;
```

На предпоследнем шаге мы заполняем `pypi_downloads_per_day` с использованием нашего простого подхода `INSERT INTO SELECT`, описанного [ранее](#timestamp-or-monotonically-increasing-column-available). Это также может быть улучшено с использованием подхода с Null таблицей, документированным [выше](#using-a-null-table-engine-for-filling-materialized-views), с дополнительным использованием дубликатной таблицы для большей устойчивости.

Хотя эта операция требует приостановки вставок, промежуточные операции могут обычно быть выполнены быстро, минимизируя любые перерывы в данных.
