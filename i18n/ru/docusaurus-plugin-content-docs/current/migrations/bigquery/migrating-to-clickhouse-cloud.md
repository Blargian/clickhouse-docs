---
title: 'Миграция с BigQuery на ClickHouse Cloud'
slug: /migrations/bigquery/migrating-to-clickhouse-cloud
description: 'Как мигрировать ваши данные с BigQuery на ClickHouse Cloud'
keywords: ['миграция', 'миграция', 'перемещение', 'данные', 'etl', 'elt', 'BigQuery']
---

import bigquery_2 from '@site/static/images/migrations/bigquery-2.png';
import bigquery_3 from '@site/static/images/migrations/bigquery-3.png';
import bigquery_4 from '@site/static/images/migrations/bigquery-4.png';
import bigquery_5 from '@site/static/images/migrations/bigquery-5.png';
import bigquery_6 from '@site/static/images/migrations/bigquery-6.png';
import bigquery_7 from '@site/static/images/migrations/bigquery-7.png';
import bigquery_8 from '@site/static/images/migrations/bigquery-8.png';
import bigquery_9 from '@site/static/images/migrations/bigquery-9.png';
import bigquery_10 from '@site/static/images/migrations/bigquery-10.png';
import bigquery_11 from '@site/static/images/migrations/bigquery-11.png';
import bigquery_12 from '@site/static/images/migrations/bigquery-12.png';
import Image from '@theme/IdealImage';

## Почему стоит использовать ClickHouse Cloud вместо BigQuery? {#why-use-clickhouse-cloud-over-bigquery}

TLDR: Потому что ClickHouse быстрее, дешевле и мощнее, чем BigQuery для современной аналитики данных:

<Image img={bigquery_2} size="md" alt="ClickHouse vs BigQuery"/>
## Загрузка данных из BigQuery в ClickHouse Cloud {#loading-data-from-bigquery-to-clickhouse-cloud}
### Набор данных {#dataset}

В качестве примера набора данных, показывающего типичную миграцию из BigQuery в ClickHouse Cloud, мы используем набор данных Stack Overflow, документированный [здесь](/getting-started/example-datasets/stackoverflow). Он содержит каждое `post`, `vote`, `user`, `comment` и `badge`, которые произошли на Stack Overflow с 2008 года по апрель 2024 года. Схема BigQuery для этих данных показана ниже:

<Image img={bigquery_3} size="lg" alt="Схема"/>

Для пользователей, которые хотят заполнить этот набор данных в экземпляре BigQuery для тестирования шагов миграции, мы предоставили данные для этих таблиц в формате Parquet в GCS-директории, а команды DDL для создания и загрузки таблиц в BigQuery доступны [здесь](https://pastila.nl/?003fd86b/2b93b1a2302cfee5ef79fd374e73f431#hVPC52YDsUfXg2eTLrBdbA==).
### Миграция данных {#migrating-data}

Миграция данных между BigQuery и ClickHouse Cloud делится на два основных типа рабочих нагрузок:

- **Начальная массовая загрузка с периодическими обновлениями** - Необходимо мигрировать исходный набор данных вместе с периодическими обновлениями через заданные интервалы, например, ежедневно. Обновления обрабатываются путем повторной отправки строк, которые были изменены, определяемых по колонке, которая может быть использована для сравнений (например, по дате). Удаления обрабатываются с помощью полной периодической перезагрузки набора данных.
- **Репликация в реальном времени или CDC** - Необходимо мигрировать начальный набор данных. Изменения в этом наборе данных должны отображаться в ClickHouse в режиме близком к реальному времени с допустимой задержкой в несколько секунд. Это фактически [процесс захвата изменений данных (CDC)](https://en.wikipedia.org/wiki/Change_data_capture), при котором таблицы в BigQuery должны синхронизироваться с ClickHouse, то есть вставки, обновления и удаления в таблице BigQuery должны применяться к эквивалентной таблице в ClickHouse.
#### Массовая загрузка через Google Cloud Storage (GCS) {#bulk-loading-via-google-cloud-storage-gcs}

BigQuery поддерживает экспорт данных в объектное хранилище Google (GCS). Для нашего примера набора данных:

1. Экспортируйте 7 таблиц в GCS. Команды для этого доступны [здесь](https://pastila.nl/?014e1ae9/cb9b07d89e9bb2c56954102fd0c37abd#0Pzj52uPYeu1jG35nmMqRQ==).

2. Импортируйте данные в ClickHouse Cloud. Для этого мы можем использовать [gcs табличную функцию](/sql-reference/table-functions/gcs). Команды DDL и запросы на импорт доступны [здесь](https://pastila.nl/?00531abf/f055a61cc96b1ba1383d618721059976#Wf4Tn43D3VCU5Hx7tbf1Qw==). Обратите внимание, что поскольку экземпляр ClickHouse Cloud состоит из нескольких вычислительных узлов, вместо функции `gcs` мы используем [s3Cluster табличную функцию](/sql-reference/table-functions/s3Cluster). Эта функция также работает с GCS-бакетами и [использует все узлы сервиса ClickHouse Cloud](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#parallel-servers) для параллельной загрузки данных.

<Image img={bigquery_4} size="md" alt="Массовая загрузка"/>

Этот подход имеет ряд преимуществ:

- Функциональность экспорта BigQuery поддерживает фильтр для экспорта подмножества данных.
- BigQuery поддерживает экспорт в [Parquet, Avro, JSON и CSV](https://cloud.google.com/bigquery/docs/exporting-data) форматы и несколько [типов сжатия](https://cloud.google.com/bigquery/docs/exporting-data) - все они поддерживаются ClickHouse.
- GCS поддерживает [управление жизненным циклом объектов](https://cloud.google.com/storage/docs/lifecycle), позволяя удалять данные, которые были экспортированы и импортированы в ClickHouse, по истечении заданного периода.
- [Google позволяет бесплатно экспортировать до 50 ТБ в день в GCS](https://cloud.google.com/bigquery/quotas#export_jobs). Пользователи платят только за хранение в GCS.
- Экспорт производит несколько файлов автоматически, ограничивая каждый из них максимум 1 ГБ данных таблицы. Это полезно для ClickHouse, потому что позволяет параллелизовать импорт.

Перед тем как попробовать следующие примеры, мы рекомендуем пользователям просмотреть [требования к разрешениям для экспорта](https://cloud.google.com/bigquery/docs/exporting-data#required_permissions) и [рекомендации по локальности](https://cloud.google.com/bigquery/docs/exporting-data#data-locations), чтобы максимально повысить производительность экспорта и импорта.
### Репликация в реальном времени или CDC через запланированные запросы {#real-time-replication-or-cdc-via-scheduled-queries}

Захват изменений данных (CDC) - это процесс, при котором таблицы синхронизируются между двумя базами данных. Это значительно более сложно, если обновления и удаления должны обрабатываться в режиме близком к реальному времени. Один из подходов заключается в том, чтобы просто запланировать периодический экспорт, используя функциональность [запланированных запросов BigQuery](https://cloud.google.com/bigquery/docs/scheduling-queries). Если вы можете принять некоторую задержку при вставке данных в ClickHouse, этот подход легко реализовать и поддерживать. Пример приводится [в этом блоге](https://clickhouse.com/blog/clickhouse-bigquery-migrating-data-for-realtime-queries#using-scheduled-queries).
## Проектирование схем {#designing-schemas}

Набор данных Stack Overflow содержит ряд связанных таблиц. Мы рекомендуем сосредоточиться на миграции основной таблицы в первую очередь. Это может быть не обязательно самая большая таблица, но скорее та, на которую вы ожидаете получения наибольшего числа аналитических запросов. Это позволит вам ознакомиться с основными концепциями ClickHouse. Эта таблица может потребовать переосмысления, так как будут добавлены дополнительные таблицы, чтобы в полной мере использовать возможности ClickHouse и получить оптимальную производительность. Мы рассматриваем этот процесс моделирования в наших [документах по моделированию данных](/data-modeling/schema-design#next-data-modelling-techniques).

Соблюдая этот принцип, мы сосредотачиваемся на основной таблице `posts`. Схема BigQuery для этой таблицы показана ниже:

```sql
CREATE TABLE stackoverflow.posts (
    id INTEGER,
    posttypeid INTEGER,
    acceptedanswerid STRING,
    creationdate TIMESTAMP,
    score INTEGER,
    viewcount INTEGER,
    body STRING,
    owneruserid INTEGER,
    ownerdisplayname STRING,
    lasteditoruserid STRING,
    lasteditordisplayname STRING,
    lasteditdate TIMESTAMP,
    lastactivitydate TIMESTAMP,
    title STRING,
    tags STRING,
    answercount INTEGER,
    commentcount INTEGER,
    favoritecount INTEGER,
    conentlicense STRING,
    parentid STRING,
    communityowneddate TIMESTAMP,
    closeddate TIMESTAMP
);
```
### Оптимизация типов {#optimizing-types}

Применение процесса [описанного здесь](/data-modeling/schema-design) приводит к следующей схеме:

```sql
CREATE TABLE stackoverflow.posts
(
   `Id` Int32,
   `PostTypeId` Enum('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
   `AcceptedAnswerId` UInt32,
   `CreationDate` DateTime,
   `Score` Int32,
   `ViewCount` UInt32,
   `Body` String,
   `OwnerUserId` Int32,
   `OwnerDisplayName` String,
   `LastEditorUserId` Int32,
   `LastEditorDisplayName` String,
   `LastEditDate` DateTime,
   `LastActivityDate` DateTime,
   `Title` String,
   `Tags` String,
   `AnswerCount` UInt16,
   `CommentCount` UInt8,
   `FavoriteCount` UInt8,
   `ContentLicense` LowCardinality(String),
   `ParentId` String,
   `CommunityOwnedDate` DateTime,
   `ClosedDate` DateTime
)
ENGINE = MergeTree
ORDER BY tuple()
COMMENT 'Оптимизированные типы'
```

Мы можем заполнить эту таблицу с помощью простого [`INSERT INTO SELECT`](/sql-reference/statements/insert-into), считывая экспортированные данные из GCS с использованием [`gcs` табличной функции](/sql-reference/table-functions/gcs). Обратите внимание, что в ClickHouse Cloud вы также можете использовать совместимую с GCS [`s3Cluster` табличную функцию](/sql-reference/table-functions/s3Cluster), чтобы параллелизовать загрузку на нескольких узлах:

```sql
INSERT INTO stackoverflow.posts SELECT * FROM gcs( 'gs://clickhouse-public-datasets/stackoverflow/parquet/posts/*.parquet', NOSIGN);
```

Мы не сохраняем никаких null в нашей новой схеме. Вышеуказанная вставка неявно преобразует их в значения по умолчанию для их соответствующих типов - 0 для целых чисел и пустое значение для строк. ClickHouse также автоматически преобразует любые числовые значения к их целевой точности.
## Каковы отличия первичных ключей ClickHouse? {#how-are-clickhouse-primary-keys-different}

Как описано [здесь](/migrations/bigquery), как и в BigQuery, ClickHouse не требует уникальности для значений столбца первичного ключа таблицы.

Аналогично кластеризации в BigQuery, данные таблицы ClickHouse хранятся на диске в порядке значений первичного ключа. Этот порядок используется оптимизатором запросов для предотвращения повторной сортировки, минимизации использования памяти для соединений и обеспечения короткозамыкания для операторов LIMIT.
В отличие от BigQuery, ClickHouse автоматически создает [с spars'ным первичным индексом](/guides/best-practices/sparse-primary-indexes), основанным на значениях столбца первичного ключа. Этот индекс используется для ускорения всех запросов, которые содержат фильтры по столбцам первичного ключа. В частности:

- Эффективность использования памяти и диска имеет первостепенное значение для масштаба, на котором ClickHouse часто применяется. Данные записываются в таблицы ClickHouse пакетами, известными как части, при этом применяются правила для объединения частей в фоновом режиме. В ClickHouse у каждой части есть свой собственный первичный индекс. Когда части объединяются, первичные индексы объединенных частей также объединяются. Обратите внимание, что эти индексы не строятся для каждой строки. Вместо этого первичный индекс для части имеет одну запись индекса для группы строк - эта техника называется разреженным индексированием.
- Разреженное индексирование возможно, потому что ClickHouse хранит строки для части на диске, упорядоченные по заданному ключу. Вместо того чтобы непосредственно находить отдельные строки (как в индексах на основе B-дерева), разреженный первичный индекс позволяет быстро (через бинарный поиск по записям индекса) определять группы строк, которые могут совпадать с запросом. Найденные группы потенциально совпадающих строк затем, в параллельном режиме, передаются в движок ClickHouse, чтобы найти совпадения. Этот дизайн индекса позволяет сохранять первичный индекс небольшим (он полностью помещается в основную память), при этом значительно ускоряя время выполнения запросов, особенно для диапазонных запросов, которые характерны для аналитики данных. Для получения дополнительных сведений мы рекомендуем [этот подробный гид](/guides/best-practices/sparse-primary-indexes).

<Image img={bigquery_5} size="md" alt="Первичные ключи ClickHouse"/>

Выбранный первичный ключ в ClickHouse будет определять не только индекс, но и порядок, в котором данные записываются на диск. Из-за этого он может существенно повлиять на уровень сжатия, что, в свою очередь, может повлиять на производительность запросов. Ключ упорядочивания, который заставляет значения большинства столбцов записываться в последовательном порядке, позволит выбранному алгоритму сжатия (и кодекам) более эффективно сжимать данные.

> Все столбцы в таблице будут отсортированы в зависимости от значения указанного ключа упорядочивания, независимо от того, включены ли они в сам ключ. Например, если `CreationDate` используется как ключ, порядок значений в остальных столбцах будет соответствовать порядку значений в столбце `CreationDate`. Можно указать несколько ключей упорядочивания - это будет упорядочивать с теми же семантиками, что и оператор `ORDER BY` в запросе `SELECT`.
### Выбор ключа упорядочивания {#choosing-an-ordering-key}

Для рассмотрения и шагов в выборе ключа упорядочивания, используя таблицу posts в качестве примера, смотрите [здесь](/data-modeling/schema-design#choosing-an-ordering-key).
## Техники моделирования данных {#data-modeling-techniques}

Мы рекомендуем пользователям, мигрирующим из BigQuery, прочитать [руководство по моделированию данных в ClickHouse](/data-modeling/schema-design). Этот гид использует тот же набор данных Stack Overflow и исследует несколько подходов с использованием возможностей ClickHouse.
### Разделы {#partitions}

Пользователи BigQuery будут знакомы с концепцией разделения таблиц для повышения производительности и управляемости больших баз данных путем разделения таблиц на более мелкие, более управляемые части, называемые разделами. Это разбиение может быть достигнуто с помощью диапазона по заданному столбцу (например, по датам), определенных списков или по хешу по ключу. Это позволяет администраторам организовывать данные на основе определенных критериев, таких как диапазоны дат или географические местоположения.

Разделение помогает улучшить производительность запросов, позволяя более быстрому доступу к данным через обрезку разделов и более эффективное индексирование. Оно также помогает в таких задачах обслуживания, как резервное копирование и удаление данных, позволяя выполнять операции над отдельными разделами, а не всей таблицей. Кроме того, разбиение может значительно улучшить масштабируемость баз данных BigQuery, распределяя нагрузку по нескольким разделам.

В ClickHouse разделение определяется в таблице при ее первоначальном объявлении с помощью предложений [`PARTITION BY`](/engines/table-engines/mergetree-family/custom-partitioning-key). Это предложение может содержать SQL-выражение по любым столбцам, результаты которого определят, в какой раздел отправляется строка.

<Image img={bigquery_6} size="md" alt="Разделы"/>

Части данных логически связаны с каждым разделом на диске и могут запрашиваться в изоляции. Для примера ниже мы разбиваем таблицу posts по годам, используя выражение [`toYear(CreationDate)`](/sql-reference/functions/date-time-functions#toyear). При вставке строк в ClickHouse это выражение будет оцениваться для каждой строки, после чего строки будут направлены в соответствующий раздел в виде новых частей данных, принадлежащих этому разделу.

```sql
CREATE TABLE posts
(
        `Id` Int32 CODEC(Delta(4), ZSTD(1)),
        `PostTypeId` Enum8('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
        `AcceptedAnswerId` UInt32,
        `CreationDate` DateTime64(3, 'UTC'),
...
        `ClosedDate` DateTime64(3, 'UTC')
)
ENGINE = MergeTree
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate)
PARTITION BY toYear(CreationDate)
```
#### Применения {#applications}

Разделение в ClickHouse имеет аналогичные применения, как и в BigQuery, но с некоторыми тонкими отличиями. В частности:

- **Управление данными** - В ClickHouse пользователи должны в первую очередь рассматривать разделение как функцию управления данными, а не как технику оптимизации запросов. Разделяя данные логически по ключу, каждый раздел может обрабатываться независимо, например, удаляться. Это позволяет пользователям перемещать разделы, а следовательно, подмножества, между [уровнями хранения](/integrations/s3#storage-tiers) эффективно по времени или [истекать данные/эффективно удалять из кластера](/sql-reference/statements/alter/partition). Например, ниже мы удаляем посты 2008 года:

```sql
SELECT DISTINCT partition
FROM system.parts
WHERE `table` = 'posts'

┌─partition─┐
│ 2008      │
│ 2009      │
│ 2010      │
│ 2011      │
│ 2012      │
│ 2013      │
│ 2014      │
│ 2015      │
│ 2016      │
│ 2017      │
│ 2018      │
│ 2019      │
│ 2020      │
│ 2021      │
│ 2022      │
│ 2023      │
│ 2024      │
└───────────┘

17 строк в наборе. Время выполнения: 0.002 сек.

ALTER TABLE posts
(DROP PARTITION '2008')

Ok.

0 строк в наборе. Время выполнения: 0.103 сек.
```

- **Оптимизация запросов** - Хотя разделы могут помочь с производительностью запросов, это зависит от паттернов доступа. Если запросы нацелены только на несколько разделов (в идеале один), производительность может потенциально повыситься. Это обычно полезно только если ключ разбиения не входит в первичный ключ и вы фильтруете по нему. Однако запросы, которые необходимо покрыть множеством разделов, могут работать хуже, чем если бы не использовалось никакое разбиение (так как в результате разбиения может быть больше частей). Преимущество нацеливания на один раздел будет еще менее выражено при использовании ключа разбиения, который уже является ранним элементом первичного ключа. Разделение также может быть использовано для [оптимизации запросов `GROUP BY`](/engines/table-engines/mergetree-family/custom-partitioning-key#group-by-optimisation-using-partition-key), если значения в каждом разделе уникальны. Однако в общем случае пользователи должны уделять внимание оптимизации первичного ключа и рассматривать разбиение как технику оптимизации запросов в исключительных случаях, когда паттерны доступа охватывают конкретное предсказуемое подмножество дня, например, разбиение по дням, с большинством запросов в последний день.
#### Рекомендации {#recommendations}

Пользователи должны рассматривать разделение как технику управления данными. Это идеально, когда данные необходимо истекать из кластера при работе с временными рядами данных, например, самый старый раздел можно [просто удалить](/sql-reference/statements/alter/partition#drop-partitionpart).

Важно: убедитесь, что ваше выражение ключа разбиения не приводит к высококардинальности, то есть создание более 100 разделов следует избегать. Например, не разбивайте данные по столбцам с высокой кардинальностью, таким как идентификаторы клиентов или имена. Вместо этого поместите идентификатор клиента или имя в первый столбец в выражении `ORDER BY`.

> Внутри ClickHouse [создаются части](/guides/best-practices/sparse-primary-indexes#clickhouse-index-design) для вставленных данных. По мере добавления данных количество частей увеличивается. Чтобы предотвратить чрезмерно высокое количество частей, что ухудшает производительность запросов (поскольку необходимо читать больше файлов), части объединяются в фоновом асинхронном процессе. Если количество частей превышает [предустановленный лимит](/operations/settings/merge-tree-settings#parts-to-throw-insert), то ClickHouse выбросит исключение при вставке как ["слишком много частей" ошибка](/knowledgebase/exception-too-many-parts). Это не должно происходить при нормальной работе и происходит только если ClickHouse неправильно настроен или используется неправильно, например, множество мелких вставок. Поскольку части создаются для каждого раздела изолированно, увеличение количества разделов вызывает увеличение числа частей, то есть количество частей увеличивается в несколько раз по сравнению с количеством разделов. Ключи разбиения с высокой кардинальностью могут, следовательно, вызвать эту ошибку и должны быть избегаемы.
## Материализованные представления против проекций {#materialized-views-vs-projections}

Концепция ClickHouse проектирования позволяет пользователям определять несколько операторов `ORDER BY` для таблицы.

В [моделировании данных ClickHouse](/data-modeling/schema-design) мы исследуем, как можно использовать материализованные представления в ClickHouse для предварительного вычисления агрегаций, преобразования строк и оптимизации запросов для различных паттернов доступа. Для последнего мы [предоставили пример](/materialized-view/incremental-materialized-view#lookup-table), где материализованное представление отправляет строки в целевую таблицу с другим ключом упорядочивания, чем у оригинальной таблицы, получающей вставки.

Например, рассмотрите следующий запрос:

```sql
SELECT avg(Score)
FROM comments
WHERE UserId = 8592047

   ┌──────────avg(Score)─┐
   │ 0.18181818181818182 │
   └─────────────────────┘

1 строка в наборе. Время выполнения: 0.040 сек. Обработано 90.38 миллионов строк, 361.59 МБ (2.25 миллиарда строк/с., 9.01 ГБ/с.)
Пиковое использование памяти: 201.93 MiB.
```

Этот запрос требует сканирования всех 90 миллионов строк (хотя и быстро), так как `UserId` не является ключом упорядочивания. Ранее мы решали эту проблему с помощью материализованного представления, действующего как поиск для `PostId`. Ту же проблему можно решить с помощью проекции. Команда ниже добавляет проекцию для `ORDER BY user_id`.

```sql
ALTER TABLE comments ADD PROJECTION comments_user_id (
SELECT * ORDER BY UserId
)

ALTER TABLE comments MATERIALIZE PROJECTION comments_user_id
```

Обратите внимание, что сначала необходимо создать проекцию, а затем материализовать ее. Эта последняя команда вызывает сохранение данных дважды на диске в двух различных порядках. Проекция также может быть определена при создании данных, как показано ниже, и будет автоматически поддерживаться по мере вставки данных.

```sql
CREATE TABLE comments
(
        `Id` UInt32,
        `PostId` UInt32,
        `Score` UInt16,
        `Text` String,
        `CreationDate` DateTime64(3, 'UTC'),
        `UserId` Int32,
        `UserDisplayName` LowCardinality(String),
        PROJECTION comments_user_id
        (
        SELECT *
        ORDER BY UserId
        )
)
ENGINE = MergeTree
ORDER BY PostId
```

Если проекция создается через команду `ALTER`, создание происходит асинхронно, когда команда `MATERIALIZE PROJECTION` выдается. Пользователи могут подтвердить ход этой операции с помощью следующего запроса, ожидая, что `is_done=1`.

```sql
SELECT
        parts_to_do,
        is_done,
        latest_fail_reason
FROM system.mutations
WHERE (`table` = 'comments') AND (command LIKE '%MATERIALIZE%')

   ┌─parts_to_do─┬─is_done─┬─latest_fail_reason─┐
1. │           1 │       0 │                    │
   └─────────────┴─────────┴────────────────────┘

1 строка в наборе. Время выполнения: 0.003 сек.
```

Если мы повторим предыдущий запрос, мы увидим, что производительность значительно улучшилась за счет дополнительного объема хранения.

```sql
SELECT avg(Score)
FROM comments
WHERE UserId = 8592047

   ┌──────────avg(Score)─┐
1. │ 0.18181818181818182 │
   └─────────────────────┘

1 строка в наборе. Время выполнения: 0.008 сек. Обработано 16.36 тысячи строк, 98.17 КБ (2.15 миллиона строк/с., 12.92 МБ/с.)
Пиковое использование памяти: 4.06 MiB.
```

С помощью команды [`EXPLAIN`](/sql-reference/statements/explain) мы также подтверждаем, что проекция была использована для обработки этого запроса:

```sql
EXPLAIN indexes = 1
SELECT avg(Score)
FROM comments
WHERE UserId = 8592047

    ┌─explain─────────────────────────────────────────────┐
 1. │ Expression ((Projection + Before ORDER BY))         │
 2. │   Aggregating                                       │
 3. │   Filter                                            │
 4. │           ReadFromMergeTree (comments_user_id)      │
 5. │           Indexes:                                  │
 6. │           PrimaryKey                                │
 7. │           Keys:                                     │
 8. │           UserId                                    │
 9. │           Condition: (UserId in [8592047, 8592047]) │
10. │           Parts: 2/2                                │
11. │           Granules: 2/11360                         │
    └─────────────────────────────────────────────────────┘

11 строк в наборе. Время выполнения: 0.004 сек.
```
### Когда использовать проекции {#when-to-use-projections}

Проекции являются привлекательной функцией для новых пользователей, так как они автоматически поддерживаются по мере вставки данных. Кроме того, запросы могут быть отправлены в одну таблицу, где проекции используются по мере необходимости для ускорения времени ответа.

<Image img={bigquery_7} size="md" alt="Проекции"/>

Это в отличие от материализованных представлений, где пользователю необходимо выбрать соответствующую оптимизированную целевую таблицу или переписать свой запрос, в зависимости от фильтров. Это ставит большую нагрузку на клиентские приложения и усложняет их.

Несмотря на эти преимущества, проекции имеют некоторые внутренние ограничения, о которых пользователи должны знать, и, таким образом, их следует применять экономно:

- Проекции не позволяют использовать разные TTL для исходной и (скрытой) целевой таблицы. Материализованные представления позволяют использовать разные TTL.
- Проекции [в настоящее время не поддерживают `optimize_read_in_order`](https://clickhouse.com/blog/clickhouse-faster-queries-with-projections-and-primary-indexes) для (скрытой) целевой таблицы.
- Легковесные обновления и удаления не поддерживаются для таблиц с проекциями.
- Материализованные представления могут быть цепочками: целевая таблица одного материализованного представления может быть исходной таблицей другого материализованного представления и так далее. Это невозможно сделать с проекциями.
- Проекции не поддерживают соединения; материализованные представления поддерживают.
- Проекции не поддерживают фильтры (`WHERE`); материализованные представления поддерживают.

Мы рекомендуем использовать проекции, когда:

- Требуется полная переупорядоченность данных. Хотя выражение в проекции может, в теории, использовать `GROUP BY`, материализованные представления более эффективны для поддержания агрегатов. Оптимизатор запросов также с большей вероятностью использует проекции, которые используют простое переупорядочение, то есть `SELECT * ORDER BY x`. Пользователи могут выбрать подмножество столбцов в этом выражении, чтобы уменьшить объем хранения.
- Пользователи готовы принять связанное увеличение объема хранения и накладные расходы на запись данных дважды. Проверьте влияние на скорость вставки и [оцените накладные расходы на хранение](/data-compression/compression-in-clickhouse).
## Переписывание запросов BigQuery в ClickHouse {#rewriting-bigquery-queries-in-clickhouse}

Ниже приводятся примеры запросов, сравнивающих BigQuery и ClickHouse. Этот список призван продемонстрировать, как использовать возможности ClickHouse для значительного упрощения запросов. Примеры здесь используют полный набор данных Stack Overflow (по апрель 2024 года).

**Пользователи (с более чем 10 вопросами), которые получают наибольшее количество просмотров:**

_BigQuery_

<Image img={bigquery_8} size="sm" alt="Переписывание запросов BigQuery" border/>

_ClickHouse_

```sql
SELECT
    OwnerDisplayName,
    sum(ViewCount) AS total_views
FROM stackoverflow.posts
WHERE (PostTypeId = 'Question') AND (OwnerDisplayName != '')
GROUP BY OwnerDisplayName
HAVING count() > 10
ORDER BY total_views DESC
LIMIT 5

   ┌─OwnerDisplayName─┬─total_views─┐
1. │ Joan Venge       │    25520387 │
2. │ Ray Vega         │    21576470 │
3. │ anon             │    19814224 │
4. │ Tim              │    19028260 │
5. │ John             │    17638812 │
   └──────────────────┴─────────────┘

5 строк в наборе. Время выполнения: 0.076 сек. Обработано 24.35 миллиона строк, 140.21 МБ (320.82 миллиона строк/с., 1.85 ГБ/с.)
Пиковое использование памяти: 323.37 MiB.
```

**Какие теги получают наибольшее количество просмотров:**

_BigQuery_

<br />

<Image img={bigquery_9} size="sm" alt="BigQuery 1" border/>

_ClickHouse_

```sql
-- ClickHouse
SELECT
    arrayJoin(arrayFilter(t -> (t != ''), splitByChar('|', Tags))) AS tags,
    sum(ViewCount) AS views
FROM stackoverflow.posts
GROUP BY tags
ORDER BY views DESC
LIMIT 5


   ┌─tags───────┬──────views─┐
1. │ javascript │ 8190916894 │
2. │ python     │ 8175132834 │
3. │ java       │ 7258379211 │
4. │ c#         │ 5476932513 │
5. │ android    │ 4258320338 │
   └────────────┴────────────┘

5 строк в наборе. Время выполнения: 0.318 сек. Обработано 59.82 миллиона строк, 1.45 ГБ (188.01 миллиона строк/с., 4.54 ГБ/с.)
Пиковое использование памяти: 567.41 MiB.
```
## Агрегатные функции {#aggregate-functions}

По возможности пользователи должны использовать агрегатные функции ClickHouse. Ниже мы показываем использование [`argMax` функции](/sql-reference/aggregate-functions/reference/argmax) для вычисления наиболее просматриваемого вопроса каждого года.

_BigQuery_

<Image img={bigquery_10} border size="sm" alt="Агрегатные функции 1"/>

<Image img={bigquery_11} border size="sm" alt="Агрегатные функции 2"/>

_ClickHouse_

```sql
-- ClickHouse
SELECT
    toYear(CreationDate) AS Year,
    argMax(Title, ViewCount) AS MostViewedQuestionTitle,
    max(ViewCount) AS MaxViewCount
FROM stackoverflow.posts
WHERE PostTypeId = 'Question'
GROUP BY Year
ORDER BY Year ASC
FORMAT Vertical


Row 1:
──────
Year:                    2008
MostViewedQuestionTitle: How to find the index for a given item in a list?
MaxViewCount:            6316987

Row 2:
──────
Year:                    2009
MostViewedQuestionTitle: How do I undo the most recent local commits in Git?
MaxViewCount:            13962748

...

Row 16:
───────
Year:                    2023
MostViewedQuestionTitle: How do I solve "error: externally-managed-environment" every time I use pip 3?
MaxViewCount:            506822

Row 17:
───────
Year:                    2024
MostViewedQuestionTitle: Warning "Third-party cookie will be blocked. Learn more in the Issues tab"
MaxViewCount:            66975

17 строк в наборе. Время выполнения: 0.225 сек. Обработано 24.35 миллиона строк, 1.86 ГБ (107.99 миллиона строк/с., 8.26 ГБ/с.)
Пиковое использование памяти: 377.26 MiB.
```
## Условные операторы и массивы {#conditionals-and-arrays}

Условные и массивные функции значительно упрощают запросы. Следующий запрос вычисляет теги (с более чем 10000 вхождений) с наибольшим процентным увеличением с 2022 по 2023 год. Обратите внимание, как следующий запрос ClickHouse лаконичен благодаря условиям, массивным функциям и возможности повторного использования псевдонимов в предложениях `HAVING` и `SELECT`.

_BigQuery_

<Image img={bigquery_12} size="sm" border alt="Conditionals and Arrays"/>

_ClickHouse_

```sql
SELECT
    arrayJoin(arrayFilter(t -> (t != ''), splitByChar('|', Tags))) AS tag,
    countIf(toYear(CreationDate) = 2023) AS count_2023,
    countIf(toYear(CreationDate) = 2022) AS count_2022,
    ((count_2023 - count_2022) / count_2022) * 100 AS percent_change
FROM stackoverflow.posts
WHERE toYear(CreationDate) IN (2022, 2023)
GROUP BY tag
HAVING (count_2022 > 10000) AND (count_2023 > 10000)
ORDER BY percent_change DESC
LIMIT 5

┌─tag─────────┬─count_2023─┬─count_2022─┬──────percent_change─┐
│ next.js     │      13788 │      10520 │   31.06463878326996 │
│ spring-boot │      16573 │      17721 │  -6.478189718413183 │
│ .net        │      11458 │      12968 │ -11.644046884639112 │
│ azure       │      11996 │      14049 │ -14.613139725247349 │
│ docker      │      13885 │      16877 │  -17.72826924216389 │
└─────────────┴────────────┴────────────┴─────────────────────┘

5 строк в наборе. Время выполнения: 0.096 сек. Обработано 5.08 миллиона строк, 155.73 МБ (53.10 миллиона строк/с, 1.63 ГБ/с.)
Пиковое использование памяти: 410.37 MiB.
```

Это завершает наше основное руководство для пользователей,Migrating from BigQuery to ClickHouse. Мы рекомендуем пользователям, мигрирующим с BigQuery, прочитать руководство по [моделированию данных в ClickHouse](/data-modeling/schema-design), чтобы узнать больше о расширенных функциях ClickHouse.
