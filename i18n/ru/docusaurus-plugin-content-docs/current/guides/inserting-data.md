---
title: 'Вставка данных в ClickHouse'
description: 'Как вставить данные в ClickHouse'
keywords: ['вставка', 'вставка данных', 'вставка в таблицу']
sidebar_label: 'Вставка данных в ClickHouse'
slug: /guides/inserting-data
---

import postgres_inserts from '@site/static/images/guides/postgres-inserts.png';
import Image from '@theme/IdealImage';

## Основной пример {#basic-example}

Вы можете использовать знакомую команду `INSERT INTO TABLE` с ClickHouse. Давайте вставим некоторые данные в таблицу, которую мы создали в начальном руководстве ["Создание таблиц в ClickHouse"](./creating-tables).

```sql
INSERT INTO helloworld.my_first_table (user_id, message, timestamp, metric) VALUES
    (101, 'Hello, ClickHouse!',                                 now(),       -1.0    ),
    (102, 'Insert a lot of rows per batch',                     yesterday(), 1.41421 ),
    (102, 'Sort your data based on your commonly-used queries', today(),     2.718   ),
    (101, 'Granules are the smallest chunks of data read',      now() + 5,   3.14159 )
```

Чтобы проверить, что это сработало, мы выполним следующий запрос `SELECT`:

```sql
SELECT * FROM helloworld.my_first_table
```

Который возвращает:

```response
user_id message                                             timestamp           metric
101         Hello, ClickHouse!                                  2024-11-13 20:01:22     -1
101         Granules are the smallest chunks of data read           2024-11-13 20:01:27 3.14159
102         Insert a lot of rows per batch                          2024-11-12 00:00:00 1.41421
102         Sort your data based on your commonly-used queries  2024-11-13 00:00:00     2.718
```

## Вставка в ClickHouse против OLTP баз данных {#inserting-into-clickhouse-vs-oltp-databases}

Как OLAP (Online Analytical Processing) база данных, ClickHouse оптимизирован для высокой производительности и масштабируемости, что позволяет теоретически вставлять миллионы строк в секунду. Это достигается за счет комбинации высокопараллельной архитектуры и эффективного столбцового сжатия, но с компромиссами в отношении немедленной согласованности. Более конкретно, ClickHouse оптимизирован для операций только добавления и предлагает только гарантии конечной согласованности.

В отличие от этого, базы данных OLTP, такие как Postgres, специально оптимизированы для транзакционных вставок с полной совместимостью ACID, что обеспечивает гарантии высокой согласованности и надежности. PostgreSQL использует MVCC (Multi-Version Concurrency Control) для управления параллельными транзакциями, что подразумевает поддержку нескольких версий данных. Эти транзакции могут, возможно, затрагивать небольшое количество строк за раз, с значительными накладными расходами, возникающими из-за ограничений надежности, что ограничивает производительность вставки.

Чтобы достичь высокой производительности вставки при сохранении сильных гарантий согласованности, пользователи должны следовать простым правилам, описанным ниже, при вставке данных в ClickHouse. Соблюдение этих правил поможет избежать проблем, с которыми пользователи часто сталкиваются в первый раз, когда они используют ClickHouse, и попытаются воспроизвести стратегию вставки, которая работает для OLTP баз данных.

## Рекомендации по вставкам {#best-practices-for-inserts}

### Вставляйте большими партиями {#insert-in-large-batch-sizes}

По умолчанию, каждая вставка, отправленная в ClickHouse, заставляет ClickHouse немедленно создать часть хранилища, содержащую данные из вставки вместе с другой метаинформацией, которую необходимо сохранить. Поэтому отправка меньшего количества вставок, каждая из которых содержит больше данных, по сравнению с отправкой большего количества вставок, каждая из которых содержит меньше данных, уменьшит количество необходимых записей. Обычно мы рекомендуем вставлять данные довольно большими партиями, по крайней мере, по 1,000 строк за раз, а лучше от 10,000 до 100,000 строк. (Дополнительные детали [здесь](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse#data-needs-to-be-batched-for-optimal-performance)).

Если большие партии невозможны, используйте асинхронные вставки, описанные ниже.

### Обеспечьте согласование партий для идемпотентных повторных попыток {#ensure-consistent-batches-for-idempotent-retries}

По умолчанию, вставки в ClickHouse являются синхронными и идемпотентными (т.е. выполнение одной и той же операции вставки несколько раз имеет такой же эффект, как выполнение ее один раз). Для таблиц семейства движка MergeTree ClickHouse будет, по умолчанию, автоматически [дедуплицировать вставки](https://clickhouse.com/blog/common-getting-started-issues-with-clickhouse#5-deduplication-at-insert-time).

Это означает, что вставки остаются устойчивыми в следующих случаях:

- 1. Если узел, получающий данные, испытывает проблемы, запрос вставки выйдет за пределы времени ожидания (или выдаст более конкретную ошибку) и не получит подтверждение.
- 2. Если данные были записаны узлом, но подтверждение не может быть возвращено отправителю запроса из-за сетевых перебоев, отправитель получит либо тайм-аут, либо сетевую ошибку.

С точки зрения клиента (i) и (ii) могут быть трудны для различения. Однако в обоих случаях неподтвержденную вставку можно немедленно повторить. При условии, что повторенный запрос вставки содержит те же данные в том же порядке, ClickHouse автоматически проигнорирует повторенную вставку, если (неподтвержденная) первоначальная вставка была успешной.

### Вставка в таблицу MergeTree или распределенную таблицу {#insert-to-a-mergetree-table-or-a-distributed-table}

Мы рекомендуем вставлять непосредственно в таблицу MergeTree (или реплицированную таблицу), балансируя запросы между набором узлов, если данные распределены, и установив `internal_replication=true`. Это позволит ClickHouse реплицировать данные на любые доступные шарды-реплики и гарантировать, что данные в конечном итоге будут согласованными.

Если такое клиентское распределение нагрузки неудобно, пользователи могут вставлять данные через [распределенную таблицу](/engines/table-engines/special/distributed), которая затем распределит записи между узлами. Опять же, рекомендуется установить `internal_replication=true`. Однако стоит заметить, что этот подход немного менее производителен, так как записи должны быть сделаны локально на узле с распределенной таблицей и затем отправлены к шарам.

### Используйте асинхронные вставки для небольших партий {#use-asynchronous-inserts-for-small-batches}

Есть сценарии, когда пакетирование на стороне клиента невозможно, например, в случае наблюдаемости с сотнями или тысячами одноп-purpose агентов, отправляющих логи, метрики, трассировки и т.д. В этом сценарии транспортировка данных в реальном времени имеет ключевое значение для быстрого обнаружения проблем и аномалий. Более того, существует риск всплесков событий в наблюдаемых системах, которые могут потенциально вызвать большие всплески памяти и связанные с этим проблемы при попытке буферизовать данные на стороне клиента. Если большие партии не могут быть вставлены, пользователи могут делегировать пакетирование ClickHouse с помощью [асинхронных вставок](/best-practices/selecting-an-insert-strategy#asynchronous-inserts).

С асинхронными вставками данные сначала вставляются в буфер, а затем записываются в хранилище базы данных позже в 3 этапа, как показано на диаграмме ниже:

<Image img={postgres_inserts} size="md" alt="Postgres вставки"/>

При включенных асинхронных вставках ClickHouse:

(1) получает запрос вставки асинхронно.  
(2) сначала записывает данные запроса в буфер в памяти.  
(3) сортирует и записывает данные как часть в хранилище базы данных, только когда происходит следующая операция сброса буфера.

Перед сбросом буфера данные других асинхронных запросов вставки от того же или других клиентов могут быть собраны в буфере. Часть, созданная при сбросе буфера, потенциально может содержать данные из нескольких асинхронных запросов вставки. Обычно эти механики перемещают пакетирование данных с клиентской стороны на серверную сторону (экземпляр ClickHouse).

:::note
Обратите внимание, что данные не могут быть найдены по запросам до сброса их в хранилище базы данных и что сброс буфера является конфигурируемым.

Полные детали по настройке асинхронных вставок можно найти [здесь](/optimize/asynchronous-inserts#enabling-asynchronous-inserts), а более глубокий анализ [здесь](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse).
:::

### Используйте официальные клиенты ClickHouse {#use-official-clickhouse-clients}

ClickHouse имеет клиенты на самых популярных языках программирования. Эти клиенты оптимизированы для обеспечения правильности выполнения вставок и нативно поддерживают асинхронные вставки либо непосредственно, как например в [Go клиенте](/integrations/go#async-insert), либо косвенно, когда это включено в настройках запроса, пользователя или соединения.

Смотрите [Клиенты и драйверы](/interfaces/cli) для полного списка доступных клиентов и драйверов ClickHouse.

### Предпочитайте нативный формат {#prefer-the-native-format}

ClickHouse поддерживает множество [форматов ввода](/interfaces/formats) во время вставки (и запроса). Это значительное отличие от OLTP баз данных и делает загрузку данных из внешних источников гораздо проще - особенно в сочетании с [табличными функциями](/sql-reference/table-functions) и возможностью загружать данные из файлов на диске. Эти форматы идеально подходят для загрузки данных по запросам и задач по обработке данных.

Для приложений, стремящихся добиться оптимальной производительности вставки, пользователи должны вставлять, используя [Нативный](/interfaces/formats/Native) формат. Это поддерживается большинством клиентов (таких как Go и Python) и гарантирует, что сервер должен выполнять минимальную работу, поскольку этот формат уже является столбцовым. Тем самым ответственность за преобразование данных в столбцовый формат ложится на клиентскую сторону. Это важно для эффективного масштабирования вставок.

В качестве альтернативы пользователи могут использовать [RowBinary формат](/interfaces/formats/RowBinary) (как используется Java клиентом), если предпочитается формат строк - он, как правило, проще в записи, чем Нативный формат. Это более эффективно с точки зрения сжатия, сетевых накладных расходов и обработки на сервере по сравнению с альтернативными строковыми форматами, такими как [JSON](/interfaces/formats/JSON). Формат [JSONEachRow](/interfaces/formats/JSONEachRow) может рассматриваться пользователями с более низкой пропускной способностью записи, которые хотят быстро интегрироваться. Пользователи должны быть предупреждены, что этот формат несет накладные расходы по CPU в ClickHouse за разбор.

### Используйте HTTP интерфейс {#use-the-http-interface}

В отличие от многих традиционных баз данных, ClickHouse поддерживает HTTP интерфейс. Пользователи могут использовать его как для вставки, так и для запросов данных, используя любые из вышеуказанных форматов. Это часто предпочтительнее по сравнению с родным протоколом ClickHouse, так как он позволяет легко переключать трафик с помощью балансировщиков нагрузки. Мы ожидаем небольшие различия в производительности вставок с родным протоколом, который имеет несколько меньшие накладные расходы. Существующие клиенты используют любой из этих протоколов (в некоторых случаях оба, например Go клиент). Родной протокол действительно позволяет удобно отслеживать прогресс запроса.

Смотрите [HTTP интерфейс](/interfaces/http) для получения дополнительной информации.

## Загрузка данных из Postgres {#loading-data-from-postgres}

Для загрузки данных из Postgres пользователи могут использовать:

- `PeerDB by ClickHouse`, инструмент ETL, специально разработанный для репликации баз данных PostgreSQL. Это доступно в обоих вариантах:
  - ClickHouse Cloud - доступно через наш [новый коннектор](/integrations/clickpipes/postgres) (Частный предварительный просмотр) в ClickPipes, нашем управляемом сервисе загрузки данных. Заинтересованные пользователи [регистрируются здесь](https://clickpipes.peerdb.io/).
  - Самоуправляемый - через [проект с открытым исходным кодом](https://github.com/PeerDB-io/peerdb).
- [Движок таблиц PostgreSQL](/integrations/postgresql#using-the-postgresql-table-engine), чтобы читать данные напрямую, как показано в предыдущих примерах. Обычно подходит, если пакетная репликация, основанная на известной контрольной точке, например, временной метке, достаточна или если это одноразовая миграция. Этот подход может масштабироваться до десятков миллионов строк. Пользователи, стремящиеся переместить более крупные наборы данных, должны рассмотреть вопрос о нескольких запросах, каждый из которых обрабатывает часть данных. Этапные таблицы могут использоваться для каждой части перед перемещением ее в финальную таблицу. Это позволяет повторно попытаться выполнить неудавшиеся запросы. Для получения дополнительных данных о данной стратегии массовой загрузки см. здесь.
- Данные могут быть экспортированы из PostgreSQL в формате CSV. Затем эти данные могут быть вставлены в ClickHouse из локальных файлов или через объектное хранилище с помощью табличных функций.

:::note Нужна помощь с вставкой больших наборов данных?
Если вам нужна помощь с вставкой больших наборов данных или вы сталкиваетесь с ошибками при импорте данных в ClickHouse Cloud, пожалуйста, свяжитесь с нами по адресу support@clickhouse.com, и мы сможем помочь.
:::
