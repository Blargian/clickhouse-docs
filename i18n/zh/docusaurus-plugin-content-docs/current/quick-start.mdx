---
'slug': '/getting-started/quick-start'
'sidebar_label': '快速开始'
'sidebar_position': 1
'keywords':
- 'clickhouse'
- 'install'
- 'getting started'
- 'quick start'
'pagination_next': 'getting-started/index'
'title': '快速开始'
'description': 'ClickHouse快速开始指南'
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';
import {VerticalStepper} from '@clickhouse/click-ui/bundled';

**欢迎来到 ClickHouse！**

在本快速入门教程中，我们将通过 8 个简单步骤帮助您设置 ClickHouse。您将下载适合您操作系统的二进制文件，学习运行 ClickHouse 服务器，使用 ClickHouse 客户端创建一个表，然后向其插入数据并运行查询以选择这些数据。

我们开始吧？

<VerticalStepper>

## 下载 ClickHouse {#download-the-binary}

ClickHouse 原生运行在 Linux、FreeBSD 和 macOS 上，并可以通过 [WSL](https://learn.microsoft.com/en-us/windows/wsl/about) 在 Windows 上运行。下载 ClickHouse 的最简单方法是运行以下 `curl` 命令。该命令会检测您的操作系统是否受支持，然后下载适合的 ClickHouse 二进制文件。

:::note
我们建议在一个新的、空的子目录中运行以下命令，因为第一次运行 ClickHouse 服务器时，会在二进制文件所在目录中创建一些配置文件。
:::

```bash
curl https://clickhouse.com/ | sh
```

您应该会看到：

```
Successfully downloaded the ClickHouse binary, you can run it as:
    ./clickhouse

You can also install it:
sudo ./clickhouse install
```

在这个阶段，您可以忽略运行 `install` 命令的提示。

:::note
对于 Mac 用户：如果您收到二进制文件的开发者无法验证的错误，请参阅 ["修复 MacOS 中的开发者验证错误"](https://clickhouse.com/docs/knowledgebase/fix-developer-verification-error-in-macos)。
:::

## 启动服务器

运行以下命令以启动 ClickHouse 服务器：

```bash
./clickhouse server
```

您应该会看到终端中充满了日志。这是预期的。在 ClickHouse 中，默认的 [日志级别](https://clickhouse.com/docs/knowledgebase/why_default_logging_verbose) 设置为 `trace` 而不是 `warning`。

## 启动客户端

使用 `clickhouse-client` 连接到您的 ClickHouse 服务。打开一个新的终端，进入您的 `clickhouse` 二进制文件保存的目录，并运行以下命令：

```bash
./clickhouse client
```

您应该会看到一个微笑的脸，表示它已连接到在 localhost 上运行的服务：

```response
my-host :)
```

## 创建表

使用 `CREATE TABLE` 定义一个新表。典型的 SQL DDL 命令在 ClickHouse 中有效，唯一的补充是 ClickHouse 中的表需要一个 `ENGINE` 子句。使用 [`MergeTree`](/engines/table-engines/mergetree-family/mergetree) 来充分利用 ClickHouse 的性能优势：

```sql
CREATE TABLE my_first_table
(
    user_id UInt32,
    message String,
    timestamp DateTime,
    metric Float32
)
ENGINE = MergeTree
PRIMARY KEY (user_id, timestamp)
```

## 插入数据

您可以在 ClickHouse 中使用熟悉的 `INSERT INTO TABLE` 命令，但重要的是要理解，每次向 `MergeTree` 表插入数据时，会导致 ClickHouse 在存储中创建我们称之为 **part** 的部分。这些部分随后会在后台由 ClickHouse 合并。

在 ClickHouse 中，我们尝试一次性批量插入大量行（数以万计甚至数百万行），以最小化在后台进程中需要合并的 [**parts**](/parts) 的数量。

在本指南中，我们暂时不需要担心这一点。运行以下命令向您的表中插入几行数据：

```sql
INSERT INTO my_first_table (user_id, message, timestamp, metric) VALUES
    (101, 'Hello, ClickHouse!',                                 now(),       -1.0    ),
    (102, 'Insert a lot of rows per batch',                     yesterday(), 1.41421 ),
    (102, 'Sort your data based on your commonly-used queries', today(),     2.718   ),
    (101, 'Granules are the smallest chunks of data read',      now() + 5,   3.14159 )
```

## 查询您的新表

您可以像在任何 SQL 数据库中一样编写 `SELECT` 查询：

```sql
SELECT *
FROM my_first_table
ORDER BY timestamp
```
请注意，响应将以漂亮的表格格式返回：

```text
┌─user_id─┬─message────────────────────────────────────────────┬───────────timestamp─┬──metric─┐
│     102 │ Insert a lot of rows per batch                     │ 2022-03-21 00:00:00 │ 1.41421 │
│     102 │ Sort your data based on your commonly-used queries │ 2022-03-22 00:00:00 │   2.718 │
│     101 │ Hello, ClickHouse!                                 │ 2022-03-22 14:04:09 │      -1 │
│     101 │ Granules are the smallest chunks of data read      │ 2022-03-22 14:04:14 │ 3.14159 │
└─────────┴────────────────────────────────────────────────────┴─────────────────────┴─────────┘

4 rows in set. Elapsed: 0.008 sec.
```

## 插入您自己的数据

下一步是将您自己的数据导入 ClickHouse。我们有许多 [表函数](/sql-reference/table-functions/index.md) 和 [集成](/integrations) 用于摄取数据。我们下面的标签中有一些示例，或者您可以查看我们的 [集成](/integrations) 页面，以获取与 ClickHouse 集成的技术的详细列表。

<Tabs groupId="read_data">
    <TabItem value="S3" label="S3" default>

        使用 [`s3` 表函数](/sql-reference/table-functions/s3.md) 从 S3 读取文件。它是一个表函数——意味着结果是一个表，可以：

        1. 被用作 `SELECT` 查询的来源（允许您运行临时查询并将数据保留在 S3 中），或者...
        2. 将结果表插入到 `MergeTree` 表中（当您准备好将数据移动到 ClickHouse 时）

        一个临时查询看起来像：

```sql
        SELECT
        passenger_count,
        avg(toFloat32(total_amount))
        FROM s3(
        'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
        'TabSeparatedWithNames'
        )
        GROUP BY passenger_count
        ORDER BY passenger_count;
```

        将数据移动到 ClickHouse 表的过程如下，其中 `nyc_taxi` 是一个 `MergeTree` 表：

```sql
        INSERT INTO nyc_taxi
        SELECT * FROM s3(
        'https://datasets-documentation.s3.eu-west-3.amazonaws.com/nyc-taxi/trips_0.gz',
        'TabSeparatedWithNames'
        )
        SETTINGS input_format_allow_errors_num=25000;
```

        查看我们的 [AWS S3 文档页面集合](/integrations/data-ingestion/s3/index.md)，以获取有关使用 S3 与 ClickHouse 的更多详细信息和示例。
        <br/>
    </TabItem>
    <TabItem value="GCS" label="GCS">

        用于从 AWS S3 读取数据的 [`s3` 表函数](/sql-reference/table-functions/s3.md) 也可以在 Google Cloud Storage 中用于文件。

        例如：

```sql
        SELECT
        *
        FROM s3(
        'https://storage.googleapis.com/my-bucket/trips.parquet',
        'MY_GCS_HMAC_KEY',
        'MY_GCS_HMAC_SECRET_KEY',
        'Parquet'
        )
        LIMIT 1000
```

        在 [`s3` 表函数页面](/sql-reference/table-functions/s3.md) 上找到更多细节。
        <br/>
    </TabItem>
    <TabItem value="URL" label="Web">

        [`url` 表函数](/sql-reference/table-functions/url) 读取来自网络的可访问文件：

```sql
        --By default, ClickHouse prevents redirects to protect from SSRF attacks.
        --The URL below requires a redirect, so we must set max_http_get_redirects > 0.
        SET max_http_get_redirects=10;

        SELECT *
        FROM url(
        'http://prod2.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-complete.csv',
        'CSV'
        );
```

        在 [`url` 表函数页面](/sql-reference/table-functions/url) 上找到更多细节。
        <br/>
    </TabItem>
    <TabItem value="local_file" label="Local">

        使用 [`file` 表引擎](/sql-reference/table-functions/file) 读取本地文件。为简化起见，将文件复制到 `user_files` 目录（该目录位于您下载 ClickHouse 二进制文件的目录中）。

```sql
        DESCRIBE TABLE file('comments.tsv')

        Query id: 8ca9b2f9-65a2-4982-954a-890de710a336

        ┌─name──────┬─type────────────────────┐
        │ id        │ Nullable(Int64)         │
        │ type      │ Nullable(String)        │
        │ author    │ Nullable(String)        │
        │ timestamp │ Nullable(DateTime64(9)) │
        │ comment   │ Nullable(String)        │
        │ children  │ Array(Nullable(Int64))  │
        └───────────┴─────────────────────────┘
```

        请注意，ClickHouse 通过分析大量行来推断您的列的名称和数据类型。如果 ClickHouse 无法从文件名中确定文件格式，您可以将其指定为第二个参数：

```sql
        SELECT count()
        FROM file(
        'comments.tsv',
        'TabSeparatedWithNames'
        )
```

        查看 [`file` 表函数](/sql-reference/table-functions/file) 文档页面以获取更多详细信息。
        <br/>
    </TabItem>
    <TabItem value="PostgreSQL" label="PostgreSQL">

        使用 [`postgresql` 表函数](/sql-reference/table-functions/postgresql) 从 PostgreSQL 中读取数据：

```sql
        SELECT *
        FROM
        postgresql(
        'localhost:5432',
        'my_database',
        'my_table',
        'postgresql_user',
        'password')
        ;
```

        查看 [`postgresql` 表函数](/sql-reference/table-functions/postgresql) 文档页面以获取更多详细信息。
        <br/>
    </TabItem>
    <TabItem value="MySQL" label="MySQL">

        使用 [`mysql` 表函数](/sql-reference/table-functions/mysql) 从 MySQL 中读取数据：

```sql
        SELECT *
        FROM
        mysql(
        'localhost:3306',
        'my_database',
        'my_table',
        'postgresql_user',
        'password')
        ;
```

        查看 [`mysql` 表函数](/sql-reference/table-functions/mysql) 文档页面以获取更多详细信息。
        <br/>
    </TabItem>
    <TabItem value="Other DBMS" label="ODBC/JDBC">

        ClickHouse 可以从任何 ODBC 或 JDBC 数据源读取数据：

```sql
        SELECT *
        FROM
        odbc(
        'DSN=mysqlconn',
        'my_database',
        'my_table'
        );
```

        查看 [`odbc` 表函数](/sql-reference/table-functions/odbc) 和 [`jdbc` 表函数](/sql-reference/table-functions/jdbc) 文档页面以获取更多详细信息。
        <br/>
    </TabItem>
    <TabItem value="messagequeue" label="消息队列">

        消息队列可以使用相应的表引擎将数据流入 ClickHouse，包括：

        - **Kafka**：使用 [`Kafka` 表引擎](/engines/table-engines/integrations/kafka) 集成 Kafka
        - **Amazon MSK**：集成 [Amazon 托管流媒体平台 Apache Kafka (MSK)](/integrations/kafka/cloud/amazon-msk/)
        - **RabbitMQ**：使用 [`RabbitMQ` 表引擎](/engines/table-engines/integrations/rabbitmq) 集成 RabbitMQ
        <br/>
    </TabItem>
    <TabItem value="datalake" label="数据湖">

        ClickHouse 具有从以下来源读取数据的表函数：

        - **Hadoop**：使用 [`hdfs` 表函数](/sql-reference/table-functions/hdfs) 与 Apache Hadoop 集成
        - **Hudi**：使用 [`hudi` 表函数](/sql-reference/table-functions/hudi) 从 S3 中现有的 Apache Hudi 表读取数据
        - **Iceberg**：使用 [`iceberg` 表函数](/sql-reference/table-functions/iceberg) 从 S3 中现有的 Apache Iceberg 表读取数据
        - **DeltaLake**：使用 [`deltaLake` 表函数](/sql-reference/table-functions/deltalake) 从 S3 中现有的 Delta Lake 表读取数据
        <br/>
    </TabItem>
    <TabItem value="Other" label="其他">

        查看我们的 [ClickHouse 集成长列表](/integrations)，了解如何将您现有的框架和数据源连接到 ClickHouse。
        <br/>
    </TabItem>
</Tabs>

## 探索

- 查看我们的 [核心概念](/managing-data/core-concepts) 部分，了解 ClickHouse 在底层工作的基本原理。
- 查看 [高级教程](tutorial.md)，深入探讨 ClickHouse 的关键概念和功能。
- 通过在 [ClickHouse 学院](https://learn.clickhouse.com/visitor_class_catalog) 参加我们的免费按需培训课程，继续学习。
- 我们提供 [示例数据集](/getting-started/example-datasets/) 的列表和插入它们的说明。
- 如果您的数据来自外部来源，请查看我们的 [集成指南集合](/integrations/)，以连接到消息队列、数据库、管道等等。
- 如果您正在使用 UI/BI 可视化工具，请查看 [连接 UI 到 ClickHouse 的用户指南](/integrations/data-visualization/)。
- 有关 [主键](/guides/best-practices/sparse-primary-indexes.md) 的用户指南是您了解主键及其定义所需的所有信息。

</VerticalStepper>
