---
'title': '会话设置'
'sidebar_label': '会话设置'
'slug': '/operations/settings/settings'
'toc_max_heading_level': 2
'description': '在``system.settings``表中找到的设置。'
---

import ExperimentalBadge from '@theme/badges/ExperimentalBadge';
import BetaBadge from '@theme/badges/BetaBadge';
import CloudAvailableBadge from '@theme/badges/CloudAvailableBadge';
import SettingsInfoBlock from '@theme/SettingsInfoBlock/SettingsInfoBlock';
import VersionHistory from '@theme/VersionHistory/VersionHistory';

<!-- Autogenerated -->
以下所有设置也可以在表 [system.settings](/docs/operations/system-tables/settings) 中找到。这些设置是从 [source](https://github.com/ClickHouse/ClickHouse/blob/master/src/Core/Settings.cpp) 自动生成的。
## add_http_cors_header {#add_http_cors_header} 


<SettingsInfoBlock type="Bool" default_value="0" />

写入添加 http CORS 头。
## additional_result_filter {#additional_result_filter} 

要应用于 `SELECT` 查询结果的额外过滤表达式。
此设置不适用于任何子查询。

**示例**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SElECT * FROM table_1;
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
```sql
SELECT *
FROM table_1
SETTINGS additional_result_filter = 'x != 2'
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
## additional_table_filters {#additional_table_filters} 


<SettingsInfoBlock type="Map" default_value="{}" />

在从指定表读取后应用的附加过滤表达式。

**示例**

```sql
INSERT INTO table_1 VALUES (1, 'a'), (2, 'bb'), (3, 'ccc'), (4, 'dddd');
SELECT * FROM table_1;
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 2 │ bb   │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
```sql
SELECT *
FROM table_1
SETTINGS additional_table_filters = {'table_1': 'x != 2'}
```
```response
┌─x─┬─y────┐
│ 1 │ a    │
│ 3 │ ccc  │
│ 4 │ dddd │
└───┴──────┘
```
## aggregate_functions_null_for_empty {#aggregate_functions_null_for_empty} 


<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在查询中重写所有聚合函数，为它们添加 [-OrNull](/sql-reference/aggregate-functions/combinators#-ornull) 后缀。启用此设置以兼容 SQL 标准。
它是通过查询重写实现的（类似于 [count_distinct_implementation](#count_distinct_implementation) 设置），以便为分布式查询获得一致的结果。

可能的值：

- 0 — 禁用。
- 1 — 启用。

**示例**

考虑以下带有聚合函数的查询：
```sql
SELECT SUM(-1), MAX(0) FROM system.one WHERE 0;
```

使用 `aggregate_functions_null_for_empty = 0`，它会产生：
```text
┌─SUM(-1)─┬─MAX(0)─┐
│       0 │      0 │
└─────────┴────────┘
```

使用 `aggregate_functions_null_for_empty = 1`，结果将是：
```text
┌─SUMOrNull(-1)─┬─MAXOrNull(0)─┐
│          NULL │         NULL │
└───────────────┴──────────────┘
```
## aggregation_in_order_max_block_bytes {#aggregation_in_order_max_block_bytes} 


<SettingsInfoBlock type="UInt64" default_value="50000000" />

在主键排序期间汇总的区块的最大字节数。较小的区块大小允许在汇总的最终合并阶段进行更多的并行处理。
## aggregation_memory_efficient_merge_threads {#aggregation_memory_efficient_merge_threads} 


<SettingsInfoBlock type="UInt64" default_value="0" />

用于合并中间汇总结果的线程数，在内存高效模式下。当更大时，消耗更多的内存。0 表示 - 同 'max_threads'。
## allow_aggregate_partitions_independently {#allow_aggregate_partitions_independently} 


<SettingsInfoBlock type="Bool" default_value="0" />

当分区键适合分组键时，启用在单独线程上独立聚合分区。当分区数量接近核心数量且分区大小大致相同时，这将是有利的。
## allow_archive_path_syntax {#allow_archive_path_syntax} 


<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "1"},{"label": "添加新设置以允许禁用归档路径语法。"}]}, {"id": "row-2","items": [{"label": "24.5"},{"label": "1"},{"label": "添加新设置以允许禁用归档路径语法。"}]}]}/>

文件/S3 引擎/表函数将解析路径为具有正确扩展名的 '::' 形式 `<archive> :: <file>`。
## allow_asynchronous_read_from_io_pool_for_merge_tree {#allow_asynchronous_read_from_io_pool_for_merge_tree} 


<SettingsInfoBlock type="Bool" default_value="0" />

使用后台 I/O 池从 MergeTree 表中读取。此设置可能提高 I/O 密集查询的性能。
## allow_changing_replica_until_first_data_packet {#allow_changing_replica_until_first_data_packet} 


<SettingsInfoBlock type="Bool" default_value="0" />

如果启用，在对冲请求中，我们可以在收到第一个数据包之前开始新的连接，即使我们已经取得了一些进展
（但进展尚未在 `receive_data_timeout` 超时之前更新），否则在我们首次取得进展后，我们将禁用更改副本。
## allow_create_index_without_type {#allow_create_index_without_type} 


<SettingsInfoBlock type="Bool" default_value="0" />

允许创建没有类型的 CREATE INDEX 查询。该查询将被忽略。用于 SQL 兼容性测试。
## allow_custom_error_code_in_throwif {#allow_custom_error_code_in_throwif} 


<SettingsInfoBlock type="Bool" default_value="0" />

启用 throwIf() 函数中的自定义错误代码。如果为 true，抛出的异常可能具有意外的错误代码。
## allow_ddl {#allow_ddl} 


<SettingsInfoBlock type="Bool" default_value="1" />

如果设置为 true，则用户被允许执行 DDL 查询。
## allow_deprecated_database_ordinary {#allow_deprecated_database_ordinary} 


<SettingsInfoBlock type="Bool" default_value="0" />

允许使用已弃用的 Ordinary 引擎创建数据库。
## allow_deprecated_error_prone_window_functions {#allow_deprecated_error_prone_window_functions} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "0"},{"label": "允许使用已弃用的容易出错的窗口函数（neighbor, runningAccumulate, runningDifferenceStartingWithFirstValue, runningDifference）"}]}]}/>

允许使用已弃用的容易出错的窗口函数（neighbor, runningAccumulate, runningDifferenceStartingWithFirstValue, runningDifference）。
## allow_deprecated_snowflake_conversion_functions {#allow_deprecated_snowflake_conversion_functions} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "禁用弃用的函数 snowflakeToDateTime[64] 和 dateTime[64]ToSnowflake。"}]}]}/>

函数 `snowflakeToDateTime`, `snowflakeToDateTime64`, `dateTimeToSnowflake`, 和 `dateTime64ToSnowflake` 被弃用，并默认禁用。
请使用函数 `snowflakeIDToDateTime`, `snowflakeIDToDateTime64`, `dateTimeToSnowflakeID`, 和 `dateTime64ToSnowflakeID` 替代。

要重新启用已弃用的函数（例如，在过渡期），请将此设置设置为 `true`。
## allow_deprecated_syntax_for_merge_tree {#allow_deprecated_syntax_for_merge_tree} 


<SettingsInfoBlock type="Bool" default_value="0" />

允许使用已弃用的引擎定义语法创建 *MergeTree 表。
## allow_distributed_ddl {#allow_distributed_ddl} 


<SettingsInfoBlock type="Bool" default_value="1" />

如果设置为 true，则用户被允许执行分布式 DDL 查询。
## allow_drop_detached {#allow_drop_detached} 


<SettingsInfoBlock type="Bool" default_value="0" />

允许执行 ALTER TABLE ... DROP DETACHED PART[ITION] ... 查询。
## allow_execute_multiif_columnar {#allow_execute_multiif_columnar} 


<SettingsInfoBlock type="Bool" default_value="1" />

允许以列式执行 multiIf 函数。
## allow_experimental_analyzer {#allow_experimental_analyzer} 


<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "默认启用分析器和计划器。"}]}]}/>

允许新的查询分析器。
## allow_experimental_codecs {#allow_experimental_codecs} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

如果设置为 true，允许指定实验性的压缩编码（但我们尚未拥有这些，因此此选项无效）。
## allow_experimental_correlated_subqueries {#allow_experimental_correlated_subqueries} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "添加新的设置以允许执行相关子查询。"}]}]}/>

允许执行相关子查询。
## allow_experimental_database_glue_catalog {#allow_experimental_database_glue_catalog} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "0"},{"label": "允许实验性数据库引擎 DataLakeCatalog，目录类型 = 'glue'"}]}]}/>

允许实验性数据库引擎 DataLakeCatalog，目录类型 = 'glue'。
## allow_experimental_database_hms_catalog {#allow_experimental_database_hms_catalog} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "允许实验性数据库引擎 DataLakeCatalog，目录类型 = 'hive'"}]}]}/>

允许实验性数据库引擎 DataLakeCatalog，目录类型 = 'hms'。
## allow_experimental_database_iceberg {#allow_experimental_database_iceberg} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "新设置。"}]}]}/>

允许实验性数据库引擎 DataLakeCatalog，目录类型 = 'iceberg'。
## allow_experimental_database_materialized_postgresql {#allow_experimental_database_materialized_postgresql} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

允许创建数据库，使用引擎=MaterializedPostgreSQL(...)。
## allow_experimental_database_unity_catalog {#allow_experimental_database_unity_catalog} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "0"},{"label": "允许实验性数据库引擎 DataLakeCatalog，目录类型 = 'unity'"}]}]}/>

允许实验性数据库引擎 DataLakeCatalog，目录类型 = 'unity'。
## allow_experimental_delta_kernel_rs {#allow_experimental_delta_kernel_rs} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新设置"}]}]}/>

允许实验性 delta-kernel-rs 实现。
## allow_experimental_dynamic_type {#allow_experimental_dynamic_type} 


<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "1"},{"label": "动态数据类型已准备好生产使用"}]}, {"id": "row-2","items": [{"label": "24.5"},{"label": "0"},{"label": "添加新的实验性动态类型"}]}]}/>

允许创建 [Dynamic](../../sql-reference/data-types/dynamic.md) 数据类型。
## allow_experimental_full_text_index {#allow_experimental_full_text_index} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "启用实验性全文索引"}]}]}/>

如果设置为 true，允许使用实验性全文索引。
## allow_experimental_funnel_functions {#allow_experimental_funnel_functions} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

启用用于漏斗分析的实验性函数。
## allow_experimental_hash_functions {#allow_experimental_hash_functions} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

启用实验性哈希函数。
## allow_experimental_inverted_index {#allow_experimental_inverted_index} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

如果设置为 true，则允许使用实验性的倒排索引。
## allow_experimental_join_condition {#allow_experimental_join_condition} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "0"},{"label": "支持与不等条件的连接，这涉及到左右表的列。例如 t1.y < t2.y。"}]}]}/>

支持与不等条件的连接，这涉及到左右表的列。例如 `t1.y < t2.y`。
## allow_experimental_join_right_table_sorting {#allow_experimental_join_right_table_sorting} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "如果设置为 true，并且满足 `join_to_sort_minimum_perkey_rows` 和 `join_to_sort_maximum_table_rows` 的条件，按键重新排列右表以提高左连接或内连接的性能"}]}]}/>

如果设置为 true，并且满足 `join_to_sort_minimum_perkey_rows` 和 `join_to_sort_maximum_table_rows` 的条件，按键重新排列右表以提高左连接或内连接的性能。
## allow_experimental_json_type {#allow_experimental_json_type} 


<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "1"},{"label": "JSON 数据类型已准备好生产使用"}]}, {"id": "row-2","items": [{"label": "24.8"},{"label": "0"},{"label": "添加新的实验性 JSON 类型"}]}]}/>

允许创建 [JSON](../../sql-reference/data-types/newjson.md) 数据类型。
## allow_experimental_kafka_offsets_storage_in_keeper {#allow_experimental_kafka_offsets_storage_in_keeper} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "允许使用实验性的 Kafka 存储引擎，该引擎将已提交的偏移存储在 ClickHouse Keeper 中。"}]}]}/>

允许实验性特性将 Kafka 相关的偏移存储在 ClickHouse Keeper 中。启用后，可以向 Kafka 表引擎指定 ClickHouse Keeper 路径和副本名称。因此，将使用新的存储引擎类型，主要将已提交的偏移存储在 ClickHouse Keeper 中。
## allow_experimental_kusto_dialect {#allow_experimental_kusto_dialect} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新增设置"}]}]}/>

启用 Kusto 查询语言（KQL）- SQL 的替代方案。
## allow_experimental_lightweight_update {#allow_experimental_lightweight_update} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "新设置"}]}]}/>

允许使用轻量级更新。
## allow_experimental_live_view {#allow_experimental_live_view} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

允许创建已弃用的 LIVE VIEW。

可能的值：

- 0 — 禁用处理实时视图。
- 1 — 启用处理实时视图。
## allow_experimental_materialized_postgresql_table {#allow_experimental_materialized_postgresql_table} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

允许使用 MaterializedPostgreSQL 表引擎。默认禁用，因为这个功能仍在实验中。
## allow_experimental_nlp_functions {#allow_experimental_nlp_functions} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

启用用于自然语言处理的实验性函数。
## allow_experimental_object_type {#allow_experimental_object_type} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

允许过时的 Object 数据类型。
## allow_experimental_parallel_reading_from_replicas {#allow_experimental_parallel_reading_from_replicas} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />

在执行 SELECT 查询时，从每个分片的 `max_parallel_replicas` 数量的副本中读取。读取是并行化并动态协调的。0 - 禁用，1 - 启用，在发生故障时静默禁用，2 - 启用，在发生故障时抛出异常。
## allow_experimental_prql_dialect {#allow_experimental_prql_dialect} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新增设置"}]}]}/>

启用 PRQL - SQL 的替代方案。
## allow_experimental_query_deduplication {#allow_experimental_query_deduplication} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

基于分区 UUID 的 SELECT 查询的实验性数据去重。
## allow_experimental_statistics {#allow_experimental_statistics} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "该设置已重命名。旧名称为 `allow_experimental_statistic`。"}]}]}/>

允许定义带有 [statistics](../../engines/table-engines/mergetree-family/mergetree.md/#table_engine-mergetree-creating-a-table) 的列，并 [操纵统计数据](../../engines/table-engines/mergetree-family/mergetree.md/#column-statistics)。
## allow_experimental_time_series_table {#allow_experimental_time_series_table} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "添加新设置以允许 TimeSeries 表引擎"}]}]}/>

允许创建使用 [TimeSeries](../../engines/table-engines/integrations/time-series.md) 表引擎的表。可能的值：
- 0 — 禁用 [TimeSeries](../../engines/table-engines/integrations/time-series.md) 表引擎。
- 1 — 启用 [TimeSeries](../../engines/table-engines/integrations/time-series.md) 表引擎。
## allow_experimental_ts_to_grid_aggregate_function {#allow_experimental_ts_to_grid_aggregate_function} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "仅适用于云"}]}]}/>

实验性的 tsToGrid 聚合函数，用于 Prometheus 类似时间序列的重采样。仅适用于云。
## allow_experimental_variant_type {#allow_experimental_variant_type} 


<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "1"},{"label": "Variant 数据类型已准备好生产使用"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "0"},{"label": "添加新的实验性 Variant 类型"}]}]}/>

允许创建 [Variant](../../sql-reference/data-types/variant.md) 数据类型。
## allow_experimental_vector_similarity_index {#allow_experimental_vector_similarity_index} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "添加新的设置以允许实验性的向量相似性索引"}]}]}/>

允许实验性的向量相似性索引。
## allow_experimental_window_view {#allow_experimental_window_view} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

启用 WINDOW VIEW。尚未成熟。
## allow_general_join_planning {#allow_general_join_planning} 


<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "在启用哈希连接算法时，允许更一般的连接规划算法。"}]}]}/>

允许更一般的连接规划算法，该算法能够处理更复杂的条件，但仅适用于哈希连接。如果未启用哈希连接，则无论此设置的值如何，都将使用常规的连接规划算法。
## allow_get_client_http_header {#allow_get_client_http_header} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "引入了一个新函数。"}]}]}/>

允许使用函数 `getClientHTTPHeader`，该函数允许获取当前 HTTP 请求头的值。出于安全原因，默认情况下不启用此功能，因为某些头信息，如 `Cookie`，可能包含敏感信息。请注意，`X-ClickHouse-*` 和 `Authentication` 头始终受到限制，无法通过此函数获取。
## allow_hyperscan {#allow_hyperscan} 


<SettingsInfoBlock type="Bool" default_value="1" />

允许使用 Hyperscan 库的函数。如果禁用，使用 rapidjson。
## allow_introspection_functions {#allow_introspection_functions} 


<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用 [自省函数](../../sql-reference/functions/introspection.md)，以便进行查询分析。

可能的值：

- 1 — 启用自省函数。
- 0 — 禁用自省函数。

**另请参见**

- [抽样查询分析器](../../operations/optimizing-performance/sampling-query-profiler.md)
- 系统表 [trace_log](/operations/system-tables/trace_log)
## allow_materialized_view_with_bad_select {#allow_materialized_view_with_bad_select} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "不允许创建引用不存在列或表的物化视图"}]}, {"id": "row-2","items": [{"label": "24.9"},{"label": "1"},{"label": "支持（但尚未启用）在 CREATE MATERIALIZED VIEW 中进行更严格的验证"}]}]}/>

允许使用引用不存在表或列的 SELECT 查询创建物化视图。它仍然必须在语法上有效。无效于可更新的物化视图。如果物化视图的模式需要从 SELECT 查询推断（即，如果 CREATE 没有列列表且没有 TO 表），则也不适用。可以在其源表创建物化视图之前使用它。
## allow_named_collection_override_by_default {#allow_named_collection_override_by_default} 


<SettingsInfoBlock type="Bool" default_value="1" />

允许默认覆盖命名集合的字段。
## allow_non_metadata_alters {#allow_non_metadata_alters} 


<SettingsInfoBlock type="Bool" default_value="1" />

允许执行不仅影响表元数据的更改，还影响磁盘上的数据。
## allow_nonconst_timezone_arguments {#allow_nonconst_timezone_arguments} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "0"},{"label": "允许在 certain 与时间相关的函数中使用非常量时区参数，例如 toTimeZone(), fromUnixTimestamp*(), snowflakeToDateTime*()。"}]}]}/>

允许在某些与时间相关的函数中使用非常量时区参数，例如 toTimeZone(), fromUnixTimestamp*(), snowflakeToDateTime*()。
## allow_nondeterministic_mutations {#allow_nondeterministic_mutations} 


<SettingsInfoBlock type="Bool" default_value="0" />

用户级设置，允许在复制表上进行使用非确定性函数（如 `dictGet`）的变更。

由于例如字典可以在节点之间不同步，默认情况下，使用字典中的值进行的变更在复制表上是被禁止的。启用此设置将允许此行为，用户必须承担确保使用的数据在所有节点之间同步的责任。

**示例**

```xml
<profiles>
    <default>
        <allow_nondeterministic_mutations>1</allow_nondeterministic_mutations>

        <!-- ... -->
    </default>

    <!-- ... -->

</profiles>
```
## allow_nondeterministic_optimize_skip_unused_shards {#allow_nondeterministic_optimize_skip_unused_shards} 


<SettingsInfoBlock type="Bool" default_value="0" />

允许在分片键中使用不确定的（如 `rand` 或 `dictGet`，因为后者在更新时存在一些注意事项）函数。

可能的值：

- 0 — 不允许。
- 1 — 允许。
## allow_not_comparable_types_in_comparison_functions {#allow_not_comparable_types_in_comparison_functions} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "默认情况下不允许在比较函数中使用不可比较的类型"}]}]}/>

允许或限制在比较函数 `equal/less/greater/etc` 中使用不可比较的类型（如 JSON/Object/AggregateFunction）。
## allow_not_comparable_types_in_order_by {#allow_not_comparable_types_in_order_by} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "默认情况下不允许在 ORDER BY 键中使用不可比较的类型"}]}]}/>

允许或限制在 ORDER BY 键中使用不可比较的类型（如 JSON/Object/AggregateFunction）。
## allow_prefetched_read_pool_for_local_filesystem {#allow_prefetched_read_pool_for_local_filesystem} 


<SettingsInfoBlock type="Bool" default_value="0" />

如果所有部分在本地文件系统上，优先使用预取线程池。
## allow_prefetched_read_pool_for_remote_filesystem {#allow_prefetched_read_pool_for_remote_filesystem} 


<SettingsInfoBlock type="Bool" default_value="1" />

如果所有部分在远程文件系统上，优先使用预取线程池。
## allow_push_predicate_ast_for_distributed_subqueries {#allow_push_predicate_ast_for_distributed_subqueries} 


<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "新增设置"}]}]}/>

允许在采用启用分析器的分布式子查询时对 AST 级别进行推送谓词。
## allow_push_predicate_when_subquery_contains_with {#allow_push_predicate_when_subquery_contains_with} 


<SettingsInfoBlock type="Bool" default_value="1" />

允许在包含 WITH 子句时推送谓词。
## allow_reorder_prewhere_conditions {#allow_reorder_prewhere_conditions} 


<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "新设置"}]}]}/>

在将条件从 WHERE 移至 PREWHERE 时，允许重新排序以优化过滤。
## allow_settings_after_format_in_insert {#allow_settings_after_format_in_insert} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.4"},{"label": "0"},{"label": "不允许在 INSERT 查询的 FORMAT 后使用 SETTINGS，因为 ClickHouse 将 SETTINGS 解释为某些值，这可能会误导"}]}]}/>

控制是否允许在 INSERT 查询的 FORMAT 后使用 `SETTINGS`。不建议使用此功能，因为这可能会将部分 `SETTINGS` 解释为值。

示例：

```sql
INSERT INTO FUNCTION null('foo String') SETTINGS max_threads=1 VALUES ('bar');
```

但以下查询仅在 `allow_settings_after_format_in_insert` 为 1 时有效：

```sql
SET allow_settings_after_format_in_insert=1;
INSERT INTO FUNCTION null('foo String') VALUES ('bar') SETTINGS max_threads=1;
```

可能的值：

- 0 — 禁止。
- 1 — 允许。

:::note
仅在您依赖旧语法的用例需要向后兼容时，使用此设置。
:::
## allow_simdjson {#allow_simdjson} 


<SettingsInfoBlock type="Bool" default_value="1" />

允许在可用，则使用 simdjson 库来处理 'JSON*' 函数。如果禁用，将使用 rapidjson。
## allow_statistics_optimize {#allow_statistics_optimize} 

<ExperimentalBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "该设置已重命名。旧名称为 `allow_statistic_optimize`。"}]}]}/>

允许使用统计信息来优化查询。
## allow_suspicious_codecs {#allow_suspicious_codecs} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "20.5"},{"label": "0"},{"label": "不允许指定无意义的压缩编码"}]}]}/>

如果设置为 true，允许指定无意义的压缩编码。
## allow_suspicious_fixed_string_types {#allow_suspicious_fixed_string_types} 


<SettingsInfoBlock type="Bool" default_value="0" />

在 CREATE TABLE 语句中允许创建类型为 FixedString(n) 且 n > 256 的列。FixedString 的长度大于等于 256 是可疑的，并且很可能表示误用。
## allow_suspicious_indices {#allow_suspicious_indices} 


<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "0"},{"label": "如果为 true，则可以定义带有相同表达式的主/次索引和排序键"}]}]}/>

拒绝带有相同表达式的主/次索引和排序键。
## allow_suspicious_low_cardinality_types {#allow_suspicious_low_cardinality_types} 



<SettingsInfoBlock type="Bool" default_value="0" />

允许或限制使用 [LowCardinality](../../sql-reference/data-types/lowcardinality.md) 与固定大小为8字节或更少的数据类型：数值数据类型和 `FixedString(8_bytes_or_less)`。

对于小的固定值，使用 `LowCardinality` 通常效率不高，因为 ClickHouse 为每行存储一个数值索引。结果是：

- 磁盘空间使用量可能会上升。
- RAM 消耗可能更高，取决于字典的大小。
- 由于额外的编码/解码操作，某些函数的性能可能会降低。

由于上述所有原因，在 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 引擎表中的合并时间可能会增加。

可能的值：

- 1 — 不限制使用 `LowCardinality`。
- 0 — 限制使用 `LowCardinality`。
## allow_suspicious_primary_key {#allow_suspicious_primary_key} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "禁止 MergeTree 中可疑的 PRIMARY KEY/ORDER BY（即 SimpleAggregateFunction）"}]}]}/>

允许在 MergeTree 中使用可疑的 `PRIMARY KEY`/`ORDER BY`（即 SimpleAggregateFunction）。
## allow_suspicious_ttl_expressions {#allow_suspicious_ttl_expressions} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.12"},{"label": "0"},{"label": "这是一个新设置，之前的行为相当于允许。如果用户错误则表示不依赖于任何表的列的 TTL 表达式。"}]}]}/>

拒绝不依赖于任何表的列的 TTL 表达式。这通常表示用户错误。
## allow_suspicious_types_in_group_by {#allow_suspicious_types_in_group_by} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "默认不允许在 GROUP BY 中使用 Variant/Dynamic 类型"}]}]}/>

允许或限制在 GROUP BY 键中使用 [Variant](../../sql-reference/data-types/variant.md) 和 [Dynamic](../../sql-reference/data-types/dynamic.md) 类型。
## allow_suspicious_types_in_order_by {#allow_suspicious_types_in_order_by} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "默认不允许在 ORDER BY 中使用 Variant/Dynamic 类型"}]}]}/>

允许或限制在 ORDER BY 键中使用 [Variant](../../sql-reference/data-types/variant.md) 和 [Dynamic](../../sql-reference/data-types/dynamic.md) 类型。
## allow_suspicious_variant_types {#allow_suspicious_variant_types} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0"},{"label": "默认不允许创建可疑变体的 Variant 类型"}]}]}/>

在 CREATE TABLE 语句中允许指定具有相似变体类型的 Variant 类型（例如，具有不同的数字或日期类型）。启用此设置可能在处理相似类型的值时引入一些歧义。
## allow_unrestricted_reads_from_keeper {#allow_unrestricted_reads_from_keeper} 



<SettingsInfoBlock type="Bool" default_value="0" />

允许不受限制（没有路径条件）的从 system.zookeeper 表读取，这可能很方便，但对 zookeeper 来说不安全。
## alter_move_to_space_execute_async {#alter_move_to_space_execute_async} 



<SettingsInfoBlock type="Bool" default_value="0" />

异步执行 ALTER TABLE MOVE ... TO [DISK|VOLUME]
## alter_partition_verbose_result {#alter_partition_verbose_result} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用显示关于成功应用于分区和部分的操作的信息。
适用于 [ATTACH PARTITION|PART](/sql-reference/statements/alter/partition#attach-partitionpart) 和 [FREEZE PARTITION](/sql-reference/statements/alter/partition#freeze-partition)。

可能的值：

- 0 — 禁用详细信息。
- 1 — 启用详细信息。

**示例**

```sql
CREATE TABLE test(a Int64, d Date, s String) ENGINE = MergeTree PARTITION BY toYYYYMDECLARE(d) ORDER BY a;
INSERT INTO test VALUES(1, '2021-01-01', '');
INSERT INTO test VALUES(1, '2021-01-01', '');
ALTER TABLE test DETACH PARTITION ID '202101';

ALTER TABLE test ATTACH PARTITION ID '202101' SETTINGS alter_partition_verbose_result = 1;

┌─command_type─────┬─partition_id─┬─part_name────┬─old_part_name─┐
│ ATTACH PARTITION │ 202101       │ 202101_7_7_0 │ 202101_5_5_0  │
│ ATTACH PARTITION │ 202101       │ 202101_8_8_0 │ 202101_6_6_0  │
└──────────────────┴──────────────┴──────────────┴───────────────┘

ALTER TABLE test FREEZE SETTINGS alter_partition_verbose_result = 1;

┌─command_type─┬─partition_id─┬─part_name────┬─backup_name─┬─backup_path───────────────────┬─part_backup_path────────────────────────────────────────────┐
│ FREEZE ALL   │ 202101       │ 202101_7_7_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_7_7_0 │
│ FREEZE ALL   │ 202101       │ 202101_8_8_0 │ 8           │ /var/lib/clickhouse/shadow/8/ │ /var/lib/clickhouse/shadow/8/data/default/test/202101_8_8_0 │
└──────────────┴──────────────┴──────────────┴─────────────┴───────────────────────────────┴─────────────────────────────────────────────────────────────┘
```
## alter_sync {#alter_sync} 



<SettingsInfoBlock type="UInt64" default_value="1" />

允许在 [ALTER](../../sql-reference/statements/alter/index.md)、[OPTIMIZE](../../sql-reference/statements/optimize.md) 或 [TRUNCATE](../../sql-reference/statements/truncate.md) 查询上设置等待以执行操作在副本上。

可能的值：

- 0 — 不等待。
- 1 — 等待自己的执行。
- 2 — 等待所有人。

云默认值：`0`。

:::note
`alter_sync` 仅适用于 `Replicated` 表，对非 `Replicated` 表的更改无效。
:::
## alter_update_mode {#alter_update_mode} 



<SettingsInfoBlock type="AlterUpdateMode" default_value="heavy" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "heavy"},{"label": "新设置"}]}]}/>

用于包含 `UPDATE` 命令的 `ALTER` 查询的模式。

可能的值：
- `heavy` - 运行常规变更。
- `lightweight` - 尝试运行轻量级更新，如果不可能则运行常规变更。
- `lightweight_force` - 如果可能，运行轻量级更新，否则抛出异常。
## analyze_index_with_space_filling_curves {#analyze_index_with_space_filling_curves} 



<SettingsInfoBlock type="Bool" default_value="1" />

如果表的索引中有空间填充曲线，例如 `ORDER BY mortonEncode(x, y)` 或 `ORDER BY hilbertEncode(x, y)`，且查询对其参数有条件，例如 `x >= 10 AND x <= 20 AND y >= 20 AND y <= 30`，则使用空间填充曲线进行索引分析。
## analyzer_compatibility_join_using_top_level_identifier {#analyzer_compatibility_join_using_top_level_identifier} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "强制从投影中解析 JOIN USING 的标识符"}]}]}/>

强制从投影中解析 JOIN USING 的标识符（例如，在 `SELECT a + 1 AS b FROM t1 JOIN t2 USING (b)` 中，连接将通过 `t1.a + 1 = t2.b` 进行，而不是 `t1.b = t2.b`）。
## any_join_distinct_right_table_keys {#any_join_distinct_right_table_keys} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "19.14"},{"label": "0"},{"label": "默认禁用 ANY RIGHT 和 ANY FULL JOIN 以避免不一致"}]}]}/>

启用 ClickHouse 服务器在 `ANY INNER|LEFT JOIN` 操作中的遗留行为。

:::note
仅在您的用例依赖于遗留 `JOIN` 行为时，才使用此设置以实现向后兼容性。
:::

当遗留行为被启用时：

- `t1 ANY LEFT JOIN t2` 和 `t2 ANY RIGHT JOIN t1` 操作的结果不相等，因为 ClickHouse 使用了左到右的多对一表键映射逻辑。
- `ANY INNER JOIN` 操作的结果包含来自左表的所有行，类似于 `SEMI LEFT JOIN` 操作。

当遗留行为被禁用时：

- `t1 ANY LEFT JOIN t2` 和 `t2 ANY RIGHT JOIN t1` 操作的结果相等，因为 ClickHouse 使用了在 `ANY RIGHT JOIN` 操作中提供一对多键映射的逻辑。
- `ANY INNER JOIN` 操作的结果包含来自左表和右表的每个键的一行。

可能的值：

- 0 — 禁用遗留行为。
- 1 — 启用遗留行为。

另请参阅：

- [JOIN 严格性](/sql-reference/statements/select/join#settings)
## apply_deleted_mask {#apply_deleted_mask} 



<SettingsInfoBlock type="Bool" default_value="1" />

启用过滤掉已使用轻量级删除删除的行。如果禁用，查询将能够读取这些行。这在调试和 "撤消删除" 场景中很有用。
## apply_mutations_on_fly {#apply_mutations_on_fly} 



<SettingsInfoBlock type="Bool" default_value="0" />

如果为真，则在未在数据部分中实现的变更（UPDATE 和 DELETE）将在 SELECT 中应用。
## apply_patch_parts {#apply_patch_parts} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新设置"}]}]}/>

如果为真，补丁部分（代表轻量级更新）将在 SELECT 中应用。
## apply_settings_from_server {#apply_settings_from_server} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "客户端代码（例如 INSERT 输入解析和查询输出格式化）将使用与服务器相同的设置，包括服务器配置中的设置。"}]}]}/>

客户端是否应接受来自服务器的设置。

这仅影响在客户端执行的操作，特别是解析 INSERT 输入数据和格式化查询结果。大部分查询执行在服务器上进行，不受此设置影响。

通常，此设置应在用户配置文件中设置（users.xml 或查询 `ALTER USER`），而不是通过客户端（客户端命令行参数、`SET` 查询或 `SELECT` 查询的 `SETTINGS` 部分）。通过客户端可以将其更改为 false，但无法更改为 true（因为如果用户配置文件中有 `apply_settings_from_server = false`，则服务器不会发送设置）。

请注意，最初（24.12）有一个服务器设置（`send_settings_to_client`），但后来被客户端设置替换，以提高可用性。
## asterisk_include_alias_columns {#asterisk_include_alias_columns} 



<SettingsInfoBlock type="Bool" default_value="0" />

为通配符查询（`SELECT *`）包含 [ALIAS](../../sql-reference/statements/create/table.md/#alias) 列。

可能的值：

- 0 - 禁用
- 1 - 启用
## asterisk_include_materialized_columns {#asterisk_include_materialized_columns} 



<SettingsInfoBlock type="Bool" default_value="0" />

为通配符查询（`SELECT *`）包含 [MATERIALIZED](/sql-reference/statements/create/view#materialized-view) 列。

可能的值：

- 0 - 禁用
- 1 - 启用
## async_insert {#async_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

如果为真，从 INSERT 查询的数据显示存储在队列中，之后在后台刷新到表中。如果 wait_for_async_insert 为 false，INSERT 查询几乎瞬间处理；否则客户端将等到数据刷新到表中。
## async_insert_busy_timeout_decrease_rate {#async_insert_busy_timeout_decrease_rate} 



<SettingsInfoBlock type="Double" default_value="0.2" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0.2"},{"label": "自适应异步插入超时下降的指数增长率"}]}]}/>

自适应异步插入超时下降的指数增长率。
## async_insert_busy_timeout_increase_rate {#async_insert_busy_timeout_increase_rate} 



<SettingsInfoBlock type="Double" default_value="0.2" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0.2"},{"label": "自适应异步插入超时增加的指数增长率"}]}]}/>

自适应异步插入超时增加的指数增长率。
## async_insert_busy_timeout_max_ms {#async_insert_busy_timeout_max_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="200" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "200"},{"label": "异步插入超时的最小值，单位为毫秒；async_insert_busy_timeout_ms 别名为 async_insert_busy_timeout_max_ms"}]}]}/>

在查询中收集的数据自首次出现以来，最大等待时间。
## async_insert_busy_timeout_min_ms {#async_insert_busy_timeout_min_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="50" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "50"},{"label": "异步插入超时的最小值，单位为毫秒；它还可以作为初始值，可能由自适应算法之后增加"}]}]}/>

如果通过 async_insert_use_adaptive_busy_timeout 启用自适应，等待的最小时间，单位为毫秒，自首次出现的数据以来。它还可以作为自适应算法的初始值。
## async_insert_deduplicate {#async_insert_deduplicate} 



<SettingsInfoBlock type="Bool" default_value="0" />

对于复制表的异步 INSERT 查询，指定是否应执行插入块的去重。
## async_insert_max_data_size {#async_insert_max_data_size} 



<SettingsInfoBlock type="UInt64" default_value="10485760" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "10485760"},{"label": "之前的值似乎太小。"}]}]}/>

在插入之前每个查询收集的未解析数据的最大字节数。
## async_insert_max_query_number {#async_insert_max_query_number} 



<SettingsInfoBlock type="UInt64" default_value="450" />

要插入的最大查询数量。
## async_insert_poll_timeout_ms {#async_insert_poll_timeout_ms} 



<SettingsInfoBlock type="Milliseconds" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "10"},{"label": "从异步插入队列轮询数据的超时（毫秒）"}]}]}/>

从异步插入队列轮询数据的超时（毫秒）。
## async_insert_use_adaptive_busy_timeout {#async_insert_use_adaptive_busy_timeout} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "使用自适应异步插入超时"}]}]}/>

如果设置为 true，则为异步插入使用自适应忙碌超时。
## async_query_sending_for_remote {#async_query_sending_for_remote} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.3"},{"label": "1"},{"label": "在执行远程查询时创建连接并异步发送查询"}]}]}/>

启用在执行远程查询时的异步连接创建和查询发送。

默认启用。
## async_socket_for_remote {#async_socket_for_remote} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.5"},{"label": "1"},{"label": "修复所有问题并再次默认启用远程查询的异步读取（Socket）"}]}, {"id": "row-2","items": [{"label": "21.3"},{"label": "0"},{"label": "由于一些问题，禁用了远程查询的 Socket 异步读取。"}]}]}/>

启用在执行远程查询时的异步读取（Socket）。

默认启用。
## azure_allow_parallel_part_upload {#azure_allow_parallel_part_upload} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "true"},{"label": "使用多个线程进行 Azure 多部分上传。"}]}]}/>

使用多个线程进行 Azure 多部分上传。
## azure_check_objects_after_upload {#azure_check_objects_after_upload} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "检查每个上传的对象在 Azure Blob 存储中是否成功上传。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "0"},{"label": "检查每个上传的对象在 Azure Blob 存储中是否成功上传。"}]}]}/>

检查每个上传的对象在 Azure Blob 存储中是否成功上传。
## azure_create_new_file_on_insert {#azure_create_new_file_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在每次插入 Azure 引擎表时创建新文件。
## azure_ignore_file_doesnt_exist {#azure_ignore_file_doesnt_exist} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "允许在 AzureBlobStorage 表引擎中读取某些键时返回 0 行，而不是抛出异常。"}]}]}/>

如果读取时文件不存在，则忽略文件的缺失。

可能的值：
- 1 — `SELECT` 返回空结果。
- 0 — `SELECT` 抛出异常。
## azure_list_object_keys_size {#azure_list_object_keys_size} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

ListObject 请求中可以返回的最大文件数量。
## azure_max_blocks_in_multipart_upload {#azure_max_blocks_in_multipart_upload} 



<SettingsInfoBlock type="UInt64" default_value="50000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "50000"},{"label": "Azure 的最大多部分上传块数。"}]}]}/>

Azure 的最大多部分上传块数。
## azure_max_inflight_parts_for_one_file {#azure_max_inflight_parts_for_one_file} 



<SettingsInfoBlock type="UInt64" default_value="20" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "20"},{"label": "并发加载的多部分上传请求的最大块数量。 0 表示无限制。"}]}]}/>

并发加载的多部分上传请求的最大块数量。 0 表示无限制。
## azure_max_single_part_copy_size {#azure_max_single_part_copy_size} 



<SettingsInfoBlock type="UInt64" default_value="268435456" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "268435456"},{"label": "使用单部分复制到 Azure Blob 存储的最大对象大小。"}]}]}/>

使用单部分复制到 Azure Blob 存储的最大对象大小。
## azure_max_single_part_upload_size {#azure_max_single_part_upload_size} 



<SettingsInfoBlock type="UInt64" default_value="104857600" />

使用单部分上传到 Azure Blob 存储的对象的最大大小。
## azure_max_single_read_retries {#azure_max_single_read_retries} 



<SettingsInfoBlock type="UInt64" default_value="4" />

在进行单次 Azure Blob 存储读取时的最大重试次数。
## azure_max_unexpected_write_error_retries {#azure_max_unexpected_write_error_retries} 



<SettingsInfoBlock type="UInt64" default_value="4" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "4"},{"label": "在 Azure Blob 存储写入期间遇到意外错误时的最大重试次数。"}]}]}/>

在 Azure Blob 存储写入期间遇到意外错误时的最大重试次数。
## azure_max_upload_part_size {#azure_max_upload_part_size} 



<SettingsInfoBlock type="UInt64" default_value="5368709120" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "5368709120"},{"label": "在 Azure Blob 存储的多部分上传中，上传部分的最大大小。"}]}]}/>

在 Azure Blob 存储的多部分上传中，上传部分的最大大小。
## azure_min_upload_part_size {#azure_min_upload_part_size} 



<SettingsInfoBlock type="UInt64" default_value="16777216" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "16777216"},{"label": "在 Azure Blob 存储的多部分上传中，上传部分的最小大小。"}]}]}/>

在 Azure Blob 存储的多部分上传中，上传部分的最小大小。
## azure_sdk_max_retries {#azure_sdk_max_retries} 



<SettingsInfoBlock type="UInt64" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "10"},{"label": "在 Azure SDK 中的最大重试次数。"}]}]}/>

在 Azure SDK 中的最大重试次数。
## azure_sdk_retry_initial_backoff_ms {#azure_sdk_retry_initial_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "10"},{"label": "在 Azure SDK 中重试之间的最小退避时间。"}]}]}/>

在 Azure SDK 中重试之间的最小退避时间。
## azure_sdk_retry_max_backoff_ms {#azure_sdk_retry_max_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1000"},{"label": "在 Azure SDK 中重试之间的最大退避时间。"}]}]}/>

在 Azure SDK 中重试之间的最大退避时间。
## azure_skip_empty_files {#azure_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "在 Azure 表引擎中允许跳过空文件。"}]}]}/>

启用或禁用在 S3 引擎中跳过空文件。

可能的值：
- 0 — 如果空文件与请求的格式不兼容，则 `SELECT` 抛出异常。
- 1 — `SELECT` 返回空结果以处理空文件。
## azure_strict_upload_part_size {#azure_strict_upload_part_size} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "在 Azure Blob 存储的多部分上传中，上传部分的确切大小。"}]}]}/>

在 Azure Blob 存储的多部分上传中，上传部分的确切大小。
## azure_throw_on_zero_files_match {#azure_throw_on_zero_files_match} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "如果 ListObjects 请求无法匹配 AzureBlobStorage 引擎中的任何文件，则允许抛出错误，而不是返回空查询结果。"}]}]}/>

如果根据 glob 扩展规则匹配到零个文件，则抛出错误。

可能的值：
- 1 — `SELECT` 抛出异常。
- 0 — `SELECT` 返回空结果。
## azure_truncate_on_insert {#azure_truncate_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在 Azure 引擎表中插入之前进行截断。
## azure_upload_part_size_multiply_factor {#azure_upload_part_size_multiply_factor} 



<SettingsInfoBlock type="UInt64" default_value="2" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "2"},{"label": "在从单次写入 Azure Blob 存储上传了 azure_multiply_parts_count_threshold 部分时，将 azure_min_upload_part_size 乘以此因子。"}]}]}/>

在从单次写入 Azure Blob 存储上传了 azure_multiply_parts_count_threshold 部分时，将 azure_min_upload_part_size 乘以此因子。
## azure_upload_part_size_multiply_parts_count_threshold {#azure_upload_part_size_multiply_parts_count_threshold} 



<SettingsInfoBlock type="UInt64" default_value="500" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "500"},{"label": "每次上传此数量的部分到 Azure Blob 存储时，azure_min_upload_part_size 都会乘以 azure_upload_part_size_multiply_factor。"}]}]}/>

每次上传此数量的部分到 Azure Blob 存储时，azure_min_upload_part_size 都会乘以 azure_upload_part_size_multiply_factor。
## backup_restore_batch_size_for_keeper_multi {#backup_restore_batch_size_for_keeper_multi} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

在备份或还原期间对 [Zoo]Keeper 的多请求的最大批大小。
## backup_restore_batch_size_for_keeper_multiread {#backup_restore_batch_size_for_keeper_multiread} 



<SettingsInfoBlock type="UInt64" default_value="10000" />

在备份或还原期间对 [Zoo]Keeper 的多读请求的最大批大小。
## backup_restore_failure_after_host_disconnected_for_seconds {#backup_restore_failure_after_host_disconnected_for_seconds} 



<SettingsInfoBlock type="UInt64" default_value="3600" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "3600"},{"label": "新设置。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "3600"},{"label": "新设置。"}]}]}/>

如果在 BACKUP ON CLUSTER 或 RESTORE ON CLUSTER 操作期间，主机在此段时间内未重新创建其在 ZooKeeper 中的短暂"存活"节点，则整个备份或还原视为失败。
此值应该大于主机在故障后重新连接到 ZooKeeper 的任何合理时间。
零表示无限制。
## backup_restore_finish_timeout_after_error_sec {#backup_restore_finish_timeout_after_error_sec} 



<SettingsInfoBlock type="UInt64" default_value="180" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "180"},{"label": "新设置。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "180"},{"label": "新设置。"}]}]}/>

发起者应该等待多长时间，以便其他主机对 "错误" 节点的反应，并停止在当前 BACKUP ON CLUSTER 或 RESTORE ON CLUSTER 操作中的工作。
## backup_restore_keeper_fault_injection_probability {#backup_restore_keeper_fault_injection_probability} 



<SettingsInfoBlock type="Float" default_value="0" />

在备份或还原期间，keeper 请求的故障的近似概率。有效值在区间 [0.0f, 1.0f] 内。
## backup_restore_keeper_fault_injection_seed {#backup_restore_keeper_fault_injection_seed} 



<SettingsInfoBlock type="UInt64" default_value="0" />

0 - 随机种子，否则为设置值。
## backup_restore_keeper_max_retries {#backup_restore_keeper_max_retries} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1000"},{"label": "应该足够大，以便整个操作备份或还原不会因临时 [Zoo]Keeper 故障而失败。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "1000"},{"label": "应该足够大，以便整个操作备份或还原不会因临时 [Zoo]Keeper 故障而失败。"}]}]}/>

在备份或还原操作中间对 [Zoo]Keeper 操作的最大重试次数。
应该足够大，以便整个操作不会因临时 [Zoo]Keeper 故障而失败。
## backup_restore_keeper_max_retries_while_handling_error {#backup_restore_keeper_max_retries_while_handling_error} 



<SettingsInfoBlock type="UInt64" default_value="20" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "20"},{"label": "新设置。"}]}, {"id": "row-2","items": [{"label": "24.10","label": "20"},{"label": "新设置。"}]}]}/>

在处理 BACKUP ON CLUSTER 或 RESTORE ON CLUSTER 操作中的错误时，对 [Zoo]Keeper 操作的最大重试次数。
## backup_restore_keeper_max_retries_while_initializing {#backup_restore_keeper_max_retries_while_initializing} 



<SettingsInfoBlock type="UInt64" default_value="20" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "20"},{"label": "新设置。"}]}, {"id": "row-2","items": [{"label": "24.10","label": "20"},{"label": "新设置。"}]}]}/>

在初始化 BACKUP ON CLUSTER 或 RESTORE ON CLUSTER 操作期间，对 [Zoo]Keeper 操作的最大重试次数。
## backup_restore_keeper_retry_initial_backoff_ms {#backup_restore_keeper_retry_initial_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="100" />

在备份或还原期间，对 [Zoo]Keeper 操作的初始退避超时。
## backup_restore_keeper_retry_max_backoff_ms {#backup_restore_keeper_retry_max_backoff_ms} 



<SettingsInfoBlock type="UInt64" default_value="5000" />

在备份或还原期间，对 [Zoo]Keeper 操作的最大退避超时。
## backup_restore_keeper_value_max_size {#backup_restore_keeper_value_max_size} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />

在备份期间 [Zoo]Keeper 节点的数据最大大小。
## backup_restore_s3_retry_attempts {#backup_restore_s3_retry_attempts} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1000"},{"label": "设置 Aws::Client::RetryStrategy，Aws::Client 自己进行重试，0 表示不重试。仅适用于备份/还原。"}]}]}/>

设置 Aws::Client::RetryStrategy，Aws::Client 自己进行重试，0 表示不重试。仅适用于备份/还原。
## cache_warmer_threads {#cache_warmer_threads} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="4" />

仅在 ClickHouse Cloud 中生效。用于在启用 [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch) 时，后台线程的数量，用于投机性地将新数据片段下载到文件缓存中。设置为零以禁用该功能。

## calculate_text_stack_trace {#calculate_text_stack_trace} 

<SettingsInfoBlock type="Bool" default_value="1" />

在查询执行过程中发生异常时计算文本栈跟踪。这是默认行为。它需要符号查找，可能会在执行大量错误查询时降低模糊测试的速度。在正常情况下，您不应禁用此选项。

## cancel_http_readonly_queries_on_client_close {#cancel_http_readonly_queries_on_client_close} 

<SettingsInfoBlock type="Bool" default_value="0" />

当客户端关闭连接而不等待响应时，取消 HTTP 只读查询（例如 SELECT）。

云默认值：`1`。

## cast_ipv4_ipv6_default_on_conversion_error {#cast_ipv4_ipv6_default_on_conversion_error} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.3"},{"label": "0"},{"label": "使函数 cast(value, 'IPv4') 和 cast(value, 'IPv6') 行为与 toIPv4 和 toIPv6 函数相同"}]}]}/>

CAST 运算符转换为 IPv4，CAST 运算符转换为 IPV6 类型，toIPv4，toIPv6 函数在转换错误时将返回默认值，而不是抛出异常。

## cast_keep_nullable {#cast_keep_nullable} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用 [CAST](/sql-reference/functions/type-conversion-functions#cast) 操作中保留 `Nullable` 数据类型。

当启用该设置且 `CAST` 函数的参数为 `Nullable` 时，结果也将转换为 `Nullable` 类型。当禁用该设置时，结果总是精确匹配目标类型。

可能的值：

- 0 — `CAST` 结果与指定的目标类型完全相同。
- 1 — 如果参数类型为 `Nullable`，则 `CAST` 结果转换为 `Nullable(DestinationDataType)`。

**示例**

以下查询结果精确匹配目标数据类型：

```sql
SET cast_keep_nullable = 0;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

结果：

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Int32                                             │
└───┴───────────────────────────────────────────────────┘
```

以下查询结果在目标数据类型上应用了 `Nullable` 修改：

```sql
SET cast_keep_nullable = 1;
SELECT CAST(toNullable(toInt32(0)) AS Int32) as x, toTypeName(x);
```

结果：

```text
┌─x─┬─toTypeName(CAST(toNullable(toInt32(0)), 'Int32'))─┐
│ 0 │ Nullable(Int32)                                   │
└───┴───────────────────────────────────────────────────┘
```

**另见**

- [CAST](/sql-reference/functions/type-conversion-functions#cast) 函数。

## cast_string_to_dynamic_use_inference {#cast_string_to_dynamic_use_inference} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "0"},{"label": "添加设置以允许通过解析将 String 转换为 Dynamic"}]}]}/>

在 String 转换为 Dynamic 时使用类型推断。

## cast_string_to_variant_use_inference {#cast_string_to_variant_use_inference} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "新设置以启用/禁用在 CAST 从 String 到 Variant 期间的类型推断"}]}]}/>

在 String 转换为 Variant 时使用类型推断。

## check_query_single_value_result {#check_query_single_value_result} 

<SettingsInfoBlock type="Bool" default_value="1" />

定义 `MergeTree` 家族引擎的 [CHECK TABLE](/sql-reference/statements/check-table) 查询结果的详细程度。

可能的值：

- 0 — 查询为表的每个数据部分显示检查状态。
- 1 — 查询显示一般表检查状态。

## check_referential_table_dependencies {#check_referential_table_dependencies} 

<SettingsInfoBlock type="Bool" default_value="0" />

检查 DDL 查询（如 DROP TABLE 或 RENAME）是否会破坏引用依赖关系。

## check_table_dependencies {#check_table_dependencies} 

<SettingsInfoBlock type="Bool" default_value="1" />

检查 DDL 查询（如 DROP TABLE 或 RENAME）是否会破坏依赖关系。

## checksum_on_read {#checksum_on_read} 

<SettingsInfoBlock type="Bool" default_value="1" />

读取时验证校验和。默认启用，并应在生产中始终启用。请不要期望禁用此设置会有任何好处。它仅可用于实验和基准测试。该设置仅适用于 MergeTree 家族的表。对于其他表引擎以及通过网络接收数据时，始终会验证校验和。

## cloud_mode {#cloud_mode} 

<SettingsInfoBlock type="Bool" default_value="0" />

云模式。

## cloud_mode_database_engine {#cloud_mode_database_engine} 

<SettingsInfoBlock type="UInt64" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "Cloud 中允许的数据库引擎"}]}]}/>

云中允许的数据库引擎。1 - 重写 DDL 使用 Replicated 数据库，2 - 重写 DDL 使用 Shared 数据库。

## cloud_mode_engine {#cloud_mode_engine} 

<SettingsInfoBlock type="UInt64" default_value="1" />

在云中允许的引擎家族。

- 0 - 允许所有
- 1 - 重写 DDL 使用 *ReplicatedMergeTree
- 2 - 重写 DDL 使用 SharedMergeTree
- 3 - 重写 DDL 使用 SharedMergeTree，除非显式传递了指定的远程磁盘。

UInt64 以最小化公开部分。

## cluster_for_parallel_replicas {#cluster_for_parallel_replicas} 

<BetaBadge/>

当前服务器所在分片的集群。

## collect_hash_table_stats_during_aggregation {#collect_hash_table_stats_during_aggregation} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用收集哈希表统计信息以优化内存分配。

## collect_hash_table_stats_during_joins {#collect_hash_table_stats_during_joins} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1"},{"label": "新设置。"}]}]}/>

启用收集哈希表统计信息以优化内存分配。

## compatibility {#compatibility} 

`compatibility` 设置使 ClickHouse 使用先前版本的默认设置，先前版本以设置的形式提供。

如果设置为非默认值，则遵循这些设置（只有未修改的设置才受 `compatibility` 设置的影响）。

该设置取一个 ClickHouse 版本号作为字符串，如 `22.3`，`22.8`。空值表示此设置被禁用。

默认禁用。

:::note
在 ClickHouse Cloud 中，兼容性设置必须由 ClickHouse Cloud 支持进行设置。请 [开一个案例](https://clickhouse.cloud/support) 以进行设置。
:::

## compatibility_ignore_auto_increment_in_create_table {#compatibility_ignore_auto_increment_in_create_table} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果为 true，则在列声明中忽略 AUTO_INCREMENT 关键字，否则将返回错误。简化了从 MySQL 的迁移。

## compatibility_ignore_collation_in_create_table {#compatibility_ignore_collation_in_create_table} 

<SettingsInfoBlock type="Bool" default_value="1" />

兼容性忽略创建表时的排序规则。

## compile_aggregate_expressions {#compile_aggregate_expressions} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用将聚合函数 JIT 编译为本地代码。启用此设置可以提高性能。

可能的值：

- 0 — 聚合在没有 JIT 编译的情况下完成。
- 1 — 使用 JIT 编译进行聚合。

**另见**

- [min_count_to_compile_aggregate_expression](#min_count_to_compile_aggregate_expression)。

## compile_expressions {#compile_expressions} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "我们相信 JIT 编译器背后的 LLVM 基础设施已经稳定到可以默认启用此设置。"}]}]}/>

将一些标量函数和运算符编译为本地代码。

## compile_sort_description {#compile_sort_description} 

<SettingsInfoBlock type="Bool" default_value="1" />

将排序描述编译为本地代码。

## connect_timeout {#connect_timeout} 

<SettingsInfoBlock type="Seconds" default_value="10" />

如果没有副本，则连接超时。

## connect_timeout_with_failover_ms {#connect_timeout_with_failover_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "1000"},{"label": "增加默认连接超时，因为异步连接"}]}]}/>

对于分布式表引擎，当使用集群定义中的“shard”和“replica”部分时，连接到远程服务器的超时（以毫秒为单位）。
如果连接不成功，将尝试多次连接到不同的副本。

## connect_timeout_with_failover_secure_ms {#connect_timeout_with_failover_secure_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "1000"},{"label": "增加安全连接中的首次健康副本连接超时"}]}]}/>

选择第一个健康副本的连接超时（对于安全连接）。

## connection_pool_max_wait_ms {#connection_pool_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

连接池已满时等待连接的时间（以毫秒为单位）。

可能的值：

- 正整数。
- 0 — 无限超时。

## connections_with_failover_max_tries {#connections_with_failover_max_tries} 

<SettingsInfoBlock type="UInt64" default_value="3" />

对于分布式表引擎，与每个副本的最大连接尝试次数。

## convert_query_to_cnf {#convert_query_to_cnf} 

<SettingsInfoBlock type="Bool" default_value="0" />

设置为 `true` 时，`SELECT` 查询将被转换为合取范式（CNF）。在某些情况下，以 CNF 形式重写查询可能会更快执行（查看此 [Github 问题](https://github.com/ClickHouse/ClickHouse/issues/11749)以了解解释）。

例如，请注意以下 `SELECT` 查询未被修改（默认行为）：

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = false;
```

结果是：

```response
┌─explain────────────────────────────────────────────────────────┐
│ SELECT x                                                       │
│ FROM                                                           │
│ (                                                              │
│     SELECT number AS x                                         │
│     FROM numbers(20)                                           │
│     WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15)) │
│ ) AS a                                                         │
│ WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))     │
│ SETTINGS convert_query_to_cnf = 0                              │
└────────────────────────────────────────────────────────────────┘
```

让我们将 `convert_query_to_cnf` 设置为 `true`，看看改变了什么：

```sql
EXPLAIN SYNTAX
SELECT *
FROM
(
    SELECT number AS x
    FROM numbers(20)
) AS a
WHERE ((x >= 1) AND (x <= 5)) OR ((x >= 10) AND (x <= 15))
SETTINGS convert_query_to_cnf = true;
```

注意 `WHERE` 子句在 CNF 中重写，但结果集是相同的 - 布尔逻辑没有改变：

```response
┌─explain───────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SELECT x                                                                                                              │
│ FROM                                                                                                                  │
│ (                                                                                                                     │
│     SELECT number AS x                                                                                                │
│     FROM numbers(20)                                                                                                  │
│     WHERE ((x <= 15) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x >= 10) OR (x >= 1)) │
│ ) AS a                                                                                                                │
│ WHERE ((x >= 10) OR (x >= 1)) AND ((x >= 10) OR (x <= 5)) AND ((x <= 15) OR (x >= 1)) AND ((x <= 15) OR (x <= 5))     │
│ SETTINGS convert_query_to_cnf = 1                                                                                     │
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

可能的值：true, false

## count_distinct_implementation {#count_distinct_implementation} 

<SettingsInfoBlock type="String" default_value="uniqExact" />

指定应使用哪个 `uniq*` 函数来执行 [COUNT(DISTINCT ...)](/sql-reference/aggregate-functions/reference/count) 结构。

可能的值：

- [uniq](/sql-reference/aggregate-functions/reference/uniq)
- [uniqCombined](/sql-reference/aggregate-functions/reference/uniqcombined)
- [uniqCombined64](/sql-reference/aggregate-functions/reference/uniqcombined64)
- [uniqHLL12](/sql-reference/aggregate-functions/reference/uniqhll12)
- [uniqExact](/sql-reference/aggregate-functions/reference/uniqexact)

## count_distinct_optimization {#count_distinct_optimization} 

<SettingsInfoBlock type="Bool" default_value="0" />

将计数不同的重写为分组子查询。

## create_if_not_exists {#create_if_not_exists} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "新设置。"}]}]}/>

默认启用 `IF NOT EXISTS` 的 `CREATE` 语句。如果此设置或 `IF NOT EXISTS` 已指定且提供的名称已存在，则不会抛出异常。

## create_index_ignore_unique {#create_index_ignore_unique} 

<SettingsInfoBlock type="Bool" default_value="0" />

在 CREATE UNIQUE INDEX 中忽略 UNIQUE 关键字。用于 SQL 兼容性测试。

## create_replicated_merge_tree_fault_injection_probability {#create_replicated_merge_tree_fault_injection_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

在 ZooKeeper 中创建元数据后，表创建过程中故障注入的概率。

## create_table_empty_primary_key_by_default {#create_table_empty_primary_key_by_default} 

<SettingsInfoBlock type="Bool" default_value="0" />

允许在未指定 ORDER BY 和主键时创建 *MergeTree 表时具有空主键。

## cross_join_min_bytes_to_compress {#cross_join_min_bytes_to_compress} 

<SettingsInfoBlock type="UInt64" default_value="1073741824" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "1073741824"},{"label": "CROSS JOIN 中压缩的最小块大小。零值表示禁用该阈值。块在达到两者中的任一阈值（按行或按字节）时进行压缩。"}]}]}/>

CROSS JOIN 中压缩的最小块大小。零值表示禁用该阈值。当达到按行或按字节的任一阈值时，此块被压缩。

## cross_join_min_rows_to_compress {#cross_join_min_rows_to_compress} 

<SettingsInfoBlock type="UInt64" default_value="10000000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "10000000"},{"label": "CROSS JOIN 中压缩区块的最小行数。零值表示禁用该阈值。当达到按行或按字节的任一阈值时，此块被压缩。"}]}]}/>

CROSS JOIN 中压缩区块的最小行数。零值表示禁用该阈值。当达到按行或按字节的任一阈值时，此块被压缩。

## data_type_default_nullable {#data_type_default_nullable} 

<SettingsInfoBlock type="Bool" default_value="0" />

允许没有显式修饰符 [NULL 或 NOT NULL](/sql-reference/statements/create/table#null-or-not-null-modifiers) 的数据类型在列定义中默认为 [Nullable](/sql-reference/data-types/nullable)。

可能的值：

- 1 — 列定义中的数据类型默认设置为 `Nullable`。
- 0 — 列定义中的数据类型默认设置为不 `Nullable`。

## database_atomic_wait_for_drop_and_detach_synchronously {#database_atomic_wait_for_drop_and_detach_synchronously} 

<SettingsInfoBlock type="Bool" default_value="0" />

为所有 `DROP` 和 `DETACH` 查询添加修饰符 `SYNC`。

可能的值：

- 0 — 查询将延迟执行。
- 1 — 查询将无延迟执行。

## database_replicated_allow_explicit_uuid {#database_replicated_allow_explicit_uuid} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "新增不允许显式指定表 UUID 的设置"}]}]}/>

0 - 不允许在 Replicated 数据库中显式指定表的 UUID。1 - 允许。2 - 允许，但忽略指定的 UUID，生成随机 UUID。

## database_replicated_allow_heavy_create {#database_replicated_allow_heavy_create} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "禁用长时间运行的 DDL 查询（CREATE AS SELECT 和 POPULATE）"}]}]}/>

允许在 Replicated 数据库引擎中运行长时间运行的 DDL 查询（CREATE AS SELECT 和 POPULATE）。请注意，它可能会长时间阻塞 DDL 队列。

## database_replicated_allow_only_replicated_engine {#database_replicated_allow_only_replicated_engine} 

<SettingsInfoBlock type="Bool" default_value="0" />

允许在 Replicated 引擎的数据库中只创建 Replicated 表。

## database_replicated_allow_replicated_engine_arguments {#database_replicated_allow_replicated_engine_arguments} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "默认不允许显式指定参数"}]}]}/>

0 - 不允许在 Replicated 数据库中显式指定 *MergeTree 表的 ZooKeeper 路径和副本名称。1 - 允许。2 - 允许，但忽略指定的路径并使用默认路径。3 - 允许且不记录警告。

## database_replicated_always_detach_permanently {#database_replicated_always_detach_permanently} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果数据库引擎是 Replicated，则将 DETACH TABLE 视为 DETACH TABLE PERMANENTLY 执行。

## database_replicated_enforce_synchronous_settings {#database_replicated_enforce_synchronous_settings} 

<SettingsInfoBlock type="Bool" default_value="0" />

强制对某些查询进行同步等待（另见 database_atomic_wait_for_drop_and_detach_synchronously，mutations_sync，alter_sync）。不建议启用这些设置。

## database_replicated_initial_query_timeout_sec {#database_replicated_initial_query_timeout_sec} 

<SettingsInfoBlock type="UInt64" default_value="300" />

设置初始 DDL 查询等待 Replicated 数据库处理先前 DDL 队列条目的时间（以秒为单位）。

可能的值：

- 正整数。
- 0 — 无限制。

## decimal_check_overflow {#decimal_check_overflow} 

<SettingsInfoBlock type="Bool" default_value="1" />

检查十进制算术/比较操作的溢出。

## deduplicate_blocks_in_dependent_materialized_views {#deduplicate_blocks_in_dependent_materialized_views} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用对从 Replicated\* 表接收数据的物化视图进行去重检查。

可能的值：

- 0 — 禁用。
- 1 — 启用。

用法

默认情况下，物化视图不执行去重，而是在源表中进行。如果插入的块由于源表中的去重而被跳过，则不会插入到附加的物化视图中。此行为存在是为了允许将高度聚合的数据插入到物化视图中，这种情况下插入的块在物化视图聚合后是相同的，但是来自对源表的不同插入。
同时，此行为破坏了 `INSERT` 的幂等性。如果主表中的 `INSERT` 成功，而物化视图中的 `INSERT` 失败（例如，因与 ClickHouse Keeper 的通信失败），则客户端将获得错误并可以重试该操作。然而，物化视图不会收到第二次插入，因为它将被主（源）表中的去重丢弃。设置 `deduplicate_blocks_in_dependent_materialized_views` 允许更改此行为。在重试时，物化视图将接收重复插入，并将自己执行去重检查，忽略源表的检查结果，并将因为首次失败而丢失的行插入。

## default_materialized_view_sql_security {#default_materialized_view_sql_security} 

<SettingsInfoBlock type="SQLSecurityType" default_value="DEFINER" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "DEFINER"},{"label": "允许在创建物化视图时设置 SQL SECURITY 选项的默认值"}]}]}/>

允许在创建物化视图时设置 SQL SECURITY 选项的默认值。[有关 SQL 安全性的更多信息](../../sql-reference/statements/create/view.md/#sql_security)。

默认值为 `DEFINER`。

## default_max_bytes_in_join {#default_max_bytes_in_join} 

<SettingsInfoBlock type="UInt64" default_value="1000000000" />

当需要限制但未设置 `max_bytes_in_join` 时，右侧表的最大大小。

## default_normal_view_sql_security {#default_normal_view_sql_security} 

<SettingsInfoBlock type="SQLSecurityType" default_value="INVOKER" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "INVOKER"},{"label": "允许在创建普通视图时设置默认 `SQL SECURITY` 选项"}]}]}/>

允许在创建普通视图时设置默认 `SQL SECURITY` 选项。[有关 SQL 安全性的更多信息](../../sql-reference/statements/create/view.md/#sql_security)。

默认值为 `INVOKER`。

## default_table_engine {#default_table_engine} 

<SettingsInfoBlock type="DefaultTableEngine" default_value="MergeTree" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "MergeTree"},{"label": "将默认表引擎设置为 MergeTree 以提高可用性"}]}]}/>

在 `CREATE` 语句中未设置 `ENGINE` 时使用的默认表引擎。

可能的值：

- 一个表示任何有效表引擎名称的字符串。

云默认值：`SharedMergeTree`。

**示例**

查询：

```sql
SET default_table_engine = 'Log';

SELECT name, value, changed FROM system.settings WHERE name = 'default_table_engine';
```

结果：

```response
┌─name─────────────────┬─value─┬─changed─┐
│ default_table_engine │ Log   │       1 │
└──────────────────────┴───────┴─────────┘
```

在此示例中，任何未指定 `Engine` 的新表将使用 `Log` 表引擎：

查询：

```sql
CREATE TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TABLE my_table;
```

结果：

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```

## default_temporary_table_engine {#default_temporary_table_engine} 

<SettingsInfoBlock type="DefaultTableEngine" default_value="Memory" />

与 [default_table_engine](#default_table_engine) 相同，但适用于临时表。

在此示例中，任何未指定 `Engine` 的新临时表将使用 `Log` 表引擎：

查询：

```sql
SET default_temporary_table_engine = 'Log';

CREATE TEMPORARY TABLE my_table (
    x UInt32,
    y UInt32
);

SHOW CREATE TEMPORARY TABLE my_table;
```

结果：

```response
┌─statement────────────────────────────────────────────────────────────────┐
│ CREATE TEMPORARY TABLE default.my_table
(
    `x` UInt32,
    `y` UInt32
)
ENGINE = Log
└──────────────────────────────────────────────────────────────────────────┘
```

## default_view_definer {#default_view_definer} 

<SettingsInfoBlock type="String" default_value="CURRENT_USER" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "CURRENT_USER"},{"label": "允许在创建视图时设置默认 `DEFINER` 选项"}]}]}/>

允许在创建视图时设置默认 `DEFINER` 选项。[有关 SQL 安全性的更多信息](../../sql-reference/statements/create/view.md/#sql_security)。

默认值为 `CURRENT_USER`。

## describe_compact_output {#describe_compact_output} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果为 true，则仅包括列名和类型到 DESCRIBE 查询的结果中。

## describe_extend_object_types {#describe_extend_object_types} 

<SettingsInfoBlock type="Bool" default_value="0" />

推导 DESCRIBE 查询中类型为 Object 的列的具体类型。

## describe_include_subcolumns {#describe_include_subcolumns} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用描述 [DESCRIBE](../../sql-reference/statements/describe-table.md) 查询的子列。例如， [Tuple](../../sql-reference/data-types/tuple.md) 的成员或 [Map](/sql-reference/data-types/map#reading-subcolumns-of-map)， [Nullable](../../sql-reference/data-types/nullable.md/#finding-null) 或 [Array](../../sql-reference/data-types/array.md/#array-size) 数据类型的子列。

可能的值：

- 0 — 子列未包含在 `DESCRIBE` 查询中。
- 1 — 子列包含在 `DESCRIBE` 查询中。

**示例**

请参见 [DESCRIBE](../../sql-reference/statements/describe-table.md) 语句的示例。

## describe_include_virtual_columns {#describe_include_virtual_columns} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果为 true，表的虚拟列将包含在 DESCRIBE 查询的结果中。

## dialect {#dialect} 

<SettingsInfoBlock type="Dialect" default_value="clickhouse" />

将使用哪个方言解析查询。

## dictionary_validate_primary_key_type {#dictionary_validate_primary_key_type} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "验证字典的主键类型。默认情况下，简单布局的 ID 类型将隐式转换为 UInt64。"}]}]}/>

验证字典的主键类型。默认情况下，简单布局的 ID 类型将隐式转换为 UInt64。

## distinct_overflow_mode {#distinct_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

设置当数据量超过其中一个限制时发生的情况。

可能的值：
- `throw`: 抛出异常（默认）。
- `break`: 停止执行查询并返回部分结果，就好像源数据用完一样。

## distributed_aggregation_memory_efficient {#distributed_aggregation_memory_efficient} 

<SettingsInfoBlock type="Bool" default_value="1" />

是否启用分布式聚合的节省内存模式。

## distributed_background_insert_batch {#distributed_background_insert_batch} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用/禁用以批量发送插入数据。

当启用批量发送时，[Distributed](../../engines/table-engines/special/distributed.md) 表引擎会尝试将多份插入数据的文件作为一次操作发送，而不是单独发送。批量发送通过更好地利用服务器和网络资源来提高集群性能。

可能的值：

- 1 — 启用。
- 0 — 禁用。

## distributed_background_insert_max_sleep_time_ms {#distributed_background_insert_max_sleep_time_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="30000" />

[Distributed](../../engines/table-engines/special/distributed.md) 表引擎发送数据的最大间隔。限制 [distributed_background_insert_sleep_time_ms](#distributed_background_insert_sleep_time_ms) 设置中设置的间隔的指数增长。

可能的值：

- 一个正整数，单位为毫秒。

## distributed_background_insert_sleep_time_ms {#distributed_background_insert_sleep_time_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="100" />

[Distributed](../../engines/table-engines/special/distributed.md) 表引擎发送数据的基本间隔。如果发生错误，实际的间隔会指数增长。

可能的值：

- 一个正整数，单位为毫秒。
## distributed_background_insert_split_batch_on_failure {#distributed_background_insert_split_batch_on_failure} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用/禁用在失败时拆分批次。

有时将特定批次发送到远程分片可能会失败，这是因为在后续复杂管道中（即具有`GROUP BY`的 `MATERIALIZED VIEW`）出现了`Memory limit exceeded`或类似错误。在这种情况下，重试是没有帮助的（这会阻塞该表的分布式发送），但逐个发送该批次中的文件可能会成功执行INSERT。

因此，将此设置安装为`1`会禁用这些批次的批处理（即临时禁用对失败批次的`distributed_background_insert_batch`）。

可能的值：

- 1 — 启用。
- 0 — 禁用。

:::note
此设置也会影响损坏的批次（这些批次可能是由于异常的服务器（机器）终止并且没有`fsync_after_insert`/`fsync_directories`对于[Distributed](../../engines/table-engines/special/distributed.md)表引擎而产生的）。
:::

:::note
您不应该依赖自动批次拆分，因为这可能会影响性能。
:::
## distributed_background_insert_timeout {#distributed_background_insert_timeout} 

<SettingsInfoBlock type="UInt64" default_value="0" />

插入查询到分布式的超时时间。该设置仅与启用insert_distributed_sync时使用。零值表示没有超时。
## distributed_cache_bypass_connection_pool {#distributed_cache_bypass_connection_pool} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。允许绕过分布式缓存连接池。
## distributed_cache_connect_max_tries {#distributed_cache_connect_max_tries} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="20" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "20"},{"label": "Cloud only"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "20"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。连接到分布式缓存的尝试次数，如果连接不成功。
## distributed_cache_data_packet_ack_window {#distributed_cache_data_packet_ack_window} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="5" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "5"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。在单个分布式缓存读请求中发送ACK的DataPacket序列窗口。
## distributed_cache_discard_connection_if_unread_data {#distributed_cache_discard_connection_if_unread_data} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "New setting"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "1"},{"label": "New setting"}]}]}/>

在ClickHouse Cloud中仅有效。如果一些数据未读，则丢弃连接。
## distributed_cache_fetch_metrics_only_from_current_az {#distributed_cache_fetch_metrics_only_from_current_az} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。仅从当前可用区域获取系统中分布式缓存指标和事件的指标。
## distributed_cache_log_mode {#distributed_cache_log_mode} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="DistributedCacheLogMode" default_value="on_error" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "on_error"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。用于写入system.distributed_cache_log的模式。
## distributed_cache_max_unacked_inflight_packets {#distributed_cache_max_unacked_inflight_packets} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="10" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "10"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。在单个分布式缓存读取请求中，未确认的在途数据包的最大数量。
## distributed_cache_min_bytes_for_seek {#distributed_cache_min_bytes_for_seek} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "New private setting."}]}]}/>

在ClickHouse Cloud中仅有效。进行分布式缓存中查找的最小字节数。
## distributed_cache_pool_behaviour_on_limit {#distributed_cache_pool_behaviour_on_limit} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="DistributedCachePoolBehaviourOnLimit" default_value="wait" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "wait"},{"label": "Cloud only"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "allocate_bypassing_pool"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。识别达到池限制时的分布式缓存连接的行为。
## distributed_cache_read_alignment {#distributed_cache_read_alignment} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。用于测试目的的设置，请勿更改。
## distributed_cache_read_only_from_current_az {#distributed_cache_read_only_from_current_az} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "New setting"}]}]}/>

在ClickHouse Cloud中仅有效。仅允许从当前可用区域读取。如果禁用，将从所有可用区域中的所有缓存服务器读取。
## distributed_cache_read_request_max_tries {#distributed_cache_read_request_max_tries} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="20" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "20"},{"label": "New setting"}]}]}/>

在ClickHouse Cloud中仅有效。如果尝试分布式缓存请求不成功，则进行的尝试次数。
## distributed_cache_receive_response_wait_milliseconds {#distributed_cache_receive_response_wait_milliseconds} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="60000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "60000"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。等待从分布式缓存接收请求数据的时间，以毫秒计。
## distributed_cache_receive_timeout_milliseconds {#distributed_cache_receive_timeout_milliseconds} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="10000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "10000"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。等待从分布式缓存接收任何响应的时间，以毫秒计。
## distributed_cache_throw_on_error {#distributed_cache_throw_on_error} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。在与分布式缓存通信期间重新抛出出现的异常或从分布式缓存收到的异常。否则在发生错误时回退为跳过分布式缓存。
## distributed_cache_wait_connection_from_pool_milliseconds {#distributed_cache_wait_connection_from_pool_milliseconds} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="100" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "100"},{"label": "A setting for ClickHouse Cloud"}]}]}/>

在ClickHouse Cloud中仅有效。如果`distributed_cache_pool_behaviour_on_limit`为wait，则等待接收来自连接池的连接所需的时间，以毫秒计。
## distributed_connections_pool_size {#distributed_connections_pool_size} 

<SettingsInfoBlock type="UInt64" default_value="1024" />

与远程服务器的同时连接数的最大值，用于对单个分布式表的所有查询进行分布式处理。我们建议将值设置为不少于集群中的服务器数量。
## distributed_ddl_entry_format_version {#distributed_ddl_entry_format_version} 

<SettingsInfoBlock type="UInt64" default_value="5" />

分布式DDL（在集群上）查询的兼容性版本。
## distributed_ddl_output_mode {#distributed_ddl_output_mode} 

<SettingsInfoBlock type="DistributedDDLOutputMode" default_value="throw" />

设置分布式DDL查询结果的格式。

可能的值：

- `throw` — 返回查询执行状态的结果集，适用于查询在所有主机上已完成的情况。如果查询在某些主机上失败，则将重新抛出第一个异常。如果查询在某些主机上尚未完成，并且超过了[distributed_ddl_task_timeout](#distributed_ddl_task_timeout)，则抛出`TIMEOUT_EXCEEDED`异常。
- `none` — 类似于throw，但分布式DDL查询不返回结果集。
- `null_status_on_timeout` — 当在相应主机上查询未完成时，结果集的某些行返回`NULL`作为执行状态，而不是抛出`TIMEOUT_EXCEEDED`异常。
- `never_throw` — 不抛出`TIMEOUT_EXCEEDED`，并且如果查询在某些主机上失败则不重新抛出异常。
- `none_only_active` - 类似于`none`，但不等待`Replicated`数据库的非活动副本。注意：在这种模式下，无法确定该查询在某些副本上未执行，并将在后台执行。
- `null_status_on_timeout_only_active` — 类似于`null_status_on_timeout`，但不等待`Replicated`数据库的非活动副本。
- `throw_only_active` — 类似于`throw`，但不等待`Replicated`数据库的非活动副本。

云的默认值：`none`。
## distributed_ddl_task_timeout {#distributed_ddl_task_timeout} 

<SettingsInfoBlock type="Int64" default_value="180" />

设置从集群中所有主机获取DDL查询响应的超时时间。如果未在所有主机上执行DDL请求，则响应将包含超时错误，并且请求将以异步模式执行。负值表示无限。

可能的值：

- 正整数。
- 0 — 异步模式。
- 负整数 — 无限超时。
## distributed_foreground_insert {#distributed_foreground_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用对[Distributed](/engines/table-engines/special/distributed)表的同步数据插入。

默认情况下，当向`Distributed`表插入数据时，ClickHouse服务器在后台模式下将数据发送到集群节点。当`distributed_foreground_insert=1`时，数据是同步处理的，只有在所有数据保存在所有分片上（如果`internal_replication`为true，则每个分片至少保存一个副本）后，`INSERT`操作才会成功。

可能的值：

- 0 — 数据以后台模式插入。
- 1 — 数据以同步模式插入。

云的默认值：`1`。

**参见**

- [分布式表引擎](/engines/table-engines/special/distributed)
- [管理分布式表](/sql-reference/statements/system#managing-distributed-tables)
## distributed_group_by_no_merge {#distributed_group_by_no_merge} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在分布式查询处理中，不要合并来自不同服务器的聚合状态，如果确信不同分片上的键是不同的，可以使用此设置。

可能的值：

- `0` — 禁用（最终查询处理在发起节点上完成）。
- `1` - 在分布式查询处理中，不合并来自不同服务器的聚合状态（查询在分片上完全处理，发起者仅代理数据），可以在确信不同分片上有不同的键时使用。
- `2` - 与`1`相同，但在发起者上应用`ORDER BY`和`LIMIT`（当查询在远程节点完全处理时，例如对于`distributed_group_by_no_merge=1`时，无法做到这一点）。

**示例**

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 1
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
│     0 │
└───────┘
```

```sql
SELECT *
FROM remote('127.0.0.{2,3}', system.one)
GROUP BY dummy
LIMIT 1
SETTINGS distributed_group_by_no_merge = 2
FORMAT PrettyCompactMonoBlock

┌─dummy─┐
│     0 │
└───────┘
```
## distributed_insert_skip_read_only_replicas {#distributed_insert_skip_read_only_replicas} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "If true, INSERT into Distributed will skip read-only replicas"}]}]}/>

启用跳过对分布式的INSERT查询的只读副本。

可能的值：

- 0 — INSERT如常进行，如果它要进入只读副本，则会失败。
- 1 — 发起者将在将数据发送到分片之前跳过只读副本。
## distributed_plan_default_reader_bucket_count {#distributed_plan_default_reader_bucket_count} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="8" />

默认的并行读取分布式查询的任务数量。任务在副本之间分布。
## distributed_plan_default_shuffle_join_bucket_count {#distributed_plan_default_shuffle_join_bucket_count} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="8" />

分布式shuffle-hash-join的默认桶数。
## distributed_plan_execute_locally {#distributed_plan_execute_locally} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

在本地运行分布式查询计划的所有任务。用于测试和调试非常有用。
## distributed_plan_force_exchange_kind {#distributed_plan_force_exchange_kind} 

<ExperimentalBadge/>

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": ""},{"label": "New experimental setting."}]}]}/>

强制在分布式查询阶段之间指定的交换操作种类。

可能的值：

 - '' - 不强制任何交换操作，让优化器选择，
 - 'Persisted' - 在对象存储中使用临时文件，
 - 'Streaming' - 通过网络流交换数据。
## distributed_plan_optimize_exchanges {#distributed_plan_optimize_exchanges} 

<SettingsInfoBlock type="Bool" default_value="1" />

删除分布式查询计划中的不必要的交换。禁用它用于调试。
## distributed_product_mode {#distributed_product_mode} 

<SettingsInfoBlock type="DistributedProductMode" default_value="deny" />

更改[分布式子查询](../../sql-reference/operators/in.md)的行为。

当查询涉及分布式表的乘积时，即当针对分布式表的查询包含某个分布式表的非GLOBAL子查询时，ClickHouse会应用此设置。

限制：

- 仅适用于IN和JOIN子查询。
- 仅当FROM部分使用包含多个分片的分布式表时。
- 如果子查询涉及一个包含多个分片的分布式表。
- 不适用于表值的[remote](../../sql-reference/table-functions/remote.md)函数。

可能的值：

- `deny` — 默认值。禁止使用这些类型的子查询（返回“禁止双分布的IN/JOIN子查询”异常）。
- `local` — 用本地表替换子查询中的数据库和表，以便为目标服务器（分片）使用，保持正常的`IN`/`JOIN`。
- `global` — 用`GLOBAL IN`/`GLOBAL JOIN`替代`IN`/`JOIN`查询。
- `allow` — 允许使用这些类型的子查询。
## distributed_push_down_limit {#distributed_push_down_limit} 

<SettingsInfoBlock type="UInt64" default_value="1" />

启用或禁用在每个分片上单独应用[LIMIT](#limit)。

这将避免：
- 通过网络发送额外的行；
- 在发起者上处理限制后的行。

从版本21.9开始，如果满足至少一个条件，您将不能再获得不准确的结果，因为`distributed_push_down_limit`会更改查询执行：
- [distributed_group_by_no_merge](#distributed_group_by_no_merge) > 0。
- 查询**没有**`GROUP BY`/`DISTINCT`/`LIMIT BY`，但它有`ORDER BY`/`LIMIT`。
- 查询**具有**`GROUP BY`/`DISTINCT`/`LIMIT BY`与`ORDER BY`/`LIMIT`并且：
    - [optimize_skip_unused_shards](#optimize_skip_unused_shards)已启用。
    - [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key)已启用。

可能的值：

- 0 — 禁用。
- 1 — 启用。

另见：

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)
- [optimize_distributed_group_by_sharding_key](#optimize_distributed_group_by_sharding_key)
## distributed_replica_error_cap {#distributed_replica_error_cap} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

- 类型：无符号整型
- 默认值：1000

每个副本的错误计数限制在该值，防止单个副本累积过多错误。

另见：

- [load_balancing](#load_balancing-round_robin)
- [表引擎Distributed](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)
## distributed_replica_error_half_life {#distributed_replica_error_half_life} 

<SettingsInfoBlock type="Seconds" default_value="60" />

- 类型：秒
- 默认值：60秒

控制在分布式表中错误归零的速度。如果一个副本在一定时间内不可用，积累了5个错误，并且设置了`distributed_replica_error_half_life`为1秒，则该副本在最后一个错误后的3秒后被视为正常。

另见：

- [load_balancing](#load_balancing-round_robin)
- [表引擎Distributed](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)
## distributed_replica_max_ignored_errors {#distributed_replica_max_ignored_errors} 

<SettingsInfoBlock type="UInt64" default_value="0" />

- 类型：无符号整型
- 默认值：0

在选择副本时，将忽略的错误数量（根据`load_balancing`算法）。

另见：

- [load_balancing](#load_balancing-round_robin)
- [表引擎Distributed](../../engines/table-engines/special/distributed.md)
- [distributed_replica_error_cap](#distributed_replica_error_cap)
- [distributed_replica_error_half_life](#distributed_replica_error_half_life)
## do_not_merge_across_partitions_select_final {#do_not_merge_across_partitions_select_final} 

<SettingsInfoBlock type="Bool" default_value="0" />

仅在选择最终时在一个分区中合并部分。
## empty_result_for_aggregation_by_constant_keys_on_empty_set {#empty_result_for_aggregation_by_constant_keys_on_empty_set} 

<SettingsInfoBlock type="Bool" default_value="1" />

在对空集的常量键进行聚合时返回空结果。
## empty_result_for_aggregation_by_empty_set {#empty_result_for_aggregation_by_empty_set} 

<SettingsInfoBlock type="Bool" default_value="0" />

在无键的空集上进行聚合时返回空结果。
## enable_adaptive_memory_spill_scheduler {#enable_adaptive_memory_spill_scheduler} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "0"},{"label": "New setting. Enable spill memory data into external storage adaptively."}]}]}/>

触发处理器自适应地将数据倾倒到外部存储中。目前支持grace join。
## enable_blob_storage_log {#enable_blob_storage_log} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "Write information about blob storage operations to system.blob_storage_log table"}]}]}/>

将有关Blob存储操作的信息写入system.blob_storage_log表。
## enable_deflate_qpl_codec {#enable_deflate_qpl_codec} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果开启，则可以使用DEFLATE_QPL编解码器来压缩列。
## enable_early_constant_folding {#enable_early_constant_folding} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用查询优化，我们分析函数和子查询结果，并在其中有常量时重写查询。
## enable_extended_results_for_datetime_functions {#enable_extended_results_for_datetime_functions} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用返回以下类型的结果：
- `Date32`具有扩展范围（与`Date`相比）适用于函数[toStartOfYear](../../sql-reference/functions/date-time-functions.md/#tostartofyear)、[toStartOfISOYear](../../sql-reference/functions/date-time-functions.md/#tostartofisoyear)、[toStartOfQuarter](../../sql-reference/functions/date-time-functions.md/#tostartofquarter)、[toStartOfMonth](../../sql-reference/functions/date-time-functions.md/#tostartofmonth)、[toLastDayOfMonth](../../sql-reference/functions/date-time-functions.md/#tolastdayofmonth)、[toStartOfWeek](../../sql-reference/functions/date-time-functions.md/#tostartofweek)、[toLastDayOfWeek](../../sql-reference/functions/date-time-functions.md/#tolastdayofweek)和[toMonday](../../sql-reference/functions/date-time-functions.md/#tomonday)。
- `DateTime64`具有扩展范围（与`DateTime`相比）适用于函数[toStartOfDay](../../sql-reference/functions/date-time-functions.md/#tostartofday)、[toStartOfHour](../../sql-reference/functions/date-time-functions.md/#tostartofhour)、[toStartOfMinute](../../sql-reference/functions/date-time-functions.md/#tostartofminute)、[toStartOfFiveMinutes](../../sql-reference/functions/date-time-functions.md/#tostartoffiveminutes)、[toStartOfTenMinutes](../../sql-reference/functions/date-time-functions.md/#tostartoftenminutes)、[toStartOfFifteenMinutes](../../sql-reference/functions/date-time-functions.md/#tostartoffifteenminutes)和[timeSlot](../../sql-reference/functions/date-time-functions.md/#timeslot)。

可能的值：

- 0 — 对于所有类型的参数，函数返回`Date`或`DateTime`。
- 1 — 函数对于`Date32`或`DateTime64`参数返回`Date32`或`DateTime64`，否则返回`Date`或`DateTime`。
## enable_filesystem_cache {#enable_filesystem_cache} 

<SettingsInfoBlock type="Bool" default_value="1" />

为远程文件系统使用缓存。此设置不会开启/关闭磁盘的缓存（必须通过磁盘配置完成），但允许在某些查询中绕过缓存。
## enable_filesystem_cache_log {#enable_filesystem_cache_log} 

<SettingsInfoBlock type="Bool" default_value="0" />

允许为每个查询记录文件系统缓存日志。
## enable_filesystem_cache_on_write_operations {#enable_filesystem_cache_on_write_operations} 

<SettingsInfoBlock type="Bool" default_value="0" />

在写操作时写入缓存。要使此设置生效，还需将其添加到磁盘配置中。
## enable_filesystem_read_prefetches_log {#enable_filesystem_read_prefetches_log} 

<SettingsInfoBlock type="Bool" default_value="0" />

在查询期间记录到system.filesystem的pre-fetch_log。应仅在测试或调试时使用，不建议默认开启。
## enable_global_with_statement {#enable_global_with_statement} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.2"},{"label": "1"},{"label": "Propagate WITH statements to UNION queries and all subqueries by default"}]}]}/>

将WITH语句传播到UNION查询和所有子查询。
## enable_hdfs_pread {#enable_hdfs_pread} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "New setting."}]}]}/>

启用或禁用HDFS文件的pread功能。默认使用`hdfsPread`。如果禁用，将使用`hdfsRead`和`hdfsSeek`来读取hdfs文件。
## enable_http_compression {#enable_http_compression} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用对HTTP请求的响应数据进行压缩。

有关更多信息，请阅读[HTTP接口说明](../../interfaces/http.md)。

可能的值：

- 0 — 禁用。
- 1 — 启用。
## enable_job_stack_trace {#enable_job_stack_trace} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "Enable by default collecting stack traces from job's scheduling."}]}]}/>

输出作业创建者的堆栈跟踪，当作业结果发生异常时。
## enable_lightweight_delete {#enable_lightweight_delete} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用MergeTree表的轻量级DELETE变更。
## enable_memory_bound_merging_of_aggregation_results {#enable_memory_bound_merging_of_aggregation_results} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用内存限制的聚合结果合并策略。
## enable_multiple_prewhere_read_steps {#enable_multiple_prewhere_read_steps} 

<SettingsInfoBlock type="Bool" default_value="1" />

将更多条件从WHERE移动到PREWHERE，并在有多个条件与AND组合时进行多个步骤读取和过滤。
## enable_named_columns_in_function_tuple {#enable_named_columns_in_function_tuple} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "Generate named tuples in function tuple() when all names are unique and can be treated as unquoted identifiers."}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "0"},{"label": "Disabled pending usability improvements"}]}]}/>

在函数tuple()中生成命名元组，当所有名称都是唯一的且可以视为未加引号的标识符时。
## enable_optimize_predicate_expression {#enable_optimize_predicate_expression} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "18.12.17"},{"label": "1"},{"label": "Optimize predicates to subqueries by default"}]}]}/>

在`SELECT`查询中开启谓词下推。

谓词下推可以显著减少分布式查询的网络流量。

可能的值：

- 0 — 禁用。
- 1 — 启用。

用法

考虑以下查询：

1.  `SELECT count() FROM test_table WHERE date = '2018-10-10'`
2.  `SELECT count() FROM (SELECT * FROM test_table) WHERE date = '2018-10-10'`

如果`enable_optimize_predicate_expression = 1`，则这两个查询的执行时间是相等的，因为ClickHouse在处理子查询时将应用`WHERE`。

如果`enable_optimize_predicate_expression = 0`，则第二个查询的执行时间则会长得多，因为`WHERE`子句在子查询完成后应用于所有数据。
## enable_optimize_predicate_expression_to_final_subquery {#enable_optimize_predicate_expression_to_final_subquery} 

<SettingsInfoBlock type="Bool" default_value="1" />

允许向最终子查询推送谓词。
## enable_order_by_all {#enable_order_by_all} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用使用`ORDER BY ALL`语法进行排序，见[ORDER BY](../../sql-reference/statements/select/order-by.md)。

可能的值：

- 0 — 禁用ORDER BY ALL。
- 1 — 启用ORDER BY ALL。

**示例**

查询：

```sql
CREATE TABLE TAB(C1 Int, C2 Int, ALL Int) ENGINE=Memory();

INSERT INTO TAB VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM TAB ORDER BY ALL; -- returns an error that ALL is ambiguous

SELECT * FROM TAB ORDER BY ALL SETTINGS enable_order_by_all = 0;
```

结果：

```text
┌─C1─┬─C2─┬─ALL─┐
│ 20 │ 20 │  10 │
│ 30 │ 10 │  20 │
│ 10 │ 20 │  30 │
└────┴────┴─────┘
```
## enable_parsing_to_custom_serialization {#enable_parsing_to_custom_serialization} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1"},{"label": "New setting"}]}]}/>

如果为true，则数据可以根据从表中获得的序列化提示直接解析到具有自定义序列化的列（例如稀疏）。
## enable_positional_arguments {#enable_positional_arguments} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.7"},{"label": "1"},{"label": "默认启用位置参数特性"}]}]}/>

启用或禁用对 [GROUP BY](/sql-reference/statements/select/group-by)、[LIMIT BY](../../sql-reference/statements/select/limit-by.md) 和 [ORDER BY](../../sql-reference/statements/select/order-by.md) 语句的支持。

可能的值：

- 0 — 不支持位置参数。
- 1 — 支持位置参数：可以使用列编号代替列名。

**示例**

查询：

```sql
CREATE TABLE positional_arguments(one Int, two Int, three Int) ENGINE=Memory();

INSERT INTO positional_arguments VALUES (10, 20, 30), (20, 20, 10), (30, 10, 20);

SELECT * FROM positional_arguments ORDER BY 2,3;
```

结果：

```text
┌─one─┬─two─┬─three─┐
│  30 │  10 │   20  │
│  20 │  20 │   10  │
│  10 │  20 │   30  │
└─────┴─────┴───────┘
```
## enable_reads_from_query_cache {#enable_reads_from_query_cache} 



<SettingsInfoBlock type="Bool" default_value="1" />

如果开启，`SELECT` 查询的结果将从 [查询缓存](../query-cache.md) 中获取。

可能的值：

- 0 - 禁用
- 1 - 启用
## enable_s3_requests_logging {#enable_s3_requests_logging} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用非常明确的 S3 请求日志。仅适用于调试。
## enable_scalar_subquery_optimization {#enable_scalar_subquery_optimization} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "19.18"},{"label": "1"},{"label": "防止标量子查询序列化或反序列化大型标量值，并可能避免多次运行相同的子查询"}]}]}/>

如果设置为 true，则防止标量子查询序列化或反序列化大型标量值，并可能避免多次运行相同的子查询。
## enable_sharing_sets_for_mutations {#enable_sharing_sets_for_mutations} 



<SettingsInfoBlock type="Bool" default_value="1" />

允许在同一变更的不同任务之间共享为 IN 子查询构建的集合对象。这可减少内存使用和 CPU 消耗。
## enable_software_prefetch_in_aggregation {#enable_software_prefetch_in_aggregation} 



<SettingsInfoBlock type="Bool" default_value="1" />

启用在聚合中使用软件预取。
## enable_unaligned_array_join {#enable_unaligned_array_join} 



<SettingsInfoBlock type="Bool" default_value="0" />

允许 ARRAY JOIN 使用多个具有不同大小的数组。当启用此设置时，数组将调整为最大数组的长度。
## enable_url_encoding {#enable_url_encoding} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "更改现有设置的默认值"}]}]}/>

允许在 [URL](../../engines/table-engines/special/url.md) 引擎表中启用/禁用对 URI 路径的解码/编码。

默认禁用。
## enable_vertical_final {#enable_vertical_final} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "在修复错误后默认重新启用垂直最终查询"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "1"},{"label": "默认使用垂直最终查询"}]}]}/>

如果启用，在 FINAL 查询期间通过将行标记为已删除并在后期过滤它们，从而删除重复的行，而不是合并行。
## enable_writes_to_query_cache {#enable_writes_to_query_cache} 



<SettingsInfoBlock type="Bool" default_value="1" />

如果开启，`SELECT` 查询的结果将存储在 [查询缓存](../query-cache.md) 中。

可能的值：

- 0 - 禁用
- 1 - 启用
## enable_zstd_qat_codec {#enable_zstd_qat_codec} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "添加新 ZSTD_QAT 编解码器"}]}]}/>

如果启用，可以使用 ZSTD_QAT 编解码器来压缩列。
## enforce_strict_identifier_format {#enforce_strict_identifier_format} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "新设置。"}]}]}/>

如果启用，仅允许包含字母数字字符和下划线的标识符。
## engine_file_allow_create_multiple_files {#engine_file_allow_create_multiple_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在文件引擎表中每次插入时创建新文件，如果格式具有后缀（`JSON`、`ORC`、`Parquet` 等）。如果启用，每次插入将创建一个新文件，名称遵循以下模式：

`data.Parquet` -> `data.1.Parquet` -> `data.2.Parquet` 等。

可能的值：
- 0 — `INSERT` 查询将新数据附加到文件末尾。
- 1 — `INSERT` 查询将创建一个新文件。
## engine_file_empty_if_not_exists {#engine_file_empty_if_not_exists} 



<SettingsInfoBlock type="Bool" default_value="0" />

允许从无文件的文件引擎表中选择数据。

可能的值：
- 0 — `SELECT` 抛出异常。
- 1 — `SELECT` 返回空结果。
## engine_file_skip_empty_files {#engine_file_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用跳过在 [File](../../engines/table-engines/special/file.md) 引擎表中的空文件。

可能的值：
- 0 — 如果空文件与请求格式不兼容，则 `SELECT` 抛出异常。
- 1 — 对于空文件，`SELECT` 返回空结果。
## engine_file_truncate_on_insert {#engine_file_truncate_on_insert} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在 [File](../../engines/table-engines/special/file.md) 引擎表中进行插入前截断。

可能的值：
- 0 — `INSERT` 查询将新数据附加到文件末尾。
- 1 — `INSERT` 查询将用新数据替换文件的现有内容。
## engine_url_skip_empty_files {#engine_url_skip_empty_files} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用跳过在 [URL](../../engines/table-engines/special/url.md) 引擎表中的空文件。

可能的值：
- 0 — 如果空文件与请求格式不兼容，则 `SELECT` 抛出异常。
- 1 — 对于空文件，`SELECT` 返回空结果。
## except_default_mode {#except_default_mode} 



<SettingsInfoBlock type="SetOperationMode" default_value="ALL" />

在 EXCEPT 查询中设置默认模式。可能的值：空字符串、'ALL'、'DISTINCT'。如果为空，则不带模式的查询将抛出异常。
## external_storage_connect_timeout_sec {#external_storage_connect_timeout_sec} 



<SettingsInfoBlock type="UInt64" default_value="10" />

连接超时时间（秒）。目前仅对 MySQL 支持。
## external_storage_max_read_bytes {#external_storage_max_read_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

限制在外部引擎表中刷新历史数据时的最大字节数。目前仅对 MySQL 表引擎、数据库引擎和字典支持。如果等于 0，则此设置被禁用。
## external_storage_max_read_rows {#external_storage_max_read_rows} 



<SettingsInfoBlock type="UInt64" default_value="0" />

限制在外部引擎表中刷新历史数据时的最大行数。目前仅对 MySQL 表引擎、数据库引擎和字典支持。如果等于 0，则此设置被禁用。
## external_storage_rw_timeout_sec {#external_storage_rw_timeout_sec} 



<SettingsInfoBlock type="UInt64" default_value="300" />

读/写超时时间（秒）。目前仅对 MySQL 支持。
## external_table_functions_use_nulls {#external_table_functions_use_nulls} 



<SettingsInfoBlock type="Bool" default_value="1" />

定义如何使用 Nullable 列的 [mysql](../../sql-reference/table-functions/mysql.md)、[postgresql](../../sql-reference/table-functions/postgresql.md) 和 [odbc](../../sql-reference/table-functions/odbc.md) 表函数。

可能的值：

- 0 — 表函数明确使用 Nullable 列。
- 1 — 表函数隐式使用 Nullable 列。

**用法**

如果设置为 `0`，表函数将不会创建 Nullable 列，并在插入时用默认值替代 NULL。这也适用于数组中的 NULL 值。
## external_table_strict_query {#external_table_strict_query} 



<SettingsInfoBlock type="Bool" default_value="0" />

如果设置为 true，则不允许将表达式转换为外部表的本地过滤器。
## extract_key_value_pairs_max_pairs_per_row {#extract_key_value_pairs_max_pairs_per_row} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "0"},{"label": "extractKeyValuePairs 函数可以生成的最大对数。作为防止消耗过多内存的保障。"}]}]}/>

extractKeyValuePairs 函数可以生成的最大对数。作为防止消耗过多内存的保障。
## extremes {#extremes} 



<SettingsInfoBlock type="Bool" default_value="0" />

是否在查询结果的列中计数极值（最小值和最大值）。接受 0 或 1。默认情况下，0（禁用）。
有关更多信息，请参见“极值”部分。
## fallback_to_stale_replicas_for_distributed_queries {#fallback_to_stale_replicas_for_distributed_queries} 



<SettingsInfoBlock type="Bool" default_value="1" />

如果更新的数据不可用，强制查询到过时的副本。参见 [复制](../../engines/table-engines/mergetree-family/replication.md)。

ClickHouse 会从表的过时副本中选择最相关的。

在从指向复制表的分布式表执行 `SELECT` 时使用。

默认情况下，1（启用）。
## filesystem_cache_boundary_alignment {#filesystem_cache_boundary_alignment} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "新设置"}]}]}/>

文件系统缓存边界对齐。此设置仅适用于非磁盘读取（例如，适用于远程表引擎/表函数的缓存，但不适用于 MergeTree 表的存储配置）。值为 0 表示没有对齐。
## filesystem_cache_enable_background_download_during_fetch {#filesystem_cache_enable_background_download_during_fetch} 

<CloudAvailableBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "新设置"}]}]}/>

仅对 ClickHouse Cloud 有效。锁定缓存以保留空间的等待时间。
## filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage {#filesystem_cache_enable_background_download_for_metadata_files_in_packed_storage} 

<CloudAvailableBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "新设置"}]}]}/>

仅对 ClickHouse Cloud 有效。锁定缓存以保留空间的等待时间。
## filesystem_cache_max_download_size {#filesystem_cache_max_download_size} 



<SettingsInfoBlock type="UInt64" default_value="137438953472" />

单个查询可以下载的最大远程文件系统缓存大小。
## filesystem_cache_name {#filesystem_cache_name} 



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": ""},{"label": "要用于无状态表引擎或数据湖的文件系统缓存名称"}]}]}/>

要用于无状态表引擎或数据湖的文件系统缓存名称。
## filesystem_cache_prefer_bigger_buffer_size {#filesystem_cache_prefer_bigger_buffer_size} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "新设置"}]}]}/>

如果启用文件系统缓存，则更倾向于使用更大的缓存区大小，以避免编写小的文件片段，这会降低缓存性能。另一方面，启用此设置可能会增加内存使用。
## filesystem_cache_reserve_space_wait_lock_timeout_milliseconds {#filesystem_cache_reserve_space_wait_lock_timeout_milliseconds} 



<SettingsInfoBlock type="UInt64" default_value="1000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1000"},{"label": "等待时间以锁定缓存以保留文件系统缓存中的空间"}]}]}/>

等待时间以锁定缓存以保留文件系统缓存中的空间。
## filesystem_cache_segments_batch_size {#filesystem_cache_segments_batch_size} 



<SettingsInfoBlock type="UInt64" default_value="20" />

限制读取缓冲区可以从缓存请求的文件片段单个批次的大小。过低的值将导致对缓存的请求过多，过高的值可能会减慢缓存的驱逐速度。
## filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit {#filesystem_cache_skip_download_if_exceeds_per_query_cache_write_limit} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "重命名设置 skip_download_if_exceeds_query_cache_limit"}]}]}/>

如果超过查询缓存大小，则跳过从远程文件系统下载。
## filesystem_prefetch_max_memory_usage {#filesystem_prefetch_max_memory_usage} 



<SettingsInfoBlock type="UInt64" default_value="1073741824" />

预取的最大内存使用量。
## filesystem_prefetch_step_bytes {#filesystem_prefetch_step_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

以字节为单位的预取步长。零表示 `auto` - 大约最佳预取步长将自动推导，但可能不是 100% 最佳。由于设置了 filesystem_prefetch_min_bytes_for_single_read_task，实际值可能不同。
## filesystem_prefetch_step_marks {#filesystem_prefetch_step_marks} 



<SettingsInfoBlock type="UInt64" default_value="0" />

以标记为单位的预取步长。零表示 `auto` - 大约最佳预取步长将自动推导，但可能不是 100% 最佳。由于设置了 filesystem_prefetch_min_bytes_for_single_read_task，实际值可能不同。
## filesystem_prefetches_limit {#filesystem_prefetches_limit} 



<SettingsInfoBlock type="UInt64" default_value="200" />

最大预取数。零表示无限。如果您想限制预取数量，建议使用设置 `filesystem_prefetches_max_memory_usage`。
## final {#final} 



<SettingsInfoBlock type="Bool" default_value="0" />

自动将 [FINAL](../../sql-reference/statements/select/from.md/#final-modifier) 修饰符应用于查询中的所有表，即适用于 [FINAL](../../sql-reference/statements/select/from.md/#final-modifier) 的表，包括连接表和子查询中的表，以及分布式表。

可能的值：

- 0 - 禁用
- 1 - 启用

示例：

```sql
CREATE TABLE test
(
    key Int64,
    some String
)
ENGINE = ReplacingMergeTree
ORDER BY key;

INSERT INTO test FORMAT Values (1, 'first');
INSERT INTO test FORMAT Values (1, 'second');

SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
┌─key─┬─some──┐
│   1 │ first │
└─────┴───────┘

SELECT * FROM test SETTINGS final = 1;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘

SET final = 1;
SELECT * FROM test;
┌─key─┬─some───┐
│   1 │ second │
└─────┴────────┘
```
## flatten_nested {#flatten_nested} 



<SettingsInfoBlock type="Bool" default_value="1" />

设置 [nested](../../sql-reference/data-types/nested-data-structures/index.md) 列的数据格式。

可能的值：

- 1 — 嵌套列被展平为单独的数组。
- 0 — 嵌套列保持为一个元组的单一数组。

**用法**

如果设置为 `0`，则可以使用任意级别的嵌套。

**示例**

查询：

```sql
SET flatten_nested = 1;
CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

结果：

```text
┌─statement───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n.a` Array(UInt32),
    `n.b` Array(UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

查询：

```sql
SET flatten_nested = 0;

CREATE TABLE t_nest (`n` Nested(a UInt32, b UInt32)) ENGINE = MergeTree ORDER BY tuple();

SHOW CREATE TABLE t_nest;
```

结果：

```text
┌─statement──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ CREATE TABLE default.t_nest
(
    `n` Nested(a UInt32, b UInt32)
)
ENGINE = MergeTree
ORDER BY tuple()
SETTINGS index_granularity = 8192 │
└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```
## force_aggregate_partitions_independently {#force_aggregate_partitions_independently} 



<SettingsInfoBlock type="Bool" default_value="0" />

强制在适用时使用优化，但启发式决定不使用它。
## force_aggregation_in_order {#force_aggregation_in_order} 



<SettingsInfoBlock type="Bool" default_value="0" />

该设置由服务器本身使用以支持分布式查询。请勿手动更改，因为这将破坏正常操作。（强制在分布式聚合期间，在远程节点上按顺序使用聚合）。
## force_data_skipping_indices {#force_data_skipping_indices} 

如果未使用传递的数据跳过索引，则禁用查询执行。

考虑以下示例：

```sql
CREATE TABLE data
(
    key Int,
    d1 Int,
    d1_null Nullable(Int),
    INDEX d1_idx d1 TYPE minmax GRANULARITY 1,
    INDEX d1_null_idx assumeNotNull(d1_null) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

SELECT * FROM data_01515;
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices=''; -- 查询将产生 CANNOT_PARSE_TEXT 错误。
SELECT * FROM data_01515 SETTINGS force_data_skipping_indices='d1_idx'; -- 查询将产生 INDEX_NOT_USED 错误。
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='d1_idx'; -- 正确。
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`'; -- 正确（全功能解析器示例）。
SELECT * FROM data_01515 WHERE d1 = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- 查询将产生 INDEX_NOT_USED 错误，因为未使用 d1_null_idx。
SELECT * FROM data_01515 WHERE d1 = 0 AND assumeNotNull(d1_null) = 0 SETTINGS force_data_skipping_indices='`d1_idx`, d1_null_idx'; -- 正确。
```
## force_grouping_standard_compatibility {#force_grouping_standard_compatibility} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.9"},{"label": "1"},{"label": "使 GROUPING 函数的输出与 SQL 标准和其他 DBMS 一致"}]}]}/>

使 GROUPING 函数在参数未用作聚合键时返回 1。
## force_index_by_date {#force_index_by_date} 



<SettingsInfoBlock type="Bool" default_value="0" />

如果无法通过日期进行索引，则禁用查询执行。

适用于 MergeTree 家族中的表。

如果 `force_index_by_date=1`，ClickHouse 会检查查询是否具有可以用于限制数据范围的日期键条件。如果没有合适的条件，它将抛出异常。然而，它不会检查条件是否减少了读取的数据量。例如，条件 `Date != ' 2000-01-01 '` 是可以接受的，即使它匹配表中的所有数据（即，运行查询需要完全扫描）。有关 MergeTree 表中的数据范围的更多信息，请参见 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)。
## force_optimize_projection {#force_optimize_projection} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在 `SELECT` 查询中强制使用 [projections](../../engines/table-engines/mergetree-family/mergetree.md/#projections)，当启用投影优化时（请参阅 [optimize_use_projections](#optimize_use_projections) 设置）。

可能的值：

- 0 — 投影优化不是强制性的。
- 1 — 投影优化是强制性的。
## force_optimize_projection_name {#force_optimize_projection_name} 

如果设置为非空字符串，则检查该投影在查询中是否至少使用一次。

可能的值：

- 字符串：在查询中使用的投影名称。
## force_optimize_skip_unused_shards {#force_optimize_skip_unused_shards} 



<SettingsInfoBlock type="UInt64" default_value="0" />

如果启用并且无法跳过未使用的分片，则禁用查询执行。如果无法跳过并且设置为启用，则将抛出异常。

可能的值：

- 0 — 禁用。ClickHouse 不会抛出异常。
- 1 — 启用。仅在表具有分片键时禁用查询执行。
- 2 — 启用。无论表是否为其定义了分片键，均禁用查询执行。
## force_optimize_skip_unused_shards_nesting {#force_optimize_skip_unused_shards_nesting} 



<SettingsInfoBlock type="UInt64" default_value="0" />

控制 [`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards)（因此仍然需要 [`force_optimize_skip_unused_shards`](#force_optimize_skip_unused_shards)）取决于分布式查询的嵌套级别（例如，当您有 `Distributed` 表，它查看另一个 `Distributed` 表时）。

可能的值：

- 0 - 禁用，`force_optimize_skip_unused_shards` 始终有效。
- 1 — 仅针对第一层启用 `force_optimize_skip_unused_shards`。
- 2 — 启用 `force_optimize_skip_unused_shards` 直到第二层。
## force_primary_key {#force_primary_key} 



<SettingsInfoBlock type="Bool" default_value="0" />

如果无法通过主键进行索引，则禁用查询执行。

适用于 MergeTree 家族中的表。

如果 `force_primary_key=1`，ClickHouse 会检查查询是否具有可以用于限制数据范围的主键条件。如果没有合适的条件，它将抛出异常。然而，它不会检查条件是否减少了读取的数据量。有关 MergeTree 表中的数据范围的更多信息，请参见 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md)。
## force_remove_data_recursively_on_drop {#force_remove_data_recursively_on_drop} 



<SettingsInfoBlock type="Bool" default_value="0" />

在 DROP 查询中递归删除数据。避免出现“目录不为空”错误，但可能会悄悄删除被分离的数据。
## formatdatetime_e_with_space_padding {#formatdatetime_e_with_space_padding} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "提高与 MySQL DATE_FORMAT/STR_TO_DATE 的兼容性"}]}]}/>

格式化器 '%e' 在函数 'formatDateTime' 中打印单数字天，并前面加空格，例如 ' 2' 而不是 '2'。
## formatdatetime_f_prints_scale_number_of_digits {#formatdatetime_f_prints_scale_number_of_digits} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新设置。"}]}]}/>

格式化器 '%f' 在函数 'formatDateTime' 中仅打印 DateTime64 的数量，而不是固定的 6 位数。
## formatdatetime_f_prints_single_zero {#formatdatetime_f_prints_single_zero} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "0"},{"label": "提高与 MySQL DATE_FORMAT()/STR_TO_DATE() 的兼容性"}]}]}/>

格式化器 '%f' 在函数 'formatDateTime' 中在格式化值没有小数秒时打印一个零，而不是六个零。
## formatdatetime_format_without_leading_zeros {#formatdatetime_format_without_leading_zeros} 



<SettingsInfoBlock type="Bool" default_value="0" />

格式化器 '%c'、'%l' 和 '%k' 在函数 'formatDateTime' 中打印没有前导零的月份和小时。
## formatdatetime_parsedatetime_m_is_month_name {#formatdatetime_parsedatetime_m_is_month_name} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "1"},{"label": "提高与 MySQL DATE_FORMAT/STR_TO_DATE 的兼容性"}]}]}/>

格式化器 '%M' 在 'formatDateTime' 和 'parseDateTime' 函数中打印/解析月份名称，而不是分钟。
## fsync_metadata {#fsync_metadata} 



<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用写入 `.sql` 文件时的 [fsync](http://pubs.opengroup.org/onlinepubs/9699919799/functions/fsync.html)。默认启用。

如果服务器有数百万个不断在创建和销毁的小表，则禁用此选项是有意义的。
## function_implementation {#function_implementation} 

为特定目标或变体（实验）选择函数实现。如果为空，则启用所有实现。
## function_json_value_return_type_allow_complex {#function_json_value_return_type_allow_complex} 



<SettingsInfoBlock type="Bool" default_value="0" />

控制是否允许为 json_value 函数返回复杂类型（例如：struct、array、map）。

```sql
SELECT JSON_VALUE('{"hello":{"world":"!"}}', '$.hello') settings function_json_value_return_type_allow_complex=true

┌─JSON_VALUE('{"hello":{"world":"!"}}', '$.hello')─┐
│ {"world":"!"}                                    │
└──────────────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

可能的值：

- true — 允许。
- false — 不允许。
## function_json_value_return_type_allow_nullable {#function_json_value_return_type_allow_nullable} 



<SettingsInfoBlock type="Bool" default_value="0" />

控制 json_value 函数在值不存在时是否允许返回 `NULL`。

```sql
SELECT JSON_VALUE('{"hello":"world"}', '$.b') settings function_json_value_return_type_allow_nullable=true;

┌─JSON_VALUE('{"hello":"world"}', '$.b')─┐
│ ᴺᵁᴸᴸ                                   │
└────────────────────────────────────────┘

1 row in set. Elapsed: 0.001 sec.
```

可能的值：

- true — 允许。
- false — 不允许。
## function_locate_has_mysql_compatible_argument_order {#function_locate_has_mysql_compatible_argument_order} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "提高与 MySQL 的 locate 函数的兼容性。"}]}]}/>

控制函数 [locate](../../sql-reference/functions/string-search-functions.md/#locate) 中的参数顺序。

可能的值：

- 0 — 函数 `locate` 接受参数 `(haystack, needle[, start_pos])`。
- 1 — 函数 `locate` 接受参数 `(needle, haystack, [, start_pos])`（与 MySQL 兼容的行为）。
## function_range_max_elements_in_block {#function_range_max_elements_in_block} 



<SettingsInfoBlock type="UInt64" default_value="500000000" />

为函数 [range](/sql-reference/functions/array-functions#rangeend-rangestart--end--step) 设置生成的数据量安全阈值。定义每个数据块生成的函数最大值（每行在一个块中的数组大小总和）。

可能的值：

- 正整数。

**另请参见**

- [max_block_size](#max_block_size)
- [min_insert_block_size_rows](#min_insert_block_size_rows)
## function_sleep_max_microseconds_per_block {#function_sleep_max_microseconds_per_block} 



<SettingsInfoBlock type="UInt64" default_value="3000000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.7"},{"label": "3000000"},{"label": "在以前的版本中，最大睡眠时间为 3 秒，仅适用于 `sleep`，而不适用于 `sleepEachRow` 函数。在新版本中，我们引入这一设置。如果您设置为与以前的版本兼容，我们将完全禁用限制。"}]}]}/>

函数 `sleep` 每个块允许睡眠的最大微秒数。如果用户以更大的值调用它，则会抛出异常。它是一个安全阈值。
## function_visible_width_behavior {#function_visible_width_behavior} 



<SettingsInfoBlock type="UInt64" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "1"},{"label": "我们更改了 `visibleWidth` 的默认行为，以更精确地计算"}]}]}/>

`visibleWidth` 行为的版本。 0 - 仅计算码点数量； 1 - 正确计算零宽和组合字符，将全宽字符计为两个，将制表符宽度估计，计算删除字符。
## geo_distance_returns_float64_on_float64_arguments {#geo_distance_returns_float64_on_float64_arguments} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "提高默认精度。"}]}]}/>

如果 `geoDistance`、`greatCircleDistance`、`greatCircleAngle` 函数的四个参数都是 Float64，则返回 Float64 并在内部计算中使用双精度。在以前的 ClickHouse 版本中，这些函数始终返回 Float32。
## geotoh3_lon_lat_input_order {#geotoh3_lon_lat_input_order} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "一个用于设置经度和纬度顺序的遗留行为的新设置"}]}]}/>

函数 'geoToH3' 如果为真，接受(lon, lat)，否则接受(lat, lon)。
## glob_expansion_max_elements {#glob_expansion_max_elements} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

允许的最大地址数量（用于外部存储、表函数等）。
## grace_hash_join_initial_buckets {#grace_hash_join_initial_buckets} 

<ExperimentalBadge/>

<SettingsInfoBlock type="NonZeroUInt64" default_value="1" />

初始的优雅哈希连接桶数量。
## grace_hash_join_max_buckets {#grace_hash_join_max_buckets} 

<ExperimentalBadge/>

<SettingsInfoBlock type="NonZeroUInt64" default_value="1024" />

优雅哈希连接桶的数量限制。
## group_by_overflow_mode {#group_by_overflow_mode} 

<SettingsInfoBlock type="OverflowModeGroupBy" default_value="throw" />

设置当用于聚合的唯一键数量超过限制时会发生什么：
- `throw`: 抛出异常
- `break`: 停止执行查询并返回部分结果
- `any`: 对已纳入集合的键继续聚合，但不添加新键。

使用 'any' 值可以运行GROUP BY的近似值。近似值的质量取决于数据的统计特性。
## group_by_two_level_threshold {#group_by_two_level_threshold} 

<SettingsInfoBlock type="UInt64" default_value="100000" />

达到多少个键后，开始进行二级聚合。0 - 未设置阈值。
## group_by_two_level_threshold_bytes {#group_by_two_level_threshold_bytes} 

<SettingsInfoBlock type="UInt64" default_value="50000000" />

在哪个字节大小的聚合状态下开始使用二级聚合。0 - 未设置阈值。当至少有一个阈值被触发时，使用二级聚合。
## group_by_use_nulls {#group_by_use_nulls} 

<SettingsInfoBlock type="Bool" default_value="0" />

改变[GROUP BY子句](/sql-reference/statements/select/group-by)在处理聚合键类型方面的行为。
当使用 `ROLLUP`、 `CUBE` 或 `GROUPING SETS` 说明时，有些聚合键可能不会用于生成某些结果行。
根据该设置，这些维度的行中的对应列用默认值或`NULL`填充。

可能的值：

- 0 — 使用聚合键类型的默认值来产生缺失值。
- 1 — ClickHouse 按照 SQL 标准的方式执行 `GROUP BY`。聚合键的类型转换为[Nullable](/sql-reference/data-types/nullable)。对于未使用的行，相应的聚合键列填充为[NULL](/sql-reference/syntax#null)。

另请参见：

- [GROUP BY子句](/sql-reference/statements/select/group-by)
## h3togeo_lon_lat_result_order {#h3togeo_lon_lat_result_order} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "一个新设置"}]}]}/>

函数 'h3ToGeo' 如果为真，则返回(lon, lat)，否则返回(lat, lon)。
## handshake_timeout_ms {#handshake_timeout_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="10000" />

在握手期间从副本接收Hello数据包的超时时间，单位为毫秒。
## hdfs_create_new_file_on_insert {#hdfs_create_new_file_on_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

在HDFS引擎表中启用或禁用每次插入时创建新文件。如果启用，每次插入时将创建一个新的HDFS文件，名称格式如下：

初始：`data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz` 等等。

可能的值：
- 0 — `INSERT` 查询将新数据附加到文件末尾。
- 1 — `INSERT` 查询创建新文件。
## hdfs_ignore_file_doesnt_exist {#hdfs_ignore_file_doesnt_exist} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "允许在HDFS表引擎中，当请求的文件不存在时返回0行，而不是抛出异常"}]}]}/>

在读取特定键时忽略文件缺失。

可能的值：
- 1 — `SELECT` 返回空结果。
- 0 — `SELECT` 抛出异常。
## hdfs_replication {#hdfs_replication} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在创建hdfs文件时可以指定实际的复制数量。
## hdfs_skip_empty_files {#hdfs_skip_empty_files} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在[HDFS](../../engines/table-engines/integrations/hdfs.md) 引擎表中跳过空文件。

可能的值：
- 0 — 如果空文件与请求格式不兼容，`SELECT` 抛出异常。
- 1 — `SELECT` 对于空文件返回空结果。
## hdfs_throw_on_zero_files_match {#hdfs_throw_on_zero_files_match} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "允许在HDFS引擎中，当ListObjects请求的文件匹配为零时抛出错误，而不是返回空查询结果"}]}]}/>

如果根据glob扩展规则匹配零个文件，则抛出错误。

可能的值：
- 1 — `SELECT` 抛出异常。
- 0 — `SELECT` 返回空结果。
## hdfs_truncate_on_insert {#hdfs_truncate_on_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在HDFS引擎表中插入前的截断。如果禁用，当尝试插入已有HDFS文件时，将抛出异常。

可能的值：
- 0 — `INSERT` 查询将新数据附加到文件末尾。
- 1 — `INSERT` 查询将现有文件的内容替换为新数据。
## hedged_connection_timeout_ms {#hedged_connection_timeout_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="50" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.4"},{"label": "50"},{"label": "在50毫秒后启动Hedged请求的新连接，而不是100毫秒，以与之前的连接超时相对应"}]}]}/>

与副本建立连接时的超时时间，用于Hedged请求。
## hnsw_candidate_list_size_for_search {#hnsw_candidate_list_size_for_search} 

<BetaBadge/>

<SettingsInfoBlock type="UInt64" default_value="256" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "256"},{"label": "新设置。以前，该值在CREATE INDEX中可选指定，默认为64。"}]}]}/>

搜索向量相似度索引时动态候选列表的大小，也称为 'ef_search'。
## hsts_max_age {#hsts_max_age} 

<SettingsInfoBlock type="UInt64" default_value="0" />

HSTS的过期时间。0表示禁用HSTS。
## http_connection_timeout {#http_connection_timeout} 

<SettingsInfoBlock type="Seconds" default_value="1" />

HTTP连接超时时间（以秒为单位）。

可能的值：

- 任何正整数。
- 0 - 禁用（无穷超时）。
## http_headers_progress_interval_ms {#http_headers_progress_interval_ms} 

<SettingsInfoBlock type="UInt64" default_value="100" />

不应比指定的时间间隔更频繁地发送HTTP头 X-ClickHouse-Progress。
## http_make_head_request {#http_make_head_request} 

<SettingsInfoBlock type="Bool" default_value="1" />

设置 `http_make_head_request` 允许在从HTTP读取数据时执行`HEAD`请求，以检索要读取的文件的信息，例如其大小。由于默认启用，在服务器不支持`HEAD`请求的情况下，可能需要禁用此设置。
## http_max_field_name_size {#http_max_field_name_size} 

<SettingsInfoBlock type="UInt64" default_value="131072" />

HTTP头中字段名称的最大长度。
## http_max_field_value_size {#http_max_field_value_size} 

<SettingsInfoBlock type="UInt64" default_value="131072" />

HTTP头中字段值的最大长度。
## http_max_fields {#http_max_fields} 

<SettingsInfoBlock type="UInt64" default_value="1000000" />

HTTP头中字段的最大数量。
## http_max_multipart_form_data_size {#http_max_multipart_form_data_size} 

<SettingsInfoBlock type="UInt64" default_value="1073741824" />

multipart/form-data内容的大小限制。此设置不能通过URL参数解析，应该在用户个人资料中设置。请注意，内容在查询执行开始之前被解析，外部表在内存中创建。这是影响该阶段的唯一限制（最大内存使用限制和执行时间限制在读取HTTP表单数据时没有效果）。
## http_max_request_param_data_size {#http_max_request_param_data_size} 

<SettingsInfoBlock type="UInt64" default_value="10485760" />

预定义HTTP请求中用于查询参数的请求数据大小限制。
## http_max_tries {#http_max_tries} 

<SettingsInfoBlock type="UInt64" default_value="10" />

通过HTTP读取的最大尝试次数。
## http_max_uri_size {#http_max_uri_size} 

<SettingsInfoBlock type="UInt64" default_value="1048576" />

设置HTTP请求的最大URI长度。

可能的值：

- 正整数。
## http_native_compression_disable_checksumming_on_decompress {#http_native_compression_disable_checksumming_on_decompress} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在解压HTTP POST数据时进行校验和验证。仅在使用ClickHouse原生压缩格式时使用（不适用于 `gzip` 或 `deflate`）。

有关更多信息，请阅读[HTTP接口说明](../../interfaces/http.md)。

可能的值：

- 0 — 禁用。
- 1 — 启用。
## http_receive_timeout {#http_receive_timeout} 

<SettingsInfoBlock type="Seconds" default_value="30" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.6"},{"label": "30"},{"label": "参见 http_send_timeout."}]}]}/>

HTTP接收超时时间（以秒为单位）。

可能的值：

- 任何正整数。
- 0 - 禁用（无穷超时）。
## http_response_buffer_size {#http_response_buffer_size} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在发送HTTP响应到客户端或刷新到磁盘（当http_wait_end_of_query启用时）之前缓冲的字节数。
## http_response_headers {#http_response_headers} 

<SettingsInfoBlock type="Map" default_value="{}" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": ""},{"label": "新设置。"}]}]}/>

允许添加或覆盖服务器将在成功查询结果的响应中返回的HTTP头。
这仅影响HTTP接口。

如果头由默认设置，则提供的值将覆盖它。
如果头未被默认设定，它将被添加到头的列表中。
服务器默认设置的头并未被此设置覆盖，将保持不变。

该设置允许您将头设置为常量值。目前没有方法可以将头设置为动态计算的值。

如果您实现了一个UI应用程序，允许用户修改设置，但同时基于返回的头做决定，建议将此设置限制为只读。

示例：`SET http_response_headers = '{"Content-Type": "image/png"}'`
## http_retry_initial_backoff_ms {#http_retry_initial_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="100" />

重试通过HTTP读取时的最小退避毫秒数。
## http_retry_max_backoff_ms {#http_retry_max_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="10000" />

重试通过HTTP读取时的最大退避毫秒数。
## http_send_timeout {#http_send_timeout} 

<SettingsInfoBlock type="Seconds" default_value="30" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.6"},{"label": "30"},{"label": "3分钟似乎太长。请注意，这是单次网络写入调用的超时，而不是整个上传操作的超时。"}]}]}/>

HTTP发送超时时间（以秒为单位）。

可能的值：

- 任何正整数。
- 0 - 禁用（无穷超时）。

:::note
仅适用于默认配置文件。更改需要重新启动服务器才能生效。
:::
## http_skip_not_found_url_for_globs {#http_skip_not_found_url_for_globs} 

<SettingsInfoBlock type="Bool" default_value="1" />

跳过带有HTTP_NOT_FOUND错误的globs的URL。
## http_wait_end_of_query {#http_wait_end_of_query} 

<SettingsInfoBlock type="Bool" default_value="0" />

在服务器端启用HTTP响应缓冲。
## http_write_exception_in_output_format {#http_write_exception_in_output_format} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.9"},{"label": "1"},{"label": "在HTTP流中，输出有效的JSON/XML格式的异常。"}]}]}/>

在输出格式中写入异常以生成有效输出。与JSON和XML格式都有效。
## http_zlib_compression_level {#http_zlib_compression_level} 

<SettingsInfoBlock type="Int64" default_value="3" />

设置对HTTP请求响应的数据压缩级别，如果[enable_http_compression = 1](#enable_http_compression)。

可能的值：从1到9的数字。
## iceberg_snapshot_id {#iceberg_snapshot_id} 

<SettingsInfoBlock type="Int64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新设置。"}]}]}/>

使用特定快照ID查询Iceberg表。
## iceberg_timestamp_ms {#iceberg_timestamp_ms} 

<SettingsInfoBlock type="Int64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新设置。"}]}]}/>

使用在特定时间戳处处于当前状态的快照查询Iceberg表。
## idle_connection_timeout {#idle_connection_timeout} 

<SettingsInfoBlock type="UInt64" default_value="3600" />

在指定秒数后关闭空闲TCP连接的超时。

可能的值：

- 正整数（0 - 立即关闭，0秒后）。
## ignore_cold_parts_seconds {#ignore_cold_parts_seconds} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="Int64" default_value="0" />

仅在ClickHouse Cloud中有效。在SELECT查询中排除新数据部分，直到它们被预热（参见[cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)）或在此秒数之前。仅适用于Replicated-/SharedMergeTree。
## ignore_data_skipping_indices {#ignore_data_skipping_indices} 

忽略查询中使用的跳过索引。

考虑以下示例：

```sql
CREATE TABLE data
(
    key Int,
    x Int,
    y Int,
    INDEX x_idx x TYPE minmax GRANULARITY 1,
    INDEX y_idx y TYPE minmax GRANULARITY 1,
    INDEX xy_idx (x,y) TYPE minmax GRANULARITY 1
)
Engine=MergeTree()
ORDER BY key;

INSERT INTO data VALUES (1, 2, 3);

SELECT * FROM data;
SELECT * FROM data SETTINGS ignore_data_skipping_indices=''; -- 查询将产生CANNOT_PARSE_TEXT错误。
SELECT * FROM data SETTINGS ignore_data_skipping_indices='x_idx'; -- 成功。
SELECT * FROM data SETTINGS ignore_data_skipping_indices='na_idx'; -- 成功。

SELECT * FROM data WHERE x = 1 AND y = 1 SETTINGS ignore_data_skipping_indices='xy_idx',force_data_skipping_indices='xy_idx' ; -- 查询将产生INDEX_NOT_USED错误，因为xy_idx被明确忽略。
SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';
```

没有忽略任何索引的查询：
```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2;

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
      Skip
        Name: xy_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
```

忽略`xy_idx`索引：
```sql
EXPLAIN indexes = 1 SELECT * FROM data WHERE x = 1 AND y = 2 SETTINGS ignore_data_skipping_indices='xy_idx';

Expression ((Projection + Before ORDER BY))
  Filter (WHERE)
    ReadFromMergeTree (default.data)
    Indexes:
      PrimaryKey
        Condition: true
        Parts: 1/1
        Granules: 1/1
      Skip
        Name: x_idx
        Description: minmax GRANULARITY 1
        Parts: 0/1
        Granules: 0/1
      Skip
        Name: y_idx
        Description: minmax GRANULARITY 1
        Parts: 0/0
        Granules: 0/0
```

适用于MergeTree系列表。
## ignore_drop_queries_probability {#ignore_drop_queries_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "0"},{"label": "允许根据指定概率忽略DROP查询以供测试"}]}]}/>

如果启用，服务器将以指定概率忽略所有DROP表查询（对于内存和JOIN引擎，它将替换DROP为TRUNCATE）。用于测试目的。
## ignore_materialized_views_with_dropped_target_table {#ignore_materialized_views_with_dropped_target_table} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "添加新设置以允许忽略已删除目标表的物化视图"}]}]}/>

在推送到视图时忽略与删除目标表的MVs。
## ignore_on_cluster_for_replicated_access_entities_queries {#ignore_on_cluster_for_replicated_access_entities_queries} 

<SettingsInfoBlock type="Bool" default_value="0" />

忽略用于控制复制访问实体的查询的ON CLUSTER子句。
## ignore_on_cluster_for_replicated_named_collections_queries {#ignore_on_cluster_for_replicated_named_collections_queries} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "忽略用于管理复制命名集合的查询的ON CLUSTER子句。"}]}]}/>

忽略用于控制复制命名集合的查询的ON CLUSTER子句。
## ignore_on_cluster_for_replicated_udf_queries {#ignore_on_cluster_for_replicated_udf_queries} 

<SettingsInfoBlock type="Bool" default_value="0" />

忽略用于管理复制UDF的查询的ON CLUSTER子句。
## implicit_select {#implicit_select} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "一个新设置。"}]}]}/>

允许在没有前导SELECT关键字的情况下写入简单的SELECT查询，这使其适合计算器式用法，例如`1 + 2`成为有效查询。

在`clickhouse-local`中默认启用，可以显式禁用。
## implicit_table_at_top_level {#implicit_table_at_top_level} 

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": ""},{"label": "一个新设置，在clickhouse-local中使用"}]}]}/>

如果不为空，顶级没有FROM的查询将从此表中读取，而不是system.one。

这在clickhouse-local中用于输入数据处理。
用户可以显式设置该设置，但不打算用于此类型的用法。

子查询不受此设置的影响（无论是标量、FROM还是IN子查询）。
UNION、INTERSECT、EXCEPT链的顶级SELECT处的查询被统一处理，并受到此设置的影响，而不管它们是否在括号中分组。
该设置如何影响视图和分布式查询是未指定的。

该设置接受一个表名（然后从当前数据库解析表）或以'database.table'形式的限定名称。
数据库和表名都必须不加引号，仅允许简单标识符。
## implicit_transaction {#implicit_transaction} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

如果启用且尚未在事务中，则将查询包装在完整事务中（开始 + 提交或回滚）。
## input_format_parallel_parsing {#input_format_parallel_parsing} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用数据格式的顺序保持并行解析。仅支持[TSV](../../interfaces/formats.md/#tabseparated)、[TSKV](../../interfaces/formats.md/#tskv)、[CSV](../../interfaces/formats.md/#csv)和[JSONEachRow](../../interfaces/formats.md/#jsoneachrow)格式。

可能的值：

- 1 — 启用。
- 0 — 禁用。
## insert_allow_materialized_columns {#insert_allow_materialized_columns} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果设置启用，则允许在插入中使用物化列。
## insert_deduplicate {#insert_deduplicate} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用 `INSERT` 的块去重（用于Replicated*表）。

可能的值：

- 0 — 禁用。
- 1 — 启用。

默认情况下，通过 `INSERT` 语句插入到复制表中的块是去重的（参见[数据复制](../../engines/table-engines/mergetree-family/replication.md)）。
对于复制的表，默认情况下每个分区仅去重100个最近的块（参见[replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window)、[replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds)）。
对于未复制的表，参见[non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window)。
## insert_deduplication_token {#insert_deduplication_token} 

该设置允许用户在MergeTree/ReplicatedMergeTree中提供自己的去重语义
例如，通过在每个INSERT语句中提供一个唯一值，
用户可以避免相同插入数据被去重。

可能的值：

- 任何字符串

`insert_deduplication_token` 仅在不为空时用于去重。

对于复制的表，默认情况下每个分区仅去重100个最新的插入（参见[replicated_deduplication_window](merge-tree-settings.md/#replicated_deduplication_window)、[replicated_deduplication_window_seconds](merge-tree-settings.md/#replicated_deduplication_window_seconds)）。
对于未复制的表，参见[non_replicated_deduplication_window](merge-tree-settings.md/#non_replicated_deduplication_window)。

:::note
`insert_deduplication_token` 在分区层面上工作（与 `insert_deduplication` 校验和相同）。多个分区可以具有相同的 `insert_deduplication_token`。
:::

示例：

```sql
CREATE TABLE test_table
( A Int64 )
ENGINE = MergeTree
ORDER BY A
SETTINGS non_replicated_deduplication_window = 100;

INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (1);

-- 下一个插入不会被去重，因为insert_deduplication_token不同
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test1' VALUES (1);

-- 下一个插入将被去重，因为insert_deduplication_token
-- 与之前一个相同
INSERT INTO test_table SETTINGS insert_deduplication_token = 'test' VALUES (2);

SELECT * FROM test_table

┌─A─┐
│ 1 │
└───┘
┌─A─┐
│ 1 │
└───┘
```
## insert_keeper_fault_injection_probability {#insert_keeper_fault_injection_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

在插入期间keeper请求失败的近似概率。有效值在区间[0.0f, 1.0f]内。
## insert_keeper_fault_injection_seed {#insert_keeper_fault_injection_seed} 

<SettingsInfoBlock type="UInt64" default_value="0" />

0 - 随机种子，其他值为设置值。
## insert_keeper_max_retries {#insert_keeper_max_retries} 

<SettingsInfoBlock type="UInt64" default_value="20" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.2"},{"label": "20"},{"label": "在INSERT期间启用对Keeper的重连请求，提高可靠性"}]}]}/>

该设置设置在插入到复制MergeTree期间对ClickHouse Keeper（或ZooKeeper）请求的最大重试次数。仅将由于网络错误、Keeper会话超时或请求超时而失败的Keeper请求视为重试。

可能的值：

- 正整数。
- 0 — 禁用重试

云的默认值：`20`。

Keeper请求重试在一定的超时后进行。超时由以下设置控制：`insert_keeper_retry_initial_backoff_ms`，`insert_keeper_retry_max_backoff_ms`。
第一次重试在`insert_keeper_retry_initial_backoff_ms`超时后进行。后续的超时将如下计算：
```
timeout = min(insert_keeper_retry_max_backoff_ms, latest_timeout * 2)
```

例如，如果`insert_keeper_retry_initial_backoff_ms=100`，`insert_keeper_retry_max_backoff_ms=10000`和`insert_keeper_max_retries=8`，那么超时将为`100, 200, 400, 800, 1600, 3200, 6400, 10000`。

除了容错能力外，重试旨在提供更好的用户体验 - 例如，如果Keeper由于升级而重启，则它们允许避免在INSERT执行期间返回错误。
## insert_keeper_retry_initial_backoff_ms {#insert_keeper_retry_initial_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="100" />

在INSERT查询执行期间重试失败的Keeper请求的初始超时（毫秒）。

可能的值：

- 正整数。
- 0 — 无超时。
## insert_keeper_retry_max_backoff_ms {#insert_keeper_retry_max_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="10000" />

在INSERT查询执行期间重试失败的Keeper请求的最大超时（毫秒）。

可能的值：

- 正整数。
- 0 — 最大超时不限制。
## insert_null_as_default {#insert_null_as_default} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用在不[nullable](/sql-reference/data-types/nullable)数据类型的列中插入[默认值](/sql-reference/statements/create/table#default_values)，而不是[NULL](/sql-reference/syntax#null)。
如果列类型不可为NULL且此设置禁用，则插入`NULL`会导致异常。如果列类型可为NULL，则`NULL`值将按原样插入，而不考虑该设置。

此设置适用于[INSERT ... SELECT](../../sql-reference/statements/insert-into.md/#inserting-the-results-of-select)查询。请注意，`SELECT`子查询可以与`UNION ALL`子句连接。

可能的值：

- 0 — 插入`NULL`到不可空列会导致异常。
- 1 — 默认列值插入代替`NULL`。
## insert_quorum {#insert_quorum} 

<SettingsInfoBlock type="UInt64Auto" default_value="0" />

:::note
此设置不适用于SharedMergeTree，更多信息请参见[SharedMergeTree一致性](/cloud/reference/shared-merge-tree#consistency)。
:::

启用法定人数写入。

- 如果 `insert_quorum < 2`，法定人数写入被禁用。
- 如果 `insert_quorum >= 2`，法定人数写入被启用。
- 如果 `insert_quorum = 'auto'`，则使用多数（`number_of_replicas / 2 + 1`）作为法定人数。

法定人数写入

只有当ClickHouse在`insert_quorum_timeout`期间成功将数据写入到`insert_quorum`副本时，`INSERT`才成功。如果因任何原因成功写入的副本数量未达到`insert_quorum`，则写入视为失败，ClickHouse将从所有已写入数据的副本中删除插入的块。

当`insert_quorum_parallel`被禁用时，法定人数中的所有副本是一致的，即它们包含所有先前`INSERT`查询的数据（`INSERT`序列是线性化的）。使用`insert_quorum`和禁用`insert_quorum_parallel`时读取数据，您可以通过使用[select_sequential_consistency](#select_sequential_consistency)来打开`SELECT`查询的顺序一致性。

ClickHouse生成异常：

- 如果在查询时可用副本的数量少于`insert_quorum`。
- 当`insert_quorum_parallel`被禁用，并尝试在前一个块尚未插入到副本的`insert_quorum`中时进行写入。这种情况可能发生在用户尝试在之前一个带有`insert_quorum`的INSERT查询完成之前执行另一个INSERT查询时。

另请参见：

- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)
## insert_quorum_parallel {#insert_quorum_parallel} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.1"},{"label": "1"},{"label": "默认使用并行仲裁插入。使用起来明显比顺序仲裁插入方便"}]}]}/>

:::note
此设置不适用于SharedMergeTree，更多信息请参见 [SharedMergeTree一致性](/cloud/reference/shared-merge-tree#consistency)。
:::

启用或禁用仲裁 `INSERT` 查询的并行性。如果启用，在前一个查询尚未完成时，可以发送额外的 `INSERT` 查询。如果禁用，对同一表的额外写入将被拒绝。

可能的值：

- 0 — 禁用。
- 1 — 启用。

另请参见：

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [select_sequential_consistency](#select_sequential_consistency)
## insert_quorum_timeout {#insert_quorum_timeout} 

<SettingsInfoBlock type="Milliseconds" default_value="600000" />

以毫秒为单位的仲裁写入超时。如果超时已过且尚未进行写入，ClickHouse将生成异常，客户端必须重复查询以将相同数据块写入相同或任何其他副本。

另请参见：

- [insert_quorum](#insert_quorum)
- [insert_quorum_parallel](#insert_quorum_parallel)
- [select_sequential_consistency](#select_sequential_consistency)
## insert_shard_id {#insert_shard_id} 

<SettingsInfoBlock type="UInt64" default_value="0" />

如果不为 `0`，则指定将数据同步插入到的 [Distributed](/engines/table-engines/special/distributed) 表的分片。

如果 `insert_shard_id` 值不正确，服务器将抛出异常。

要获取 `requested_cluster` 上的分片数量，可以检查服务器配置或使用以下查询：

```sql
SELECT uniq(shard_num) FROM system.clusters WHERE cluster = 'requested_cluster';
```

可能的值：

- 0 — 禁用。
- 从 `1` 到相应的 [Distributed](/engines/table-engines/special/distributed) 表的 `shards_num` 的任何数字。

**示例**

查询：

```sql
CREATE TABLE x AS system.numbers ENGINE = MergeTree ORDER BY number;
CREATE TABLE x_dist AS x ENGINE = Distributed('test_cluster_two_shards_localhost', currentDatabase(), x);
INSERT INTO x_dist SELECT * FROM numbers(5) SETTINGS insert_shard_id = 1;
SELECT * FROM x_dist ORDER BY number ASC;
```

结果：

```text
┌─number─┐
│      0 │
│      0 │
│      1 │
│      1 │
│      2 │
│      2 │
│      3 │
│      3 │
│      4 │
│      4 │
└────────┘
```
## interactive_delay {#interactive_delay} 

<SettingsInfoBlock type="UInt64" default_value="100000" />

以微秒为单位的间隔，用于检查请求执行是否已被取消并发送进度。
## intersect_default_mode {#intersect_default_mode} 

<SettingsInfoBlock type="SetOperationMode" default_value="ALL" />

设置 INTERSECT 查询的默认模式。可能的值：空字符串，'ALL'，'DISTINCT'。如果为空，则不包含模式的查询将抛出异常。
## join_algorithm {#join_algorithm} 

<SettingsInfoBlock type="JoinAlgorithm" default_value="direct,parallel_hash,hash" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "direct,parallel_hash,hash"},{"label": "'default' 被弃用，推荐明确指定连接算法，且现在更推荐使用 parallel_hash 而不是 hash"}]}]}/>

指定使用哪个 [JOIN](../../sql-reference/statements/select/join.md) 算法。

可以指定多个算法，具体查询将根据类型/严格性和表引擎选择可用的算法。

可能的值：

- grace_hash

 [Grace hash join](https://en.wikipedia.org/wiki/Hash_join#Grace_hash_join) 被使用。Grace hash 提供了一种算法选项，可以高效处理复杂连接，同时限制内存使用。

 Grace 连接的第一阶段读取右表，并根据键列的哈希值将其拆分为 N 桶（最初，N 为 `grace_hash_join_initial_buckets`）。这样做是为了确保每个桶可以独立处理。将第一桶的行添加到内存中的哈希表中，而其他行将保存到磁盘。如果哈希表的内存使用超过限制（例如，由 [`max_bytes_in_join`](/operations/settings/settings#max_bytes_in_join) 设置），桶的数量将增加，并重新分配每行的桶。任何不属于当前桶的行将被冲洗并重新分配。

 支持 `INNER/LEFT/RIGHT/FULL ALL/ANY JOIN`。

- hash

 [Hash join algorithm](https://en.wikipedia.org/wiki/Hash_join) 被使用。最通用的实现支持各种类型和严格性的组合以及在 `JOIN ON` 部分用 `OR` 组合的多个连接键。

 使用 `hash` 算法时，`JOIN` 的右侧部分被加载到 RAM 中。

- parallel_hash

 `hash` 连接的变种，将数据拆分为多个桶并同时构建多个哈希表以加快这一过程。

 使用 `parallel_hash` 算法时，`JOIN` 的右侧部分也被加载到 RAM 中。

- partial_merge

 一种 [sort-merge算法](https://en.wikipedia.org/wiki/Sort-merge_join) 的变种，其中只有右表被完全排序。

 `RIGHT JOIN` 和 `FULL JOIN` 仅在 'ALL' 严格性下支持（不支持 `SEMI`、`ANTI`、`ANY` 和 `ASOF`）。

 使用 `partial_merge` 算法时，ClickHouse 对数据进行排序并转储到磁盘。ClickHouse 中的 `partial_merge` 算法与经典实现略有不同。首先，ClickHouse 按连接键对右表进行排序，并为已排序的块创建最小-最大索引。然后按 `join key` 对左表的部分进行排序，并在右表上对它们进行连接。最小-最大索引也用于跳过不需要的右表块。

- direct

 当右表的存储支持键值请求时，可以应用此算法。

 `direct` 算法使用左表的行作为键在右表中执行查找。仅由特殊存储支持，例如 [Dictionary](/engines/table-engines/special/dictionary) 或 [EmbeddedRocksDB](../../engines/table-engines/integrations/embedded-rocksdb.md)，并且仅支持 `LEFT` 和 `INNER` JOIN。

- auto

 设置为 `auto` 时，首先尝试 `hash` 连接，若内存限制被违反，则动态切换到其他算法。

- full_sorting_merge

 [Sort-merge algorithm](https://en.wikipedia.org/wiki/Sort-merge_join) 在加入之前对连接的表进行完全排序。

- prefer_partial_merge

 ClickHouse 总是尽可能尝试使用 `partial_merge` 连接，否则使用 `hash`。*已弃用*，与 `partial_merge,hash` 相同。

- default (已弃用)

 旧值，请勿再使用。与 `direct,hash` 相同，即尝试首先使用直接连接，然后使用哈希连接。
## join_any_take_last_row {#join_any_take_last_row} 

<SettingsInfoBlock type="Bool" default_value="0" />

更改与 `ANY` 严格性连接操作的行为。

:::note
此设置仅适用于使用 [Join](../../engines/table-engines/special/join.md) 引擎表的 `JOIN` 操作。
:::

可能的值：

- 0 — 如果右表有多个匹配的行，则仅连接找到的第一行。
- 1 — 如果右表有多个匹配的行，则仅连接找到的最后一行。

另请参见：

- [JOIN 子句](/sql-reference/statements/select/join)
- [Join 表引擎](../../engines/table-engines/special/join.md)
- [join_default_strictness](#join_default_strictness)
## join_default_strictness {#join_default_strictness} 

<SettingsInfoBlock type="JoinStrictness" default_value="ALL" />

设置 [JOIN 子句](/sql-reference/statements/select/join) 的默认严格性。

可能的值：

- `ALL` — 如果右表有多个匹配行，ClickHouse 从匹配行创建一个 [笛卡尔积](https://en.wikipedia.org/wiki/Cartesian_product)。这是标准 SQL 的正常 `JOIN` 行为。
- `ANY` — 如果右表有多个匹配行，仅连接找到的第一行。如果右表只有一行匹配，`ANY` 和 `ALL` 的结果相同。
- `ASOF` — 用于连接具有不确定匹配的序列。
- `空字符串` — 如果查询中未指定 `ALL` 或 `ANY`，ClickHouse 将抛出异常。
## join_on_disk_max_files_to_merge {#join_on_disk_max_files_to_merge} 

<SettingsInfoBlock type="UInt64" default_value="64" />

限制在执行磁盘上的 MergeJoin 操作时允许并行排序的文件数量。

设置的值越大，使用的 RAM 越多，所需的磁盘 I/O 越少。

可能的值：

- 任何正整数，从 2 开始。
## join_output_by_rowlist_perkey_rows_threshold {#join_output_by_rowlist_perkey_rows_threshold} 

<SettingsInfoBlock type="UInt64" default_value="5" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "5"},{"label": "右表的每个键的平均行数的下限，以确定是否以行列表的形式输出 hash join。"}]}]}/>

右表的每个键的平均行数的下限，以确定是否以行列表的形式输出 hash join。
## join_overflow_mode {#join_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

定义 ClickHouse 在达到以下任意连接限制时执行的操作：

- [max_bytes_in_join](/operations/settings/settings#max_bytes_in_join)
- [max_rows_in_join](/operations/settings/settings#max_rows_in_join)

可能的值：

- `THROW` — ClickHouse 抛出异常并中断操作。
- `BREAK` — ClickHouse 中断操作并不会抛出异常。

默认值：`THROW`。

**另请参见**

- [JOIN 子句](/sql-reference/statements/select/join)
- [Join 表引擎](/engines/table-engines/special/join)
## join_to_sort_maximum_table_rows {#join_to_sort_maximum_table_rows} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="10000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "10000"},{"label": "右表的最大行数，以确定在左连接或内连接中是否按键重新排列右表"}]}]}/>

右表的最大行数，以确定在左连接或内连接中是否按键重新排列右表。
## join_to_sort_minimum_perkey_rows {#join_to_sort_minimum_perkey_rows} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="40" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "40"},{"label": "右表的每个键的平均行数的下限，以确定是否按键重新排列右表。此设置确保不会对稀疏表键应用优化"}]}]}/>

右表的每个键的平均行数的下限，以确定是否按键重新排列右表。此设置确保不会对稀疏表键应用优化。
## join_use_nulls {#join_use_nulls} 

<SettingsInfoBlock type="Bool" default_value="0" />

设置 [JOIN](../../sql-reference/statements/select/join.md) 行为的类型。在合并表时，可能出现空单元格。ClickHouse 根据此设置以不同方式填充它们。

可能的值：

- 0 — 空单元格填充为对应字段类型的默认值。
- 1 — `JOIN` 的行为与标准 SQL 相同。对应字段的类型被转换为 [Nullable](/sql-reference/data-types/nullable)，空单元格则填充为 [NULL](/sql-reference/syntax)。
## joined_subquery_requires_alias {#joined_subquery_requires_alias} 

<SettingsInfoBlock type="Bool" default_value="1" />

强制连接的子查询和表函数具有别名，以便进行正确的名称限定。
## kafka_disable_num_consumers_limit {#kafka_disable_num_consumers_limit} 

<SettingsInfoBlock type="Bool" default_value="0" />

禁用对 kafka_num_consumers 的限制，此限制取决于可用 CPU 核心的数量。
## kafka_max_wait_ms {#kafka_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="5000" />

从 [Kafka](/engines/table-engines/integrations/kafka) 读取消息之前的等待时间（以毫秒为单位）。

可能的值：

- 正整数。
- 0 — 无限超时。

另请参见：

- [Apache Kafka](https://kafka.apache.org/)
## keeper_map_strict_mode {#keeper_map_strict_mode} 

<SettingsInfoBlock type="Bool" default_value="0" />

在对 KeeperMap 执行操作时实施额外检查。例如，在已存在的键插入时抛出异常。
## keeper_max_retries {#keeper_max_retries} 

<SettingsInfoBlock type="UInt64" default_value="10" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "10"},{"label": "通用 keeper 操作的最大重试次数"}]}]}/>

通用 keeper 操作的最大重试次数。
## keeper_retry_initial_backoff_ms {#keeper_retry_initial_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="100" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "100"},{"label": "通用 keeper 操作的初始退避超时"}]}]}/>

通用 keeper 操作的初始退避超时。
## keeper_retry_max_backoff_ms {#keeper_retry_max_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="5000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "5000"},{"label": "通用 keeper 操作的最大退避超时"}]}]}/>

通用 keeper 操作的最大退避超时。
## least_greatest_legacy_null_behavior {#least_greatest_legacy_null_behavior} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "新设置"}]}]}/>

如果启用，函数 'least' 和 'greatest' 在其参数之一为 NULL 时将返回 NULL。
## legacy_column_name_of_tuple_literal {#legacy_column_name_of_tuple_literal} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.7"},{"label": "0"},{"label": "仅出于兼容性原因添加此设置。在从 21.7 版本及以下升级到更高版本时，设置为 'true' 是有意义的"}]}]}/>

以列名的形式列出大元组字面量中所有元素的名称，而不是哈希值。此设置仅存在于兼容性原因。在从 21.7 版本及以下版本逐步升级时，设置为 'true' 是有意义的。
## lightweight_delete_mode {#lightweight_delete_mode} 

<SettingsInfoBlock type="LightweightDeleteMode" default_value="alter_update" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "alter_update"},{"label": "新设置"}]}]}/>

执行轻量级删除内部更新查询的模式。

可能的值：
- `alter_update` - 运行创建重量级变更的 `ALTER UPDATE` 查询。
- `lightweight_update` - 如果可能，运行轻量级更新，否则运行 `ALTER UPDATE`。
- `lightweight_update_force` - 如果可能，运行轻量级更新，否则抛出异常。
## lightweight_deletes_sync {#lightweight_deletes_sync} 

<SettingsInfoBlock type="UInt64" default_value="2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "2"},{"label": "与 'mutation_sync' 相同，但仅控制轻量级删除的执行"}]}]}/>

与 [`mutations_sync`](#mutations_sync) 相同，但仅控制轻量级删除的执行。

可能的值：

- 0 - 变更异步执行。
- 1 - 查询等待轻量级删除在当前服务器上完成。
- 2 - 查询等待轻量级删除在所有副本上完成（如果存在）。

**另请参见**

- [ALTER 查询的同步性](../../sql-reference/statements/alter/index.md/#synchronicity-of-alter-queries)
- [变更](../../sql-reference/statements/alter/index.md/#mutations)
## limit {#limit} 

<SettingsInfoBlock type="UInt64" default_value="0" />

设置从查询结果中获取的最大行数。它调整由 [LIMIT](/sql-reference/statements/select/limit) 子句设置的值，以使查询中指定的限制不超过此设置所定义的限制。

可能的值：

- 0 — 行数没有限制。
- 正整数。
## live_view_heartbeat_interval {#live_view_heartbeat_interval} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Seconds" default_value="15" />

以秒为单位的心跳间隔，用于指示实时查询处于活动状态。
## load_balancing {#load_balancing} 

<SettingsInfoBlock type="LoadBalancing" default_value="random" />

指定用于分布式查询处理的副本选择算法。

ClickHouse 支持以下选择副本的算法：

- [随机](#load_balancing-random)（默认）
- [最近主机名](#load_balancing-nearest_hostname)
- [主机名 levenshtein 距离](#load_balancing-hostname_levenshtein_distance)
- [按顺序](#load_balancing-in_order)
- [第一个或随机](#load_balancing-first_or_random)
- [轮询](#load_balancing-round_robin)

另请参见：

- [distributed_replica_max_ignored_errors](#distributed_replica_max_ignored_errors)
### 随机（默认） {#load_balancing-random}

```sql
load_balancing = random
```

对每个副本计算错误数量。查询将发送到错误最少的副本，如果有多个，则可以发送到其中任何一个。
缺点：未考虑服务器的接近性；如果副本具有不同的数据，您也会得到不同的数据。
### 最近主机名 {#load_balancing-nearest_hostname}

```sql
load_balancing = nearest_hostname
```

对每个副本计算错误数量。每 5 分钟，错误数量会整体减半。因此，错误数量是对近期时间的计算，并具有指数平滑效果。如果有一个副本的错误数量最少（即最近在其他副本上发生的错误），则将查询发送给它。如果有多个副本的错误数量相同，则查询将发送到与配置文件中服务器主机名最相似的副本（在最小长度的相同位置字符不同的数量上）。

例如，example01-01-1 和 example01-01-2 在一个位置上不同，而 example01-01-1 和 example01-02-2 在两个位置上不同。
这种方法可能看起来很原始，但它不需要有关网络拓扑的外部数据，并且它不比较 IP 地址，这对于我们的 IPv6 地址而言是复杂的。

因此，如果存在等价副本，将首选名称最接近的那个。
我们还可以假设在没有故障的情况下，将查询发送到同一服务器时，分布式查询也将到达相同服务器。因此，即使副本上放置了不同的数据，查询返回的结果也大多是相同的。
### 主机名 levenshtein 距离 {#load_balancing-hostname_levenshtein_distance}

```sql
load_balancing = hostname_levenshtein_distance
```

与 `nearest_hostname` 一样，但它采用 [levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) 的方式进行主机名比较。例如：

```text
example-clickhouse-0-0 ample-clickhouse-0-0
1

example-clickhouse-0-0 example-clickhouse-1-10
2

example-clickhouse-0-0 example-clickhouse-12-0
3
```
### 按顺序 {#load_balancing-in_order}

```sql
load_balancing = in_order
```

具有相同错误数量的副本按照其在配置中的指定顺序访问。
当您确切知道哪个副本更可取时，此方法是合适的。
### 第一个或随机 {#load_balancing-first_or_random}

```sql
load_balancing = first_or_random
```

该算法选择集合中的第一个副本，或如果第一个不可用，则选择随机副本。这在交叉副本拓扑设置中非常有效，但在其他配置中无用。

`first_or_random` 算法解决了 `in_order` 算法的问题。在 `in_order` 中，如果一个副本出现故障，则下一个副本承受了双重负担，而其余副本则处理正常的流量。在使用 `first_or_random` 算法时，负载在仍可用的副本之间均匀分配。

可以通过使用设置 `load_balancing_first_offset` 明确指定第一个副本。这更多地控制了在副本之间重新平衡查询工作负载。
### 轮询 {#load_balancing-round_robin}

```sql
load_balancing = round_robin
```

该算法在具有相同错误数量的副本之间使用轮询策略（仅计算带有 `round_robin` 策略的查询）。
## load_balancing_first_offset {#load_balancing_first_offset} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在使用 FIRST_OR_RANDOM 负载均衡策略时，优先发送查询到哪个副本。
## load_marks_asynchronously {#load_marks_asynchronously} 

<SettingsInfoBlock type="Bool" default_value="0" />

异步加载 MergeTree 标记。
## local_filesystem_read_method {#local_filesystem_read_method} 

<SettingsInfoBlock type="String" default_value="pread_threadpool" />

从本地文件系统读取数据的方法之一：read、pread、mmap、io_uring、pread_threadpool。

'io_uring' 方法是实验性的，不能用于 Log、TinyLog、StripeLog、File、Set 和 Join 表及其他在并发读写情况下存在的可附加文件。
如果您在网上阅读有关 'io_uring' 的各种文章，请不要被它们所迷惑。除非在存在大量小的 IO 请求的情况下（而在 ClickHouse 中并非如此），否则这并不是一种更好的读取文件的方法。没有理由启用 'io_uring'。
## local_filesystem_read_prefetch {#local_filesystem_read_prefetch} 

<SettingsInfoBlock type="Bool" default_value="0" />

在从本地文件系统读取数据时是否使用预取。
## lock_acquire_timeout {#lock_acquire_timeout} 

<SettingsInfoBlock type="Seconds" default_value="120" />

定义锁请求在失败之前等待的时间（以秒为单位）。

锁定超时用于保护在执行读取/写入操作的表时防止死锁。当超时到期并且锁请求失败时，ClickHouse 服务器将抛出异常“锁定尝试超时！可能避免的死锁。客户端应重试。”并带有错误代码 `DEADLOCK_AVOIDED`。

可能的值：

- 正整数（以秒为单位）。
- 0 — 无锁定超时。
## log_comment {#log_comment} 

指定 [system.query_log](../system-tables/query_log.md) 表中 `log_comment` 字段的值和服务器日志的注释文本。

可用于提高服务器日志的可读性。此外，它有助于从运行 [clickhouse-test](../../development/tests.md) 后选择与测试相关的查询，以便从 `system.query_log` 中进行筛选。

可能的值：

- 任何字符串，长度不超过 [max_query_size](#max_query_size)。如果超过了 max_query_size，服务器将抛出异常。

**示例**

查询：

```sql
SET log_comment = 'log_comment test', log_queries = 1;
SELECT 1;
SYSTEM FLUSH LOGS;
SELECT type, query FROM system.query_log WHERE log_comment = 'log_comment test' AND event_date >= yesterday() ORDER BY event_time DESC LIMIT 2;
```

结果：

```text
┌─type────────┬─query─────┐
│ QueryStart  │ SELECT 1; │
│ QueryFinish │ SELECT 1; │
└─────────────┴───────────┘
```
## log_formatted_queries {#log_formatted_queries} 

<SettingsInfoBlock type="Bool" default_value="0" />

允许将格式化查询记录到 [system.query_log](../../operations/system-tables/query_log.md) 系统表中（填充 [system.query_log](../../operations/system-tables/query_log.md) 中的 `formatted_query` 列）。

可能的值：

- 0 — 系统表中不记录格式化查询。
- 1 — 系统表中记录格式化查询。
## log_processors_profiles {#log_processors_profiles} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "默认启用"}]}]}/>

将处理器在执行/等待数据时花费的时间写入 `system.processors_profile_log` 表。

另请参见：

- [`system.processors_profile_log`](../../operations/system-tables/processors_profile_log.md)
- [`EXPLAIN PIPELINE`](../../sql-reference/statements/explain.md/#explain-pipeline)
## log_profile_events {#log_profile_events} 

<SettingsInfoBlock type="Bool" default_value="1" />

将查询性能统计信息记录到 query_log、query_thread_log 和 query_views_log 中。
## log_queries {#log_queries} 

<SettingsInfoBlock type="Bool" default_value="1" />

设置查询日志。

使用此设置发送到 ClickHouse 的查询将根据 [query_log](../../operations/server-configuration-parameters/settings.md/#query_log) 服务器配置参数中的规则记录。

示例：

```text
log_queries=1
```
## log_queries_cut_to_length {#log_queries_cut_to_length} 

<SettingsInfoBlock type="UInt64" default_value="100000" />

如果查询长度大于指定阈值（以字节为单位），则在写入查询日志时剪切查询。同时限制普通文本日志中打印的查询长度。
## log_queries_min_query_duration_ms {#log_queries_min_query_duration_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

如果启用（非零），速度快于该设置值的查询将不会被记录（您可以将其视为 [MySQL 慢查询日志](https://dev.mysql.com/doc/refman/5.7/slow-query-log.html) 中的 `long_query_time`），这基本上意味着您在以下表中不会找到它们：

- `system.query_log`
- `system.query_thread_log`

仅以下类型的查询将进入日志：

- `QUERY_FINISH`
- `EXCEPTION_WHILE_PROCESSING`

- 类型：毫秒
- 默认值：0（任何查询）
## log_queries_min_type {#log_queries_min_type} 

<SettingsInfoBlock type="LogQueriesType" default_value="QUERY_START" />

`query_log` 最小类型以进行记录。

可能的值：
- `QUERY_START` (`=1`)
- `QUERY_FINISH` (`=2`)
- `EXCEPTION_BEFORE_START` (`=3`)
- `EXCEPTION_WHILE_PROCESSING` (`=4`)

可以用于限制哪些实体将写入 `query_log`，例如您只对错误感兴趣，则可以使用 `EXCEPTION_WHILE_PROCESSING`：

```text
log_queries_min_type='EXCEPTION_WHILE_PROCESSING'
```
## log_queries_probability {#log_queries_probability} 

<SettingsInfoBlock type="Float" default_value="1" />

允许用户仅以指定概率随机选择的样本将查询写入 [query_log](../../operations/system-tables/query_log.md)、[query_thread_log](../../operations/system-tables/query_thread_log.md) 和 [query_views_log](../../operations/system-tables/query_views_log.md) 系统表。这有助于减少每秒大量查询带来的负载。

可能的值：

- 0 — 查询不记录在系统表中。
- 正的浮点数，范围在 [0..1] 内。例如，如果设置值为 `0.5`，则大约一半的查询将记录在系统表中。
- 1 — 所有查询都记录在系统表中。
## log_query_settings {#log_query_settings} 

<SettingsInfoBlock type="Bool" default_value="1" />

将查询设置记录到 query_log 中以及 OpenTelemetry 的跨度日志中。
## log_query_threads {#log_query_threads} 

<SettingsInfoBlock type="Bool" default_value="0" />

设置查询线程日志。

查询线程记录到 [system.query_thread_log](../../operations/system-tables/query_thread_log.md) 表。这一设置仅在 [log_queries](#log_queries) 为真时有效。使用此设置运行的 ClickHouse 查询的线程根据 [query_thread_log](/operations/server-configuration-parameters/settings#query_thread_log) 服务器配置参数中的规则被记录。

可能的值：

- 0 — 禁用。
- 1 — 启用。

**示例**

```text
log_query_threads=1
```
## log_query_views {#log_query_views} 

<SettingsInfoBlock type="Bool" default_value="1" />

设置查询视图日志。

当 ClickHouse 运行的查询与此设置启用时存在关联的视图（物化视图或实时视图）时，它们将记录在 [query_views_log](/operations/server-configuration-parameters/settings#query_views_log) 服务器配置参数中。

示例：

```text
log_query_views=1
```
## low_cardinality_allow_in_native_format {#low_cardinality_allow_in_native_format} 

<SettingsInfoBlock type="Bool" default_value="1" />

允许或限制在 [Native](../../interfaces/formats.md/#native) 格式下使用 [LowCardinality](../../sql-reference/data-types/lowcardinality.md) 数据类型。

如果限制使用 `LowCardinality`，则 ClickHouse 服务器在 `SELECT` 查询中将 `LowCardinality` 列转换为普通列，并在 `INSERT` 查询中将普通列转换为 `LowCardinality` 列。

此设置主要是为不支持 `LowCardinality` 数据类型的第三方客户端而设置的。

可能的值：

- 1 — 使用 `LowCardinality` 不受限制。
- 0 — 使用 `LowCardinality` 受限。
## low_cardinality_max_dictionary_size {#low_cardinality_max_dictionary_size} 

<SettingsInfoBlock type="UInt64" default_value="8192" />

设置共享全局字典的最大行数，对于可以写入存储文件系统的 [LowCardinality](../../sql-reference/data-types/lowcardinality.md) 数据类型。此设置可以防止无限字典增长所造成的 RAM 问题。所有由于最大字典大小限制而无法编码的数据，ClickHouse 都会以普通方法写入。

可能的值：

- 任何正整数。
## low_cardinality_use_single_dictionary_for_part {#low_cardinality_use_single_dictionary_for_part} 

<SettingsInfoBlock type="Bool" default_value="0" />

开启或关闭对数据部分使用单一字典的选项。

默认情况下，ClickHouse 服务器会监控字典的大小，如果字典溢出，则服务器开始写入下一个字典。要禁止创建多个字典，请设置 `low_cardinality_use_single_dictionary_for_part = 1`。

可能的值：

- 1 — 禁止为数据部分创建多个字典。
- 0 — 允许为数据部分创建多个字典。
## low_priority_query_wait_time_ms {#low_priority_query_wait_time_ms} 

<BetaBadge/>

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1000"},{"label": "新设置。"}]}]}/>

当查询优先级机制被使用时（参见设置 `priority`），低优先级查询将在高优先级查询完成之前等待。此设置指定等待的持续时间。
## make_distributed_plan {#make_distributed_plan} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "新的实验性设置。"}]}]}/>

制作分布式查询计划。
## materialize_skip_indexes_on_insert {#materialize_skip_indexes_on_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "添加新的设置以允许在插入时禁用跳过索引的物化"}]}]}/>

如果 INSERT 构建并存储跳过索引。如果禁用，跳过索引将在合并过程中或通过显式的 MATERIALIZE INDEX 构建和存储。
## materialize_statistics_on_insert {#materialize_statistics_on_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "添加新的设置以允许在插入时禁用统计信息的物化"}]}]}/>

如果 INSERT 构建并插入统计信息。如果禁用，统计信息将在合并过程中或通过显式的 MATERIALIZE STATISTICS 构建和存储。
## materialize_ttl_after_modify {#materialize_ttl_after_modify} 

<SettingsInfoBlock type="Bool" default_value="1" />

对旧数据应用 TTL，之后 ALTER MODIFY TTL 查询。
## materialized_views_ignore_errors {#materialized_views_ignore_errors} 

<SettingsInfoBlock type="Bool" default_value="0" />

允许忽略 MATERIALIZED VIEW 的错误，并将原始块传递到表中，不管 MVs 的情况。
## max_analyze_depth {#max_analyze_depth} 

<SettingsInfoBlock type="UInt64" default_value="5000" />

解释器执行的最大分析次数。
## max_ast_depth {#max_ast_depth} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

查询语法树的最大嵌套深度。如果超过，将引发异常。

:::note
此时，嵌套深度检查不会在解析时进行，而是在解析查询后进行。这意味着在解析期间可能会创建过深的语法树，但查询将失败。
:::
## max_ast_elements {#max_ast_elements} 

<SettingsInfoBlock type="UInt64" default_value="50000" />

查询语法树中元素的最大数量。如果超过，将引发异常。

:::note
此时，嵌套元素检查不会在解析时进行，而是在解析查询后进行。这意味着在解析期间可能会创建过深的语法树，但查询将失败。
:::
## max_autoincrement_series {#max_autoincrement_series} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1000"},{"label": "新设置"}]}]}/>

由 `generateSeriesID` 函数创建的系列的数量限制。

由于每个系列代表 Keeper 中的一个节点，建议每个系列的数量不超过几百万。
## max_backup_bandwidth {#max_backup_bandwidth} 

<SettingsInfoBlock type="UInt64" default_value="0" />

特定备份在服务器上的最大读取速度（字节/秒）。零表示无限制。
## max_block_size {#max_block_size} 

<SettingsInfoBlock type="NonZeroUInt64" default_value="65409" />

在 ClickHouse 中，数据按块处理，块是列部分的集合。单个块的内部处理周期是高效的，但处理每个块时会产生明显的成本。

`max_block_size` 设置指示在从表加载数据时建议单个块中包含的最大行数。`max_block_size` 大小的块并不总是从表中加载：如果 ClickHouse 确定需要检索的数据量较少，则处理一个较小的块。

块大小不应过小，以避免在处理每个块时产生显著的成本。它也不应过大，以确保带有 LIMIT 子句的查询在处理第一个块后能够快速执行。设置 `max_block_size` 时，目标应是避免在多个线程中提取大量列时消耗过多的内存，并保持至少一些缓存局部性。
## max_bytes_before_external_group_by {#max_bytes_before_external_group_by} 

<SettingsInfoBlock type="UInt64" default_value="0" />

云默认值：每副本内存量的一半。

启用或禁止在外部内存中执行 `GROUP BY` 子句。
（参见 [在外部内存中进行 GROUP BY](/sql-reference/statements/select/group-by#group-by-in-external-memory)）

可能的值：

- 单个 [GROUP BY](/sql-reference/statements/select/group-by) 操作可以使用的最大 RAM 容量（以字节为单位）。
- `0` — 禁用外部内存中的 `GROUP BY`。

:::note
如果在 GROUP BY 操作期间的内存使用超过此阈值（以字节为单位），则激活“外部聚合”模式（将数据溢出到磁盘）。

建议值为可用系统内存的一半。
:::
## max_bytes_before_external_sort {#max_bytes_before_external_sort} 

<SettingsInfoBlock type="UInt64" default_value="0" />

云默认值：每副本内存量的一半。

启用或禁用在外部内存中执行 `ORDER BY` 子句。请参见 [ORDER BY 实现细节](../../sql-reference/statements/select/order-by.md#implementation-details)
如果在 ORDER BY 操作期间内存使用超过此阈值（以字节为单位），则激活“外部排序”模式（将数据溢出到磁盘）。

可能的值：

- 单个 [ORDER BY](../../sql-reference/statements/select/order-by) 操作可以使用的最大 RAM 容量（以字节为单位）。
  建议值为可用系统内存的一半。
- `0` — 禁用外部内存中的 `ORDER BY`。
## max_bytes_before_remerge_sort {#max_bytes_before_remerge_sort} 

<SettingsInfoBlock type="UInt64" default_value="1000000000" />

在带有 LIMIT 的 ORDER BY 的情况下，当内存使用高于指定阈值时，执行额外的步骤以在最终合并之前合并块，以保持仅返回前 LIMIT 行。
## max_bytes_in_distinct {#max_bytes_in_distinct} 

<SettingsInfoBlock type="UInt64" default_value="0" />

当使用 DISTINCT 时，哈希表在内存中使用的状态的最大字节数（未压缩字节）。
## max_bytes_in_join {#max_bytes_in_join} 

<SettingsInfoBlock type="UInt64" default_value="0" />

用于连接表时哈希表的最大字节数。

该设置适用于 [SELECT ... JOIN](/sql-reference/statements/select/join) 操作和 [Join 表引擎](/engines/table-engines/special/join)。

如果查询包含连接，ClickHouse 会对每个中间结果检查此设置。

当达到限制时，ClickHouse 可以采取不同的操作。使用 [join_overflow_mode](/operations/settings/settings#join_overflow_mode) 设置来选择操作。

可能的值：

- 正整数。
- 0 — 禁用内存控制。
## max_bytes_in_set {#max_bytes_in_set} 

<SettingsInfoBlock type="UInt64" default_value="0" />

通过子查询创建的 IN 子句中使用的集合的最大字节数（未压缩数据）。
## max_bytes_ratio_before_external_group_by {#max_bytes_ratio_before_external_group_by} 

<SettingsInfoBlock type="Double" default_value="0.5" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0.5"},{"label": "默认启用自动溢出到磁盘。"}]}]}/>

允许的可用内存比例，用于 `GROUP BY`。达到后，将使用外部内存进行聚合。

例如，如果设置为 `0.6`，则 `GROUP BY` 将允许在执行开始时使用 60% 的可用内存（针对服务器/用户/合并），之后将开始使用外部聚合。
## max_bytes_ratio_before_external_sort {#max_bytes_ratio_before_external_sort} 

<SettingsInfoBlock type="Double" default_value="0.5" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0.5"},{"label": "默认启用自动溢出到磁盘。"}]}]}/>

允许的可用内存比例，用于 `ORDER BY`。达到后，将使用外部排序。

例如，如果设置为 `0.6`，则 `ORDER BY` 将允许在执行开始时使用 60% 的可用内存（针对服务器/用户/合并），之后将开始使用外部排序。
## max_bytes_to_read {#max_bytes_to_read} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在运行查询时，可以从表中读取的最大字节数（未压缩数据）。
该限制会针对每个处理的数据块进行检查，只适用于最深的表表达式，并且在从远程服务器读取时，仅在远程服务器上进行检查。
## max_bytes_to_read_leaf {#max_bytes_to_read_leaf} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在运行分布式查询时，可以从叶节点的本地表中读取的最大字节数（未压缩数据）。虽然分布式查询可以对每个分片（叶节点）发出多个子查询——此限制仅在叶节点的读取阶段进行检查，并在根节点的结果合并阶段被忽略。

例如，一个集群由 2 个分片组成，每个分片包含 100 字节的数据。一条分布式查询希望从两个表中读取所有数据，其设置为 `max_bytes_to_read=150` 将失败，因为总共为 200 字节。一条带有 `max_bytes_to_read_leaf=150` 的查询将成功，因为叶节点最多将读取 100 字节。

该限制会针对每个处理的数据块进行检查。

:::note
该设置在 `prefer_localhost_replica=1` 时不稳定。
:::
## max_bytes_to_sort {#max_bytes_to_sort} 

<SettingsInfoBlock type="UInt64" default_value="0" />

排序之前的最大字节数。如果需要处理的未压缩字节数超过指定数量，`ORDER BY` 操作的行为将由 `sort_overflow_mode` 决定，默认设置为 `throw`。
## max_bytes_to_transfer {#max_bytes_to_transfer} 

<SettingsInfoBlock type="UInt64" default_value="0" />

可以传递到远程服务器或在执行 GLOBAL IN/JOIN 部分时保存到临时表的最大字节数（未压缩数据）。
## max_columns_to_read {#max_columns_to_read} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在单一查询中可以从表中读取的最大列数。如果查询需要读取超过指定数量的列，则会引发异常。

:::tip
此设置用于防止过于复杂的查询。
:::

`0` 值表示无限制。
## max_compress_block_size {#max_compress_block_size} 

<SettingsInfoBlock type="UInt64" default_value="1048576" />

写入表之前未压缩数据的最大块大小。默认值为 1,048,576 (1 MiB)。指定较小的块大小通常会导致压缩比略有降低，缓存局部性导致压缩和解压缩速度略有增加，内存消耗降低。

:::note
这是一个专家级设置，如果您刚刚开始使用 ClickHouse 不应更改它。
:::

不要将压缩块（由字节组成的一块内存）与查询处理块（来自表的一组行）混淆。
## max_concurrent_queries_for_all_users {#max_concurrent_queries_for_all_users} 

<SettingsInfoBlock type="UInt64" default_value="0" />

当此设置的值小于或等于当前同时处理的查询数时，抛出异常。

示例：`max_concurrent_queries_for_all_users` 可以设置为 99 供所有用户使用，数据库管理员可以为自己设置为 100，以便在服务器过载时执行查询进行调查。

为一个查询或用户修改设置不会影响其他查询。

可能的值：

- 正整数。
- 0 — 无限制。

**示例**

```xml
<max_concurrent_queries_for_all_users>99</max_concurrent_queries_for_all_users>
```

**另见**

- [max_concurrent_queries](/operations/server-configuration-parameters/settings#max_concurrent_queries)
## max_concurrent_queries_for_user {#max_concurrent_queries_for_user} 

<SettingsInfoBlock type="UInt64" default_value="0" />

每个用户同时处理的查询的最大数量。

可能的值：

- 正整数。
- 0 — 无限制。

**示例**

```xml
<max_concurrent_queries_for_user>5</max_concurrent_queries_for_user>
```
## max_distributed_connections {#max_distributed_connections} 

<SettingsInfoBlock type="UInt64" default_value="1024" />

对单个 Distributed 表执行单个查询时与远程服务器的最大同时连接数。我们建议设置的值不低于集群中的服务器数量。

以下参数仅在创建 Distributed 表（以及启动服务器）时使用，因此在运行时没有理由更改它们。
## max_distributed_depth {#max_distributed_depth} 

<SettingsInfoBlock type="UInt64" default_value="5" />

限制 [Distributed](../../engines/table-engines/special/distributed.md) 表的递归查询的最大深度。

如果 exceeded 该值，服务器报出异常。

可能的值：

- 正整数。
- 0 — 无限深度。
## max_download_buffer_size {#max_download_buffer_size} 

<SettingsInfoBlock type="UInt64" default_value="10485760" />

每个线程的并行下载（例如，对于 URL 引擎）最大缓冲区大小。
## max_download_threads {#max_download_threads} 

<SettingsInfoBlock type="MaxThreads" default_value="4" />

下载数据的最大线程数（例如，对于 URL 引擎）。
## max_estimated_execution_time {#max_estimated_execution_time} 

<SettingsInfoBlock type="Seconds" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "分离 max_execution_time 和 max_estimated_execution_time"}]}]}/>

最大查询估计执行时间（以秒为单位）。在 [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 过期时，对每个数据块进行检查。
## max_execution_speed {#max_execution_speed} 

<SettingsInfoBlock type="UInt64" default_value="0" />

每秒执行的最大行数。在 [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 过期时，对每个数据块进行检查。如果执行速度过快，将降低执行速度。
## max_execution_speed_bytes {#max_execution_speed_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

每秒执行的最大字节数。在 [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 过期时，对每个数据块进行检查。如果执行速度过快，将降低执行速度。
## max_execution_time {#max_execution_time} 

<SettingsInfoBlock type="Seconds" default_value="0" />

查询的最大执行时间（以秒为单位）。

`max_execution_time` 参数可能有些难以理解。它根据当前查询执行速度的插值来操作（该行为由 [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 控制）。

如果预计执行时间超过指定的 `max_execution_time`，ClickHouse 将中断查询。默认情况下，`timeout_before_checking_execution_speed` 设置为 10 秒。这意味着在查询执行 10 秒后，ClickHouse 将开始估算总执行时间。例如，如果将 `max_execution_time` 设置为 3600 秒（1 小时），如果估算的时间超过这个 3600 秒的限制，ClickHouse 将终止查询。如果将 `timeout_before_checking_execution_speed` 设置为 0，ClickHouse 将使用时钟时间作为 `max_execution_time` 的基础。

如果查询运行时间超过指定的秒数，将由 'timeout_overflow_mode' 决定行为，默认设置为 `throw`。

:::note
超时在数据处理过程中仅在指定位置检查并且查询可以停止。目前在合并聚合状态或查询分析期间无法停止，实际运行时间将高于此设置的值。
:::
## max_execution_time_leaf {#max_execution_time_leaf} 

<SettingsInfoBlock type="Seconds" default_value="0" />

在语义上类似于 [`max_execution_time`](#max_execution_time)，但仅应用于分布式或远程查询的叶节点。

例如，如果我们想将叶节点上的执行时间限制为 `10s`，但对初始节点没有限制，而不是在嵌套子查询的设置中使用 `max_execution_time`：

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t SETTINGS max_execution_time = 10));
```

我们可以将 `max_execution_time_leaf` 作为查询设置使用：

```sql
SELECT count()
FROM cluster(cluster, view(SELECT * FROM t)) SETTINGS max_execution_time_leaf = 10;
```
## max_expanded_ast_elements {#max_expanded_ast_elements} 

<SettingsInfoBlock type="UInt64" default_value="500000" />

展开别名和星号后的查询语法树的最大节点数。
## max_fetch_partition_retries_count {#max_fetch_partition_retries_count} 

<SettingsInfoBlock type="UInt64" default_value="5" />

从另一个主机获取分区时的重试次数。
## max_final_threads {#max_final_threads} 

<SettingsInfoBlock type="MaxThreads" default_value="'auto(N)'" />

设置带有 [FINAL](/sql-reference/statements/select/from#final-modifier) 修饰符的 `SELECT` 查询数据读取阶段的最大并行线程数。

可能的值：

- 正整数。
- 0 或 1 — 禁用。`SELECT` 查询在单线程中执行。
## max_http_get_redirects {#max_http_get_redirects} 

<SettingsInfoBlock type="UInt64" default_value="0" />

最大允许的 HTTP GET 重定向跳数。确保采取额外的安全措施，以防止恶意服务器将您的请求重定向到意外服务。\n\n例如，当外部服务器重定向到另一个地址，但该地址似乎在公司的基础设施内部，发送 HTTP 请求到内部服务器时，您可能会从内部网络请求内部 API，从而绕过身份验证，甚至查询其他服务，例如 Redis 或 Memcached。当您没有内部基础设施（包括在您的 localhost 上运行的任何东西）或信任服务器时，允许重定向是安全的。不过请注意，如果 URL 使用的是 HTTP 而不是 HTTPS，那么您不仅需要信任远程服务器，还需要信任您的 ISP 以及中间的每一条网络连接。
## max_hyperscan_regexp_length {#max_hyperscan_regexp_length} 

<SettingsInfoBlock type="UInt64" default_value="0" />

定义 [hyperscan 多匹配函数](/sql-reference/functions/string-search-functions#multimatchany) 中每个正则表达式的最大长度。

可能的值：

- 正整数。
- 0 - 长度不限制。

**示例**

查询：

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 3;
```

结果：

```text
┌─multiMatchAny('abcd', ['ab', 'bcd', 'c', 'd'])─┐
│                                              1 │
└────────────────────────────────────────────────┘
```

查询：

```sql
SELECT multiMatchAny('abcd', ['ab','bcd','c','d']) SETTINGS max_hyperscan_regexp_length = 2;
```

结果：

```text
异常：正则表达式长度过大。
```

**另见**

- [max_hyperscan_regexp_total_length](#max_hyperscan_regexp_total_length)
## max_hyperscan_regexp_total_length {#max_hyperscan_regexp_total_length} 

<SettingsInfoBlock type="UInt64" default_value="0" />

设置每个 [hyperscan 多匹配函数](/sql-reference/functions/string-search-functions#multimatchany) 中所有正则表达式的最大总长度。

可能的值：

- 正整数。
- 0 - 长度不限制。

**示例**

查询：

```sql
SELECT multiMatchAny('abcd', ['a','b','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

结果：

```text
┌─multiMatchAny('abcd', ['a', 'b', 'c', 'd'])─┐
│                                           1 │
└─────────────────────────────────────────────┘
```

查询：

```sql
SELECT multiMatchAny('abcd', ['ab','bc','c','d']) SETTINGS max_hyperscan_regexp_total_length = 5;
```

结果：

```text
异常：正则表达式总长度过大。
```

**另见**

- [max_hyperscan_regexp_length](#max_hyperscan_regexp_length)
## max_insert_block_size {#max_insert_block_size} 

<SettingsInfoBlock type="UInt64" default_value="1048449" />

用于插入表的块大小（以行数计）。仅在服务器形成块时适用。例如，通过 HTTP 接口的 INSERT，服务器解析数据格式并形成指定大小的块。但是在使用 clickhouse-client 时，客户端自己解析数据，因此服务器上的 `max_insert_block_size` 设置不会影响插入块的大小。当使用 INSERT SELECT 时，此设置也没有意义，因为数据是使用在 SELECT 后形成的相同块插入的。

默认值略高于 `max_block_size`。原因在于某些表引擎（`*MergeTree`）为每个插入的块在磁盘上形成一个数据部分，这是一个相当大的实体。同样，`*MergeTree` 表在插入期间对数据进行排序，足够大的块大小可以在 RAM 中允许对更多数据进行排序。
## max_insert_delayed_streams_for_parallel_write {#max_insert_delayed_streams_for_parallel_write} 

<SettingsInfoBlock type="UInt64" default_value="0" />

延迟最终部分刷新时的最大流（列）数。默认值 - auto（在底层存储支持并行写入时为 100，否则禁用）
## max_insert_threads {#max_insert_threads} 

<SettingsInfoBlock type="UInt64" default_value="0" />

执行 `INSERT SELECT` 查询的最大线程数。

可能的值：

- 0（或 1） — `INSERT SELECT` 没有并行执行。
- 正整数，大于 1。

云默认值：从 `2` 到 `4`，具体取决于服务大小。

并行 `INSERT SELECT` 仅在 `SELECT` 部分以并行方式执行时有效，参见 [max_threads](#max_threads) 设置。
更高的值会导致更高的内存使用。
## max_joined_block_size_rows {#max_joined_block_size_rows} 

<SettingsInfoBlock type="UInt64" default_value="65409" />

JOIN 结果的最大块大小（如果连接算法支持）。0表示无限制。
## max_limit_for_vector_search_queries {#max_limit_for_vector_search_queries} 

<BetaBadge/>

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1000"},{"label": "新设置"}]}]}/>

LIMIT 大于此设置的 SELECT 查询无法使用向量相似性索引。帮助防止向量相似性索引中的内存溢出。
## max_live_view_insert_blocks_before_refresh {#max_live_view_insert_blocks_before_refresh} 

<ExperimentalBadge/>

<SettingsInfoBlock type="UInt64" default_value="64" />

限制插入的最大块数，超过此数量的可合并块将被丢弃并重新执行查询。
## max_local_read_bandwidth {#max_local_read_bandwidth} 

<SettingsInfoBlock type="UInt64" default_value="0" />

本地读取的最大速度（字节/秒）。
## max_local_write_bandwidth {#max_local_write_bandwidth} 

<SettingsInfoBlock type="UInt64" default_value="0" />

本地写入的最大速度（字节/秒）。
## max_memory_usage {#max_memory_usage} 

<SettingsInfoBlock type="UInt64" default_value="0" />

云默认值：取决于副本上的 RAM 数量。

单个服务器上运行查询时使用的最大 RAM 数量。
`0` 的值表示无限制。

该设置不考虑可用内存或机器上的总内存量。限制适用于单个服务器上的单个查询。

您可以使用 `SHOW PROCESSLIST` 查看每个查询的当前内存消耗。
每个查询的峰值内存消耗会被跟踪并记录到日志中。

内存使用未完全跟踪以下聚合函数的状态，这些函数来自 `String` 和 `Array` 参数：
- `min`
- `max`
- `any`
- `anyLast`
- `argMin`
- `argMax`

内存消耗也受 `[max_memory_usage_for_user](/operations/settings/settings#max_memory_usage_for_user)` 和 `[max_server_memory_usage](/operations/server-configuration-parameters/settings#max_server_memory_usage)` 参数的限制。
## max_memory_usage_for_user {#max_memory_usage_for_user} 

<SettingsInfoBlock type="UInt64" default_value="0" />

单个服务器上运行用户查询时使用的最大 RAM 数量。零表示无限制。

默认情况下，不限制数量（`max_memory_usage_for_user = 0`）。

另见 `[max_memory_usage](/operations/settings/settings#max_memory_usage)` 的描述。

例如，如果您想为名为 `clickhouse_read` 的用户设置 `max_memory_usage_for_user` 为 1000 字节，可以使用以下语句：

```sql
ALTER USER clickhouse_read SETTINGS max_memory_usage_for_user = 1000;
```

您可以通过注销客户端，重新登录，然后使用 `getSetting` 函数来验证设置是否生效：

```sql
SELECT getSetting('max_memory_usage_for_user');
```
## max_network_bandwidth {#max_network_bandwidth} 

<SettingsInfoBlock type="UInt64" default_value="0" />

限制通过网络进行的数据交换速度（字节/秒）。该设置适用于每个查询。

可能的值：

- 正整数。
- 0 — 禁用数据速度控制。
## max_network_bandwidth_for_all_users {#max_network_bandwidth_for_all_users} 

<SettingsInfoBlock type="UInt64" default_value="0" />

限制通过网络进行的数据交换速度（字节/秒）。该设置适用于服务器上所有同时运行的查询。

可能的值：

- 正整数。
- 0 — 禁用数据速度控制。
## max_network_bandwidth_for_user {#max_network_bandwidth_for_user} 

<SettingsInfoBlock type="UInt64" default_value="0" />

限制通过网络进行的数据交换速度（字节/秒）。该设置适用于单个用户执行的所有同时运行查询。

可能的值：

- 正整数。
- 0 — 禁用数据速度控制。
## max_network_bytes {#max_network_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

限制在执行查询时通过网络接收或发送的数据量（以字节为单位）。该设置适用于每个单独的查询。

可能的值：

- 正整数。
- 0 — 禁用数据量控制。
## max_number_of_partitions_for_independent_aggregation {#max_number_of_partitions_for_independent_aggregation} 

<SettingsInfoBlock type="UInt64" default_value="128" />

在表中应用优化的最大分区数量。
## max_os_cpu_wait_time_ratio_to_throw {#max_os_cpu_wait_time_ratio_to_throw} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "设置值已更改并回退到 25.4"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "新设置"}]}]}/>

操作系统 CPU 等待 (OSCPUWaitMicroseconds 指标) 和忙态 (OSCPUVirtualTimeMicroseconds 指标) 时间之间的最大比率，以视为拒绝查询。使用在最小和最大比率之间的线性插值来计算概率，该概率在此点为 1。
## max_parallel_replicas {#max_parallel_replicas} 

<SettingsInfoBlock type="NonZeroUInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1000"},{"label": "默认情况下使用最多1000个并行副本。"}]}]}/>

在执行查询时，每个分片的最大副本数量。

可能的值：

- 正整数。

**附加信息**

该选项会根据使用的设置生成不同的结果。

:::note
当涉及连接或子查询时，如果所有表不满足特定要求，则此设置会产生不正确的结果。有关详细信息，请参见 [Distributed Subqueries and max_parallel_replicas](/operations/settings/settings#max_parallel_replicas)。
:::
### 使用 `SAMPLE` 键进行并行处理

如果在多个服务器上并行执行查询，则查询可能会更快。但在以下情况下，查询性能可能会下降：

- 采样键在分区键中的位置不允许有效的范围扫描。
- 向表中添加采样键会使其他列的过滤效率降低。
- 采样键是计算成本较高的表达式。
- 集群延迟分布较长，从而增加查询整体延迟。

### 使用 [parallel_replicas_custom_key](#parallel_replicas_custom_key) 进行并行处理

此设置对任何复制表都是有用的。
## max_parser_backtracks {#max_parser_backtracks} 

<SettingsInfoBlock type="UInt64" default_value="1000000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1000000"},{"label": "限制解析的复杂性"}]}]}/>

最大解析器回溯次数（在递归下降解析过程中尝试不同替代方案的次数）。
## max_parser_depth {#max_parser_depth} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

限制递归下降解析器的最大递归深度。允许控制堆栈大小。

可能的值：

- 正整数。
- 0 — 递归深度不受限制。
## max_parsing_threads {#max_parsing_threads} 

<SettingsInfoBlock type="MaxThreads" default_value="'auto(N)'" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "0"},{"label": "添加单独设置以控制并行解析中的线程数"}]}]}/>

解析输入格式中支持并行解析的数据的最大线程数。默认情况下，自动确定。
## max_partition_size_to_drop {#max_partition_size_to_drop} 

<SettingsInfoBlock type="UInt64" default_value="50000000000" />

在查询时删除分区的限制。值为0表示可以无限制地删除分区。

云默认值：1 TB。

:::note
此查询设置会覆盖其服务器设置的等效值，见 [max_partition_size_to_drop](/operations/server-configuration-parameters/settings#max_partition_size_to_drop)。
:::
## max_partitions_per_insert_block {#max_partitions_per_insert_block} 

<SettingsInfoBlock type="UInt64" default_value="100" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "19.5"},{"label": "100"},{"label": "对单个块中的分区数量添加限制"}]}]}/>

限制单个插入块中的最大分区数量，如果块中包含过多的分区，则会抛出异常。

- 正整数。
- 0 — 没有限制的分区数量。

**详细信息**

在插入数据时，ClickHouse计算插入块中的分区数量。如果分区数量超过 `max_partitions_per_insert_block`，则ClickHouse会根据 `throw_on_max_partitions_per_insert_block` 记录警告或抛出异常。异常的内容如下：

> "单个INSERT块中的分区过多 (`partitions_count` 个分区，限制为 " + toString(max_partitions) + ").
  该限制由 'max_partitions_per_insert_block' 设置控制。
  大量的分区是一个常见的误解。它会导致严重的负面性能影响，包括慢速服务器启动、缓慢的INSERT查询和慢速的SELECT查询。推荐的表的分区总数应少于1000..10000。请注意，分区并不是为了加快SELECT查询的速度（ORDER BY键足以使范围查询快速）。
  分区用于数据操作（DROP PARTITION等）。"

:::note
此设置是一个安全阈值，因为使用大量的分区是一种常见的误解。
:::
## max_partitions_to_read {#max_partitions_to_read} 

<SettingsInfoBlock type="Int64" default_value="-1" />

限制在单个查询中可以访问的最大分区数。

在创建表时指定的设置值可以通过查询级别的设置覆盖。

可能的值：

- 正整数
- `-1` — 不限制（默认）

:::note
您还可以在表的设置中指定 MergeTree 设置 [`max_partitions_to_read`](/operations/settings/settings#max_partitions_to_read)。
:::
## max_parts_to_move {#max_parts_to_move} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "1000"},{"label": "新设置"}]}]}/>

限制在一个查询中可以移动的部分数量。零表示不限制。
## max_query_size {#max_query_size} 

<SettingsInfoBlock type="UInt64" default_value="262144" />

解析SQL解析器的查询字符串的最大字节数。
INSERT查询的VALUES子句中的数据由单独的流解析器处理（消耗O(1) RAM）且不受此限制的影响。

:::note
`max_query_size` 不能在SQL查询中设置（例如， `SELECT now() SETTINGS max_query_size=10000`），因为 ClickHouse 需要分配一个缓冲区来解析查询，而该缓冲区的大小由 `max_query_size` 设置决定，必须在查询执行前进行配置。
:::
## max_read_buffer_size {#max_read_buffer_size} 

<SettingsInfoBlock type="NonZeroUInt64" default_value="1048576" />

读取文件系统的缓冲区的最大大小。
## max_read_buffer_size_local_fs {#max_read_buffer_size_local_fs} 

<SettingsInfoBlock type="UInt64" default_value="131072" />

从本地文件系统读取的缓冲区的最大大小。如果设置为0，则将使用max_read_buffer_size。
## max_read_buffer_size_remote_fs {#max_read_buffer_size_remote_fs} 

<SettingsInfoBlock type="UInt64" default_value="0" />

从远程文件系统读取的缓冲区的最大大小。如果设置为0，则将使用max_read_buffer_size。
## max_recursive_cte_evaluation_depth {#max_recursive_cte_evaluation_depth} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "1000"},{"label": "递归CTE评估深度的最大限制"}]}]}/>

递归CTE评估深度的最大限制。
## max_remote_read_network_bandwidth {#max_remote_read_network_bandwidth} 

<SettingsInfoBlock type="UInt64" default_value="0" />

用于读取的数据交换的最大网络速度（以字节/秒计）。
## max_remote_write_network_bandwidth {#max_remote_write_network_bandwidth} 

<SettingsInfoBlock type="UInt64" default_value="0" />

用于写入的数据交换的最大网络速度（以字节/秒计）。
## max_replica_delay_for_distributed_queries {#max_replica_delay_for_distributed_queries} 

<SettingsInfoBlock type="UInt64" default_value="300" />

禁用延迟的副本用于分布式查询。请参阅 [复制](../../engines/table-engines/mergetree-family/replication.md)。

设置的时间（以秒为单位）。如果副本的延迟大于或等于设置值，则不使用该副本。

可能的值：

- 正整数。
- 0 — 不检查副本延迟。

为了防止使用任何延迟不为零的副本，您可以将此参数设置为1。

在从指向复制表的分布式表执行 `SELECT` 时使用。
## max_result_bytes {#max_result_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

限制结果的大小（未压缩，单位为字节）。如果达到阈值，查询将在处理数据块后停止，
但不会切割结果的最后一个块，因此结果大小可能大于阈值。

**注意事项**

结果在内存中的大小会计入此阈值。
即使结果大小较小，它仍可能引用内存中较大的数据结构，
表示低基数列的字典和聚合函数列的区域，
因此尽管结果大小较小，阈值仍可能会被超出。

:::warning
该设置相当低级，使用时应谨慎。
:::
## max_result_rows {#max_result_rows} 

<SettingsInfoBlock type="UInt64" default_value="0" />

云默认值： `0`。

限制结果中的行数。对子查询和在远程服务器上运行分布式查询的部分时也进行检查。
当值为 `0` 时不应用限制。

如果达到阈值，查询将在处理数据块后停止，
但不会切割结果的最后一个块，因此结果大小可能会大于阈值。
## max_rows_in_distinct {#max_rows_in_distinct} 

<SettingsInfoBlock type="UInt64" default_value="0" />

使用 DISTINCT 时不同行的最大数量。
## max_rows_in_join {#max_rows_in_join} 

<SettingsInfoBlock type="UInt64" default_value="0" />

限制在连接表时使用的哈希表中的行数。

此设置适用于 [SELECT ... JOIN](/sql-reference/statements/select/join) 操作和 [Join](/engines/table-engines/special/join) 表引擎。

如果查询包含多个连接，ClickHouse 会检查此设置以获取每个中间结果。

当达到限制时，ClickHouse 可以进行不同的操作。使用 [`join_overflow_mode`](/operations/settings/settings#join_overflow_mode) 设置选择操作。

可能的值：

- 正整数。
- `0` — 无限行数。
## max_rows_in_set {#max_rows_in_set} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在IN子句中从子查询创建的数据集的最大行数。
## max_rows_in_set_to_optimize_join {#max_rows_in_set_to_optimize_join} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "禁用连接优化，因为它会阻止按顺序读取优化"}]}]}/>

在连接之前，通过彼此的行集过滤连接表的集合的最大大小。

可能的值：

- 0 — 禁用。
- 任何正整数。
## max_rows_to_group_by {#max_rows_to_group_by} 

<SettingsInfoBlock type="UInt64" default_value="0" />

聚合时从聚合中接收的唯一键的最大数量。此设置允许您限制聚合时的内存消耗。

如果在GROUP BY期间生成的聚合行数超过指定数量（唯一GROUP BY键），则行为将由 'group_by_overflow_mode' 决定，默认情况下是 `throw`，但也可以转换为近似GROUP BY模式。
## max_rows_to_read {#max_rows_to_read} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在运行查询时，从表中可以读取的最大行数。
限制会针对每个处理的数据块进行检查，仅应用于最深的表表达式，并在从远程服务器读取时，仅在远程服务器上检查。
## max_rows_to_read_leaf {#max_rows_to_read_leaf} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在运行分布式查询时，从叶节点的本地表中可以读取的最大行数。虽然分布式查询可以对每个分片（叶子）发出多个子查询，但此限制仅在叶子节点的读取阶段检查，在根节点的结果合并阶段忽略。

例如，集群由2个分片组成，每个分片包含一个有100行的表。预计要读取所有数据的分布式查询，设置为 `max_rows_to_read=150` 将失败，因为总共将有200行。使用 `max_rows_to_read_leaf=150` 的查询将成功，因为叶节点最多将读取100行。

对每个处理的数据块进行检查。

:::note
此设置在 `prefer_localhost_replica=1` 时不稳定。
:::
## max_rows_to_sort {#max_rows_to_sort} 

<SettingsInfoBlock type="UInt64" default_value="0" />

排序前的最大行数。此设置允许您在排序时限制内存消耗。
如果在ORDER BY操作中必须处理的记录数量超过指定数量，
行为将由 `sort_overflow_mode` 决定，默认设置为 `throw`。
## max_rows_to_transfer {#max_rows_to_transfer} 

<SettingsInfoBlock type="UInt64" default_value="0" />

可以传递到远程服务器或在执行GLOBAL IN/JOIN部分时保存到临时表的最大大小（以行计）。
## max_sessions_for_user {#max_sessions_for_user} 

<SettingsInfoBlock type="UInt64" default_value="0" />

每个经身份验证的用户同时连接到ClickHouse服务器的最大会话数。

示例：

```xml
<profiles>
    <single_session_profile>
        <max_sessions_for_user>1</max_sessions_for_user>
    </single_session_profile>
    <two_sessions_profile>
        <max_sessions_for_user>2</max_sessions_for_user>
    </two_sessions_profile>
    <unlimited_sessions_profile>
        <max_sessions_for_user>0</max_sessions_for_user>
    </unlimited_sessions_profile>
</profiles>
<users>
    <!-- 用户Alice一次最多可以连接到ClickHouse服务器一次。 -->
    <Alice>
        <profile>single_session_user</profile>
    </Alice>
    <!-- 用户Bob可以使用2个并发会话。 -->
    <Bob>
        <profile>two_sessions_profile</profile>
    </Bob>
    <!-- 用户Charles可以使用任意数量的并发会话。 -->
    <Charles>
        <profile>unlimited_sessions_profile</profile>
    </Charles>
</users>
```

可能的值：
- 正整数
- `0` — 无限数量的并发会话（默认）
## max_size_to_preallocate_for_aggregation {#max_size_to_preallocate_for_aggregation} 

<SettingsInfoBlock type="UInt64" default_value="1000000000000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1000000000000"},{"label": "为更大的表启用优化。"}]}]}/>

在聚合之前，所有哈希表中允许预分配的总空间的元素数量。
## max_size_to_preallocate_for_joins {#max_size_to_preallocate_for_joins} 

<SettingsInfoBlock type="UInt64" default_value="1000000000000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "100000000"},{"label": "新设置。"}]}]}/>

在连接之前，所有哈希表中允许预分配的总空间的元素数量。
## max_streams_for_merge_tree_reading {#max_streams_for_merge_tree_reading} 

<SettingsInfoBlock type="UInt64" default_value="0" />

如果不为零，则限制MergeTree表的读取流数量。
## max_streams_multiplier_for_merge_tables {#max_streams_multiplier_for_merge_tables} 

<SettingsInfoBlock type="Float" default_value="5" />

从合并表读取时请求更多的流。将流分散到Merge表将使用的表中。这允许更均匀地分配线程的工作，对于合并表大小不一致的情况尤其有用。
## max_streams_to_max_threads_ratio {#max_streams_to_max_threads_ratio} 

<SettingsInfoBlock type="Float" default_value="1" />

允许您使用比线程数量更多的源 —— 以更均匀地分配线程的工作。假设这是一个临时解决方案，因为在将来可以使源的数量等于线程的数量，但每个源动态选择可用的工作。
## max_subquery_depth {#max_subquery_depth} 

<SettingsInfoBlock type="UInt64" default_value="100" />

如果查询有超过指定数量的嵌套子查询，则抛出异常。

:::tip
这使您可以进行理智检查，以保护集群的用户防止编写过于复杂的查询。
:::
## max_table_size_to_drop {#max_table_size_to_drop} 

<SettingsInfoBlock type="UInt64" default_value="50000000000" />

在查询时删除表的限制。值为0表示可以在没有任何限制的情况下删除所有表。

云默认值：1 TB。

:::note
此查询设置会覆盖其服务器设置的等效值，见 [max_table_size_to_drop](/operations/server-configuration-parameters/settings#max_table_size_to_drop)。
:::
## max_temporary_columns {#max_temporary_columns} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在运行查询时，必须同时保留在RAM中的临时列的最大数量，包括常量列。如果查询生成的临时列数量超过指定数量，则将抛出异常。

:::tip
此设置对于防止过于复杂的查询非常有用。
:::

`0`值表示没有限制。
## max_temporary_data_on_disk_size_for_query {#max_temporary_data_on_disk_size_for_query} 

<SettingsInfoBlock type="UInt64" default_value="0" />

并发运行查询时，临时文件在磁盘上消耗的最大数据量（以字节为单位）。

可能的值：

- 正整数。
- `0` — 不限制（默认）
## max_temporary_data_on_disk_size_for_user {#max_temporary_data_on_disk_size_for_user} 

<SettingsInfoBlock type="UInt64" default_value="0" />

同时运行用户查询时，临时文件在磁盘上消耗的最大数据量（以字节为单位）。

可能的值：

- 正整数。
- `0` — 不限制（默认）
## max_temporary_non_const_columns {#max_temporary_non_const_columns} 

<SettingsInfoBlock type="UInt64" default_value="0" />

与 `max_temporary_columns` 类似，但不计算常量列，运行查询时必须同时保留在RAM中的临时列的最大数量。

:::note
常量列在运行查询时会经常形成，但它们几乎不需要计算资源。
:::
## max_threads {#max_threads} 

<SettingsInfoBlock type="MaxThreads" default_value="'auto(N)'" />

查询处理线程的最大数量，排除从远程服务器检索数据的线程（见 'max_distributed_connections' 参数）。

此参数适用于在并行进行查询处理管道相同阶段的线程。
例如，当从表中读取数据时，如果可以使用至少 'max_threads' 数量的线程并行评估带函数的表达式，使用WHERE过滤并进行GROUP BY的预聚合，则将使用 'max_threads'。

对于由于LIMIT而快速完成的查询，您可以设置较低的 'max_threads'。例如，如果所需条目位于每个块中，而max_threads = 8，则会获取8个块，尽管只需读取一个块就足够了。

`max_threads` 值越小，消耗的内存越少。
## max_threads_for_indexes {#max_threads_for_indexes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

处理索引的最大线程数。
## max_untracked_memory {#max_untracked_memory} 

<SettingsInfoBlock type="UInt64" default_value="4194304" />

小的分配和释放在线程局部变量中进行分组，只有在绝对值大于指定值时才会被跟踪或剖析。如果该值高于 'memory_profiler_step'，则会有效降低到 'memory_profiler_step'。
## memory_overcommit_ratio_denominator {#memory_overcommit_ratio_denominator} 

<SettingsInfoBlock type="UInt64" default_value="1073741824" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.5"},{"label": "1073741824"},{"label": "默认启用内存过度提交功能"}]}]}/>

表示在全局级别达到硬限制时的软内存限制。
该值用于计算查询的过度提交比例。
零表示跳过查询。
有关 [内存过度提交](memory-overcommit.md) 的更多信息。
## memory_overcommit_ratio_denominator_for_user {#memory_overcommit_ratio_denominator_for_user} 

<SettingsInfoBlock type="UInt64" default_value="1073741824" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.5"},{"label": "1073741824"},{"label": "默认启用内存过度提交功能"}]}]}/>

表示在用户级别达到硬限制时的软内存限制。
该值用于计算查询的过度提交比例。
零表示跳过查询。
有关 [内存过度提交](memory-overcommit.md) 的更多信息。
## memory_profiler_sample_max_allocation_size {#memory_profiler_sample_max_allocation_size} 

<SettingsInfoBlock type="UInt64" default_value="0" />

以 `memory_profiler_sample_probability` 的概率收集大小小于或等于指定值的随机分配。 0表示禁用。您可能希望将 'max_untracked_memory' 设置为0以使此阈值按预期工作。
## memory_profiler_sample_min_allocation_size {#memory_profiler_sample_min_allocation_size} 

<SettingsInfoBlock type="UInt64" default_value="0" />

以 `memory_profiler_sample_probability` 的概率收集大小大于或等于指定值的随机分配。 0表示禁用。您可能希望将 'max_untracked_memory' 设置为0以使此阈值按预期工作。
## memory_profiler_sample_probability {#memory_profiler_sample_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

收集随机分配和释放并将其写入系统.trace_log，使用 'MemorySample' trace_type。概率适用于每个分配/释放，无论分配的大小如何（可以通过 `memory_profiler_sample_min_allocation_size` 和 `memory_profiler_sample_max_allocation_size` 进行更改）。请注意，只有当未跟踪内存的量超过 'max_untracked_memory' 时，采样才会发生。您可能希望将 'max_untracked_memory' 设置为0，以获得更细粒度的采样。
## memory_profiler_step {#memory_profiler_step} 

<SettingsInfoBlock type="UInt64" default_value="4194304" />

设置内存剖析器的步长。每当查询的内存使用量超过以字节为单位的每个后续步长时，内存剖析器将收集分配堆栈跟踪并将其写入 [trace_log](/operations/system-tables/trace_log)。

可能的值：

- 正整数字节数。

- 设置为0将关闭内存剖析器。
## memory_tracker_fault_probability {#memory_tracker_fault_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

用于测试 `exception safety` - 每次以指定的概率分配内存时抛出异常。
## memory_usage_overcommit_max_wait_microseconds {#memory_usage_overcommit_max_wait_microseconds} 

<SettingsInfoBlock type="UInt64" default_value="5000000" />

在用户级别发生内存过度提交时，线程等待内存被释放的最大时间。
如果达到超时且内存未释放，则抛出异常。
有关 [内存过度提交](memory-overcommit.md) 的更多信息。
## merge_table_max_tables_to_look_for_schema_inference {#merge_table_max_tables_to_look_for_schema_inference} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1000"},{"label": "一个新设置"}]}]}/>

在创建没有显式模式的 `Merge` 表或使用 `merge` 表函数时，从不超过指定数量的匹配表中推断模式。
如果表的数量超过此值，则将从指定数量表中的第一个推断模式。
## merge_tree_coarse_index_granularity {#merge_tree_coarse_index_granularity} 

<SettingsInfoBlock type="UInt64" default_value="8" />

在搜索数据时，ClickHouse检查索引文件中的数据标记。如果ClickHouse发现所需的键在某个范围内，则会将该范围划分为 `merge_tree_coarse_index_granularity` 个子范围，并递归地在其中搜索所需的键。

可能的值：

- 任意正偶数。
## merge_tree_compact_parts_min_granules_to_multibuffer_read {#merge_tree_compact_parts_min_granules_to_multibuffer_read} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="UInt64" default_value="16" />

仅在ClickHouse Cloud中生效。MergeTree表的紧凑部分的条带中使用多缓冲读取器的颗粒数，支持并行读取和预取。如果使用多缓冲读取器从远程文件系统读取，则会增加读取请求的数量。
## merge_tree_determine_task_size_by_prewhere_columns {#merge_tree_determine_task_size_by_prewhere_columns} 

<SettingsInfoBlock type="Bool" default_value="1" />

是否仅使用预先列的大小来确定读取任务的大小。
## merge_tree_max_bytes_to_use_cache {#merge_tree_max_bytes_to_use_cache} 

<SettingsInfoBlock type="UInt64" default_value="2013265920" />

如果 ClickHouse 在一次查询中读取超过 `merge_tree_max_bytes_to_use_cache` 字节，它将不使用未压缩块的缓存。

未压缩块的缓存存储为查询提取的数据。 ClickHouse 使用此缓存来加快对重复小查询的响应。此设置保护缓存不被读取大量数据的查询破坏。[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) 服务器设置定义未压缩块缓存的大小。

可能的值：

- 任意正整数。
## merge_tree_max_rows_to_use_cache {#merge_tree_max_rows_to_use_cache} 

<SettingsInfoBlock type="UInt64" default_value="1048576" />

如果 ClickHouse 在一次查询中读取超过 `merge_tree_max_rows_to_use_cache` 行，它将不使用未压缩块的缓存。

未压缩块的缓存存储为查询提取的数据。 ClickHouse 使用此缓存来加快对重复小查询的响应。此设置保护缓存不被读取大量数据的查询破坏。[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size) 服务器设置定义未压缩块缓存的大小。

可能的值：

- 任意正整数。
## merge_tree_min_bytes_for_concurrent_read {#merge_tree_min_bytes_for_concurrent_read} 

<SettingsInfoBlock type="UInt64" default_value="251658240" />

如果从 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 表的一个文件中读取的字节数超过 `merge_tree_min_bytes_for_concurrent_read`，则 ClickHouse 尝试在多个线程中并发读取此文件。

可能的值：

- 正整数。
## merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem {#merge_tree_min_bytes_for_concurrent_read_for_remote_filesystem} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "该设置已弃用"}]}]}/>

在从远程文件系统读取时，需要从一个文件中读取的最小字节数，才能使 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 引擎并行化读取。不建议使用此设置。

可能的值：

- 正整数。
## merge_tree_min_bytes_for_seek {#merge_tree_min_bytes_for_seek} 

<SettingsInfoBlock type="UInt64" default_value="0" />

如果在一次文件中要读取的两个数据块之间的距离小于 `merge_tree_min_bytes_for_seek` 字节，则 ClickHouse 会顺序读取包含两个块的文件范围，从而避免额外的查找。

可能的值：

- 任意正整数。
## merge_tree_min_bytes_per_task_for_remote_reading {#merge_tree_min_bytes_per_task_for_remote_reading} 

<SettingsInfoBlock type="UInt64" default_value="2097152" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "2097152"},{"label": "值与 `filesystem_prefetch_min_bytes_for_single_read_task` 统一"}]}]}/>

每个任务的最小读取字节数。
## merge_tree_min_read_task_size {#merge_tree_min_read_task_size} 

<SettingsInfoBlock type="UInt64" default_value="8" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "8"},{"label": "新设置"}]}]}/>

任务大小的硬下限（即使颗粒数量较少而可用线程数量较多，也不会分配较小的任务。
## merge_tree_min_rows_for_concurrent_read {#merge_tree_min_rows_for_concurrent_read} 

<SettingsInfoBlock type="UInt64" default_value="163840" />

如果从 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 表文件中读取的行数超过 `merge_tree_min_rows_for_concurrent_read`，则 ClickHouse 尝试在多个线程中并发读取此文件。

可能的值：

- 正整数。
## merge_tree_min_rows_for_concurrent_read_for_remote_filesystem {#merge_tree_min_rows_for_concurrent_read_for_remote_filesystem} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "该设置已被弃用"}]}]}/>

在从远程文件系统读取时，MergeTree 引擎在可以并行读取之前，从一个文件读取的最低行数。我们不建议使用此设置。

可能的值：

- 正整数。
## merge_tree_min_rows_for_seek {#merge_tree_min_rows_for_seek} 

<SettingsInfoBlock type="UInt64" default_value="0" />

如果在一个文件中，两个数据块之间的距离小于 `merge_tree_min_rows_for_seek` 行，则 ClickHouse 不会寻址文件，而是顺序读取数据。

可能的值：

- 任何正整数。
## merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability {#merge_tree_read_split_ranges_into_intersecting_and_non_intersecting_injection_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "用于测试 `PartsSplitter` - 每次从 MergeTree 读取时将读取范围拆分为相交和不相交，按指定概率进行拆分。"}]}]}/>

用于测试 `PartsSplitter` - 每次从 MergeTree 读取时将读取范围拆分为相交和不相交，按指定概率进行拆分。
## merge_tree_use_const_size_tasks_for_remote_reading {#merge_tree_use_const_size_tasks_for_remote_reading} 

<SettingsInfoBlock type="Bool" default_value="1" />

是否使用固定大小的任务从远程表读取。
## merge_tree_use_deserialization_prefixes_cache {#merge_tree_use_deserialization_prefixes_cache} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "一个新设置控制 MergeTree 中反序列化前缀缓存的使用"}]}]}/>

在从 MergeTree 的 Wide 部分读取时，启用从文件前缀缓存列元数据。
## merge_tree_use_prefixes_deserialization_thread_pool {#merge_tree_use_prefixes_deserialization_thread_pool} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "一个新设置控制 MergeTree 中并行前缀反序列化的线程池使用"}]}]}/>

启用在 MergeTree 的 Wide 部分中并行读取前缀的线程池。该线程池的大小由服务器设置 `max_prefixes_deserialization_thread_pool_size` 控制。
## merge_tree_use_v1_object_and_dynamic_serialization {#merge_tree_use_v1_object_and_dynamic_serialization} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "为 JSON 和 Dynamic 类型添加新序列化 V2 版本"}]}]}/>

启用时，MergeTree 中将使用 JSON 和 Dynamic 类型的 V1 序列化版本，而不是 V2。更改此设置仅在服务器重启后生效。
## metrics_perf_events_enabled {#metrics_perf_events_enabled} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果启用，在查询执行期间将测量一些性能事件。
## metrics_perf_events_list {#metrics_perf_events_list} 

以逗号分隔的性能指标列表，在查询执行期间将被测量。为空表示所有事件。有关可用事件的信息，请参见源中的 PerfEventInfo。
## min_bytes_to_use_direct_io {#min_bytes_to_use_direct_io} 

<SettingsInfoBlock type="UInt64" default_value="0" />

执行直接 I/O 访问存储磁盘所需的最小数据量。

ClickHouse 在从表读取数据时使用此设置。如果要读取的所有数据的总存储量超过 `min_bytes_to_use_direct_io` 字节，则 ClickHouse 使用 `O_DIRECT` 选项从存储磁盘读取数据。

可能的值：

- 0 — 禁用直接 I/O。
- 正整数。
## min_bytes_to_use_mmap_io {#min_bytes_to_use_mmap_io} 

<SettingsInfoBlock type="UInt64" default_value="0" />

这是一个实验性设置。设置读取大文件而不复制数据的最小内存量，数据直接从内核到用户空间。推荐阈值约为 64 MB，因为 [mmap/munmap](https://en.wikipedia.org/wiki/Mmap) 较慢。仅在处理大文件时有意义，并且仅在数据驻留在页缓存中时有效。

可能的值：

- 正整数。
- 0 — 大文件只通过从内核复制数据到用户空间来读取。
## min_chunk_bytes_for_parallel_parsing {#min_chunk_bytes_for_parallel_parsing} 

<SettingsInfoBlock type="NonZeroUInt64" default_value="10485760" />

- 类型：无符号整数
- 默认值：1 MiB

每个线程将并行解析的最小数据块大小（以字节为单位）。
## min_compress_block_size {#min_compress_block_size} 

<SettingsInfoBlock type="UInt64" default_value="65536" />

对于 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 表。为了在处理查询时降低延迟，如果写入下一个标记时块的大小至少为 `min_compress_block_size`，则将对其进行压缩。默认值为 65,536。

如果未压缩的数据小于 `max_compress_block_size`，则块的实际大小不小于此值，并且至少不小于一个标记的数据量。

让我们来看一个例子。假设在创建表时设置了 `index_granularity` 为 8192。

我们正在写入 UInt32 类型的列（每个值 4 字节）。当写入 8192 行时，总共将是 32 KB 的数据。由于 min_compress_block_size = 65,536，因此每两个标记形成一个压缩块。

我们正在写入一个 URL 列，类型为 String（每个值的平均大小约为 60 字节）。当写入 8192 行时，平均将稍少于 500 KB 的数据。由于这超过了 65,536，因此每个标记都会形成一个压缩块。在这种情况下，当从磁盘范围内读取单个标记的数据时，额外的数据不会被解压缩。

:::note
这是一个专家级设置，如果您刚开始使用 ClickHouse，则不应更改它。
:::
## min_count_to_compile_aggregate_expression {#min_count_to_compile_aggregate_expression} 

<SettingsInfoBlock type="UInt64" default_value="3" />

开始 JIT 编译所需的相同汇总表达式的最小数量。仅在启用 [compile_aggregate_expressions](#compile_aggregate_expressions) 设置时有效。

可能的值：

- 正整数。
- 0 — 相同的聚合表达式总是 JIT 编译。
## min_count_to_compile_expression {#min_count_to_compile_expression} 

<SettingsInfoBlock type="UInt64" default_value="3" />

在编译之前执行相同表达式所需的最小次数。
## min_count_to_compile_sort_description {#min_count_to_compile_sort_description} 

<SettingsInfoBlock type="UInt64" default_value="3" />

在 JIT 编译它们之前所需的相同排序描述的数量。
## min_execution_speed {#min_execution_speed} 

<SettingsInfoBlock type="UInt64" default_value="0" />

最低执行速度，以每秒行数为单位。在每个数据块检查时会执行 [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 。如果执行速度较低，则会抛出异常。
## min_execution_speed_bytes {#min_execution_speed_bytes} 

<SettingsInfoBlock type="UInt64" default_value="0" />

每秒执行的字节数的最小值。在每个数据块检查时会执行 [`timeout_before_checking_execution_speed`](/operations/settings/settings#timeout_before_checking_execution_speed) 。如果执行速度较低，则会抛出异常。
## min_external_sort_block_bytes {#min_external_sort_block_bytes} 

<SettingsInfoBlock type="UInt64" default_value="104857600" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "104857600"},{"label": "新设置。"}]}]}/>

将被转储到磁盘的外部排序的最小块大小（以字节为单位），以避免生成过多文件。
## min_external_table_block_size_bytes {#min_external_table_block_size_bytes} 

<SettingsInfoBlock type="UInt64" default_value="268402944" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "268402944"},{"label": "将传递给外部表的块压缩到指定的字节大小，如果块不够大。"}]}]}/>

将传递给外部表的块压缩到指定的字节大小，如果块不够大。
## min_external_table_block_size_rows {#min_external_table_block_size_rows} 

<SettingsInfoBlock type="UInt64" default_value="1048449" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1048449"},{"label": "将传递给外部表的块压缩到指定的行数，如果块不够大"}]}]}/>

将传递给外部表的块压缩到指定的行数，如果块不够大。
## min_free_disk_bytes_to_perform_insert {#min_free_disk_bytes_to_perform_insert} 

<SettingsInfoBlock type="UInt64" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "在仍允许临时写入的情况下，保持一些从插入中得来的空闲磁盘空间字节。"}]}]}/>

执行插入所需的最小可用磁盘空间字节。
## min_free_disk_ratio_to_perform_insert {#min_free_disk_ratio_to_perform_insert} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "在仍允许临时写入的情况下，保持从插入中获得的一些空闲磁盘空间字节，并用比例表示总磁盘空间。"}]}]}/>

执行插入所需的最小空闲磁盘空间比例。
## min_free_disk_space_for_temporary_data {#min_free_disk_space_for_temporary_data} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在进行外部排序和聚合时，写入临时数据时需保持的最小磁盘空间。
## min_hit_rate_to_use_consecutive_keys_optimization {#min_hit_rate_to_use_consecutive_keys_optimization} 

<SettingsInfoBlock type="Float" default_value="0.5" />

缓存的最小命中率，用于优化聚合中的连续键以保持它启用。
## min_insert_block_size_bytes {#min_insert_block_size_bytes} 

<SettingsInfoBlock type="UInt64" default_value="268402944" />

设置可以通过 `INSERT` 查询插入到表中的块中的最小字节数。较小的块将被压缩成更大的块。

可能的值：

- 正整数。
- 0 — 禁用压缩。
## min_insert_block_size_bytes_for_materialized_views {#min_insert_block_size_bytes_for_materialized_views} 

<SettingsInfoBlock type="UInt64" default_value="0" />

设置可以通过 `INSERT` 查询插入到表中的块中的最小字节数。较小的块将被压缩成更大的块。此设置仅适用于插入到 [物化视图](../../sql-reference/statements/create/view.md) 的块。通过调整此设置，您可以控制在推送到物化视图时的块压缩，并避免过度使用内存。

可能的值：

- 任何正整数。
- 0 — 禁用压缩。

**另请参见**

- [min_insert_block_size_bytes](#min_insert_block_size_bytes)
## min_insert_block_size_rows {#min_insert_block_size_rows} 

<SettingsInfoBlock type="UInt64" default_value="1048449" />

设置可以通过 `INSERT` 查询插入到表中的块中的最小行数。较小的块将被压缩成更大的块。

可能的值：

- 正整数。
- 0 — 禁用压缩。
## min_insert_block_size_rows_for_materialized_views {#min_insert_block_size_rows_for_materialized_views} 

<SettingsInfoBlock type="UInt64" default_value="0" />

设置可以通过 `INSERT` 查询插入到表中的块中的最小行数。较小的块将被压缩成更大的块。此设置仅适用于插入到 [物化视图](../../sql-reference/statements/create/view.md) 的块。通过调整此设置，您可以控制在推送到物化视图时的块压缩，并避免过度使用内存。

可能的值：

- 任何正整数。
- 0 — 禁用压缩。

**另请参见**

- [min_insert_block_size_rows](#min_insert_block_size_rows)
## min_joined_block_size_bytes {#min_joined_block_size_bytes} 

<SettingsInfoBlock type="UInt64" default_value="524288" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "524288"},{"label": "新设置。"}]}]}/>

JOIN 结果的最小块大小（如果连接算法支持）。0 表示无限制。
## min_os_cpu_wait_time_ratio_to_throw {#min_os_cpu_wait_time_ratio_to_throw} 

<SettingsInfoBlock type="Float" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "设置值已更改并移植到 25.4"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "新设置"}]}]}/>

考虑拒绝查询的操作系统 CPU 等待（OSCPUWaitMicroseconds 指标）和忙碌（OSCPUVirtualTimeMicroseconds 指标）时间的最小比例。使用线性插值在最小和最大比率之间计算概率，此时概率为 0。
## mongodb_throw_on_unsupported_query {#mongodb_throw_on_unsupported_query} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "1"},{"label": "新设置。"}]}, {"id": "row-2","items": [{"label": "24.10"},{"label": "1"},{"label": "新设置。"}]}]}/>

如果启用，当无法构建 MongoDB 查询时，MongoDB 表将返回错误。否则，ClickHouse 将读取整个表并在本地处理它。当 'allow_experimental_analyzer=0' 时，此选项不适用。
## move_all_conditions_to_prewhere {#move_all_conditions_to_prewhere} 

<SettingsInfoBlock type="Bool" default_value="1" />

将所有有效条件从 WHERE 转移到 PREWHERE。
## move_primary_key_columns_to_end_of_prewhere {#move_primary_key_columns_to_end_of_prewhere} 

<SettingsInfoBlock type="Bool" default_value="1" />

将包含主键列的 PREWHERE 条件移到 AND 链的末尾。这些条件很可能在主键分析期间被考虑，因此不会对 PREWHERE 过滤产生很大贡献。
## multiple_joins_try_to_keep_original_names {#multiple_joins_try_to_keep_original_names} 

<SettingsInfoBlock type="Bool" default_value="0" />

在多重连接重写时，不要向顶层表达式列表添加别名。
## mutations_execute_nondeterministic_on_initiator {#mutations_execute_nondeterministic_on_initiator} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果为 true，则以常量非确定性函数（例如，`now()` 函数）在发起者上执行，并在 `UPDATE` 和 `DELETE` 查询中替换为文字。这有助于在执行具有常量非确定性函数的变更时保持副本中的数据同步。默认值：`false`。
## mutations_execute_subqueries_on_initiator {#mutations_execute_subqueries_on_initiator} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果为 true，则标量子查询在发起者上执行，并在 `UPDATE` 和 `DELETE` 查询中替换为文字。默认值：`false`。
## mutations_max_literal_size_to_replace {#mutations_max_literal_size_to_replace} 

<SettingsInfoBlock type="UInt64" default_value="16384" />

在 `UPDATE` 和 `DELETE` 查询中要替换的序列化字面量的最大大小（以字节为单位）。仅在启用上述两个设置中的至少一个时生效。默认值：16384（16 KiB）。
## mutations_sync {#mutations_sync} 

<SettingsInfoBlock type="UInt64" default_value="0" />

允许 `ALTER TABLE ... UPDATE|DELETE|MATERIALIZE INDEX|MATERIALIZE PROJECTION|MATERIALIZE COLUMN|MATERIALIZE STATISTICS` 查询（[mutations](../../sql-reference/statements/alter/index.md/#mutations)）同步执行。

可能的值：

- 0 - 变更异步执行。
- 1 - 查询等待当前服务器上的所有变更完成。
- 2 - 查询等待所有副本上的所有变更完成（如果存在）。
## mysql_datatypes_support_level {#mysql_datatypes_support_level} 

定义 MySQL 类型如何转换为相应的 ClickHouse 类型。以逗号分隔的列表，可以是 `decimal`、`datetime64`、`date2Date32` 或 `date2String` 的任意组合。
- `decimal`: 将 `NUMERIC` 和 `DECIMAL` 类型转换为 `Decimal`（在大精度允许的情况下）。
- `datetime64`: 将 `DATETIME` 和 `TIMESTAMP` 类型转换为 `DateTime64`（如果精度不为 `0`）。
- `date2Date32`: 将 `DATE` 转换为 `Date32`，而不是 `Date`。优先于 `date2String`。
- `date2String`: 将 `DATE` 转换为 `String` 而不是 `Date`。被 `datetime64` 覆盖。
## mysql_map_fixed_string_to_text_in_show_columns {#mysql_map_fixed_string_to_text_in_show_columns} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "减少将 ClickHouse 连接到 BI 工具的配置工作量。"}]}]}/>

如果启用，[FixedString](../../sql-reference/data-types/fixedstring.md) ClickHouse 数据类型将显示为 [SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns) 中的 `TEXT`。

仅在通过 MySQL 连接时生效。

- 0 - 使用 `BLOB`。
- 1 - 使用 `TEXT`。
## mysql_map_string_to_text_in_show_columns {#mysql_map_string_to_text_in_show_columns} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "减少将 ClickHouse 连接到 BI 工具的配置工作量。"}]}]}/>

如果启用，[String](../../sql-reference/data-types/string.md) ClickHouse 数据类型将显示为 [SHOW COLUMNS](../../sql-reference/statements/show.md/#show_columns) 中的 `TEXT`。

仅在通过 MySQL 连接时生效。

- 0 - 使用 `BLOB`。
- 1 - 使用 `TEXT`。
## mysql_max_rows_to_insert {#mysql_max_rows_to_insert} 

<SettingsInfoBlock type="UInt64" default_value="65536" />

MySQL 存储引擎中 MySQL 批量插入的最大行数。
## network_compression_method {#network_compression_method} 

<SettingsInfoBlock type="String" default_value="LZ4" />

设置用于服务器之间以及服务器与 [clickhouse-client](../../interfaces/cli.md) 之间通信的数据压缩方法。

可能的值：

- `LZ4` — 设置 LZ4 压缩方法。
- `ZSTD` — 设置 ZSTD 压缩方法。

**另请参见**

- [network_zstd_compression_level](#network_zstd_compression_level)
## network_zstd_compression_level {#network_zstd_compression_level} 

<SettingsInfoBlock type="Int64" default_value="1" />

调整 ZSTD 压缩级别。仅在 [network_compression_method](#network_compression_method) 设置为 `ZSTD` 时使用。

可能的值：

- 从 1 到 15 的正整数。
## normalize_function_names {#normalize_function_names} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.3"},{"label": "1"},{"label": "将函数名称规范化为其标准名称，这对投影查询路由是必要的"}]}]}/>

将函数名称规范化为其标准名称。
## number_of_mutations_to_delay {#number_of_mutations_to_delay} 

<SettingsInfoBlock type="UInt64" default_value="0" />

如果被变更的表中有至少那么多未完成的变更，则人为地减慢表的变更速度。0 - 禁用。
## number_of_mutations_to_throw {#number_of_mutations_to_throw} 

<SettingsInfoBlock type="UInt64" default_value="0" />

如果被变更的表中有至少那么多未完成的变更，则抛出“变更过多...”异常。0 - 禁用。
## odbc_bridge_connection_pool_size {#odbc_bridge_connection_pool_size} 

<SettingsInfoBlock type="UInt64" default_value="16" />

ODBC 桥中每个连接设置字符串的连接池大小。
## odbc_bridge_use_connection_pooling {#odbc_bridge_use_connection_pooling} 

<SettingsInfoBlock type="Bool" default_value="1" />

在 ODBC 桥中使用连接池。如果设置为 false，则每次都会创建新连接。
## offset {#offset} 

<SettingsInfoBlock type="UInt64" default_value="0" />

设置在开始返回查询结果的行之前要跳过的行数。它调整由 [OFFSET](/sql-reference/statements/select/offset) 子句设置的偏移量，使这两个值相加。

可能的值：

- 0 — 不跳过任何行。
- 正整数。

**示例**

输入表：

```sql
CREATE TABLE test (i UInt64) ENGINE = MergeTree() ORDER BY i;
INSERT INTO test SELECT number FROM numbers(500);
```

查询：

```sql
SET limit = 5;
SET offset = 7;
SELECT * FROM test LIMIT 10 OFFSET 100;
```
结果：

```text
┌───i─┐
│ 107 │
│ 108 │
│ 109 │
└─────┘
```
## opentelemetry_start_trace_probability {#opentelemetry_start_trace_probability} 

<SettingsInfoBlock type="Float" default_value="0" />

设置 ClickHouse 可以为执行的查询启动跟踪的概率（如果没有提供父 [trace context](https://www.w3.org/TR/trace-context/)）。

可能的值：

- 0 — 禁用对所有执行查询的跟踪（如果没有提供父跟踪上下文）。
- 正浮点数，范围在 [0..1] 之间。例如，如果设置值为 `0.5`，则 ClickHouse 可以平均启动一半查询的跟踪。
- 1 — 启用对所有执行查询的跟踪。
## opentelemetry_trace_processors {#opentelemetry_trace_processors} 

<SettingsInfoBlock type="Bool" default_value="0" />

收集处理器的 OpenTelemetry spans。
## optimize_aggregation_in_order {#optimize_aggregation_in_order} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用 [GROUP BY](/sql-reference/statements/select/group-by) 优化，用于 [SELECT](../../sql-reference/statements/select/index.md) 查询以相应顺序聚合 MergeTree 表中的数据。

可能的值：

- 0 — 禁用 `GROUP BY` 优化。
- 1 — 启用 `GROUP BY` 优化。

**另请参见**

- [GROUP BY 优化](/sql-reference/statements/select/group-by#group-by-optimization-depending-on-table-sorting-key)
## optimize_aggregators_of_group_by_keys {#optimize_aggregators_of_group_by_keys} 

<SettingsInfoBlock type="Bool" default_value="1" />

消除选择部分 GROUP BY 键的 min/max/any/anyLast 聚合器。
## optimize_and_compare_chain {#optimize_and_compare_chain} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "一个新设置"}]}]}/>

填充 AND 链中的常量比较以增强筛选能力。支持操作符 `<`、`<=`、`>`、`>=`、`=` 及其混合。例如，`(a < b) AND (b < c) AND (c < 5)` 将变为 `(a < b) AND (b < c) AND (c < 5) AND (b < 5) AND (a < 5)`。
## optimize_append_index {#optimize_append_index} 

<SettingsInfoBlock type="Bool" default_value="0" />

使用 [constraints](../../sql-reference/statements/create/table.md/#constraints) 作为附加索引条件。默认值为 `false`。

可能的值：

- true, false
## optimize_arithmetic_operations_in_aggregate_functions {#optimize_arithmetic_operations_in_aggregate_functions} 

<SettingsInfoBlock type="Bool" default_value="1" />

将算术运算移出聚合函数。
## optimize_count_from_files {#optimize_count_from_files} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用从不同输入格式的文件计数行数的优化。适用于表函数/引擎 `file`/`s3`/`url`/`hdfs`/`azureBlobStorage`。

可能的值：

- 0 — 禁用优化。
- 1 — 启用优化。
## optimize_distinct_in_order {#optimize_distinct_in_order} 

启用 DISTINCT 优化（如果某些列在 DISTINCT 中形成排序的前缀）。例如，MergeTree 中的排序键或 ORDER BY 语句的前缀。
## optimize_distributed_group_by_sharding_key {#optimize_distributed_group_by_sharding_key} 

通过避免在发起者服务器上进行代价高昂的聚合来优化 `GROUP BY sharding_key` 查询（这将减少发起者服务器上的查询内存使用）。

支持以下类型的查询（以及它们的所有组合）：

- `SELECT DISTINCT [..., ]sharding_key[, ...] FROM dist`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...]`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] ORDER BY x`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1`
- `SELECT ... FROM dist GROUP BY sharding_key[, ...] LIMIT 1 BY x`

以下类型的查询不受支持（后续可能会支持其中一些）：

- `SELECT ... GROUP BY sharding_key[, ...] WITH TOTALS`
- `SELECT ... GROUP BY sharding_key[, ...] WITH ROLLUP`
- `SELECT ... GROUP BY sharding_key[, ...] WITH CUBE`
- `SELECT ... GROUP BY sharding_key[, ...] SETTINGS extremes=1`

可能的值：

- 0 — 禁用。
- 1 — 启用。

另请参见：

- [distributed_group_by_no_merge](#distributed_group_by_no_merge)
- [distributed_push_down_limit](#distributed_push_down_limit)
- [optimize_skip_unused_shards](#optimize_skip_unused_shards)

:::note
目前它要求 `optimize_skip_unused_shards` （原因在于，有一天它可能默认启用，而仅在使用分布式表插入数据时才能正常工作，即数据根据 sharding_key 分布）。
:::
## optimize_extract_common_expressions {#optimize_extract_common_expressions} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "通过提取联接中的常见表达式来优化 WHERE、PREWHERE、ON、HAVING 和 QUALIFY 表达式。"}]}]}/>

允许从 WHERE、PREWHERE、ON、HAVING 和 QUALIFY 表达式的结合中提取公共表达式。类似于 `(A AND B) OR (A AND C)` 的逻辑表达式可以重写为 `A AND (B OR C)`，这可能有助于利用：
- 简单过滤表达式中的索引
- 交叉到内部连接优化。
## optimize_functions_to_subcolumns {#optimize_functions_to_subcolumns} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "1"},{"label": "默认启用设置"}]}]}/>

启用或禁用通过将某些函数转换为读取子列进行优化。这减少了读取的数据量。

可以转换的函数包括：

- [length](/sql-reference/functions/array-functions#length) 读取 [size0](../../sql-reference/data-types/array.md/#array-size) 子列。
- [empty](/sql-reference/functions/array-functions#empty) 读取 [size0](../../sql-reference/data-types/array.md/#array-size) 子列。
- [notEmpty](/sql-reference/functions/array-functions#notempty) 读取 [size0](../../sql-reference/data-types/array.md/#array-size) 子列。
- [isNull](/sql-reference/functions/functions-for-nulls#isnull) 读取 [null](../../sql-reference/data-types/nullable.md/#finding-null) 子列。
- [isNotNull](/sql-reference/functions/functions-for-nulls#isnotnull) 读取 [null](../../sql-reference/data-types/nullable.md/#finding-null) 子列。
- [count](/sql-reference/aggregate-functions/reference/count) 读取 [null](../../sql-reference/data-types/nullable.md/#finding-null) 子列。
- [mapKeys](/sql-reference/functions/tuple-map-functions#mapkeys) 读取 [keys](/sql-reference/data-types/map#reading-subcolumns-of-map) 子列。
- [mapValues](/sql-reference/functions/tuple-map-functions#mapvalues) 读取 [values](/sql-reference/data-types/map#reading-subcolumns-of-map) 子列。

可能的值：

- 0 — 禁用优化。
- 1 — 启用优化。
## optimize_group_by_constant_keys {#optimize_group_by_constant_keys} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.9"},{"label": "1"},{"label": "默认优化常数键的 GROUP BY"}]}]}/>

当块中的所有键都是常量时，优化 GROUP BY。
## optimize_group_by_function_keys {#optimize_group_by_function_keys} 

<SettingsInfoBlock type="Bool" default_value="1" />

消除选择部分 GROUP BY 键的其他键的函数。
## optimize_if_chain_to_multiif {#optimize_if_chain_to_multiif} 

<SettingsInfoBlock type="Bool" default_value="0" />

将 if(cond1, then1, if(cond2, ...)) 链替换为 multiIf。目前对数值类型没有好处。
## optimize_if_transform_strings_to_enum {#optimize_if_transform_strings_to_enum} 



<SettingsInfoBlock type="Bool" default_value="0" />

将 If 和 Transform 中的字符串类型参数替换为枚举。默认禁用，因为这可能会导致分布式查询中的不一致更改，从而导致查询失败。
## optimize_injective_functions_in_group_by {#optimize_injective_functions_in_group_by} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "1"},{"label": "在分析器的 GROUP BY 部分用其参数替换注入函数"}]}]}/>

将注入函数替换为其在 GROUP BY 部分的参数。
## optimize_injective_functions_inside_uniq {#optimize_injective_functions_inside_uniq} 



<SettingsInfoBlock type="Bool" default_value="1" />

删除 uniq*() 函数内部的一个参数的注入函数。
## optimize_min_equality_disjunction_chain_length {#optimize_min_equality_disjunction_chain_length} 



<SettingsInfoBlock type="UInt64" default_value="3" />

用于优化的表达式 `expr = x1 OR ... expr = xN` 的最小长度。
## optimize_min_inequality_conjunction_chain_length {#optimize_min_inequality_conjunction_chain_length} 



<SettingsInfoBlock type="UInt64" default_value="3" />

用于优化的表达式 `expr <> x1 AND ... expr <> xN` 的最小长度。
## optimize_move_to_prewhere {#optimize_move_to_prewhere} 



<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用在 [SELECT](../../sql-reference/statements/select/index.md) 查询中自动进行 [PREWHERE](../../sql-reference/statements/select/prewhere.md) 优化。

仅适用于 [*MergeTree](../../engines/table-engines/mergetree-family/index.md) 表。

可能的值：

- 0 — 禁用自动 `PREWHERE` 优化。
- 1 — 启用自动 `PREWHERE` 优化。
## optimize_move_to_prewhere_if_final {#optimize_move_to_prewhere_if_final} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在带有 [FINAL](/sql-reference/statements/select/from#final-modifier) 修饰符的 [SELECT](../../sql-reference/statements/select/index.md) 查询中自动进行 [PREWHERE](../../sql-reference/statements/select/prewhere.md) 优化。

仅适用于 [*MergeTree](../../engines/table-engines/mergetree-family/index.md) 表。

可能的值：

- 0 — 禁用在带有 `FINAL` 修饰符的 `SELECT` 查询中的自动 `PREWHERE` 优化。
- 1 — 启用在带有 `FINAL` 修饰符的 `SELECT` 查询中的自动 `PREWHERE` 优化。

**参见**

- [optimize_move_to_prewhere](#optimize_move_to_prewhere) 设置
## optimize_multiif_to_if {#optimize_multiif_to_if} 



<SettingsInfoBlock type="Bool" default_value="1" />

用单个条件替换 `multiIf`。
## optimize_normalize_count_variants {#optimize_normalize_count_variants} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.3"},{"label": "1"},{"label": "将语义上等于 count() 的聚合函数重写为默认的 count()"}]}]}/>

将语义上等于 count() 的聚合函数重写为 count()。
## optimize_on_insert {#optimize_on_insert} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.1"},{"label": "1"},{"label": "默认启用 INSERT 时的数据优化以改善用户体验"}]}]}/>

启用或禁用插入前的数据转换，就像在该块上执行了合并（根据表引擎）。

可能的值：

- 0 — 禁用。
- 1 — 启用。

**示例**

启用和禁用之间的区别：

查询：

```sql
SET optimize_on_insert = 1;

CREATE TABLE test1 (`FirstTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY FirstTable;

INSERT INTO test1 SELECT number % 2 FROM numbers(5);

SELECT * FROM test1;

SET optimize_on_insert = 0;

CREATE TABLE test2 (`SecondTable` UInt32) ENGINE = ReplacingMergeTree ORDER BY SecondTable;

INSERT INTO test2 SELECT number % 2 FROM numbers(5);

SELECT * FROM test2;
```

结果：

```text
┌─FirstTable─┐
│          0 │
│          1 │
└────────────┘

┌─SecondTable─┐
│           0 │
│           0 │
│           0 │
│           1 │
│           1 │
└─────────────┘
```

请注意，此设置会影响 [物化视图](/sql-reference/statements/create/view#materialized-view) 的行为。
## optimize_or_like_chain {#optimize_or_like_chain} 



<SettingsInfoBlock type="Bool" default_value="0" />

优化多个 OR LIKE 为 multiMatchAny。此优化默认不应启用，因为在某些情况下会违反索引分析。 
## optimize_read_in_order {#optimize_read_in_order} 



<SettingsInfoBlock type="Bool" default_value="1" />

在 [SELECT](../../sql-reference/statements/select/index.md) 查询中启用 [ORDER BY](/sql-reference/statements/select/order-by#optimization-of-data-reading) 优化，以从 [MergeTree](../../engines/table-engines/mergetree-family/mergetree.md) 表读取数据。

可能的值：

- 0 — 禁用 `ORDER BY` 优化。
- 1 — 启用 `ORDER BY` 优化。

**参见**

- [ORDER BY 子句](/sql-reference/statements/select/order-by#optimization-of-data-reading)
## optimize_read_in_window_order {#optimize_read_in_window_order} 



<SettingsInfoBlock type="Bool" default_value="1" />

在窗口子句中启用 ORDER BY 优化，以便以相应的顺序读取 MergeTree 表中的数据。
## optimize_redundant_functions_in_order_by {#optimize_redundant_functions_in_order_by} 



<SettingsInfoBlock type="Bool" default_value="1" />

从 ORDER BY 中删除如果其参数也在 ORDER BY 中的函数。
## optimize_respect_aliases {#optimize_respect_aliases} 



<SettingsInfoBlock type="Bool" default_value="1" />

如果设置为 true，则它将在 WHERE/GROUP BY/ORDER BY 中尊重别名，从而帮助分区修剪/二级索引/优化_聚合_顺序/优化_读取_顺序/优化_简单_计数。
## optimize_rewrite_aggregate_function_with_if {#optimize_rewrite_aggregate_function_with_if} 



<SettingsInfoBlock type="Bool" default_value="1" />

在逻辑上等效时，将带有 if 表达式的聚合函数重写为参数。例如，`avg(if(cond, col, null))` 可重写为 `avgOrNullIf(cond, col)`。这可能会提高性能。

:::note
仅在分析器下受支持（`enable_analyzer = 1`）。
:::
## optimize_rewrite_array_exists_to_has {#optimize_rewrite_array_exists_to_has} 



<SettingsInfoBlock type="Bool" default_value="0" />

在逻辑上等效时，将 arrayExists() 函数重写为 has()。例如，arrayExists(x -> x = 1, arr) 可以重写为 has(arr, 1)。
## optimize_rewrite_sum_if_to_count_if {#optimize_rewrite_sum_if_to_count_if} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "1"},{"label": "仅在分析器中可用，在该分析器中正常工作"}]}]}/>

在逻辑上等效时，将 sumIf() 和 sum(if()) 函数重写为 countIf() 函数。
## optimize_skip_merged_partitions {#optimize_skip_merged_partitions} 



<SettingsInfoBlock type="Bool" default_value="0" />

在 [OPTIMIZE TABLE ... FINAL](../../sql-reference/statements/optimize.md) 查询中启用或禁用优化，如果只有一个分片的级别 > 0 且没有过期的 TTL。

- `OPTIMIZE TABLE ... FINAL SETTINGS optimize_skip_merged_partitions=1`

默认情况下，`OPTIMIZE TABLE ... FINAL` 查询即使只有一个分片，也会重写该分片。

可能的值：

- 1 - 启用优化。
- 0 - 禁用优化。
## optimize_skip_unused_shards {#optimize_skip_unused_shards} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用对在 `WHERE/PREWHERE` 中具有分片键条件的 [SELECT](../../sql-reference/statements/select/index.md) 查询跳过未使用的分片（假设数据是通过分片键分布的，否则查询将得出错误结果）。

可能的值：

- 0 — 禁用。
- 1 — 启用。
## optimize_skip_unused_shards_limit {#optimize_skip_unused_shards_limit} 



<SettingsInfoBlock type="UInt64" default_value="1000" />

限制分片键值的数量，如果达到限制，则关闭 `optimize_skip_unused_shards`。

过多的值可能需要显著的处理量，而好处是值得怀疑的，因为如果您在 `IN (...)` 中有大量值，那么查询很可能还是会发送至所有分片。
## optimize_skip_unused_shards_nesting {#optimize_skip_unused_shards_nesting} 



<SettingsInfoBlock type="UInt64" default_value="0" />

控制 [`optimize_skip_unused_shards`](#optimize_skip_unused_shards)（因此仍需要 [`optimize_skip_unused_shards`](#optimize_skip_unused_shards)）取决于分布式查询的嵌套级别（当您拥有 `Distributed` 表查找另一个 `Distributed` 表时的情况）。

可能的值：

- 0 — 禁用，`optimize_skip_unused_shards` 始终生效。
- 1 — 仅对第一级启用 `optimize_skip_unused_shards`。
- 2 — 仅对第二级启用 `optimize_skip_unused_shards`。
## optimize_skip_unused_shards_rewrite_in {#optimize_skip_unused_shards_rewrite_in} 



<SettingsInfoBlock type="Bool" default_value="1" />

重写查询中的 IN 以排除不属于分片的值（需要 optimize_skip_unused_shards）。

可能的值：

- 0 — 禁用。
- 1 — 启用。
## optimize_sorting_by_input_stream_properties {#optimize_sorting_by_input_stream_properties} 



<SettingsInfoBlock type="Bool" default_value="1" />

通过输入流的排序属性优化排序。
## optimize_substitute_columns {#optimize_substitute_columns} 



<SettingsInfoBlock type="Bool" default_value="0" />

使用 [约束](../../sql-reference/statements/create/table.md/#constraints) 进行列替换。默认值为 `false`。

可能的值：

- true, false
## optimize_syntax_fuse_functions {#optimize_syntax_fuse_functions} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用将具有相同参数的聚合函数融合。它重写查询，包含至少两个具有相同参数的 [sum](/sql-reference/aggregate-functions/reference/sum)、[count](/sql-reference/aggregate-functions/reference/count) 或 [avg](/sql-reference/aggregate-functions/reference/avg) 的聚合函数为 [sumCount](/sql-reference/aggregate-functions/reference/sumcount)。

可能的值：

- 0 — 不融合相同参数的函数。
- 1 — 融合相同参数的函数。

**示例**

查询：

```sql
CREATE TABLE fuse_tbl(a Int8, b Int8) Engine = Log;
SET optimize_syntax_fuse_functions = 1;
EXPLAIN SYNTAX SELECT sum(a), sum(b), count(b), avg(b) from fuse_tbl FORMAT TSV;
```

结果：

```text
SELECT
    sum(a),
    sumCount(b).1,
    sumCount(b).2,
    (sumCount(b).1) / (sumCount(b).2)
FROM fuse_tbl
```
## optimize_throw_if_noop {#optimize_throw_if_noop} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在 [OPTIMIZE](../../sql-reference/statements/optimize.md) 查询未执行合并时抛出异常。

默认情况下，`OPTIMIZE` 即使没有执行任何操作也会成功返回。此设置使您可以区分这些情况，并在异常消息中获取原因。

可能的值：

- 1 — 启用抛出异常。
- 0 — 禁用抛出异常。
## optimize_time_filter_with_preimage {#optimize_time_filter_with_preimage} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "通过将函数转换为没有转换的等效比较来优化日期和日期时间谓词（例如 `toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31'`）"}]}]}/>

通过将函数转换为没有转换的等效比较来优化日期和日期时间谓词（例如，`toYear(col) = 2023 -> col >= '2023-01-01' AND col <= '2023-12-31'`）。
## optimize_trivial_approximate_count_query {#optimize_trivial_approximate_count_query} 



<SettingsInfoBlock type="Bool" default_value="0" />

对支持这种估计的存储执行的简单计数优化时使用近似值，例如 EmbeddedRocksDB。

可能的值：

   - 0 — 禁用优化。
   - 1 — 启用优化。
## optimize_trivial_count_query {#optimize_trivial_count_query} 



<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用使用来自 MergeTree 的元数据的简单查询 `SELECT count() FROM table` 的优化。如果需要使用行级安全性，请禁用此设置。

可能的值：

   - 0 — 禁用优化。
   - 1 — 启用优化。

另见：

- [optimize_functions_to_subcolumns](#optimize_functions_to_subcolumns)
## optimize_trivial_insert_select {#optimize_trivial_insert_select} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "在许多情况下，此优化没有意义。"}]}]}/>

优化简单的 `INSERT INTO table SELECT ... FROM TABLES` 查询。
## optimize_uniq_to_count {#optimize_uniq_to_count} 



<SettingsInfoBlock type="Bool" default_value="1" />

重写 uniq 和其变体（uniqUpTo 除外）为 count，如果子查询具有 distinct 或 group by 子句。
## optimize_use_implicit_projections {#optimize_use_implicit_projections} 



<SettingsInfoBlock type="Bool" default_value="1" />

自动选择隐式投影以执行 SELECT 查询。
## optimize_use_projections {#optimize_use_projections} 



<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用在处理 `SELECT` 查询时进行 [投影](../../engines/table-engines/mergetree-family/mergetree.md/#projections) 优化。

可能的值：

- 0 — 禁用投影优化。
- 1 — 启用投影优化。
## optimize_using_constraints {#optimize_using_constraints} 



<SettingsInfoBlock type="Bool" default_value="0" />

使用 [约束](../../sql-reference/statements/create/table.md/#constraints) 进行查询优化。默认值为 `false`。

可能的值：

- true, false
## os_thread_priority {#os_thread_priority} 



<SettingsInfoBlock type="Int64" default_value="0" />

设置执行查询的线程的优先级（[nice](https://en.wikipedia.org/wiki/Nice_(Unix))）。操作系统调度程序在选择每个可用 CPU 核心上运行的下一个线程时考虑此优先级。

:::note
要使用此设置，您需要设置 `CAP_SYS_NICE` 能力。`clickhouse-server` 包在安装时会进行设置。一些虚拟环境不允许您设置 `CAP_SYS_NICE` 能力。在这种情况下，`clickhouse-server` 在启动时会显示相关消息。
:::

可能的值：

- 您可以设置值的范围为 `[-20, 19]`。

较低的值意味着更高的优先级。具有较低 `nice` 优先级值的线程比高值的线程被更频繁地执行。对于长时间运行的非交互式查询，高值是更可取的，因为它允许它们在短暂的交互式查询到达时快速放弃资源。
## output_format_compression_level {#output_format_compression_level} 



<SettingsInfoBlock type="UInt64" default_value="3" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "3"},{"label": "允许在查询输出中更改压缩级别"}]}]}/>

如果查询输出被压缩，则为默认压缩级别。该设置在 `SELECT` 查询具有 `INTO OUTFILE` 或在写入到表函数 `file`、`url`、`hdfs`、`s3` 或 `azureBlobStorage` 时应用。

可能的值：从 `1` 到 `22`。
## output_format_compression_zstd_window_log {#output_format_compression_zstd_window_log} 



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "允许在使用 zstd 压缩时更改查询输出的 zstd 窗口日志"}]}]}/>

当输出压缩方法为 `zstd` 时可以使用。如果大于 `0`，此设置显式设置压缩窗口大小（2 的幂）并启用 zstd 压缩的长距离模式。这可以帮助实现更好的压缩比。

可能的值：非负数。请注意，如果值过小或过大，`zstdlib` 将抛出异常。典型值从 `20`（窗口大小 = `1MB`）到 `30`（窗口大小 = `1GB`）。
## output_format_parallel_formatting {#output_format_parallel_formatting} 



<SettingsInfoBlock type="Bool" default_value="1" />

启用或禁用数据格式的并行格式化。仅支持 [TSV](../../interfaces/formats.md/#tabseparated)、[TSKV](../../interfaces/formats.md/#tskv)、[CSV](../../interfaces/formats.md/#csv) 和 [JSONEachRow](../../interfaces/formats.md/#jsoneachrow) 格式。

可能的值：

- 1 — 启用。
- 0 — 禁用。
## page_cache_block_size {#page_cache_block_size} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1048576"},{"label": "允许在每个查询级别上调整此设置。"}]}]}/>

存储在用户空间页面缓存中的文件块的大小，以字节为单位。所有通过缓存的读取都将按此大小的倍数向上舍入。

此设置可以在每个查询级别上进行调整，但不同块大小的缓存条目不能重用。更改此设置会有效失效现有的缓存条目。

较高的值，如 1 MiB 适合高吞吐量查询，而较低的值，如 64 KiB 适合低延迟点查询。
## page_cache_inject_eviction {#page_cache_inject_eviction} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "添加了用户空间页面缓存。"}]}]}/>

用户空间页面缓存将有时随机失效某些页面。用于测试目的。
## page_cache_lookahead_blocks {#page_cache_lookahead_blocks} 



<SettingsInfoBlock type="UInt64" default_value="16" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "16"},{"label": "允许在每个查询级别上调整此设置。"}]}]}/>

在用户空间页面缓存失效时，从底层存储一次读取多达如此多的连续块，如果它们也不在缓存中。每个块是 page_cache_block_size 字节。

较高的值适合高吞吐量查询，而低延迟点查询在没有预读的情况下会更好。
## parallel_distributed_insert_select {#parallel_distributed_insert_select} 



<SettingsInfoBlock type="UInt64" default_value="0" />

启用并行分布式 `INSERT ... SELECT` 查询。

如果我们执行 `INSERT INTO distributed_table_a SELECT ... FROM distributed_table_b` 查询，并且两个表使用相同的集群且两个表都是 [复制的](../../engines/table-engines/mergetree-family/replication.md) 或非复制的，那么该查询将在每个分片上进行本地处理。

可能的值：

- 0 — 禁用。
- 1 — `SELECT` 将在分布式引擎的底层表的每个分片上执行。
- 2 — `SELECT` 和 `INSERT` 将在分布式引擎的底层表的每个分片上执行。
## parallel_hash_join_threshold {#parallel_hash_join_threshold} 



<SettingsInfoBlock type="UInt64" default_value="100000" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "100000"},{"label": "新设置"}]}, {"id": "row-2","items": [{"label": "25.4"},{"label": "0"},{"label": "新设置"}]}, {"id": "row-3","items": [{"label": "25.3"},{"label": "0"},{"label": "新设置"}]}]}/>

当应用基于哈希的连接算法时，此阈值帮助决定使用 `hash` 还是 `parallel_hash`（仅在可用右表大小估计时）。

当我们知道右表大小低于阈值时，会使用前者。
## parallel_replica_offset {#parallel_replica_offset} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />

这是一个内部设置，不应直接使用，表示“并行副本”模式的实现细节。该设置将由发起服务器为分布式查询自动设置，以便在并行副本中参与查询处理的副本的索引。
## parallel_replicas_allow_in_with_subquery {#parallel_replicas_allow_in_with_subquery} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "如果为真，IN 的子查询将在每个跟随副本上执行"}]}]}/>

如果为真，IN 的子查询将在每个跟随副本上执行。
## parallel_replicas_count {#parallel_replicas_count} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />

这是一个内部设置，不应直接使用，表示“并行副本”模式的实现细节。该设置将由发起服务器为分布式查询自动设置，以便参与查询处理的并行副本的数量。
## parallel_replicas_custom_key {#parallel_replicas_custom_key} 

<BetaBadge/>

可以用于在特定表之间分配工作量的任意整数表达式。
该值可以是任何整数表达式。

简单的使用主键的表达式更为理想。

如果在包括多个副本的单个分片的集群上使用此设置，则这些副本将被转换为虚拟分片。
否则，它的行为与 `SAMPLE` 键相同，将使用每个分片的多个副本。
## parallel_replicas_custom_key_range_lower {#parallel_replicas_custom_key_range_lower} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "添加设置以控制使用并行副本和动态分片时的范围过滤器"}]}]}/>

允许范围类型过滤器根据自定义范围 `[parallel_replicas_custom_key_range_lower, INT_MAX]` 在副本之间均匀分配工作量。

当与 [parallel_replicas_custom_key_range_upper](#parallel_replicas_custom_key_range_upper) 一起使用时，它使过滤器能够在副本之间均匀分配范围 `[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]` 的工作量。

注意：此设置不会导致在查询处理期间过滤任何额外的数据，而是更改范围过滤器在并行处理时对范围 `[0, INT_MAX]` 的分解点。
## parallel_replicas_custom_key_range_upper {#parallel_replicas_custom_key_range_upper} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "添加设置以控制使用并行副本和动态分片时的范围过滤器。0 的值禁用上限"}]}]}/>

允许范围类型过滤器根据自定义范围 `[0, parallel_replicas_custom_key_range_upper]` 在副本之间均匀分配工作量。0 的值禁用上限，将其设置为自定义键表达式的最大值。

当与 [parallel_replicas_custom_key_range_lower](#parallel_replicas_custom_key_range_lower) 一起使用时，它使过滤器能够在副本间均匀分配范围 `[parallel_replicas_custom_key_range_lower, parallel_replicas_custom_key_range_upper]` 的工作量。

注意：此设置不会导致在查询处理期间过滤任何额外的数据，而是更改范围过滤器在并行处理时对范围 `[0, INT_MAX]` 的分解点。
## parallel_replicas_for_cluster_engines {#parallel_replicas_for_cluster_engines} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "1"},{"label": "新设置。"}]}]}/>

用其 -Cluster 替代表函数引擎。
## parallel_replicas_for_non_replicated_merge_tree {#parallel_replicas_for_non_replicated_merge_tree} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="0" />

如果为真，ClickHouse 还将对非复制的 MergeTree 表使用并行副本算法。
## parallel_replicas_index_analysis_only_on_coordinator {#parallel_replicas_index_analysis_only_on_coordinator} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1"},{"label": "索引分析仅在副本协调器上完成，在其他副本上跳过。仅在启用 parallel_replicas_local_plan 时有效。"}]}]}/>

索引分析仅在副本协调器上完成，在其他副本上跳过。仅在启用 parallel_replicas_local_plan 时有效。
## parallel_replicas_insert_select_local_pipeline {#parallel_replicas_insert_select_local_pipeline} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "在并行副本的分布式 INSERT SELECT 中使用本地管道。目前由于性能问题被禁用"}]}, {"id": "row-2","items": [{"label": "25.4","label": "0"},{"label": "在并行副本的分布式 INSERT SELECT 中使用本地管道。目前由于性能问题被禁用"}]}]}/>

在并行副本的分布式 INSERT SELECT 中使用本地管道。
## parallel_replicas_local_plan {#parallel_replicas_local_plan} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "在并行副本的查询中为本地副本使用本地计划"}]}, {"id": "row-2","items": [{"label": "24.11","label": "1"},{"label": "在并行副本的查询中为本地副本使用本地计划"}]}, {"id": "row-3","items": [{"label": "24.10","label": "1"},{"label": "在并行副本的查询中为本地副本使用本地计划"}]}]}/>

为本地副本构建本地计划。
## parallel_replicas_mark_segment_size {#parallel_replicas_mark_segment_size} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.9"},{"label": "0"},{"label": "此设置的值现在由系统自动确定。"}]}, {"id": "row-2","items": [{"label": "24.1","label": "128"},{"label": "添加新设置以控制新并行副本协调器实施中的段大小"}]}]}/>

部分虚拟划分为段，以分布在副本之间进行并行读取。该设置控制这些段的大小。不推荐在不确定的情况下更改此值。值应在范围 [128; 16384] 内。
## parallel_replicas_min_number_of_rows_per_replica {#parallel_replicas_min_number_of_rows_per_replica} 

<BetaBadge/>



<SettingsInfoBlock type="UInt64" default_value="0" />

限制查询中使用的副本数量为 (估计要读取的行数 / min_number_of_rows_per_replica)。最大仍然受 'max_parallel_replicas' 的限制。
## parallel_replicas_mode {#parallel_replicas_mode} 

<BetaBadge/>



<SettingsInfoBlock type="ParallelReplicasMode" default_value="read_tasks" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "read_tasks"},{"label": "此设置作为并行副本特性 Beta 的一部分引入"}]}]}/>

用于自定义键的并行副本类型的过滤器。默认 - 对自定义键使用模运算，范围 - 对自定义键使用范围过滤器，使用自定义键的值类型的所有可能值。
## parallel_replicas_only_with_analyzer {#parallel_replicas_only_with_analyzer} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "仅在启用分析器时支持并行副本"}]}]}/>

必须启用分析器才能使用并行副本。如果禁用分析器，查询执行将回退到本地执行，即使并行读取副本已启用。未启用分析器下使用并行副本是不被支持的。
## parallel_replicas_prefer_local_join {#parallel_replicas_prefer_local_join} 

<BetaBadge/>



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "如果为真，则当 JOIN 可以使用并行副本算法，并且右 JOIN 部分的所有存储为 *MergeTree，将使用本地 JOIN 而不是 GLOBAL JOIN。"}]}]}/>

如果为真，并且 JOIN 可以使用并行副本算法，并且右 JOIN 部分的所有存储都是 *MergeTree，则将使用本地 JOIN，而不是 GLOBAL JOIN。
## parallel_view_processing {#parallel_view_processing} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用推送到附加视图的并行处理，而不是顺序处理。
## parallelize_output_from_storages {#parallelize_output_from_storages} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.5"},{"label": "1"},{"label": "允许在执行从文件/url/s3等读取的查询时进行并行处理。这可能会重新排序行。"}]}]}/>

为从存储读取步骤的输出并行化。它允许在从存储读取后尽快进行查询处理的并行化，前提是可能的。
## parsedatetime_e_requires_space_padding {#parsedatetime_e_requires_space_padding} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "改善与 MySQL DATE_FORMAT/STR_TO_DATE 的兼容性"}]}]}/>

在函数 'parseDateTime' 中，格式化器 '%e' 期望单数字的日期是以空格填充的，例如，' 2' 可以接受，但 '2' 会引发错误。
## parsedatetime_parse_without_leading_zeros {#parsedatetime_parse_without_leading_zeros} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.11"},{"label": "1"},{"label": "改善与 MySQL DATE_FORMAT/STR_TO_DATE 的兼容性"}]}]}/>

在函数 'parseDateTime' 中，格式化器 '%c'、'%l' 和 '%k' 在解析月份和小时时不带前导零。
## partial_merge_join_left_table_buffer_bytes {#partial_merge_join_left_table_buffer_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

如果不为0，则在部分合并连接中对左侧表格进行更大的组块。它在每个连接线程中使用最多 2 倍于指定的内存。
## partial_merge_join_rows_in_right_blocks {#partial_merge_join_rows_in_right_blocks} 



<SettingsInfoBlock type="UInt64" default_value="65536" />

限制部分合并连接算法中右侧连接数据块的大小，用于[JOIN](../../sql-reference/statements/select/join.md) 查询。

ClickHouse 服务器：

1. 将右侧连接数据拆分为最大行数为指定值的块。
2. 用每个块的最小值和最大值进行索引。
3. 如果可能，将准备好的块卸载到磁盘。

可能的值：

- 任何正整数。推荐范围：\ [1000, 100000\]。
## partial_result_on_first_cancel {#partial_result_on_first_cancel} 



<SettingsInfoBlock type="Bool" default_value="0" />

允许查询在取消后返回部分结果。
## parts_to_delay_insert {#parts_to_delay_insert} 



<SettingsInfoBlock type="UInt64" default_value="0" />

如果目标表在单个分区中包含至少这么多活动部分，则人造地减缓插入到表的速度。
## parts_to_throw_insert {#parts_to_throw_insert} 



<SettingsInfoBlock type="UInt64" default_value="0" />

如果目标表的单个分区中活动部分超过这个数量，则抛出'Too many parts ...'异常。
## periodic_live_view_refresh {#periodic_live_view_refresh} 



<SettingsInfoBlock type="Seconds" default_value="60" />

定期刷新的实时视图被强制刷新的时间间隔。
## poll_interval {#poll_interval} 



<SettingsInfoBlock type="UInt64" default_value="10" />

在服务器查询等待循环中阻塞指定的秒数。
## postgresql_connection_attempt_timeout {#postgresql_connection_attempt_timeout} 



<SettingsInfoBlock type="UInt64" default_value="2" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "2"},{"label": "允许控制 PostgreSQL 连接的 'connect_timeout' 参数。"}]}]}/>

单次尝试连接 PostgreSQL 端点的连接超时（以秒为单位）。
该值作为连接 URL 的 `connect_timeout` 参数传递。
## postgresql_connection_pool_auto_close_connection {#postgresql_connection_pool_auto_close_connection} 



<SettingsInfoBlock type="Bool" default_value="0" />

在将连接返回到池之前关闭连接。
## postgresql_connection_pool_retries {#postgresql_connection_pool_retries} 



<SettingsInfoBlock type="UInt64" default_value="2" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "2"},{"label": "允许控制 PostgreSQL 连接池中的重试次数。"}]}]}/>

PostgreSQL 表引擎和数据库引擎的连接池推送/弹出重试次数。
## postgresql_connection_pool_size {#postgresql_connection_pool_size} 



<SettingsInfoBlock type="UInt64" default_value="16" />

PostgreSQL 表引擎和数据库引擎的连接池大小。
## postgresql_connection_pool_wait_timeout {#postgresql_connection_pool_wait_timeout} 



<SettingsInfoBlock type="UInt64" default_value="5000" />

PostgreSQL 表引擎和数据库引擎中空池的连接池推送/弹出超时。默认情况下，它将在空池上阻塞。
## postgresql_fault_injection_probability {#postgresql_fault_injection_probability} 



<SettingsInfoBlock type="Float" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "0"},{"label": "新设置"}]}]}/>

内部（用于复制）PostgreSQL 查询失败的近似概率。有效值的范围为 [0.0f, 1.0f]
## prefer_column_name_to_alias {#prefer_column_name_to_alias} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在查询表达式和子句中使用原始列名而不是别名。这在别名与列名相同时尤其重要，请参见 [Expression Aliases](/sql-reference/syntax#notes-on-usage)。启用此设置会使 ClickHouse 的别名语法规则与大多数其他数据库引擎更加兼容。

可能的值：

- 0 — 列名被替换为别名。
- 1 — 列名未被替换为别名。

**示例**

启用和禁用之间的区别：

查询：

```sql
SET prefer_column_name_to_alias = 0;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

结果：

```text
从服务器收到异常 (版本 21.5.1)：
代码：184. DB::Exception: 从 localhost:9000 收到。DB::Exception: 聚合函数 avg(number) 在查询中出现在另一个聚合函数内部：在处理 avg(number) AS number 时。
```

查询：

```sql
SET prefer_column_name_to_alias = 1;
SELECT avg(number) AS number, max(number) FROM numbers(10);
```

结果：

```text
┌─number─┬─max(number)─┐
│    4.5 │           9 │
└────────┴─────────────┘
```
## prefer_external_sort_block_bytes {#prefer_external_sort_block_bytes} 



<SettingsInfoBlock type="UInt64" default_value="16744704" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.5"},{"label": "16744704"},{"label": "更倾向于外部排序的最大块字节，减少合并期间的内存使用。"}]}]}/>

更倾向于外部排序的最大块字节，减少合并期间的内存使用。
## prefer_global_in_and_join {#prefer_global_in_and_join} 



<SettingsInfoBlock type="Bool" default_value="0" />

启用将 `IN`/`JOIN` 操作符替换为 `GLOBAL IN`/`GLOBAL JOIN`。

可能的值：

- 0 — 禁用。`IN`/`JOIN` 操作符不被替换为 `GLOBAL IN`/`GLOBAL JOIN`。
- 1 — 启用。`IN`/`JOIN` 操作符被替换为 `GLOBAL IN`/`GLOBAL JOIN`。

**用法**

虽然 `SET distributed_product_mode=global` 可以改变分布式表的查询行为，但不适用于本地表或来自外部资源的表。这时，`prefer_global_in_and_join` 设置便发挥作用。

例如，我们有查询服务节点，它们包含不适合分发的本地表。我们需要在分布式处理期间动态计算它们的数据，使用 `GLOBAL` 关键字 — `GLOBAL IN`/`GLOBAL JOIN`。

`prefer_global_in_and_join` 的另一个用例是访问由外部引擎创建的表。此设置帮助在连接此类表时减少对外部源的调用次数：每个查询仅一次调用。

**另请参见：**

- [分布式子查询](/sql-reference/operators/in#distributed-subqueries) 了解如何使用 `GLOBAL IN`/`GLOBAL JOIN`
## prefer_localhost_replica {#prefer_localhost_replica} 



<SettingsInfoBlock type="Bool" default_value="1" />

启用/禁用在处理分布式查询时优选使用本地主机副本。

可能的值：

- 1 — 如果存在，ClickHouse 总是将查询发送到本地主机副本。
- 0 — ClickHouse 使用 [load_balancing](#load_balancing) 设置指定的平衡策略。

:::note
如果您在没有 [parallel_replicas_custom_key](#parallel_replicas_custom_key) 的情况下使用 [max_parallel_replicas](#max_parallel_replicas)，请禁用此设置。
如果设置了 [parallel_replicas_custom_key](#parallel_replicas_custom_key)，仅在它用于包含多个副本的多个分片的集群上禁用此设置。
如果它用于具有单个分片和多个副本的集群，则禁用此设置会产生负面影响。
:::
## prefer_warmed_unmerged_parts_seconds {#prefer_warmed_unmerged_parts_seconds} 

<CloudAvailableBadge/>



<SettingsInfoBlock type="Int64" default_value="0" />

仅在 ClickHouse Cloud 中有效。 如果一个合并的部分少于这么多秒的历史并且尚未预热（参见 [cache_populated_by_fetch](merge-tree-settings.md/#cache_populated_by_fetch)），但所有源部分都可用并且已预热，SELECT 查询将从这些部分读取。仅适用于 Replicated-/SharedMergeTree。请注意，这只检查 CacheWarmer 是否处理了该部分；如果该部分是通过其他方式获取到缓存中，它仍然会被视为冷部分，直到 CacheWarmer 处理它；如果它被预热后从缓存中驱逐，它仍然会被视为暖部分。
## preferred_block_size_bytes {#preferred_block_size_bytes} 



<SettingsInfoBlock type="UInt64" default_value="1000000" />

此设置调整查询处理的数据块大小，并表示对更粗糙的 'max_block_size' 设置的额外微调。如果列很大，并且在 'max_block_size' 行时，块大小可能会大于指定的字节量，则其大小将被降低以提高 CPU 缓存局部性。
## preferred_max_column_in_block_size_bytes {#preferred_max_column_in_block_size_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

读取时对最大列大小的限制。 有助于减少缓存未命中次数。 应接近于 L2 缓存大小。
## preferred_optimize_projection_name {#preferred_optimize_projection_name} 

如果设置为非空字符串，ClickHouse 将尝试在查询中应用指定的投影。

可能的值：

- 字符串：首选投影的名称
## prefetch_buffer_size {#prefetch_buffer_size} 



<SettingsInfoBlock type="UInt64" default_value="1048576" />

从文件系统读取的预取缓冲区的最大大小。
## print_pretty_type_names {#print_pretty_type_names} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "1"},{"label": "更好的用户体验。"}]}]}/>

允许在 `DESCRIBE` 查询和 `toTypeName()` 函数中以漂亮的方式打印深层嵌套的类型名称，并带有缩进。

示例：

```sql
CREATE TABLE test (a Tuple(b String, c Tuple(d Nullable(UInt64), e Array(UInt32), f Array(Tuple(g String, h Map(String, Array(Tuple(i String, j UInt64))))), k Date), l Nullable(String))) ENGINE=Memory;
DESCRIBE TABLE test FORMAT TSVRaw SETTINGS print_pretty_type_names=1;
```

```
a   Tuple(
    b String,
    c Tuple(
        d Nullable(UInt64),
        e Array(UInt32),
        f Array(Tuple(
            g String,
            h Map(
                String,
                Array(Tuple(
                    i String,
                    j UInt64
                ))
            )
        )),
        k Date
    ),
    l Nullable(String)
)
```
## priority {#priority} 



<SettingsInfoBlock type="UInt64" default_value="0" />

查询的优先级。 1 - 最高，较高的值 - 较低的优先级； 0 - 不使用优先级。
## push_external_roles_in_interserver_queries {#push_external_roles_in_interserver_queries} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "新设置。"}]}]}/>

在执行查询时启用将用户角色从发起者推送到其他节点。
## query_cache_compress_entries {#query_cache_compress_entries} 



<SettingsInfoBlock type="Bool" default_value="1" />

在 [查询缓存](../query-cache.md) 中压缩条目。 以牺牲插入到缓存中或从缓存中读取的速度为代价，减少查询缓存的内存消耗。

可能的值：

- 0 - 禁用
- 1 - 启用
## query_cache_max_entries {#query_cache_max_entries} 



<SettingsInfoBlock type="UInt64" default_value="0" />

当前用户在 [查询缓存](../query-cache.md) 中可以存储的查询结果的最大数量。 0 表示无限制。

可能的值：

- 正整数 >= 0。
## query_cache_max_size_in_bytes {#query_cache_max_size_in_bytes} 



<SettingsInfoBlock type="UInt64" default_value="0" />

当前用户可以在 [查询缓存](../query-cache.md) 中分配的最大内存量（以字节为单位）。 0 表示无限制。

可能的值：

- 正整数 >= 0。
## query_cache_min_query_duration {#query_cache_min_query_duration} 



<SettingsInfoBlock type="Milliseconds" default_value="0" />

查询需要运行的最小持续时间（以毫秒为单位），其结果将存储在 [查询缓存](../query-cache.md) 中。

可能的值：

- 正整数 >= 0。
## query_cache_min_query_runs {#query_cache_min_query_runs} 



<SettingsInfoBlock type="UInt64" default_value="0" />

`SELECT` 查询在结果存储在 [查询缓存](../query-cache.md) 中之前必须运行的最小次数。

可能的值：

- 正整数 >= 0。
## query_cache_nondeterministic_function_handling {#query_cache_nondeterministic_function_handling} 



<SettingsInfoBlock type="QueryResultCacheNondeterministicFunctionHandling" default_value="throw" />

控制 [查询缓存](../query-cache.md) 如何处理具有非确定性函数（如 `rand()` 或 `now()`）的 `SELECT` 查询。

可能的值：

- `'throw'` - 抛出异常并且不缓存查询结果。
- `'save'` - 缓存查询结果。
- `'ignore'` - 不缓存查询结果且不抛出异常。
## query_cache_share_between_users {#query_cache_share_between_users} 



<SettingsInfoBlock type="Bool" default_value="0" />

如果启用，来自 [查询缓存](../query-cache.md) 的 `SELECT` 查询结果可以被其他用户读取。
由于安全原因，不建议启用此设置。

可能的值：

- 0 - 禁用
- 1 - 启用
## query_cache_squash_partial_results {#query_cache_squash_partial_results} 



<SettingsInfoBlock type="Bool" default_value="1" />

将部分结果块压缩为 [max_block_size](#max_block_size) 的大小。 减少对查询缓存的插入性能，但提高缓存条目的可压缩性（请参见 [query_cache_compress-entries](#query_cache_compress_entries)）。

可能的值：

- 0 - 禁用
- 1 - 启用
## query_cache_system_table_handling {#query_cache_system_table_handling} 



<SettingsInfoBlock type="QueryResultCacheSystemTableHandling" default_value="throw" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "throw"},{"label": "查询缓存不再缓存对系统表的查询结果"}]}]}/>

控制 [查询缓存](../query-cache.md) 如何处理针对系统表的 `SELECT` 查询，即 `system.*` 和 `information_schema.*` 数据库中的表。

可能的值：

- `'throw'` - 抛出异常并不缓存查询结果。
- `'save'` - 缓存查询结果。
- `'ignore'` - 不缓存查询结果且不抛出异常。
## query_cache_tag {#query_cache_tag} 



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": ""},{"label": "用于标记查询缓存设置的新设置。"}]}]}/>

一个充当 [查询缓存](../query-cache.md) 条标签的字符串。
相同查询的不同标签被查询缓存视为不同的查询。

可能的值：

- 任何字符串
## query_cache_ttl {#query_cache_ttl} 



<SettingsInfoBlock type="Seconds" default_value="60" />

在这个时间（以秒为单位）之后，条目在 [查询缓存](../query-cache.md) 中变得过时。

可能的值：

- 正整数 >= 0。
## query_condition_cache_store_conditions_as_plaintext {#query_condition_cache_store_conditions_as_plaintext} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新设置"}]}]}/>

以明文存储 [查询条件缓存](/operations/query-condition-cache) 的过滤条件。
如果启用，system.query_condition_cache 将显示逐字的过滤条件，这使得调试缓存问题更加容易。
默认情况下禁用，因为明文过滤条件可能会暴露敏感信息。

可能的值：

- 0 - 禁用
- 1 - 启用
## query_metric_log_interval {#query_metric_log_interval} 



<SettingsInfoBlock type="Int64" default_value="-1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "-1"},{"label": "新设置。"}]}]}/>

收集单个查询的 [query_metric_log](../../operations/system-tables/query_metric_log.md) 的时间间隔（以毫秒为单位）。

如果设置为任何负值，则将取 [query_metric_log 设置](/operations/server-configuration-parameters/settings#query_metric_log) 中的 `collect_interval_milliseconds` 值，如果不存在，默认为 1000。

要禁用单个查询的收集，请将 `query_metric_log_interval` 设置为 0。

默认值： -1
## query_plan_aggregation_in_order {#query_plan_aggregation_in_order} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.12"},{"label": "1"},{"label": "启用一些关于查询计划的重构"}]}]}/>

切换查询计划级优化的顺序聚合。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_convert_join_to_in {#query_plan_convert_join_to_in} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新设置"}]}]}/>

允许将 JOIN 转换为带有 IN 的子查询，如果输出列仅与左表相关联。
## query_plan_convert_outer_join_to_inner_join {#query_plan_convert_outer_join_to_inner_join} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "1"},{"label": "允许将 OUTER JOIN 转换为 INNER JOIN，如果 JOIN 后的过滤器始终过滤默认值"}]}]}/>

如果 JOIN 后的过滤器始终过滤默认值，允许将 OUTER JOIN 转换为 INNER JOIN。
## query_plan_enable_multithreading_after_window_functions {#query_plan_enable_multithreading_after_window_functions} 



<SettingsInfoBlock type="Bool" default_value="1" />

在评估窗口函数后启用多线程，以允许并行流处理。
## query_plan_enable_optimizations {#query_plan_enable_optimizations} 



<SettingsInfoBlock type="Bool" default_value="1" />

切换查询计划级的查询优化。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 在查询计划级别禁用所有优化
- 1 - 启用查询计划级别的优化（但单个优化可能仍然通过其个别设置被禁用）
## query_plan_execute_functions_after_sorting {#query_plan_execute_functions_after_sorting} 



<SettingsInfoBlock type="Bool" default_value="1" />

切换一个查询计划级优化，它将表达式转移到排序步骤之后。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_filter_push_down {#query_plan_filter_push_down} 



<SettingsInfoBlock type="Bool" default_value="1" />

切换一个查询计划级优化，它将过滤器下推到执行计划中。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_join_shard_by_pk_ranges {#query_plan_join_shard_by_pk_ranges} 



<SettingsInfoBlock type="Bool" default_value="0" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新设置"}]}]}/>

如果连接键包含两个表的主键前缀，则为 JOIN 应用分片。支持 hash、parallel_hash 和 full_sorting_merge 算法。
## query_plan_join_swap_table {#query_plan_join_swap_table} 



<SettingsInfoBlock type="BoolAuto" default_value="auto" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "auto"},{"label": "新设置。右侧表之前总是被选择。"}]}]}/>

确定连接中哪个侧的表应该是构建表（也称为内表，即在哈希连接中插入到哈希表中的表）在查询计划中。此设置仅支持具有 `JOIN ON` 子句的 `ALL` 连接严格性。可能的值为：
- 'auto': 让计划程序决定使用哪个表作为构建表。
- 'false': 从不交换表（右侧表为构建表）。
- 'true': 总是交换表（左侧表为构建表）。
## query_plan_lift_up_array_join {#query_plan_lift_up_array_join} 



<SettingsInfoBlock type="Bool" default_value="1" />

切换一个查询计划级优化，它将 ARRAY JOIN 提升到执行计划中。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_lift_up_union {#query_plan_lift_up_union} 



<SettingsInfoBlock type="Bool" default_value="1" />

切换一个查询计划级优化，它将查询计划的大型子树提升到联合中，以启用进一步的优化。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_max_limit_for_lazy_materialization {#query_plan_max_limit_for_lazy_materialization} 



<SettingsInfoBlock type="UInt64" default_value="10" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "10"},{"label": "添加新的设置以控制允许使用查询计划进行惰性物化优化的最大限制值。如果为零，则没有限制"}]}]}/>

控制允许使用查询计划进行惰性物化优化的最大限制值。如果为零，则没有限制。
## query_plan_max_optimizations_to_apply {#query_plan_max_optimizations_to_apply} 



<SettingsInfoBlock type="UInt64" default_value="10000" />

限制应用于查询计划的优化总数，参见设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations)。
有助于避免复杂查询的优化时间过长。
在 EXPLAIN PLAN 查询中，达到此限制后将停止应用优化并返回计划原样。
对于常规查询执行，如果实际优化数量超过此设置，将抛出异常。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::
## query_plan_merge_expressions {#query_plan_merge_expressions} 



<SettingsInfoBlock type="Bool" default_value="1" />

切换一个查询计划级优化，它合并连续的过滤器。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_merge_filter_into_join_condition {#query_plan_merge_filter_into_join_condition} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "添加新设置以将过滤器合并到连接条件中"}]}]}/>

允许将过滤器合并到 JOIN 条件中，将 CROSS JOIN 转换为 INNER。
## query_plan_merge_filters {#query_plan_merge_filters} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "0"},{"label": "允许在查询计划中合并过滤器"}]}, {"id": "row-2","items": [{"label": "24.11"},{"label": "1"},{"label": "允许在查询计划中合并过滤器。这是正确支持新分析器的过滤器下推所必需的。"}]}]}/>

允许在查询计划中合并过滤器。
## query_plan_optimize_lazy_materialization {#query_plan_optimize_lazy_materialization} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "添加新设置以使用查询计划进行惰性物化优化"}]}]}/>

使用查询计划进行惰性物化优化。
## query_plan_optimize_prewhere {#query_plan_optimize_prewhere} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "允许将过滤器下推到支持的存储的 PREWHERE 表达式"}]}]}/>

允许将过滤器下推到支持的存储的 PREWHERE 表达式。
## query_plan_push_down_limit {#query_plan_push_down_limit} 



<SettingsInfoBlock type="Bool" default_value="1" />

切换一个查询计划级优化，它将 LIMIT 下推到执行计划中。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_read_in_order {#query_plan_read_in_order} 



<SettingsInfoBlock type="Bool" default_value="1" />

切换查询计划级的有序读取优化。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_remove_redundant_distinct {#query_plan_remove_redundant_distinct} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.2"},{"label": "1"},{"label": "在查询计划中移除冗余 DISTINCT 步骤"}]}]}/>

切换一个查询计划级优化，它删除冗余的 DISTINCT 步骤。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_remove_redundant_sorting {#query_plan_remove_redundant_sorting} 



<SettingsInfoBlock type="Bool" default_value="1" />



<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.1"},{"label": "1"},{"label": "在查询计划中移除冗余排序。例如，移除与子查询中 ORDER BY 子句相关的排序步骤"}]}]}/>

切换一个查询计划级优化，它移除冗余的排序步骤，例如在子查询中。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅在开发人员调试时使用。该设置可能在未来以向后不兼容的方式进行更改或删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_reuse_storage_ordering_for_window_functions {#query_plan_reuse_storage_ordering_for_window_functions} 

<SettingsInfoBlock type="Bool" default_value="1" />

切换一个查询计划级别的优化，该优化在为窗口函数排序时使用存储排序。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅供开发人员用于调试。该设置在未来可能会以不向后兼容的方式进行更改或被删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_split_filter {#query_plan_split_filter} 

<SettingsInfoBlock type="Bool" default_value="1" />

:::note
这是一个专家级设置，仅供开发人员用于调试。该设置在未来可能会以不向后兼容的方式进行更改或被删除。
:::

切换一个查询计划级别的优化，该优化将过滤器拆分为表达式。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_try_use_vector_search {#query_plan_try_use_vector_search} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "新设置。"}]}]}/>

切换一个查询计划级别的优化，该优化尝试使用向量相似度索引。
仅在设置 [query_plan_enable_optimizations](#query_plan_enable_optimizations) 为 1 时生效。

:::note
这是一个专家级设置，仅供开发人员用于调试。该设置在未来可能会以不向后兼容的方式进行更改或被删除。
:::

可能的值：

- 0 - 禁用
- 1 - 启用
## query_plan_use_new_logical_join_step {#query_plan_use_new_logical_join_step} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "启用新步骤"}]}, {"id": "row-2","items": [{"label": "25.1"},{"label": "0"},{"label": "新的连接步骤，内部变更"}]}]}/>

在查询计划中使用新的逻辑连接步骤
## query_profiler_cpu_time_period_ns {#query_profiler_cpu_time_period_ns} 

<SettingsInfoBlock type="UInt64" default_value="1000000000" />

设置 [query profiler](../../operations/optimizing-performance/sampling-query-profiler.md) 的 CPU 时钟计时器周期。此计时器仅计算 CPU 时间。

可能的值：

- 正整数，以纳秒为单位。

    推荐值：

            - 10000000（每秒 100 次）纳秒及以上，适用于单个查询。
            - 1000000000（每秒一次）适用于集群范围的分析。

- 0 以关闭计时器。

**在 ClickHouse Cloud 中暂时禁用。**

另请参见：

- 系统表 [trace_log](/operations/system-tables/trace_log)
## query_profiler_real_time_period_ns {#query_profiler_real_time_period_ns} 

<SettingsInfoBlock type="UInt64" default_value="1000000000" />

设置 [query profiler](../../operations/optimizing-performance/sampling-query-profiler.md) 的实际时钟计时器周期。实际时钟计时器计数墙钟时间。

可能的值：

- 正整数，以纳秒为单位。

    推荐值：

            - 10000000（每秒 100 次）纳秒及以下，适用于单个查询。
            - 1000000000（每秒一次）适用于集群范围的分析。

- 0 以关闭计时器。

**在 ClickHouse Cloud 中暂时禁用。**

另请参见：

- 系统表 [trace_log](/operations/system-tables/trace_log)
## queue_max_wait_ms {#queue_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

请求队列中的等待时间，如果并发请求的数量超过最大值。
## rabbitmq_max_wait_ms {#rabbitmq_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="5000" />

在重试之前从 RabbitMQ 读取的等待时间。
## read_backoff_max_throughput {#read_backoff_max_throughput} 

<SettingsInfoBlock type="UInt64" default_value="1048576" />

在读取缓慢时减少线程数量的设置。当读取带宽低于每秒此字节数时计数事件。
## read_backoff_min_concurrency {#read_backoff_min_concurrency} 

<SettingsInfoBlock type="UInt64" default_value="1" />

在读取缓慢时尽量保持最小线程数的设置。
## read_backoff_min_events {#read_backoff_min_events} 

<SettingsInfoBlock type="UInt64" default_value="2" />

在读取缓慢时减少线程数量的设置。减少线程数量之前的事件数量。
## read_backoff_min_interval_between_events_ms {#read_backoff_min_interval_between_events_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

在读取缓慢时减少线程数量的设置。如果前一个事件经过的时间少于某个时间间隔，则不再考虑该事件。
## read_backoff_min_latency_ms {#read_backoff_min_latency_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="1000" />

在读取缓慢时减少线程数量的设置。仅关注耗时至少这一秒的读取。
## read_from_filesystem_cache_if_exists_otherwise_bypass_cache {#read_from_filesystem_cache_if_exists_otherwise_bypass_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

允许以被动模式使用文件系统缓存——利用现有的缓存条目，但不向缓存中添加更多条目。如果将此设置用于重的临时查询而将其关闭用于短的实时查询，则可以避免因过重的查询导致的缓存抖动，并提高整体系统效率。
## read_from_page_cache_if_exists_otherwise_bypass_cache {#read_from_page_cache_if_exists_otherwise_bypass_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "添加用户空间页面缓存"}]}]}/>

以被动模式使用用户空间页面缓存，类似于 read_from_filesystem_cache_if_exists_otherwise_bypass_cache。
## read_in_order_two_level_merge_threshold {#read_in_order_two_level_merge_threshold} 

<SettingsInfoBlock type="UInt64" default_value="100" />

在多线程按主键顺序读取时，需读取的最小部分数以运行初步合并步骤。
## read_in_order_use_buffering {#read_in_order_use_buffering} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.7"},{"label": "1"},{"label": "按主键顺序读取时合并前使用缓冲"}]}]}/>

按主键顺序读取时在合并之前使用缓冲。这会提高查询执行的并行性
## read_in_order_use_virtual_row {#read_in_order_use_virtual_row} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "0"},{"label": "按主键顺序或其单调函数方式读取时使用虚拟行。它在搜索多个部分时很有用，因为只接触相关部分。"}]}]}/>

按主键顺序或其单调函数方式读取时使用虚拟行。它在搜索多个部分时很有用，因为只接触相关部分。
## read_overflow_mode {#read_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

当达到限制时应如何处理。
## read_overflow_mode_leaf {#read_overflow_mode_leaf} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

设置当读取的数据量超过某个叶子限制时会发生什么情况。

可能的选项：
- `throw`: 抛出异常（默认）。
- `break`: 停止执行查询并返回部分结果。
## read_priority {#read_priority} 

<SettingsInfoBlock type="Int64" default_value="0" />

从本地文件系统或远程文件系统读取数据的优先级。仅支持 'pread_threadpool' 方法用于本地文件系统和 `threadpool` 方法用于远程文件系统。
## read_through_distributed_cache {#read_through_distributed_cache} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "ClickHouse Cloud 的一个设置"}]}]}/>

仅在 ClickHouse Cloud 中有效。允许从分布式缓存中读取
## readonly {#readonly} 

<SettingsInfoBlock type="UInt64" default_value="0" />

0 - 没有只读限制。1 - 仅读请求，以及更改显式允许的设置。2 - 仅读请求，以及更改设置，但不包括 'readonly' 设置。
## receive_data_timeout_ms {#receive_data_timeout_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="2000" />

接收来自副本的第一个数据包或正进度的数据包的连接超时
## receive_timeout {#receive_timeout} 

<SettingsInfoBlock type="Seconds" default_value="300" />

从网络接收数据的超时，单位为秒。如果在此间隔内未接收到字节，则会抛出异常。如果您在客户端设置此参数，则套接字的 'send_timeout' 也将在相应的服务器连接端进行设置。
## regexp_max_matches_per_row {#regexp_max_matches_per_row} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

设置每行单个正则表达式的最大匹配数。用于防止在使用贪婪正则表达式时内存过载，在 [extractAllGroupsHorizontal](/sql-reference/functions/string-search-functions#extractallgroupshorizontal) 函数中。

可能的值：

- 正整数。
## reject_expensive_hyperscan_regexps {#reject_expensive_hyperscan_regexps} 

<SettingsInfoBlock type="Bool" default_value="1" />

拒绝使用 hyperscan 进行评估可能会昂贵的模式（由于 NFA 状态爆炸）
## remerge_sort_lowered_memory_bytes_ratio {#remerge_sort_lowered_memory_bytes_ratio} 

<SettingsInfoBlock type="Float" default_value="2" />

如果重新合并后的内存使用量没有减少到此比例，重新合并将被禁用。
## remote_filesystem_read_method {#remote_filesystem_read_method} 

<SettingsInfoBlock type="String" default_value="threadpool" />

从远程文件系统读取数据的方法，可选：read, threadpool。
## remote_filesystem_read_prefetch {#remote_filesystem_read_prefetch} 

<SettingsInfoBlock type="Bool" default_value="1" />

在从远程文件系统读取数据时应使用预取。
## remote_fs_read_backoff_max_tries {#remote_fs_read_backoff_max_tries} 

<SettingsInfoBlock type="UInt64" default_value="5" />

最大尝试次数以获取带退避
## remote_fs_read_max_backoff_ms {#remote_fs_read_max_backoff_ms} 

<SettingsInfoBlock type="UInt64" default_value="10000" />

在尝试从远程磁盘读取数据时的最大等待时间
## remote_read_min_bytes_for_seek {#remote_read_min_bytes_for_seek} 

<SettingsInfoBlock type="UInt64" default_value="4194304" />

远程读取（url, s3）进行寻址所需的最小字节，而不是忽略读取。
## rename_files_after_processing {#rename_files_after_processing} 

- **类型:** 字符串

- **默认值:** 空字符串

此设置允许指定通过 `file` 表函数处理的文件的重命名模式。当选项设置后，所有通过 `file` 表函数读取的文件将在处理成功时根据指定的模式与占位符重命名。
### 占位符

- `%a` — 完整的原始文件名（例如，“sample.csv”）。
- `%f` — 无扩展名的原始文件名（例如，“sample”）。
- `%e` — 带点的原始文件扩展名（例如，“.csv”）。
- `%t` — 时间戳（以微秒为单位）。
- `%%` — 百分号（“%”）。
### 示例
- 选项: `--rename_files_after_processing="processed_%f_%t%e"`

- 查询: `SELECT * FROM file('sample.csv')`

如果成功读取 `sample.csv`，则文件将重命名为 `processed_sample_1683473210851438.csv`
## replace_running_query {#replace_running_query} 

<SettingsInfoBlock type="Bool" default_value="0" />

在使用 HTTP 接口时，可以传递 'query_id' 参数。此参数是作为查询标识符的任意字符串。
如果此时同一用户的查询中已经存在相同的 'query_id'，则行为取决于 'replace_running_query' 参数。

`0`（默认值）– 抛出异常（如查询已存在，阻止运行）。

`1` – 取消旧查询并开始运行新查询。

将此参数设置为 1 以实现分割条件建议。在输入下一个字符后，如果旧查询尚未完成，则应取消它。
## replace_running_query_max_wait_ms {#replace_running_query_max_wait_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="5000" />

在启用 [replace_running_query](#replace_running_query) 设置时，运行相同 `query_id` 的查询完成的等待时间。

可能的值：

- 正整数。
- 0 — 抛出异常，阻止运行新查询，如果服务器已经执行具有相同 `query_id` 的查询。
## replication_wait_for_inactive_replica_timeout {#replication_wait_for_inactive_replica_timeout} 

<SettingsInfoBlock type="Int64" default_value="120" />

指定等待非活动副本执行 [ALTER](../../sql-reference/statements/alter/index.md) 、[OPTIMIZE](../../sql-reference/statements/optimize.md) 或 [TRUNCATE](../../sql-reference/statements/truncate.md) 查询的最长时间（以秒为单位）。

可能的值：

- 0 — 不等待。
- 负整数 — 无限等待。
- 正整数 — 等待的秒数。
## restore_replace_external_dictionary_source_to_null {#restore_replace_external_dictionary_source_to_null} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "新设置。"}]}]}/>

在恢复时将外部字典源替换为 Null。对测试目的有用
## restore_replace_external_engines_to_null {#restore_replace_external_engines_to_null} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "新设置。"}]}]}/>

出于测试目的。替换所有外部引擎为 Null，以免发起外部连接。
## restore_replace_external_table_functions_to_null {#restore_replace_external_table_functions_to_null} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "新设置。"}]}]}/>

出于测试目的。替换所有外部表函数为 Null，以免发起外部连接。
## restore_replicated_merge_tree_to_shared_merge_tree {#restore_replicated_merge_tree_to_shared_merge_tree} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "0"},{"label": "新设置。"}]}]}/>

在 RESTORE 期间将表引擎从 Replicated*MergeTree 替换为 Shared*MergeTree。
## result_overflow_mode {#result_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

云默认值: `throw`

设置如果结果的数量超过某个限制应该如何处理。

可能的值：
- `throw`: 抛出异常（默认）。
- `break`: 停止执行查询并返回部分结果，如同源数据耗尽。

使用 'break' 类似于使用 LIMIT。`Break` 仅在块级别中中断执行。这意味着返回的行数大于
[`max_result_rows`](/operations/settings/settings#max_result_rows) 、[`max_block_size`](/operations/settings/settings#max_block_size) 的倍数，并且依赖于 [`max_threads`](/operations/settings/settings#max_threads)。

**示例**

```sql title="Query"
SET max_threads = 3, max_block_size = 3333;
SET max_result_rows = 3334, result_overflow_mode = 'break';

SELECT *
FROM numbers_mt(100000)
FORMAT Null;
```

```text title="Result"
6666 rows in set. ...
```
## rewrite_count_distinct_if_with_count_distinct_implementation {#rewrite_count_distinct_if_with_count_distinct_implementation} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.8"},{"label": "1"},{"label": "允许用 [count_distinct_implementation](#count_distinct_implementation) 设置重写 countDistinctIf"}]}]}/>

允许您将 `countDistinctIf` 重写为 [count_distinct_implementation](#count_distinct_implementation) 设置。

可能的值：

- true — 允许。
- false — 不允许。
## s3_allow_multipart_copy {#s3_allow_multipart_copy} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.2"},{"label": "1"},{"label": "新设置。"}]}]}/>

允许在 S3 中进行分段复制。
## s3_allow_parallel_part_upload {#s3_allow_parallel_part_upload} 

<SettingsInfoBlock type="Bool" default_value="1" />

使用多个线程进行 S3 分段上传。这可能导致稍高的内存使用量。
## s3_check_objects_after_upload {#s3_check_objects_after_upload} 

<SettingsInfoBlock type="Bool" default_value="0" />

在上传到 S3 后使用 head 请求检查每个上传的对象，以确保上传成功。
## s3_connect_timeout_ms {#s3_connect_timeout_ms} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1000"},{"label": "引入新的专用设置用于 S3 连接超时"}]}]}/>

连接来自 S3 磁盘的主机的超时。
## s3_create_new_file_on_insert {#s3_create_new_file_on_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

在 S3 表中启用或禁用每次插入创建新文件。如果启用，则每次插入将创建一个新的 S3 对象，其键类似于以下模式：

初始: `data.Parquet.gz` -> `data.1.Parquet.gz` -> `data.2.Parquet.gz` 等。

可能的值：
- 0 — `INSERT` 查询创建一个新文件，或者如果文件已存在则失败，并且未设置 s3_truncate_on_insert。
- 1 — `INSERT` 查询在每次插入时创建一个新文件，如果未设置 s3_truncate_on_insert，则使用后缀（从第二个开始）。

有关更多详细信息，请参见 [这里](/integrations/s3#inserting-data)。
## s3_disable_checksum {#s3_disable_checksum} 

<SettingsInfoBlock type="Bool" default_value="0" />

在将文件发送到 S3 时不计算校验和。这可以通过避免对文件进行过多处理来加快写入速度。由于 MergeTree 表的数据会由 ClickHouse 进行校验和处理，因此它通常是安全的，并且在通过 HTTPS 访问 S3 时，TLS 层已经在网络传输中提供了完整性。虽然额外的校验和在 S3 上提供了深度防御。
## s3_ignore_file_doesnt_exist {#s3_ignore_file_doesnt_exist} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "0"},{"label": "允许在 S3 表引擎中读取某些键时返回 0 行，而不是抛出异常。"}]}]}/>

在读取某些键时，如果文件不存在，则忽略文件缺失。

可能的值：
- 1 — `SELECT` 返回空结果。
- 0 — `SELECT` 抛出异常。
## s3_list_object_keys_size {#s3_list_object_keys_size} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

通过 ListObject 请求返回的最大文件数量。
## s3_max_connections {#s3_max_connections} 

<SettingsInfoBlock type="UInt64" default_value="1024" />

每个服务器的最大连接数。
## s3_max_get_burst {#s3_max_get_burst} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在达到请求每秒限制之前可以同时发出的最大请求数量。默认（0）等于 `s3_max_get_rps`
## s3_max_get_rps {#s3_max_get_rps} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在达到限制之前对 S3 GET 请求每秒速率的限制。零表示无限制。
## s3_max_inflight_parts_for_one_file {#s3_max_inflight_parts_for_one_file} 

<SettingsInfoBlock type="UInt64" default_value="20" />

在分段上传请求中同时加载的最大部分数。0 表示无限制。
## s3_max_part_number {#s3_max_part_number} 

<SettingsInfoBlock type="UInt64" default_value="10000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "10000"},{"label": "S3 上传部分的最大部分数"}]}]}/>

S3 上传部分的最大部分数。
## s3_max_put_burst {#s3_max_put_burst} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在达到请求每秒限制之前可以同时发出的最大请求数量。默认（0）等于 `s3_max_put_rps`
## s3_max_put_rps {#s3_max_put_rps} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在达到限制之前对 S3 PUT 请求每秒速率的限制。零表示无限制。
## s3_max_redirects {#s3_max_redirects} 

<SettingsInfoBlock type="UInt64" default_value="10" />

允许的最大 S3 重定向跳数。
## s3_max_single_operation_copy_size {#s3_max_single_operation_copy_size} 

<SettingsInfoBlock type="UInt64" default_value="33554432" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "33554432"},{"label": "S3 中单个复制操作的最大大小"}]}]}/>

S3 中单个操作复制的最大大小。此设置仅在 s3_allow_multipart_copy 为真时使用。
## s3_max_single_part_upload_size {#s3_max_single_part_upload_size} 

<SettingsInfoBlock type="UInt64" default_value="33554432" />

使用单部分上传到 S3 的对象的最大大小。
## s3_max_single_read_retries {#s3_max_single_read_retries} 

<SettingsInfoBlock type="UInt64" default_value="4" />

在单个 S3 读取期间的最大重试次数。
## s3_max_unexpected_write_error_retries {#s3_max_unexpected_write_error_retries} 

<SettingsInfoBlock type="UInt64" default_value="4" />

在 S3 写入过程中出现意外错误时的最大重试次数。
## s3_max_upload_part_size {#s3_max_upload_part_size} 

<SettingsInfoBlock type="UInt64" default_value="5368709120" />

在分段上传到 S3 时上传部分的最大大小。
## s3_min_upload_part_size {#s3_min_upload_part_size} 

<SettingsInfoBlock type="UInt64" default_value="16777216" />

在分段上传到 S3 时上传部分的最小大小。
## s3_request_timeout_ms {#s3_request_timeout_ms} 

<SettingsInfoBlock type="UInt64" default_value="30000" />

发送和接收数据到/从 S3 的空闲超时。如果单个 TCP 读取或写入调用阻塞这么长时间，则失败。
## s3_retry_attempts {#s3_retry_attempts} 

<SettingsInfoBlock type="UInt64" default_value="100" />

Aws::Client::RetryStrategy 的设置，Aws::Client 本身会进行重试，0 表示不重试。
## s3_skip_empty_files {#s3_skip_empty_files} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "我们希望能够提供更好的用户体验"}]}]}/>

启用或禁用在 [S3](../../engines/table-engines/integrations/s3.md) 引擎表中跳过空文件。

可能的值：
- 0 — 如果空文件与请求的格式不兼容，`SELECT` 抛出异常。
- 1 — `SELECT` 对于空文件返回空结果。
## s3_slow_all_threads_after_network_error {#s3_slow_all_threads_after_network_error} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新设置"}]}]}/>

设置为 `true` 时，那么对同一端点执行 S3 请求的所有线程将在出现可重试的网络错误后减慢一段时间。
设置为 `false` 时，则每个执行 S3 请求的线程在网络错误上使用独立的后退集合。
## s3_strict_upload_part_size {#s3_strict_upload_part_size} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在 S3 的分段上传过程中上传部分的确切大小（某些实现不支持可变大小的部分）。
## s3_throw_on_zero_files_match {#s3_throw_on_zero_files_match} 

<SettingsInfoBlock type="Bool" default_value="0" />

当 ListObjects 请求找不到任何文件时抛出错误。
## s3_truncate_on_insert {#s3_truncate_on_insert} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用 S3 引擎表插入之前的截断。如果禁用，如果 S3 对象已经存在，尝试插入将抛出异常。

可能的值：
- 0 — `INSERT` 查询创建一个新文件，或者如果文件存在则失败，并且未设置 s3_create_new_file_on_insert。
- 1 — `INSERT` 查询用新数据替换文件的现有内容。

有关更多详细信息，请参见 [这里](/integrations/s3#inserting-data)。
## s3_upload_part_size_multiply_factor {#s3_upload_part_size_multiply_factor} 

<SettingsInfoBlock type="UInt64" default_value="2" />

每次从单个写入上传到 S3 时，按此因子乘以 s3_min_upload_part_size。
## s3_upload_part_size_multiply_parts_count_threshold {#s3_upload_part_size_multiply_parts_count_threshold} 

<SettingsInfoBlock type="UInt64" default_value="500" />

每次上传到 S3 的部分数量超过此数字时，将 s3_min_upload_part_size 乘以 s3_upload_part_size_multiply_factor。 
## s3_use_adaptive_timeouts {#s3_use_adaptive_timeouts} 

<SettingsInfoBlock type="Bool" default_value="1" />

设置为 `true` 时，所有 S3 请求的前两次尝试都将使用较低的发送和接收超时。
设置为 `false` 时，所有尝试都将使用相同的超时。
## s3_validate_request_settings {#s3_validate_request_settings} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.6"},{"label": "1"},{"label": "允许禁用 S3 请求设置的验证"}]}]}/>

启用 S3 请求设置验证。

可能的值：
- 1 — 验证设置。
- 0 — 不验证设置。
## s3queue_default_zookeeper_path {#s3queue_default_zookeeper_path} 

<SettingsInfoBlock type="String" default_value="/clickhouse/s3queue/" />

S3Queue 引擎的默认 zookeeper 路径前缀。
## s3queue_enable_logging_to_s3queue_log {#s3queue_enable_logging_to_s3queue_log} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用写入 system.s3queue_log。该值可以通过表设置按表覆盖。
## s3queue_migrate_old_metadata_to_buckets {#s3queue_migrate_old_metadata_to_buckets} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新设置。"}]}]}/>

将 S3Queue 表的旧元数据结构迁移到新结构。
## schema_inference_cache_require_modification_time_for_url {#schema_inference_cache_require_modification_time_for_url} 

<SettingsInfoBlock type="Bool" default_value="1" />

对具有最后修改时间验证的 URL 使用缓存中的模式（对于带有 Last-Modified 头的 URL）。
## schema_inference_use_cache_for_azure {#schema_inference_use_cache_for_azure} 

<SettingsInfoBlock type="Bool" default_value="1" />

在使用 Azure 表函数时在模式推断中使用缓存。
## schema_inference_use_cache_for_file {#schema_inference_use_cache_for_file} 

<SettingsInfoBlock type="Bool" default_value="1" />

在使用文件表函数时在模式推断中使用缓存。
## schema_inference_use_cache_for_hdfs {#schema_inference_use_cache_for_hdfs} 

<SettingsInfoBlock type="Bool" default_value="1" />

在使用 HDFS 表函数时在模式推断中使用缓存。
## schema_inference_use_cache_for_s3 {#schema_inference_use_cache_for_s3} 

<SettingsInfoBlock type="Bool" default_value="1" />

在使用 S3 表函数时在模式推断中使用缓存。
## schema_inference_use_cache_for_url {#schema_inference_use_cache_for_url} 

<SettingsInfoBlock type="Bool" default_value="1" />

在使用 URL 表函数时在模式推断中使用缓存。
## secondary_indices_enable_bulk_filtering {#secondary_indices_enable_bulk_filtering} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "针对数据跳过索引的新过滤算法"}]}]}/>

启用索引的批量过滤算法。它预计会更好，但我们有此设置以兼容和控制。
## select_sequential_consistency {#select_sequential_consistency} 

<SettingsInfoBlock type="UInt64" default_value="0" />

:::note
此设置在 SharedMergeTree 和 ReplicatedMergeTree 之间的行为有所不同，详情请参见 [SharedMergeTree 一致性](/cloud/reference/shared-merge-tree#consistency)，了解 `select_sequential_consistency` 在 SharedMergeTree 中的行为。
:::

启用或禁用 `SELECT` 查询的顺序一致性。要求 `insert_quorum_parallel` 处于禁用状态（默认启用）。

可能的值：

- 0 — 禁用。
- 1 — 启用。

用法

当启用顺序一致性时，ClickHouse 允许客户端仅对那些包含所有先前 `INSERT` 查询所执行数据的副本执行 `SELECT` 查询。 如果客户端引用的是部分副本，ClickHouse 将生成异常。 SELECT 查询不会包含尚未写入副本法定人数的数据。

当 `insert_quorum_parallel` 启用时（默认），则 `select_sequential_consistency` 无效。 这是因为并行的 `INSERT` 查询可以写入不同的法定副本集合，因此无法保证单个副本接收到所有写入。

另请参见：

- [insert_quorum](#insert_quorum)
- [insert_quorum_timeout](#insert_quorum_timeout)
- [insert_quorum_parallel](#insert_quorum_parallel)
## send_logs_level {#send_logs_level} 

<SettingsInfoBlock type="LogsLevel" default_value="fatal" />

以指定的最低日志级别向客户端发送服务器文本日志。有效值：'trace'，'debug'，'information'，'warning'，'error'，'fatal'，'none'
## send_logs_source_regexp {#send_logs_source_regexp} 

发送与指定正则表达式匹配的日志源名称的服务器文本日志。空表示所有源。
## send_progress_in_http_headers {#send_progress_in_http_headers} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用 `clickhouse-server` 响应中的 `X-ClickHouse-Progress` HTTP 响应头。

有关更多信息，请阅读 [HTTP 接口描述](../../interfaces/http.md)。

可能的值：

- 0 — 禁用。
- 1 — 启用。
## send_timeout {#send_timeout} 

<SettingsInfoBlock type="Seconds" default_value="300" />

发送数据到网络的超时时间，以秒为单位。如果客户端在此时间内需要发送一些数据但无法发送任何字节，则会抛出异常。如果您在客户端上设置此设置，套接字的 'receive_timeout' 也将在服务器上的相应连接端设置。
## serialize_query_plan {#serialize_query_plan} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "0"},{"label": "新设置"}]}]}/>

序列化查询计划以进行分布式处理
## session_timezone {#session_timezone} 

<BetaBadge/>

设置当前会话或查询的隐式时区。
隐式时区是应用于未明确定义时区的 DateTime/DateTime64 类型值的时区。
该设置优先于全局配置的（服务器级别）隐式时区。
值为 '' （空字符串）表示当前会话或查询的隐式时区等于 [服务器时区](../server-configuration-parameters/settings.md/#timezone)。

您可以使用函数 `timeZone()` 和 `serverTimeZone()` 获取会话时区和服务器时区。

可能的值：

- 任何来自 `system.time_zones` 的时区名称，例如 `Europe/Berlin`、`UTC` 或 `Zulu`

示例：

```sql
SELECT timeZone(), serverTimeZone() FORMAT CSV

"Europe/Berlin","Europe/Berlin"
```

```sql
SELECT timeZone(), serverTimeZone() SETTINGS session_timezone = 'Asia/Novosibirsk' FORMAT CSV

"Asia/Novosibirsk","Europe/Berlin"
```

将会话时区 'America/Denver' 分配给内部未明确定义时区的 DateTime：

```sql
SELECT toDateTime64(toDateTime64('1999-12-12 23:23:23.123', 3), 3, 'Europe/Zurich') SETTINGS session_timezone = 'America/Denver' FORMAT TSV

1999-12-13 07:23:23.123
```

:::warning
并非所有解析 DateTime/DateTime64 的函数都遵守 `session_timezone`。这可能导致微妙的错误。
请参阅以下示例和解释。
:::

```sql
CREATE TABLE test_tz (`d` DateTime('UTC')) ENGINE = Memory AS SELECT toDateTime('2000-01-01 00:00:00', 'UTC');

SELECT *, timeZone() FROM test_tz WHERE d = toDateTime('2000-01-01 00:00:00') SETTINGS session_timezone = 'Asia/Novosibirsk'
0 rows in set.

SELECT *, timeZone() FROM test_tz WHERE d = '2000-01-01 00:00:00' SETTINGS session_timezone = 'Asia/Novosibirsk'
┌───────────────────d─┬─timeZone()───────┐
│ 2000-01-01 00:00:00 │ Asia/Novosibirsk │
└─────────────────────┴──────────────────┘
```

这发生是因为不同的解析管道：

- 第一个 `SELECT` 查询中未明确定义时区的 `toDateTime()` 考虑了 `session_timezone` 和全局时区的设置。
- 在第二个查询中，DateTime 是从字符串解析的，并继承了现有列 `d` 的类型和时区。因此，`session_timezone` 设置和全局时区不会被遵循。

**另请参见**

- [timezone](../server-configuration-parameters/settings.md/#timezone)
## set_overflow_mode {#set_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

设置当数据量超出某些限制时发生的情况。

可能的值：
- `throw`: 抛出异常（默认）。
- `break`: 停止执行查询并返回部分结果，仿佛源数据耗尽。
## shared_merge_tree_sync_parts_on_partition_operations {#shared_merge_tree_sync_parts_on_partition_operations} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1"},{"label": "新设置。默认情况下，部分始终同步"}]}]}/>

在 SMT 表中自动同步 MOVE|REPLACE|ATTACH 分区操作后的数据部分集。仅限云
## short_circuit_function_evaluation {#short_circuit_function_evaluation} 

<SettingsInfoBlock type="ShortCircuitFunctionEvaluation" default_value="enable" />

允许根据 [短路方案](https://en.wikipedia.org/wiki/Short-circuit_evaluation) 计算 [if](../../sql-reference/functions/conditional-functions.md/#if)、[multiIf](../../sql-reference/functions/conditional-functions.md/#multiif)、[and](/sql-reference/functions/logical-functions#and) 和 [or](/sql-reference/functions/logical-functions#or) 函数。这有助于优化这些函数中复杂表达式的执行，防止可能的异常（例如，意外时的零除）。

可能的值：

- `enable` — 为适合的函数启用短路函数求值（可能抛出异常或计算密集）。
- `force_enable` — 为所有函数启用短路函数求值。
- `disable` — 禁用短路函数求值。
## short_circuit_function_evaluation_for_nulls {#short_circuit_function_evaluation_for_nulls} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "允许仅在所有参数中非 NULL 值的行上执行具有 Nullable 参数的函数"}]}]}/>

优化当任何参数为 NULL 时返回 NULL 的函数的评估。当函数参数中 NULL 值的百分比超过 short_circuit_function_evaluation_for_nulls_threshold 时，系统跳过逐行评估函数。相反，它会立即为所有行返回 NULL，避免不必要的计算。
## short_circuit_function_evaluation_for_nulls_threshold {#short_circuit_function_evaluation_for_nulls_threshold} 

<SettingsInfoBlock type="Double" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "NULL 值比例阈值，仅在所有参数中非 NULL 值的行上执行具有 Nullable 参数的函数。仅在启用设置 short_circuit_function_evaluation_for_nulls 时适用。"}]}]}/>

NULL 值的比例阈值，以仅在所有参数中非 NULL 值的行上执行带有 Nullable 参数的函数。仅在启用设置 short_circuit_function_evaluation_for_nulls 时适用。
当包含 NULL 值的行比例超过此阈值时，这些包含 NULL 值的行将不被评估。
## show_table_uuid_in_table_create_query_if_not_nil {#show_table_uuid_in_table_create_query_if_not_nil} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "20.7"},{"label": "0"},{"label": "停止在 CREATE 查询中显示表的 UID，以 Engine=Atomic 为例"}]}]}/>

设置 `SHOW TABLE` 查询的显示。

可能的值：

- 0 — 查询将不显示表 UUID。
- 1 — 查询将显示表 UUID。
## single_join_prefer_left_table {#single_join_prefer_left_table} 

<SettingsInfoBlock type="Bool" default_value="1" />

对于单个 JOIN 情况，发生标识符歧义时优先选择左侧表
## skip_redundant_aliases_in_udf {#skip_redundant_aliases_in_udf} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "启用时，这允许您在同一表中多次使用相同的用户定义函数多个物化列。"}]}]}/>

在用户定义函数中不使用（替换）冗余别名，以简化其使用。

可能的值：

- 1 — 在 UDF 中跳过（替换）别名。
- 0 — 在 UDF 中不跳过（替换）别名。

**示例**

启用和禁用之间的区别：

查询：

```sql
SET skip_redundant_aliases_in_udf = 0;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

结果：

```text
SELECT ((4 + 2) + 1 AS y, y + 2)
```

查询：

```sql
SET skip_redundant_aliases_in_udf = 1;
CREATE FUNCTION IF NOT EXISTS test_03274 AS ( x ) -> ((x + 1 as y, y + 2));

EXPLAIN SYNTAX SELECT test_03274(4 + 2);
```

结果：

```text
SELECT ((4 + 2) + 1, ((4 + 2) + 1) + 2)
```
## skip_unavailable_shards {#skip_unavailable_shards} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用静默跳过不可用的分片。

如果所有副本都不可用，则分片被视为不可用。副本在以下情况下不可用：

- ClickHouse 无法以任何原因连接到副本。

    连接到副本时，ClickHouse 会进行多次尝试。如果所有这些尝试都失败，则该副本被视为不可用。

- 副本无法通过 DNS 解析。

    如果无法通过 DNS 解析副本的主机名，可能表明以下情况：

    - 副本的主机没有 DNS 记录。它可能发生在使用动态 DNS 的系统中，例如 [Kubernetes](https://kubernetes.io)，节点可能在停机期间无法解析，这并不是错误。

    - 配置错误。 ClickHouse 配置文件包含错误的主机名。

可能的值：

- 1 — 启用跳过。

    如果分片不可用，ClickHouse 将基于部分数据返回结果，并且不报告节点可用性问题。

- 0 — 禁用跳过。

    如果分片不可用，ClickHouse 将引发异常。
## sleep_after_receiving_query_ms {#sleep_after_receiving_query_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

接收查询后的休眠时间
## sleep_in_send_data_ms {#sleep_in_send_data_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

发送数据时的休眠时间
## sleep_in_send_tables_status_ms {#sleep_in_send_tables_status_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="0" />

在发送表状态响应时的休眠时间
## sort_overflow_mode {#sort_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

设置在排序之前接收的行数超过某些限制时发生的情况。

可能的值：
- `throw`: 抛出异常。
- `break`: 停止执行查询并返回部分结果。
## split_intersecting_parts_ranges_into_layers_final {#split_intersecting_parts_ranges_into_layers_final} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "在 FINAL 优化期间允许将相交的部分范围分割成多个层次"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "1"},{"label": "在 FINAL 优化期间允许将相交的部分范围分割成多个层次"}]}]}/>

在 FINAL 优化期间将相交的部分范围分割成层次
## split_parts_ranges_into_intersecting_and_non_intersecting_final {#split_parts_ranges_into_intersecting_and_non_intersecting_final} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.2"},{"label": "1"},{"label": "允许在 FINAL 优化期间将部分范围拆分为相交和非相交"}]}, {"id": "row-2","items": [{"label": "24.1"},{"label": "1"},{"label": "允许在 FINAL 优化期间将部分范围拆分为相交和非相交"}]}]}/>

在 FINAL 优化期间将部分范围拆分为相交和非相交
## splitby_max_substrings_includes_remaining_string {#splitby_max_substrings_includes_remaining_string} 

<SettingsInfoBlock type="Bool" default_value="0" />

控制函数 [splitBy*()](../../sql-reference/functions/splitting-merging-functions.md) 的行为，当参数 `max_substrings` > 0 时，是否在结果数组的最后一个元素中包括剩余字符串。

可能的值：

- `0` - 剩余字符串将不包含在结果数组的最后一个元素中。
- `1` - 剩余字符串将包含在结果数组的最后一个元素中。这是 Spark 的 [`split()`](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.split.html) 函数和 Python 的 ['string.split()'](https://docs.python.org/3/library/stdtypes.html#str.split) 方法的行为。
## stop_refreshable_materialized_views_on_startup {#stop_refreshable_materialized_views_on_startup} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

在服务器启动时，防止调度可刷新的物化视图，如同使用 SYSTEM STOP VIEWS。您可以手动启动它们，例如使用 `SYSTEM START VIEWS` 或 `SYSTEM START VIEW <name>`。新创建的视图也适用此设置。对非可刷新的物化视图没有影响。
## storage_file_read_method {#storage_file_read_method} 

<SettingsInfoBlock type="LocalFSReadMethod" default_value="pread" />

从存储文件中读取数据的方法，可以是：`read`，`pread`，`mmap`。mmap 方法不适用于 clickhouse-server （它旨在用于 clickhouse-local）。
## storage_system_stack_trace_pipe_read_timeout_ms {#storage_system_stack_trace_pipe_read_timeout_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="100" />

从管道读取以接收来自线程的信息的最大时间，查询 `system.stack_trace` 表时使用。此设置用于测试目的，并不打算由用户更改。
## stream_flush_interval_ms {#stream_flush_interval_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="7500" />

用于具有流式表的表的情况下，发生超时或当线程生成 [max_insert_block_size](#max_insert_block_size) 行时。

默认值是 7500。

值越小，数据刷入表的频率越高。将值设置得过低会导致性能下降。
## stream_like_engine_allow_direct_select {#stream_like_engine_allow_direct_select} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.12"},{"label": "0"},{"label": "默认情况下不允许直接选择 Kafka/RabbitMQ/FileLog"}]}]}/>

允许对 Kafka、RabbitMQ、FileLog、Redis Streams 和 NATS 引擎的直接 SELECT 查询。如果有附加的物化视图，则即使启用此设置也不允许 SELECT 查询。
## stream_like_engine_insert_queue {#stream_like_engine_insert_queue} 

当流式引擎从多个队列读取时，用户需要在写入时选择一个队列以插入。由 Redis Streams 和 NATS 使用。
## stream_poll_timeout_ms {#stream_poll_timeout_ms} 

<SettingsInfoBlock type="Milliseconds" default_value="500" />

从流存储中轮询数据的超时。
## system_events_show_zero_values {#system_events_show_zero_values} 

<SettingsInfoBlock type="Bool" default_value="0" />

允许从 [`system.events`](../../operations/system-tables/events.md) 中选择零值事件。

某些监控系统要求为每个检查点传递所有度量值，即使度量值为零。

可能的值：

- 0 — 禁用。
- 1 — 启用。

**示例**

查询

```sql
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

结果

```text
Ok.
```

查询
```sql
SET system_events_show_zero_values = 1;
SELECT * FROM system.events WHERE event='QueryMemoryLimitExceeded';
```

结果

```text
┌─event────────────────────┬─value─┬─description───────────────────────────────────────────┐
│ QueryMemoryLimitExceeded │     0 │ 超过查询的内存限制次数。                              │
└──────────────────────────┴───────┴───────────────────────────────────────────────────────┘
```
## table_function_remote_max_addresses {#table_function_remote_max_addresses} 

<SettingsInfoBlock type="UInt64" default_value="1000" />

设置从模式生成的 [remote](../../sql-reference/table-functions/remote.md) 函数的最大地址数。

可能的值：

- 正整数。
## tcp_keep_alive_timeout {#tcp_keep_alive_timeout} 

<SettingsInfoBlock type="Seconds" default_value="290" />

连接保持空闲的时间（以秒为单位），直到 TCP 开始发送保活探测包。
## temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds {#temporary_data_in_cache_reserve_space_wait_lock_timeout_milliseconds} 

<SettingsInfoBlock type="UInt64" default_value="600000" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.4"},{"label": "600000"},{"label": "等待锁定缓存以在文件系统缓存中为临时数据保留空间的时间"}]}]}/>

等待锁定缓存以在文件系统缓存中为临时数据保留空间的时间
## temporary_files_codec {#temporary_files_codec} 

<SettingsInfoBlock type="String" default_value="LZ4" />

设置用于在磁盘上进行排序和连接操作的临时文件的压缩编解码器。

可能的值：

- LZ4 — 应用 [LZ4](https://en.wikipedia.org/wiki/LZ4_(compression_algorithm)) 压缩。
- NONE — 不应用任何压缩。
## throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert {#throw_if_deduplication_in_dependent_materialized_views_enabled_with_async_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "1"},{"label": "依赖物化视图中的去重无法与异步插入同时工作"}]}]}/>

当设置 `deduplicate_blocks_in_dependent_materialized_views` 与 `async_insert` 一起启用时，在 INSERT 查询时抛出异常。它保证了正确性，因为这些功能无法一起工作。
## throw_if_no_data_to_insert {#throw_if_no_data_to_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

允许或禁止空 INSERT，默认启用（在空插入时抛出错误）。仅适用于使用 [`clickhouse-client`](/interfaces/cli) 或使用 [gRPC 接口](/interfaces/grpc) 的 INSERT。
## throw_on_error_from_cache_on_write_operations {#throw_on_error_from_cache_on_write_operations} 

<SettingsInfoBlock type="Bool" default_value="0" />

在写入操作中（INSERT、合并）在缓存时忽略缓存中的错误
## throw_on_max_partitions_per_insert_block {#throw_on_max_partitions_per_insert_block} 

<SettingsInfoBlock type="Bool" default_value="1" />

允许您控制当达到 `max_partitions_per_insert_block` 时的行为。

可能的值：
- `true`  - 当插入块达到 `max_partitions_per_insert_block` 时，抛出异常。
- `false` - 当达到 `max_partitions_per_insert_block` 时记录警告。

:::tip
如果您试图了解更改 [`max_partitions_per_insert_block`](/operations/settings/settings#max_partitions_per_insert_block) 对用户的影响，这可能会非常有用。
:::
## throw_on_unsupported_query_inside_transaction {#throw_on_unsupported_query_inside_transaction} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Bool" default_value="1" />

如果在事务内使用不支持的查询，则抛出异常。
## timeout_before_checking_execution_speed {#timeout_before_checking_execution_speed} 

<SettingsInfoBlock type="Seconds" default_value="10" />

检查执行速度是否过慢（不低于 `min_execution_speed`）的时间，以秒为单位。
## timeout_overflow_mode {#timeout_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

设置如果查询运行时间超过 `max_execution_time` 或估计的运行时间超过 `max_estimated_execution_time` 时的行为。

可能的值：
- `throw`: 抛出异常（默认）。
- `break`: 停止执行查询并返回部分结果，仿佛源数据耗尽。
## timeout_overflow_mode_leaf {#timeout_overflow_mode_leaf} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

设置当叶子节点中的查询运行时间超过 `max_execution_time_leaf` 时的行为。

可能的值：
- `throw`: 抛出异常（默认）。
- `break`: 停止执行查询并返回部分结果，仿佛源数据耗尽。
## totals_auto_threshold {#totals_auto_threshold} 

<SettingsInfoBlock type="Float" default_value="0.5" />

`totals_mode = 'auto'` 的阈值。
请参阅 "WITH TOTALS 修饰符" 部分。
## totals_mode {#totals_mode} 

<SettingsInfoBlock type="TotalsMode" default_value="after_having_exclusive" />

当 HAVING 存在时如何计算总计，以及当 max_rows_to_group_by 和 group_by_overflow_mode = 'any' 存在时。
请参阅 "WITH TOTALS 修饰符" 部分。
## trace_profile_events {#trace_profile_events} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用或禁用在每次更新配置事件时收集堆栈跟踪以及配置事件名称和增量值，并将其发送到 [trace_log](/operations/system-tables/trace_log)。

可能的值：

- 1 — 启用配置事件追踪。
- 0 — 禁用配置事件追踪。
## transfer_overflow_mode {#transfer_overflow_mode} 

<SettingsInfoBlock type="OverflowMode" default_value="throw" />

设置当数据量超过某些限制时发生的情况。

可能的值：
- `throw`: 抛出异常（默认）。
- `break`: 停止执行查询并返回部分结果，仿佛源数据耗尽。
## transform_null_in {#transform_null_in} 

<SettingsInfoBlock type="Bool" default_value="0" />

启用 [NULL](/sql-reference/syntax#null) 值对于 [IN](../../sql-reference/operators/in.md) 操作符的相等性。

默认情况下，`NULL` 值无法进行比较，因为 `NULL` 表示未定义值。因此，比较 `expr = NULL` 必须始终返回 `false`。通过此设置，`NULL = NULL` 在 `IN` 操作符中返回 `true`。

可能的值：

- 0 — `IN` 操作符中 `NULL` 值的比较返回 `false`。
- 1 — `IN` 操作符中 `NULL` 值的比较返回 `true`。

**示例**

考虑 `null_in` 表：

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
│    3 │     3 │
└──────┴───────┘
```

查询：

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 0;
```

结果：

```text
┌──idx─┬────i─┐
│    1 │    1 │
└──────┴──────┘
```

查询：

```sql
SELECT idx, i FROM null_in WHERE i IN (1, NULL) SETTINGS transform_null_in = 1;
```

结果：

```text
┌──idx─┬─────i─┐
│    1 │     1 │
│    2 │  NULL │
└──────┴───────┘
```

**另请参见**

- [IN 操作符中的 NULL 处理](/sql-reference/operators/in#null-processing)
## traverse_shadow_remote_data_paths {#traverse_shadow_remote_data_paths} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "在查询 system.remote_data_paths 时遍历影子目录。"}]}]}/>

在查询 system.remote_data_paths 时，遍历冻结数据（影子目录）以及实际表数据。
## union_default_mode {#union_default_mode} 

设置组合 `SELECT` 查询结果的模式。此设置仅在与 [UNION](../../sql-reference/statements/select/union.md) 共享时使用，而未明确指定 `UNION ALL` 或 `UNION DISTINCT`。

可能的值：

- `'DISTINCT'` — ClickHouse 输出通过组合查询结果删除的重复行。
- `'ALL'` — ClickHouse 输出通过组合查询结果包含的所有行，包括重复行。
- `''` — ClickHouse 在使用 `UNION` 时生成异常。

请参见 [UNION](../../sql-reference/statements/select/union.md) 中的示例。
## unknown_packet_in_send_data {#unknown_packet_in_send_data} 

<SettingsInfoBlock type="UInt64" default_value="0" />

在第 N 数据包中发送未知包而不是数据
## update_parallel_mode {#update_parallel_mode} 

<SettingsInfoBlock type="UpdateParallelMode" default_value="auto" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "auto"},{"label": "新设置"}]}]}/>

确定并发更新查询的行为。

可能的值：
- `sync` - 按顺序运行所有 `UPDATE` 查询。
- `auto` - 仅按顺序运行与在同一查询中更新的列和另一个查询中表达式使用的列之间存在依赖关系的 `UPDATE` 查询。
- `async` - 不同步更新查询。
## update_sequential_consistency {#update_sequential_consistency} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新设置"}]}]}/>

如果为真，部分集更新到最新版本，然后才执行更新。
## use_async_executor_for_materialized_views {#use_async_executor_for_materialized_views} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "0"},{"label": "新设置。"}]}]}/>

使用异步和潜在的多线程执行物化视图查询，可以加速在 INSERT 过程中处理视图，但也会消耗更多内存。
## use_cache_for_count_from_files {#use_cache_for_count_from_files} 

<SettingsInfoBlock type="Bool" default_value="1" />

启用在表函数 `file`/`s3`/`url`/`hdfs`/`azureBlobStorage` 中计数文件行的缓存。

默认启用。
## use_client_time_zone {#use_client_time_zone} 

<SettingsInfoBlock type="Bool" default_value="0" />

使用客户端时区来解释 DateTime 字符串值，而不是使用服务器时区。
## use_compact_format_in_distributed_parts_names {#use_compact_format_in_distributed_parts_names} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.1"},{"label": "1"},{"label": "默认情况下为异步 INSERT 使用紧凑格式"}]}]}/>

在将数据插入带有 `Distributed` 引擎的表时，为后台（`distributed_foreground_insert`） INSERT 使用紧凑格式存储块。

可能的值：

- 0 — 使用 `user[:password]@host:port#default_database` 目录格式。
- 1 — 使用 `[shard{shard_index}[_replica{replica_index}]]` 目录格式。

:::note
- 当 `use_compact_format_in_distributed_parts_names=0` 时，来自集群定义的更改不会应用于后台 INSERT。
- 当 `use_compact_format_in_distributed_parts_names=1` 时，更改集群定义中节点的顺序将更改 `shard_index`/`replica_index`，请注意。
:::
## use_concurrency_control {#use_concurrency_control} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.12"},{"label": "1"},{"label": "默认情况下启用并发控制"}]}]}/>

尊重服务器的并发控制（请参见 `concurrent_threads_soft_limit_num` 和 `concurrent_threads_soft_limit_ratio_to_cores` 全局服务器设置）。如果禁用，允许在服务器超负荷的情况下使用更多线程（不推荐在正常使用中，主要用于测试）。
## use_hedged_requests {#use_hedged_requests} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "21.9"},{"label": "1"},{"label": "默认启用Hedged Requests功能"}]}]}/>

启用远程查询的hedged requests逻辑。它允许为查询建立与不同副本的多个连接。 
当在 `hedged_connection_timeout` 时间内未与副本建立现有连接，或在 `receive_data_timeout` 内未接收到数据时，启用新连接。查询使用发送非空进度包（或数据包，如果 `allow_changing_replica_until_first_data_packet`）；其他连接被取消。支持 `max_parallel_replicas > 1` 的查询。

默认启用。

在Cloud上默认禁用。

## use_hive_partitioning {#use_hive_partitioning} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "1"},{"label": "默认启用该设置。"}]} ,{"id": "row-2","items": [{"label": "24.8"},{"label": "0"},{"label": "允许为File、URL、S3、AzureBlobStorage和HDFS引擎使用hive分区。"}]}]}/>

启用时，ClickHouse将检测文件类表引擎中的Hive风格分区路径（`/name=value/`）[File](/sql-reference/table-functions/file#hive-style-partitioning) /[S3](/sql-reference/table-functions/s3#hive-style-partitioning) /[URL](/sql-reference/table-functions/url#hive-style-partitioning) /[HDFS](/sql-reference/table-functions/hdfs#hive-style-partitioning) /[AzureBlobStorage](/sql-reference/table-functions/azureBlobStorage#hive-style-partitioning)，并允许将分区列用作查询中的虚拟列。这些虚拟列将与分区路径中的名称相同，但以`_`开头。

## use_iceberg_metadata_files_cache {#use_iceberg_metadata_files_cache} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "新设置"}]}]}/>

如果启用，iceberg表函数和iceberg存储可能会利用iceberg元数据文件缓存。

可选值：

- 0 - 禁用
- 1 - 启用

## use_iceberg_partition_pruning {#use_iceberg_partition_pruning} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.6"},{"label": "1"},{"label": "默认启用Iceberg分区裁剪。"}]},{"id": "row-2","items": [{"label": "25.1"},{"label": "0"},{"label": "Iceberg分区裁剪的新设置。"}]}]}/>

为Iceberg表使用Iceberg分区裁剪。

## use_index_for_in_with_subqueries {#use_index_for_in_with_subqueries} 

<SettingsInfoBlock type="Bool" default_value="1" />

如果在IN运算符的右侧存在子查询或表表达式，则尝试使用索引。

## use_index_for_in_with_subqueries_max_values {#use_index_for_in_with_subqueries_max_values} 

<SettingsInfoBlock type="UInt64" default_value="0" />

IN运算符右侧集合的最大大小，以便使用表索引进行过滤。它允许避免因准备大型查询的附加数据结构而导致的性能下降和更高的内存使用。零表示没有限制。

## use_json_alias_for_old_object_type {#use_json_alias_for_old_object_type} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.8"},{"label": "0"},{"label": "使用JSON类型别名创建旧的[Object('json')](../../sql-reference/data-types/json.md)类型"}]}]}/>

启用时，`JSON`数据类型别名将用于创建旧的[Object('json')](../../sql-reference/data-types/json.md)类型，而不是新的[JSON](../../sql-reference/data-types/newjson.md)类型。

## use_legacy_to_time {#use_legacy_to_time} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "新设置。允许用户使用旧的toTime函数逻辑，其工作方式与toTimeWithFixedDate相同。"}]}]}/>

启用时，允许使用传统的toTime函数，该函数将带时间的日期转换为某个固定日期，同时保留时间。
否则，将使用新的toTime函数，该函数将不同类型的数据转换为时间类型。
旧的遗留函数也可以无条件访问，即toTimeWithFixedDate。

## use_page_cache_for_disks_without_file_cache {#use_page_cache_for_disks_without_file_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.3"},{"label": "0"},{"label": "添加用户空间页面缓存"}]}]}/>

对于未启用文件系统缓存的远程磁盘使用用户空间页面缓存。

## use_page_cache_with_distributed_cache {#use_page_cache_with_distributed_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.3"},{"label": "0"},{"label": "新设置"}]}]}/>

在使用分布式缓存时使用用户空间页面缓存。

## use_query_cache {#use_query_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

如果启用，`SELECT`查询可能会利用[查询缓存](../query-cache.md)。参数[enable_reads_from_query_cache](#enable_reads_from_query_cache)和[enable_writes_to_query_cache](#enable_writes_to_query_cache)更详细地控制缓存的使用。

可选值：

- 0 - 禁用
- 1 - 启用

## use_query_condition_cache {#use_query_condition_cache} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.4"},{"label": "1"},{"label": "一种新的优化"}]},{"id": "row-2","items": [{"label": "25.3"},{"label": "0"},{"label": "新设置。"}]}]}/>

启用[查询条件缓存](/operations/query-condition-cache)，该缓存存储在数据部分中不满足`WHERE`子句条件的粒度范围，并将此信息重复利用作为后续查询的短暂索引。

可选值：

- 0 - 禁用
- 1 - 启用

## use_skip_indexes {#use_skip_indexes} 

<SettingsInfoBlock type="Bool" default_value="1" />

在查询执行期间使用数据跳过索引。

可选值：

- 0 — 禁用。
- 1 — 启用。

## use_skip_indexes_if_final {#use_skip_indexes_if_final} 

<SettingsInfoBlock type="Bool" default_value="0" />

控制在执行带有FINAL修饰符的查询时，是否使用跳过索引。

默认情况下，该设置禁用，因为跳过索引可能会排除包含最新数据的行（粒度），这可能导致结果不正确。启用后，跳过索引甚至在FINAL修饰符下也会应用，这可能会提高性能，但有导致漏掉近期更新的风险。

可选值：

- 0 — 禁用。
- 1 — 启用。

## use_skip_indexes_if_final_exact_mode {#use_skip_indexes_if_final_exact_mode} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "0"},{"label": "引入此设置以帮助FINAL查询在使用跳过索引时返回正确结果"}]}]}/>

控制在执行带有FINAL修饰符的查询时，跳过索引返回的粒度是否在较新部分中扩展，以返回正确的结果。

使用跳过索引可能会排除包含最新数据的行（粒度），这可能导致结果不正确。此设置可以确保通过扫描与跳过索引返回的范围重叠的新部分来返回正确结果。

可选值：

- 0 — 禁用。
- 1 — 启用。

## use_structure_from_insertion_table_in_table_functions {#use_structure_from_insertion_table_in_table_functions} 

<SettingsInfoBlock type="UInt64" default_value="2" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "22.11"},{"label": "2"},{"label": "改善在表函数中使用插入表的结构"}]}]}/>

使用插入表的结构，而不是从数据推断模式。可选值：0 - 禁用，1 - 启用，2 - 自动。

## use_uncompressed_cache {#use_uncompressed_cache} 

<SettingsInfoBlock type="Bool" default_value="0" />

是否使用未压缩块的缓存。接受0或1。默认情况下，0（禁用）。
使用未压缩缓存（仅适用于MergeTree系列的表）可以显著减少延迟并提高处理大量短查询时的吞吐量。为频繁发送短请求的用户启用此设置。还注意[uncompressed_cache_size](/operations/server-configuration-parameters/settings#uncompressed_cache_size)配置参数（仅在配置文件中设置）- 未压缩缓存块的大小。默认情况下，大小为8 GiB。未压缩缓存根据需要填充，未使用的数据会被自动删除。

对于读取至少一定数量数据量（100万行或更多）的查询，未压缩缓存将自动禁用，以为确实较小的查询留出空间。这意味着您可以将'use_uncompressed_cache'设置始终设为1。

## use_variant_as_common_type {#use_variant_as_common_type} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.1"},{"label": "0"},{"label": "允许在没有公共类型的情况下使用Variant作为if/multiIf的结果类型"}]}]}/>

允许在没有公共类型的情况下，使用`Variant`类型作为[if](../../sql-reference/functions/conditional-functions.md/#if)/[multiIf](../../sql-reference/functions/conditional-functions.md/#multiif)/[array](../../sql-reference/functions/array-functions.md)/[map](../../sql-reference/functions/tuple-map-functions.md)函数的结果类型。

示例：

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(if(number % 2, number, range(number))) as variant_type FROM numbers(1);
SELECT if(number % 2, number, range(number)) as variant FROM numbers(5);
```

```text
┌─variant_type───────────────────┐
│ Variant(Array(UInt64), UInt64) │
└────────────────────────────────┘
┌─variant───┐
│ []        │
│ 1         │
│ [0,1]     │
│ 3         │
│ [0,1,2,3] │
└───────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL)) AS variant_type FROM numbers(1);
SELECT multiIf((number % 4) = 0, 42, (number % 4) = 1, [1, 2, 3], (number % 4) = 2, 'Hello, World!', NULL) AS variant FROM numbers(4);
```

```text
─variant_type─────────────────────────┐
│ Variant(Array(UInt8), String, UInt8) │
└──────────────────────────────────────┘

┌─variant───────┐
│ 42            │
│ [1,2,3]       │
│ Hello, World! │
│ ᴺᵁᴸᴸ          │
└───────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(array(range(number), number, 'str_' || toString(number))) as array_of_variants_type from numbers(1);
SELECT array(range(number), number, 'str_' || toString(number)) as array_of_variants FROM numbers(3);
```

```text
┌─array_of_variants_type────────────────────────┐
│ Array(Variant(Array(UInt64), String, UInt64)) │
└───────────────────────────────────────────────┘

┌─array_of_variants─┐
│ [[],0,'str_0']    │
│ [[0],1,'str_1']   │
│ [[0,1],2,'str_2'] │
└───────────────────┘
```

```sql
SET use_variant_as_common_type = 1;
SELECT toTypeName(map('a', range(number), 'b', number, 'c', 'str_' || toString(number))) as map_of_variants_type from numbers(1);
SELECT map('a', range(number), 'b', number, 'c', 'str_' || toString(number)) as map_of_variants FROM numbers(3);
```

```text
┌─map_of_variants_type────────────────────────────────┐
│ Map(String, Variant(Array(UInt64), String, UInt64)) │
└─────────────────────────────────────────────────────┘

┌─map_of_variants───────────────┐
│ {'a':[],'b':0,'c':'str_0'}    │
│ {'a':[0],'b':1,'c':'str_1'}   │
│ {'a':[0,1],'b':2,'c':'str_2'} │
└───────────────────────────────┘
```

## use_with_fill_by_sorting_prefix {#use_with_fill_by_sorting_prefix} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "23.5"},{"label": "1"},{"label": "ORDER BY子句中WITH FILL列之前的列形成排序前缀。排序前缀中值不同的行被独立填充"}]}]}/>

ORDER BY子句中WITH FILL列之前的列形成排序前缀。排序前缀中值不同的行被独立填充。

## validate_enum_literals_in_operators {#validate_enum_literals_in_operators} 

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.1"},{"label": "0"},{"label": "新设置"}]}]}/>

如果启用，将验证在`IN`、`NOT IN`、`==`、`!=`等运算符中的枚举字面量是否与枚举类型匹配，如果字面量不是有效的枚举值，则抛出异常。

## validate_mutation_query {#validate_mutation_query} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.11"},{"label": "1"},{"label": "默认情况下验证变更查询的新设置。"}]}]}/>

在接受变更查询之前进行验证。变更在后台执行，运行无效查询将导致变更进入卡顿状态，需要手动干预。

仅在遇到向后不兼容的错误时更改此设置。

## validate_polygons {#validate_polygons} 

<SettingsInfoBlock type="Bool" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "20.4"},{"label": "1"},{"label": "如果多边形在pointInPolygon函数中无效，默认抛出异常，而不是返回可能错误的结果"}]}]}/>

启用或禁用在[pointInPolygon](/sql-reference/functions/geo/coordinates#pointinpolygon)函数中，若多边形自交或自切，则抛出异常。

可选值：

- 0 — 禁用抛出异常。`pointInPolygon`接受无效多边形并返回可能不正确的结果。
- 1 — 启用抛出异常。

## vector_search_filter_strategy {#vector_search_filter_strategy} 

<BetaBadge/>

<SettingsInfoBlock type="VectorSearchFilterStrategy" default_value="auto" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "auto"},{"label": "新设置"}]}]}/>

如果向量搜索查询有WHERE子句，则此设置决定是先评估（预过滤）还是首先检查向量相似度索引（后过滤）。可选值：
- 'auto' - 后过滤（确切语义可能会在将来更改）。
- 'postfilter' - 使用向量相似度索引识别最近邻，然后应用其他过滤器。
- 'prefilter' - 先评估其他过滤器，然后执行暴力搜索以识别邻居。

## vector_search_postfilter_multiplier {#vector_search_postfilter_multiplier} 

<BetaBadge/>

<SettingsInfoBlock type="Float" default_value="1" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "25.5"},{"label": "1"},{"label": "新设置"}]}]}/>

在对其他谓词进行后过滤之前，将从向量相似度索引获取的最近邻乘以此数字。

## wait_changes_become_visible_after_commit_mode {#wait_changes_become_visible_after_commit_mode} 

<ExperimentalBadge/>

<SettingsInfoBlock type="TransactionsWaitCSNMode" default_value="wait_unknown" />

等待已提交的更改在最新快照中实际变为可见。

## wait_for_async_insert {#wait_for_async_insert} 

<SettingsInfoBlock type="Bool" default_value="1" />

如果为真，则等待异步插入的处理。

## wait_for_async_insert_timeout {#wait_for_async_insert_timeout} 

<SettingsInfoBlock type="Seconds" default_value="120" />

等待处理异步插入的超时时间。

## wait_for_window_view_fire_signal_timeout {#wait_for_window_view_fire_signal_timeout} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Seconds" default_value="10" />

在事件时间处理期间，等待窗口视图触发信号的超时时间。

## window_view_clean_interval {#window_view_clean_interval} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Seconds" default_value="60" />

窗口视图中，释放过时数据的清理间隔（以秒为单位）。

## window_view_heartbeat_interval {#window_view_heartbeat_interval} 

<ExperimentalBadge/>

<SettingsInfoBlock type="Seconds" default_value="15" />

指示观察查询处于活动状态的心跳间隔（以秒为单位）。

## workload {#workload} 

<SettingsInfoBlock type="String" default_value="default" />

用于访问资源的工作负载名称。

## write_through_distributed_cache {#write_through_distributed_cache} 

<CloudAvailableBadge/>

<SettingsInfoBlock type="Bool" default_value="0" />

<VersionHistory rows={[{"id": "row-1","items": [{"label": "24.10"},{"label": "0"},{"label": "用于ClickHouse Cloud的设置"}]}]}/>

仅在ClickHouse Cloud中有效。允许写入分布式缓存（写入s3将通过分布式缓存完成）。

## zstd_window_log_max {#zstd_window_log_max} 

<SettingsInfoBlock type="Int64" default_value="0" />

允许选择ZSTD的最大窗口日志（它不会用于MergeTree系列）。
