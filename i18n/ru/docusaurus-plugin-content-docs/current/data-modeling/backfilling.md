---
slug: /data-modeling/backfilling
title: 'Заполнение данных'
description: 'Как использовать заполнение больших наборов данных в ClickHouse'
keywords: ['материализованные представления', 'заполнение', 'вставка данных', 'устойчивая загрузка данных']
---

import nullTableMV from '@site/static/images/data-modeling/null_table_mv.png';
import Image from '@theme/IdealImage';

# Заполнение данных

Независимо от того, новичок ли вы в ClickHouse или отвечаете за существующее развертывание, пользователям неизбежно потребуется заполнить таблицы историческими данными. В некоторых случаях это относительно просто, но может стать более сложным, когда необходимо заполнить материализованные представления. Этот гид документирует некоторые процессы для этой задачи, которые пользователи могут применить к своему случаю использования.

:::note
Этот гид предполагает, что пользователи уже знакомы с концепцией [Инкрементных материализованных представлений](/materialized-view/incremental-materialized-view) и [загрузкой данных с использованием табличных функций, таких как s3 и gcs](/integrations/s3). Мы также рекомендуем пользователям прочитать наш гид по [оптимизации производительности вставки из объектного хранилища](/integrations/s3/performance), советы из которого можно применить к вставкам на протяжении всего этого гида.
:::
## Пример набора данных {#example-dataset}

На протяжении этого гида мы используем набор данных PyPI. Каждая строка в этом наборе представляет загрузку Python пакета с помощью инструмента, такого как `pip`.

Например, подмножество охватывает один день - `2024-12-17` и доступно публично по адресу `https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/`. Пользователи могут выполнять запросы с:

```sql
SELECT count()
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/*.parquet')

┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

1 row in set. Elapsed: 32.726 sec. Processed 2.04 миллиарда строк, 170.05 KB (62.34 миллиона строк/с., 5.20 KB/с.)
Пиковое использование памяти: 239.50 MiB.
```

Полный набор данных для этого облака содержит более 320 ГБ файлов parquet. В приведенных ниже примерах мы намеренно ориентируемся на подмножества, используя шаблоны glob.

Мы предполагаем, что пользователь потребляет поток этих данных, например, из Kafka или объектного хранилища, для данных после этой даты. Схема для этих данных показана ниже:

```sql
DESCRIBE TABLE s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/*.parquet')
FORMAT PrettyCompactNoEscapesMonoBlock
SETTINGS describe_compact_output = 1

┌─name───────────────┬─type────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│ timestamp │ Nullable(DateTime64(6))                                                                                                                 │
│ country_code       │ Nullable(String)                                                                                                                        │
│ url │ Nullable(String)                                                                                                                        │
│ project            │ Nullable(String)                                                                                                                        │
│ file │ Tuple(filename Nullable(String), project Nullable(String), version Nullable(String), type Nullable(String))                             │
│ installer          │ Tuple(name Nullable(String), version Nullable(String))                                                                                  │
│ python             │ Nullable(String)                                                                                                                        │
│ implementation     │ Tuple(name Nullable(String), version Nullable(String))                                                                                  │
│ distro             │ Tuple(name Nullable(String), version Nullable(String), id Nullable(String), libc Tuple(lib Nullable(String), version Nullable(String))) │
│ system │ Tuple(name Nullable(String), release Nullable(String))                                                                                  │
│ cpu                │ Nullable(String)                                                                                                                        │
│ openssl_version    │ Nullable(String)                                                                                                                        │
│ setuptools_version │ Nullable(String)                                                                                                                        │
│ rustc_version      │ Nullable(String)                                                                                                                        │
│ tls_protocol       │ Nullable(String)                                                                                                                        │
│ tls_cipher         │ Nullable(String)                                                                                                                        │
└────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
```

:::note
Полный набор данных PyPI, состоящий более чем из 1 триллиона строк, доступен в нашей публичной демо-среде [clickpy.clickhouse.com](https://clickpy.clickhouse.com). Для получения дополнительной информации об этом наборе данных, включая то, как демон использует материализованные представления для повышения производительности и как данные заполняются ежедневно, смотрите [здесь](https://github.com/ClickHouse/clickpy).
:::
## Сценарии заполнения {#backfilling-scenarios}

Заполнение данных обычно необходимо, когда поток данных потребляется с определенного момента времени. Эти данные вставляются в таблицы ClickHouse с [инкрементными материализованными представлениями](/materialized-view/incremental-materialized-view), которые срабатывают на блоках по мере их вставки. Эти представления могут преобразовывать данные перед вставкой или вычислять агрегаты и отправлять результаты в целевые таблицы для последующего использования в downstream-приложениях.

Мы попытаемся рассмотреть следующие сценарии:

1. **Заполнение данных при существующем приеме данных** - Загружаются новые данные, и исторические данные необходимо заполнить. Эти исторические данные были идентифицированы.
2. **Добавление материализованных представлений к существующим таблицам** - Новые материализованные представления нужно добавить в настройку, для которой уже были заполнены исторические данные, и данные уже транслируются.

Мы предполагаем, что данные будут заполняться из объектного хранилища. В любом случае, мы стремимся избегать пауз в вставке данных.

Мы рекомендуем заполнять исторические данные из объектного хранилища. Данные следует экспортировать в Parquet, где это возможно, для оптимальной производительности чтения и сжатия (уменьшенный сетевой трафик). Размер файла около 150MB обычно предпочтителен, но ClickHouse поддерживает более [70 форматов файлов](/interfaces/formats) и способен обрабатывать файлы любых размеров.
## Использование дублирующих таблиц и представлений {#using-duplicate-tables-and-views}

Для всех вышеназванных сценариев мы полагаемся на концепцию "дублирующих таблиц и представлений". Эти таблицы и представления представляют собой копии тех, которые использовались для потоковых данных, и позволяют выполнять заполнение изолированно с легким средством восстановления в случае возникновения сбоя. Например, у нас есть следующая основная таблица `pypi` и материализованное представление, которое вычисляет количество загрузок на проект Python:

```sql
CREATE TABLE pypi
(
    `timestamp` DateTime,
    `country_code` LowCardinality(String),
    `project` String,
    `type` LowCardinality(String),
    `installer` LowCardinality(String),
    `python_minor` LowCardinality(String),
    `system` LowCardinality(String),
    `on` String
)
ENGINE = MergeTree
ORDER BY (project, timestamp)

CREATE TABLE pypi_downloads
(
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY project

CREATE MATERIALIZED VIEW pypi_downloads_mv TO pypi_downloads
AS SELECT
 project,
    count() AS count
FROM pypi
GROUP BY project
```

Мы наполняем основную таблицу и связанное представление подмножеством данных:

```sql
INSERT INTO pypi SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{000..100}.parquet')

0 rows in set. Elapsed: 15.702 sec. Processed 41.23 миллиона строк, 3.94 GB (2.63 миллиона строк/с., 251.01 MB/с.)
Пиковое использование памяти: 977.49 MiB.

SELECT count() FROM pypi

┌──count()─┐
│ 20612750 │ -- 20.61 миллиона
└──────────┘

1 row in set. Elapsed: 0.004 sec.

SELECT sum(count)
FROM pypi_downloads


┌─sum(count)─┐
│   20612750 │ -- 20.61 миллиона
└────────────┘

1 row in set. Elapsed: 0.006 sec. Processed 96.15 тысяч строк, 769.23 KB (16.53 миллиона строк/с., 132.26 MB/с.)
Пиковое использование памяти: 682.38 KiB.
```

Предположим, мы хотим загрузить другое подмножество `{101..200}`. Хотя мы могли бы вставить непосредственно в `pypi`, мы можем сделать это заполнение изолированно, создав дублирующие таблицы.

Если заполнение не удалось, мы не затронули наши основные таблицы и можем просто [обрезать](/managing-data/truncate) наши дублирующие таблицы и повторить.

Чтобы создать новые копии этих представлений, мы можем использовать оператор `CREATE TABLE AS` с суффиксом `_v2`:

```sql
CREATE TABLE pypi_v2 AS pypi

CREATE TABLE pypi_downloads_v2 AS pypi_downloads

CREATE MATERIALIZED VIEW pypi_downloads_mv_v2 TO pypi_downloads_v2
AS SELECT
 project,
    count() AS count
FROM pypi_v2
GROUP BY project
```

Мы заполняем это нашим 2-м подмножеством примерно того же размера и подтверждаем успешную загрузку.

```sql
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{101..200}.parquet')

0 rows in set. Elapsed: 17.545 sec. Processed 40.80 миллионов строк, 3.90 GB (2.33 миллиона строк/с., 222.29 MB/с.)
Пиковое использование памяти: 991.50 MiB.

SELECT count()
FROM pypi_v2

┌──count()─┐
│ 20400020 │ -- 20.40 миллиона
└──────────┘

1 row in set. Elapsed: 0.004 sec.

SELECT sum(count)
FROM pypi_downloads_v2

┌─sum(count)─┐
│   20400020 │ -- 20.40 миллиона
└────────────┘

1 row in set. Elapsed: 0.006 sec. Processed 95.49 тысяч строк, 763.90 KB (14.81 миллиона строк/с., 118.45 MB/с.)
Пиковое использование памяти: 688.77 KiB.
```

Если на любом этапе этого второго задания возникла ошибка, мы могли бы просто [обрезать](/managing-data/truncate) наши `pypi_v2` и `pypi_downloads_v2` и повторить загрузку данных.

После завершения загрузки данных мы можем переместить данные из наших дублирующих таблиц в основные таблицы, используя оператор [`ALTER TABLE MOVE PARTITION`](/sql-reference/statements/alter/partition#move-partition-to-table).

```sql
ALTER TABLE pypi_v2 MOVE PARTITION () TO pypi

0 rows in set. Elapsed: 1.401 sec.

ALTER TABLE pypi_downloads_v2 MOVE PARTITION () TO pypi_downloads

0 rows in set. Elapsed: 0.389 sec.
```

:::note Названия партиций
Вызов `MOVE PARTITION` выше использует название партиции `()`. Это представляет единственную партию для этой таблицы (которая не имеет партиционирования). Для таблиц, которые партиционированы, пользователям нужно будет вызывать несколько `MOVE PARTITION` - по одному для каждой партиции. Названия текущих партиций можно установить из таблицы [`system.parts`](/operations/system-tables/parts), например: `SELECT DISTINCT partition FROM system.parts WHERE (table = 'pypi_v2')`.
:::

Теперь мы можем подтвердить, что `pypi` и `pypi_downloads` содержат полные данные. `pypi_downloads_v2` и `pypi_v2` можно безопасно удалить.

```sql
SELECT count()
FROM pypi

┌──count()─┐
│ 41012770 │ -- 41.01 миллиона
└──────────┘

1 row in set. Elapsed: 0.003 sec.

SELECT sum(count)
FROM pypi_downloads

┌─sum(count)─┐
│   41012770 │ -- 41.01 миллиона
└────────────┘

1 row in set. Elapsed: 0.007 sec. Processed 191.64 тысячи строк, 1.53 MB (27.34 миллиона строк/с., 218.74 MB/с.)

SELECT count()
FROM pypi_v2
```

Важно отметить, что операция `MOVE PARTITION` является как легковесной (используя жесткие ссылки), так и атомарной, т.е. она либо завершается успешно, либо заканчивается с ошибкой без промежуточного состояния.

Мы сильно используем этот процесс в наших сценариях заполнения ниже.

Заметьте, что этот процесс требует от пользователей выбирать размер каждой операции вставки.

Более крупные вставки, т.е. больше строк, будут означать, что потребуется меньше операций `MOVE PARTITION`. Однако это должно быть сбалансировано с учетом затрат в случае сбоя вставки, например, из-за прерывания сети, чтобы восстановить. Пользователи могут дополнить этот процесс пакетной загрузкой файлов, чтобы снизить риск. Это может быть выполнено как с помощью диапазонных запросов, например, `WHERE timestamp BETWEEN 2024-12-17 09:00:00 AND 2024-12-17 10:00:00`, или с помощью шаблонов glob. Например,

```sql
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{101..200}.parquet')
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{201..300}.parquet')
INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-000000000{301..400}.parquet')
--продолжать до загрузки всех файлов ИЛИ выполнение вызова MOVE PARTITION
```

:::note
ClickPipes использует этот подход при загрузке данных из объектного хранения, автоматически создавая дубликаты целевой таблицы и ее материализованных представлений, избегая необходимости пользователю выполнять указанные выше шаги. Используя несколько рабочих потоков, каждый из которых обрабатывает разные подмножества (через шаблоны glob) и имеет свои дублирующие таблицы, данные могут быть быстро загружены с семантикой exactly-once. Для заинтересованных пользователей дополнительную информацию можно найти [в этом блоге](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part3).
:::
## Сценарий 1: Заполнение данных при существующем приеме данных {#scenario-1-backfilling-data-with-existing-data-ingestion}

В этом сценарии мы предполагаем, что данные для заполнения не находятся в изолированном облаке и, следовательно, требуется фильтрация. Данные уже вставляются, и можно идентифицировать временную метку или монотонный столбец, с которого необходимо заполнить исторические данные.

Этот процесс включает следующие шаги:

1. Идентифицировать контрольную точку - либо временную метку, либо значение столбца, с которого необходимо восстановить исторические данные.
2. Создать дубликаты главной таблицы и целевых таблиц для материализованных представлений.
3. Создать копии любых материализованных представлений, указывающих на целевые таблицы, созданные на этапе (2).
4. Вставить данные в нашу дублирующую основную таблицу, созданную на этапе (2).
5. Переместить все партиции из дублирующих таблиц в их оригинальные версии. Удалить дублирующие таблицы.

Например, в наших данных PyPI мы можем идентифицировать минимальную временную метку и, таким образом, нашу "контрольную точку".

```sql
SELECT min(timestamp)
FROM pypi

┌──────min(timestamp)─┐
│ 2024-12-17 09:00:00 │
└─────────────────────┘

1 row in set. Elapsed: 0.163 sec. Processed 1.34 миллиарда строк, 5.37 GB (8.24 миллиарда строк/с., 32.96 GB/с.)
Пиковое использование памяти: 227.84 MiB.
```

Из вышеуказанного мы знаем, что нам нужно загрузить данные до `2024-12-17 09:00:00`. Используя наш ранее описанный процесс, мы создаем дублирующие таблицы и представления и загружаем подмножество, используя фильтр по временной метке.

```sql
CREATE TABLE pypi_v2 AS pypi

CREATE TABLE pypi_downloads_v2 AS pypi_downloads

CREATE MATERIALIZED VIEW pypi_downloads_mv_v2 TO pypi_downloads_v2
AS SELECT project, count() AS count
FROM pypi_v2
GROUP BY project

INSERT INTO pypi_v2 SELECT *
FROM s3('https://datasets-documentation.s3.eu-west-3.amazonaws.com/pypi/2024-12-17/1734393600-*.parquet')
WHERE timestamp < '2024-12-17 09:00:00'

0 rows in set. Elapsed: 500.152 sec. Processed 2.74 миллиарда строк, 364.40 GB (5.47 миллиона строк/с., 728.59 MB/с.)
```
:::note
Фильтрация по временным меткам в Parquet может быть очень эффективной. ClickHouse будет читать только столбец временной метки, чтобы определить полный диапазон данных для загрузки, минимизируя сетевой трафик. Индексы Parquet, такие как min-max, также могут быть использованы движком запросов ClickHouse.
:::

После завершения этой вставки мы можем переместить соответствующие партиции.

```sql
ALTER TABLE pypi_v2 MOVE PARTITION () TO pypi

ALTER TABLE pypi_downloads_v2 MOVE PARTITION () TO pypi_downloads
```

Если исторические данные находятся в изолированном облаке, фильтр по времени не требуется. Если временная или монотонная колонка недоступна, изолируйте свои исторические данные.

:::note Просто используйте ClickPipes в ClickHouse Cloud
Пользователи ClickHouse Cloud должны использовать ClickPipes для восстановления исторических резервных копий, если данные могут быть изолированы в своем собственном облаке (и фильтр не требуется). Кроме того, параллелизуя загрузку с помощью нескольких рабочих потоков, тем самым уменьшая время загрузки, ClickPipes автоматизирует указанный выше процесс - создавая дублирующие таблицы как для основной таблицы, так и для материализованных представлений.
:::
## Сценарий 2: Добавление материализованных представлений к существующим таблицам {#scenario-2-adding-materialized-views-to-existing-tables}

Не редкость, что новые материализованные представления нужно добавить в настройку, для которой было заполнено значительное количество данных, и данные вставляются. Временная метка или монотонный увеличивающийся столбец, который можно использовать для идентификации точки в потоке, полезны здесь и избегают пауз в загрузке данных. В приведенных ниже примерах мы предполагаем оба случая, предпочитая подходы, которые избегают пауз в загрузке.

:::note Избегайте POPULATE
Мы не рекомендуем использовать команду [`POPULATE`](/sql-reference/statements/create/view#materialized-view) для заполнения материализованных представлений для чего-либо, кроме небольших наборов данных, где загрузка приостановлена. Этот оператор может пропустить строки, вставленные в его исходную таблицу, с материализованным представлением, созданным после завершения хеширования на заполнение. Более того, это заполнение выполняется по всем данным и подвержено прерываниям или ограничениям памяти для больших наборов данных.
:::
### Временная метка или монотонно увеличивающийся столбец доступны {#timestamp-or-monotonically-increasing-column-available}

В этом случае мы рекомендуем, чтобы новое материализованное представление включало фильтр, который ограничивает строки теми, которые больше произвольных данных в будущем. Затем материализованное представление можно заполнить с этой даты, используя исторические данные из главной таблицы. Метод заполнения зависит от размера данных и сложности связанного запроса.

Наш самый простой подход включает следующие шаги:

1. Создать наше материализованное представление с фильтром, который рассматривает только строки, превышающие произвольное время в ближайшем будущем.
2. Запустить запрос `INSERT INTO SELECT`, который вставляет данные в целевую таблицу материализованного представления, считывая из исходной таблицы с агрегатным запросом представления.

Это можно дополнительно улучшить, чтобы нацелить подмножества данных на шаге (2) и/или использовать дублирующую целевую таблицу для материализованного представления (присоедините партиции к оригиналу после завершения вставки) для облегчения восстановления после сбоя.

Рассмотрим следующее материализованное представление, которое вычисляет самые популярные проекты по часам.

```sql
CREATE TABLE pypi_downloads_per_day
(
    `hour` DateTime,
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY (project, hour)


CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi
GROUP BY
    hour,
 project
```

Хотя мы можем добавить целевую таблицу, прежде чем добавлять материализованное представление, мы изменяем его `SELECT`-часть, чтобы включить фильтр, который рассматривает только строки, превышающие произвольное время в ближайшем будущем - в этом случае мы предполагаем, что `2024-12-17 09:00:00` является ближайшим временем в будущем.

```sql
CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project, count() AS count
FROM pypi WHERE timestamp >= '2024-12-17 09:00:00'
GROUP BY hour, project
```

После того как это представление добавлено, мы можем заполнить все данные для материализованного представления до этой даты.

Самый простой способ сделать это - просто выполнить запрос из материализованного представления по главной таблице с фильтром, который игнорирует недавно добавленные данные, вставляя результаты в целевую таблицу нашего представления через `INSERT INTO SELECT`. Например, для вышеуказанного представления:

```sql
INSERT INTO pypi_downloads_per_day SELECT
 toStartOfHour(timestamp) AS hour,
 project,
    count() AS count
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
GROUP BY
    hour,
 project

Ok.

0 rows in set. Elapsed: 2.830 sec. Processed 798.89 миллионов строк, 17.40 GB (282.28 миллиона строк/с., 6.15 GB/с.)
Пиковое использование памяти: 543.71 MiB.
```

:::note
В приведенном выше примере наша целевая таблица - это [SummingMergeTree](/engines/table-engines/mergetree-family/summingmergetree). В этом случае мы можем просто использовать наш оригинальный агрегатный запрос. Для более сложных случаев, которые используют [AggregatingMergeTree](/engines/table-engines/mergetree-family/aggregatingmergetree), пользователи будут использовать функции `-State` для агрегатов. Пример этого можно найти [здесь](/integrations/s3/performance#be-aware-of-merges).
:::

В нашем случае это относительно легкая агрегация, которая завершается за меньше чем за 3 секунды и использует менее 600 MiB памяти. Для более сложных или долгих агрегаций пользователи могут сделать этот процесс более устойчивым, используя ранее описанный подход с дублирующей таблицей, т.е. создать теневую целевую таблицу, например `pypi_downloads_per_day_v2`, вставить в нее данные и затем прикрепить ее результирующие партиции к `pypi_downloads_per_day`.

Часто запрос материализованного представления может быть более сложным (это не удивительно, иначе пользователи бы не использовали представления!) и требовать ресурсов. В редких случаях ресурсы для запроса превышают возможности сервера. Это подчеркивает одно из преимуществ материализованных представлений ClickHouse - они являются инкрементными и не обрабатывают весь набор данных за один раз!

В этом случае у пользователей есть несколько вариантов:

1. Измените свой запрос, чтобы заполнить диапазоны, например `WHERE timestamp BETWEEN 2024-12-17 08:00:00 AND 2024-12-17 09:00:00`, `WHERE timestamp BETWEEN 2024-12-17 07:00:00 AND 2024-12-17 08:00:00` и т.д.
2. Используйте [драйвер Null](/engines/table-engines/special/null) для заполнения материализованного представления. Это имитирует типичное инкрементальное заполнение материализованного представления, выполняя его запрос по блокам данных (настраиваемого размера).

(1) представляет собой самый простой подход и часто бывает достаточно. Мы не включаем примеры для краткости.

Мы рассмотрим (2) более подробно ниже.
#### Использование драйвера Null для заполнения материализованных представлений {#using-a-null-table-engine-for-filling-materialized-views}

[Драйвер Null](/engines/table-engines/special/null) предоставляет движок хранения, который не сохраняет данные (рассматривайте его как `/dev/null` мира движков таблиц). Хотя это кажется противоречивым, материализованные представления все равно будут выполняться на данных, вставленных в этот движок таблиц. Это позволяет построить материализованные представления без сохранения оригинальных данных - избегая ввода-вывода и связанных расходов на хранение.

Важно отметить, что любые материализованные представления, прикрепленные к движку таблицы, все равно выполняются по блокам данных по мере вставки - отправляя свои результаты в целевую таблицу. Эти блоки имеют настраиваемый размер. Хотя более крупные блоки могут быть более эффективными (и быстрее обрабатываться), они потребляют больше ресурсов (в основном памяти). Использование этого движка таблицы позволяет нам постепенно строить наше материализованное представление, т.е. по одному блоку за раз, избегая необходимости держать всю агрегацию в памяти.

<Image img={nullTableMV} size="md" alt="Денормализация в ClickHouse"/>

<br />

Рассмотрим следующий пример:

```sql
CREATE TABLE pypi_v2
(
    `timestamp` DateTime,
    `project` String
)
ENGINE = Null

CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv_v2 TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi_v2
GROUP BY
    hour,
 project
```

Здесь мы создаем таблицу Null, `pypi_v2`, чтобы получить строки, которые будут использоваться для построения нашего материализованного представления. Обратите внимание, как мы ограничиваем схему только необходимыми нам колонками. Наше материализованное представление выполняет агрегацию по строкам, вставленным в эту таблицу (по одному блоку за раз), отправляя результаты в нашу целевую таблицу, `pypi_downloads_per_day`.

:::note
Мы использовали `pypi_downloads_per_day` в качестве нашей целевой таблицы здесь. Для дополнительной устойчивости пользователи могут создать дублирующую таблицу, `pypi_downloads_per_day_v2`, и использовать ее в качестве целевой таблицы представления, как показано в предыдущих примерах. После завершения вставки партиции в `pypi_downloads_per_day_v2` могут, в свою очередь, быть перемещены в `pypi_downloads_per_day.` Это позволит восстановиться в случае, если ваша вставка потерпела провал из-за проблем с памятью или прерываний сервера, т.е. мы просто обрезаем `pypi_downloads_per_day_v2`, настраиваем параметры и пробуем снова.
:::

Чтобы заполнить это материализованное представление, мы просто вставляем соответствующие данные для заполнения в `pypi_v2` из `pypi.`

```sql
INSERT INTO pypi_v2 SELECT timestamp, project FROM pypi WHERE timestamp < '2024-12-17 09:00:00'

0 rows in set. Elapsed: 27.325 sec. Processed 1.50 миллиарда строк, 33.48 GB (54.73 миллиона строк/с., 1.23 GB/с.)
Пиковое использование памяти: 639.47 MiB.
```

Обратите внимание, что наше использование памяти здесь составляет `639.47 MiB`.
##### Настройка производительности и ресурсов {#tuning-performance--resources}

Несколько факторов определят производительность и используемые ресурсы в указанном выше сценарии. Прежде чем пытаться настроить, мы рекомендуем читателям ознакомиться с механикой вставки, подробно описанной в разделе [Использование потоков для чтения](/integrations/s3/performance#using-threads-for-reads) руководства [Оптимизация производительности вставки и чтения из S3](/integrations/s3/performance). Вкратце:

- **Параллелизм чтения** - Количество потоков, используемых для чтения. Контролируется через [`max_threads`](/operations/settings/settings#max_threads). В ClickHouse Cloud это определяется размером экземпляра и по умолчанию равно количеству vCPU. Увеличение этого значения может улучшить производительность чтения за счет большего использования памяти.
- **Параллелизм вставки** - Количество потоков вставки, используемых для вставки. Контролируется через [`max_insert_threads`](/operations/settings/settings#max_insert_threads). В ClickHouse Cloud это определяется размером экземпляра (от 2 до 4) и в OSS выставляется в 1. Увеличение этого значения может улучшить производительность за счет большего использования памяти.
- **Размер блока вставки** - Данные обрабатываются в цикле, где они извлекаются, разбираются и формируются в встраиваемые блоки на основе [ключа партиционирования](/engines/table-engines/mergetree-family/custom-partitioning-key). Эти блоки сортируются, оптимизируются, сжимаются и записываются в хранилище в виде новых [частей данных](/parts). Размер вставочного блока, контролируемый настройками [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) и [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes) (несжатый), влияет на использование памяти и ввод-вывод диска. Более крупные блоки используют больше памяти, но создают меньше частей, уменьшая ввод-вывод и фоновое слияние. Эти настройки представляют собой минимальные пороги (тот, который достигается первым, вызывает сброс).
- **Размер блока материализованного представления** - Кроме вышеперечисленных механик для основной вставки, перед вставкой в материализованные представления блоки также компрессируются для более эффективной обработки. Размер этих блоков определяется настройками [`min_insert_block_size_bytes_for_materialized_views`](/operations/settings/settings#min_insert_block_size_bytes_for_materialized_views) и [`min_insert_block_size_rows_for_materialized_views`](/operations/settings/settings#min_insert_block_size_rows_for_materialized_views). Более крупные блоки позволяют более эффективную обработку за счет большего использования памяти. По умолчанию эти настройки возвращаются к значениям настроек исходной таблицы [`min_insert_block_size_rows`](/operations/settings/settings#min_insert_block_size_rows) и [`min_insert_block_size_bytes`](/operations/settings/settings#min_insert_block_size_bytes) соответственно.

Для улучшения производительности пользователи могут следовать руководствам, изложенным в разделе [Настройка потоков и размера блока для вставок](/integrations/s3/performance#tuning-threads-and-block-size-for-inserts) руководства [Оптимизация для вставки и чтения из S3](/integrations/s3/performance). Обычно нет необходимости вносить изменения в `min_insert_block_size_bytes_for_materialized_views` и `min_insert_block_size_rows_for_materialized_views`, чтобы улучшить производительность. Если они были изменены, используйте те же лучшие практики, как обсуждено для `min_insert_block_size_rows` и `min_insert_block_size_bytes`.

Чтобы минимизировать использование памяти, пользователи могут поэкспериментировать с этими настройками. Это неизбежно снизит производительность. Используя ранний запрос, мы показываем примеры ниже.

Снижение `max_insert_threads` до 1 снижает наши накладные расходы по памяти.

```sql
INSERT INTO pypi_v2
SELECT
    timestamp,
 project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1

0 rows in set. Elapsed: 27.752 sec. Processed 1.50 миллиарда строк, 33.48 GB (53.89 миллиона строк/с., 1.21 GB/с.)
Пиковое использование памяти: 506.78 MiB.
```

Мы можем еще больше сократить использование памяти, снизив настройку `max_threads` до 1.

```sql
INSERT INTO pypi_v2
SELECT timestamp, project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1, max_threads = 1

Ok.

0 rows in set. Elapsed: 43.907 sec. Processed 1.50 миллиарда строк, 33.48 GB (34.06 миллиона строк/с., 762.54 MB/с.)
Пиковое использование памяти: 272.53 MiB.
```

Наконец, мы можем еще больше сократить использование памяти, установив `min_insert_block_size_rows` в 0 (отключает его как фактор, влияющий на размер блока) и `min_insert_block_size_bytes` в 10485760 (10 MiB).

```sql
INSERT INTO pypi_v2
SELECT
    timestamp,
 project
FROM pypi
WHERE timestamp < '2024-12-17 09:00:00'
SETTINGS max_insert_threads = 1, max_threads = 1, min_insert_block_size_rows = 0, min_insert_block_size_bytes = 10485760

0 rows in set. Elapsed: 43.293 sec. Processed 1.50 миллиарда строк, 33.48 GB (34.54 миллиона строк/с., 773.36 MB/с.)
Пиковое использование памяти: 218.64 MiB.
```

Наконец, имейте в виду, что снижение размеров блоков производит больше частей и вызывает большее давление на слияние. Как обсуждено [здесь](/integrations/s3/performance#be-aware-of-merges), эти настройки следует изменять с осторожностью.
### Отсутствие временной метки или монотонно увеличивающейся колонки {#no-timestamp-or-monotonically-increasing-column}

Вышеупомянутые процессы зависят от наличия у пользователя временной метки или монотонно увеличивающейся колонки. В некоторых случаях это просто недоступно. В таком случае мы рекомендуем следующий процесс, который использует многие шаги, описанные ранее, но требует от пользователей приостановить прием данных.

1. Приостановите вставки в вашу основную таблицу.
2. Создайте дубликат вашей целевой таблицы с использованием синтаксиса `CREATE AS`.
3. Присоедините партиции из оригинальной целевой таблицы к дубликату, используя [`ALTER TABLE ATTACH`](/sql-reference/statements/alter/partition#attach-partitionpart). **Примечание:** Эта операция присоединения отличается от ранее использованного перемещения. Используя жесткие ссылки, данные в оригинальной таблице сохраняются.
4. Создайте новые материализованные представления.
5. Перезапустите вставки. **Примечание:** Вставки будут обновлять только целевую таблицу, а не дубликат, который будет ссылаться только на оригинальные данные.
6. Заполните материализованное представление, применив тот же процесс, что и ранее для данных с временными метками, используя дублирующую таблицу в качестве источника.

Рассмотрим следующий пример с использованием PyPI и нашим предыдущим новым материализованным представлением `pypi_downloads_per_day` (предположим, что мы не можем использовать временную метку):

```sql
SELECT count() FROM pypi

┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

1 row in set. Elapsed: 0.003 sec.

-- (1) Приостановите вставки
-- (2) Создайте дубликат нашей целевой таблицы

CREATE TABLE pypi_v2 AS pypi

SELECT count() FROM pypi_v2

┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

1 row in set. Elapsed: 0.004 sec.

-- (3) Присоедините партиции из оригинальной целевой таблицы к дубликату.

ALTER TABLE pypi_v2
 (ATTACH PARTITION tuple() FROM pypi)

-- (4) Создайте наши новые материализованные представления

CREATE TABLE pypi_downloads_per_day
(
    `hour` DateTime,
    `project` String,
    `count` Int64
)
ENGINE = SummingMergeTree
ORDER BY (project, hour)


CREATE MATERIALIZED VIEW pypi_downloads_per_day_mv TO pypi_downloads_per_day
AS SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi
GROUP BY
    hour,
 project

-- (4) Перезапустите вставки. Мы повторяем здесь, вставляя одну строку.

INSERT INTO pypi SELECT *
FROM pypi
LIMIT 1

SELECT count() FROM pypi

┌────count()─┐
│ 2039988138 │ -- 2.04 миллиарда
└────────────┘

1 row in set. Elapsed: 0.003 sec.

-- обратите внимание, что pypi_v2 содержит то же количество строк, что и ранее

SELECT count() FROM pypi_v2
┌────count()─┐
│ 2039988137 │ -- 2.04 миллиарда
└────────────┘

-- (5) Заполните представление, используя резервную таблицу pypi_v2

INSERT INTO pypi_downloads_per_day SELECT
 toStartOfHour(timestamp) as hour,
 project,
    count() AS count
FROM pypi_v2
GROUP BY
    hour,
 project

0 rows in set. Elapsed: 3.719 sec. Обработано 2.04 миллиарда строк, 47.15 ГБ (548.57 миллионов строк/с., 12.68 ГБ/с.)

DROP TABLE pypi_v2;
```

На предпоследнем шаге мы заполняем `pypi_downloads_per_day`, используя наш простой подход `INSERT INTO SELECT`, описанный [ранее](#timestamp-or-monotonically-increasing-column-available). Это также можно улучшить, используя подход с таблицей Null, описанный [выше](#using-a-null-table-engine-for-filling-materialized-views), с опциональным использованием дублирующей таблицы для большей надежности.

Хотя эта операция требует приостановки вставок, промежуточные операции обычно могут быть выполнены быстро - минимизируя любые перерывы в данных.
