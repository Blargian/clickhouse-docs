---
title: 'Миграция из BigQuery в ClickHouse Cloud'
slug: /migrations/bigquery/migrating-to-clickhouse-cloud
description: 'Как мигрировать ваши данные из BigQuery в ClickHouse Cloud'
keywords: ['migrate', 'migration', 'migrating', 'data', 'etl', 'elt', 'BigQuery']
---

import bigquery_2 from '@site/static/images/migrations/bigquery-2.png';
import bigquery_3 from '@site/static/images/migrations/bigquery-3.png';
import bigquery_4 from '@site/static/images/migrations/bigquery-4.png';
import bigquery_5 from '@site/static/images/migrations/bigquery-5.png';
import bigquery_6 from '@site/static/images/migrations/bigquery-6.png';
import bigquery_7 from '@site/static/images/migrations/bigquery-7.png';
import bigquery_8 from '@site/static/images/migrations/bigquery-8.png';
import bigquery_9 from '@site/static/images/migrations/bigquery-9.png';
import bigquery_10 from '@site/static/images/migrations/bigquery-10.png';
import bigquery_11 from '@site/static/images/migrations/bigquery-11.png';
import bigquery_12 from '@site/static/images/migrations/bigquery-12.png';
import Image from '@theme/IdealImage';

## Почему стоит использовать ClickHouse Cloud вместо BigQuery? {#why-use-clickhouse-cloud-over-bigquery}

TLDR: Потому что ClickHouse быстрее, дешевле и мощнее, чем BigQuery для современной аналитики данных:

<Image img={bigquery_2} size="md" alt="ClickHouse vs BigQuery"/>
## Загрузка данных из BigQuery в ClickHouse Cloud {#loading-data-from-bigquery-to-clickhouse-cloud}
### Набор данных {#dataset}

В качестве примера набора данных для демонстрации типичной миграции из BigQuery в ClickHouse Cloud мы используем набор данных Stack Overflow, задокументированный [здесь](/getting-started/example-datasets/stackoverflow). Он содержит каждый `post`, `vote`, `user`, `comment` и `badge`, которые произошли на Stack Overflow с 2008 года по апрель 2024 года. Схема BigQuery для этих данных показана ниже:

<Image img={bigquery_3} size="lg" alt="Схема"/>

Для пользователей, которые хотят заполнить этот набор данных в экземпляре BigQuery, чтобы протестировать шаги миграции, мы предоставили данные для этих таблиц в формате Parquet в GCS-хранилище, а команды DDL для создания и загрузки таблиц в BigQuery доступны [здесь](https://pastila.nl/?003fd86b/2b93b1a2302cfee5ef79fd374e73f431#hVPC52YDsUfXg2eTLrBdbA==).
### Миграция данных {#migrating-data}

Миграция данных между BigQuery и ClickHouse Cloud делится на два основных типа рабочих нагрузок:

- **Первоначальная массовая загрузка с периодическими обновлениями** - Необходимо мигрировать первоначальный набор данных вместе с периодическими обновлениями через заданные интервалы, например, ежедневно. Обновления здесь обрабатываются повторной отправкой строк, которые изменились - определяемых с помощью столбца, который можно использовать для сравнений (например, даты). Удаления обрабатываются с помощью полной периодической перезагрузки набора данных.
- **Репликация в реальном времени или CDC** - Необходимо мигрировать первоначальный набор данных. Изменения в этом наборе данных должны быть отражены в ClickHouse почти в реальном времени с допустимой задержкой всего в несколько секунд. Это фактически процесс [Change Data Capture (CDC)](https://en.wikipedia.org/wiki/Change_data_capture), при котором таблицы в BigQuery должны быть синхронизированы с ClickHouse, то есть вставки, обновления и удаления в таблице BigQuery должны быть применены к эквивалентной таблице в ClickHouse.
#### Массовая загрузка через Google Cloud Storage (GCS) {#bulk-loading-via-google-cloud-storage-gcs}

BigQuery поддерживает экспорт данных в объектное хранилище Google (GCS). Для нашего примера набора данных:

1. Экспортируйте 7 таблиц в GCS. Команды для этого доступны [здесь](https://pastila.nl/?014e1ae9/cb9b07d89e9bb2c56954102fd0c37abd#0Pzj52uPYeu1jG35nmMqRQ==).

2. Импортируйте данные в ClickHouse Cloud. Для этого мы можем использовать [функцию таблицы gcs](/sql-reference/table-functions/gcs). Команды DDL и запросы импорта доступны [здесь](https://pastila.nl/?00531abf/f055a61cc96b1ba1383d618721059976#Wf4Tn43D3VCU5Hx7tbf1Qw==). Обратите внимание, что поскольку экземпляр ClickHouse Cloud состоит из нескольких вычислительных узлов, вместо функции таблицы `gcs` мы используем [функцию таблицы s3Cluster](/sql-reference/table-functions/s3Cluster). Эта функция также работает с GCS-бакетами и [использует все узлы сервиса ClickHouse Cloud](https://clickhouse.com/blog/supercharge-your-clickhouse-data-loads-part1#parallel-servers) для загрузки данных параллельно.

<Image img={bigquery_4} size="md" alt="Массовая загрузка"/>

Этот подход имеет ряд преимуществ:

- Функциональность экспорта BigQuery поддерживает фильтрацию для экспорта подмножества данных.
- BigQuery поддерживает экспорт в форматы [Parquet, Avro, JSON и CSV](https://cloud.google.com/bigquery/docs/exporting-data) и несколько [типов сжатия](https://cloud.google.com/bigquery/docs/exporting-data) - все поддерживаются ClickHouse.
- GCS поддерживает [управление жизненным циклом объектов](https://cloud.google.com/storage/docs/lifecycle), позволяя удалять данные, которые были экспортированы и импортированы в ClickHouse, после истечения определенного периода.
- [Google позволяет экспортировать до 50 ТБ в день в GCS бесплатно](https://cloud.google.com/bigquery/quotas#export_jobs). Пользователи платят только за хранилище GCS.
- Экспорт создает несколько файлов автоматически, ограничивая каждый максимум 1 ГБ табличных данных. Это выгодно для ClickHouse, поскольку позволяет параллелизовать импорт.

Перед тем как попробовать следующие примеры, мы рекомендуем пользователям ознакомиться с [разрешениями, необходимыми для экспорта](https://cloud.google.com/bigquery/docs/exporting-data#required_permissions) и [рекомендациями по локализации](https://cloud.google.com/bigquery/docs/exporting-data#data-locations), чтобы максимизировать производительность экспорта и импорта.
### Репликация в реальном времени или CDC через запланированные запросы {#real-time-replication-or-cdc-via-scheduled-queries}

Change Data Capture (CDC) - это процесс, при котором таблицы синхронизируются между двумя базами данных. Это значительно сложнее, если обновления и удаления должны обрабатываться почти в реальном времени. Один из подходов - просто запланировать периодический экспорт с использованием [функциональности запланированных запросов BigQuery](https://cloud.google.com/bigquery/docs/scheduling-queries). При условии, что вы можете принять некоторую задержку в данных, которые будут вставлены в ClickHouse, этот подход легко реализовать и поддерживать. Пример приведен в [этой публикации в блоге](https://clickhouse.com/blog/clickhouse-bigquery-migrating-data-for-realtime-queries#using-scheduled-queries).
## Проектирование схем {#designing-schemas}

Набор данных Stack Overflow содержит несколько связанных таблиц. Мы рекомендуем сначала сосредоточиться на миграции основной таблицы. Это может не обязательно быть самой крупной таблицей, а скорее той, по которой вы ожидаете получить наибольшее количество аналитических запросов. Это позволит вам ознакомиться с основными концепциями ClickHouse. Эта таблица может потребовать перепроектирования, поскольку добавляются дополнительные таблицы, чтобы в полной мере использовать возможности ClickHouse и достичь оптимальной производительности. Мы изучаем этот процесс моделирования в нашей [документации по моделированию данных](/data-modeling/schema-design#next-data-modeling-techniques).

Согласно этому принципу, мы сосредоточимся на основной таблице `posts`. Схема BigQuery для этой таблицы показана ниже:

```sql
CREATE TABLE stackoverflow.posts (
    id INTEGER,
    posttypeid INTEGER,
    acceptedanswerid STRING,
    creationdate TIMESTAMP,
    score INTEGER,
    viewcount INTEGER,
    body STRING,
    owneruserid INTEGER,
    ownerdisplayname STRING,
    lasteditoruserid STRING,
    lasteditordisplayname STRING,
    lasteditdate TIMESTAMP,
    lastactivitydate TIMESTAMP,
    title STRING,
    tags STRING,
    answercount INTEGER,
    commentcount INTEGER,
    favoritecount INTEGER,
    conentlicense STRING,
    parentid STRING,
    communityowneddate TIMESTAMP,
    closeddate TIMESTAMP
);
```
### Оптимизация типов {#optimizing-types}

Применение процесса, описанного [здесь](/data-modeling/schema-design), приводит к следующей схеме:

```sql
CREATE TABLE stackoverflow.posts
(
   `Id` Int32,
   `PostTypeId` Enum('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
   `AcceptedAnswerId` UInt32,
   `CreationDate` DateTime,
   `Score` Int32,
   `ViewCount` UInt32,
   `Body` String,
   `OwnerUserId` Int32,
   `OwnerDisplayName` String,
   `LastEditorUserId` Int32,
   `LastEditorDisplayName` String,
   `LastEditDate` DateTime,
   `LastActivityDate` DateTime,
   `Title` String,
   `Tags` String,
   `AnswerCount` UInt16,
   `CommentCount` UInt8,
   `FavoriteCount` UInt8,
   `ContentLicense` LowCardinality(String),
   `ParentId` String,
   `CommunityOwnedDate` DateTime,
   `ClosedDate` DateTime
)
ENGINE = MergeTree
ORDER BY tuple()
COMMENT 'Оптимизированные типы'
```

Мы можем заполнить эту таблицу с помощью простого [`INSERT INTO SELECT`](/sql-reference/statements/insert-into), считывая экспортированные данные из GCS, используя [`gcs` функцию таблицы](/sql-reference/table-functions/gcs). Обратите внимание, что в ClickHouse Cloud вы также можете использовать совместимую с GCS [`s3Cluster` функцию таблицы](/sql-reference/table-functions/s3Cluster) для параллелизации загрузки по нескольким узлам:

```sql
INSERT INTO stackoverflow.posts SELECT * FROM gcs( 'gs://clickhouse-public-datasets/stackoverflow/parquet/posts/*.parquet', NOSIGN);
```

Мы не сохраняем никаких null-значений в нашей новой схеме. Вышеупомянутый insert неявно преобразует их в значения по умолчанию для их соответствующих типов - 0 для целых чисел и пустое значение для строк. ClickHouse также автоматически преобразует любые числовые значения к их целевой точности.
## Как отличаются первичные ключи ClickHouse? {#how-are-clickhouse-primary-keys-different}

Как описано [здесь](/migrations/bigquery), как и в BigQuery, ClickHouse не обеспечивает уникальность для значений первичного ключа таблицы.

Подобно кластеризации в BigQuery, данные таблицы ClickHouse хранятся на диске в порядке, заданном столбцами первичного ключа. Этот порядок сортировки используется оптимизатором запросов для предотвращения повторной сортировки, минимизации использования памяти для соединений и обеспечения короткого замыкания для ограничений.

В отличие от BigQuery, ClickHouse автоматически создает [средний (разреженный) первичный индекс](/guides/best-practices/sparse-primary-indexes) на основе значений столбцов первичного ключа. Этот индекс используется для ускорения всех запросов, содержащих фильтры по столбцам первичного ключа. Конкретно:

- Эффективность использования памяти и диска имеет первостепенное значение при масштабировании, на котором часто используется ClickHouse. Данные записываются в таблицы ClickHouse большими частями, известными как части, с правилами для фона слияния частей. В ClickHouse каждая часть имеет свой собственный первичный индекс. Когда части сливаются, первичные индексы объединяются. Обратите внимание, что эти индексы не создаются для каждой строки. Вместо этого первичный индекс для части имеет одну запись индекса на группу строк - эта техника называется разреженным индексированием.
- Разреженное индексирование возможно, потому что ClickHouse хранит строки для части на диске в порядке, определяемом указанным ключом. Вместо того чтобы напрямую находить отдельные строки (как индекс на основе B-дерева), разреженный первичный индекс позволяет быстро (путем бинарного поиска по записям индекса) идентифицировать группы строк, которые могут соответствовать запросу. Найденные группы потенциально соответствующих строк затем параллельно передаются в движок ClickHouse для поиска соответствий. Этот дизайн индекса позволяет первичному индексу быть малым (он полностью помещается в основную память), при этом значительно ускоряя время выполнения запросов, особенно для запросов диапазона, которые типичны для аналитики данных. Для получения дополнительных сведений мы рекомендуем [это подробное руководство](/guides/best-practices/sparse-primary-indexes).

<Image img={bigquery_5} size="md" alt="Первичные ключи ClickHouse"/>

Выбранный первичный ключ в ClickHouse определит не только индекс, но и порядок, в котором данные записываются на диск. Из-за этого это может значительно повлиять на уровень сжатия, что, в свою очередь, может повлиять на производительность запросов. Ключ сортировки, который заставляет значения большинства столбцов записываться в последовательном порядке, позволит выбранному алгоритму сжатия (и кодекам) более эффективно сжать данные.

> Все столбцы в таблице будут отсортированы на основе значения указанного ключа упорядочивания, независимо от того, включены ли они в сам ключ. Например, если `CreationDate` используется в качестве ключа, порядок значений во всех других столбцах будет соответствовать порядку значений в столбце `CreationDate`. Можно указать несколько ключей упорядочивания - это будет упорядочено с той же семантикой, что и оператор `ORDER BY` в запросе `SELECT`.
### Выбор ключа упорядочивания {#choosing-an-ordering-key}

Для соображений и шагов по выбору ключа упорядочивания, используя таблицу постов в качестве примера, смотрите [здесь](/data-modeling/schema-design#choosing-an-ordering-key).
## Техники моделирования данных {#data-modeling-techniques}

Мы рекомендуем пользователям, migrating from BigQuery, прочитать [руководство по моделированию данных в ClickHouse](/data-modeling/schema-design). Этот гид использует тот же набор данных Stack Overflow и изучает несколько подходов, используя функции ClickHouse.
### Партиции {#partitions}

Пользователи BigQuery будут знакомы с концепцией партиционирования таблиц для повышения производительности и управляемости для больших баз данных, разбивая таблицы на более мелкие, более управляемые части, называемые партициями. Это партиционирование можно осуществить, используя либо диапазон по заданному столбцу (например, даты), определенные списки, либо через хеш по ключу. Это позволяет администраторам организовывать данные на основе определенных критериев, таких как диапазоны дат или географические местоположения.

Партиционирование помогает улучшить производительность запросов, позволяя более быстрый доступ к данным через отбор партиций и более эффективное индексирование. Это также помогает в задачах технического обслуживания, таких как резервное копирование и удаление данных, позволяя проводить операции на отдельных партициях, а не на всей таблице. Кроме того, партиционирование может значительно улучшить масштабируемость баз данных BigQuery путем распределения нагрузки между несколькими партициями.

В ClickHouse партиционирование указывается в таблице при ее первоначальном определении с помощью [`PARTITION BY`](/engines/table-engines/mergetree-family/custom-partitioning-key) оператора. Этот оператор может содержать SQL-выражение по любым столбцам, результаты которого определяют, в какую партицию будет отправлена строка.

<Image img={bigquery_6} size="md" alt="Партиции"/>

Части данных логически ассоциированы с каждой партицией на диске и могут запрашиваться изолированно. Для приведенного ниже примера мы партиционируем таблицу постов по году, используя выражение [`toYear(CreationDate)`](/sql-reference/functions/date-time-functions#toyear). По мере вставки строк в ClickHouse это выражение будет оцениваться для каждой строки - строки затем направляются в соответствующую партицию в форме новых частей данных, принадлежащих этой партиции.

```sql
CREATE TABLE posts
(
        `Id` Int32 CODEC(Delta(4), ZSTD(1)),
        `PostTypeId` Enum8('Question' = 1, 'Answer' = 2, 'Wiki' = 3, 'TagWikiExcerpt' = 4, 'TagWiki' = 5, 'ModeratorNomination' = 6, 'WikiPlaceholder' = 7, 'PrivilegeWiki' = 8),
        `AcceptedAnswerId` UInt32,
        `CreationDate` DateTime64(3, 'UTC'),
...
        `ClosedDate` DateTime64(3, 'UTC')
)
ENGINE = MergeTree
ORDER BY (PostTypeId, toDate(CreationDate), CreationDate)
PARTITION BY toYear(CreationDate)
```
#### Применения {#applications}

Партиционирование в ClickHouse имеет аналогичные применения, как и в BigQuery, но с некоторыми тонкими различиями. Более конкретно:

- **Управление данными** - В ClickHouse пользователи должны в первую очередь рассматривать партиционирование как функцию управления данными, а не как технику оптимизации запросов. Разделяя данные логически на основе ключа, каждую партицию можно обрабатывать независимо, например, удалить. Это позволяет пользователям перемещать партиции, а значит, подмножества, между [уровнями хранения](/integrations/s3#storage-tiers) эффективно по времени или [истекать данные/эффективно удалять из кластера](/sql-reference/statements/alter/partition). В примере ниже мы удаляем публикации за 2008 год:

```sql
SELECT DISTINCT partition
FROM system.parts
WHERE `table` = 'posts'

┌─partition─┐
│ 2008      │
│ 2009      │
│ 2010      │
│ 2011      │
│ 2012      │
│ 2013      │
│ 2014      │
│ 2015      │
│ 2016      │
│ 2017      │
│ 2018      │
│ 2019      │
│ 2020      │
│ 2021      │
│ 2022      │
│ 2023      │
│ 2024      │
└───────────┘

17 строк в наборе. Затраченное время: 0.002 сек.

ALTER TABLE posts
(DROP PARTITION '2008')

Ok.

0 строк в наборе. Затраченное время: 0.103 сек.
```

- **Оптимизация запросов** - Хотя партиции могут помочь с производительностью запросов, это зависит от шаблонов доступа. Если запросы нацелены только на несколько партиций (в идеале одну), производительность может потенциально улучшиться. Это обычно полезно только в том случае, если ключ партиционирования не находится в первичном ключе, и вы фильтруете по нему. Однако запросы, которым необходимо охватывать многие партиции, могут говорить о худшей производительности, чем если бы партиционирование не использовалось (поскольку в результате партиционирования может быть больше частей). Преимущество нацеливания на одну партицию будет еще менее выражено или отсутствовать, если ключ партиционирования уже является ранним элементом первичного ключа. Партиционирование также можно использовать для [оптимизации запросов с оператором `GROUP BY`](/engines/table-engines/mergetree-family/custom-partitioning-key#group-by-optimisation-using-partition-key), если значения в каждой партиции уникальны. Однако, в общем, пользователи должны убедиться, что первичный ключ оптимизирован, и только в исключительных случаях рассматривать партиционирование как технику оптимизации запросов, когда шаблоны доступа соответствуют конкретному предсказуемому подмножеству дня, например, партиционирование по дням, при этом большинство запросов - за последний день.
#### Рекомендации {#recommendations}

Пользователи должны рассматривать партиционирование как технику управления данными. Это идеально, когда данные необходимо удалить из кластера при работе с данными временных рядов, например, старую партицию можно [просто удалить](/sql-reference/statements/alter/partition#drop-partitionpart).

Важно: убедитесь, что ваше выражение ключа партиционирования не приводит к множеству с высокой кардинальностью, т.е. следует избегать создания более чем 100 партиций. Например, не партиционируйте ваши данные по столбцам с высокой кардинальностью, таким как идентификаторы или имена клиентов. Вместо этого сделайте идентификатор или имя клиента первым столбцом в выражении `ORDER BY`.

> Внутри ClickHouse [создает части](/guides/best-practices/sparse-primary-indexes#clickhouse-index-design) для вставленных данных. По мере вставки данных количество частей увеличивается. Чтобы предотвратить чрезмерное увеличение количества частей, что приведет к ухудшению производительности запросов (из-за чтения большего количества файлов), части объединяются в фоновом асинхронном процессе. Если количество частей превышает [преднастройку](/operations/settings/merge-tree-settings#parts_to_throw_insert), ClickHouse выдаст исключение на вставку как ["слишком много частей" ошибка](/knowledgebase/exception-too-many-parts). Этого не должно происходить при нормальной работе и происходит только если ClickHouse настроен неправильно или используется неправильно, например, множество мелких вставок. Поскольку части создаются для каждой партиции по отдельности, увеличение количества партиций вызывает увеличение количества частей, т.е. это кратное количество партиций. Ключи партиционирования с высокой кардинальностью могут, следовательно, вызвать эту ошибку и должны быть избегаемы.
## Материализованные представления против проекций {#materialized-views-vs-projections}

Концепция проекций в ClickHouse позволяет пользователям указывать несколько операторов `ORDER BY` для таблицы.

В [моделировании данных ClickHouse](/data-modeling/schema-design) мы изучаем, как можно использовать материализованные представления в ClickHouse для предварительного вычисления агрегатов, преобразования строк и оптимизации запросов для различных шаблонов доступа. Для последнего мы [предоставили пример](/materialized-view/incremental-materialized-view#lookup-table), где материализованное представление отправляет строки в целевую таблицу с другим ключом упорядочивания, чем у оригинальной таблицы, получающей вставки.

Например, рассмотрим следующий запрос:

```sql
SELECT avg(Score)
FROM comments
WHERE UserId = 8592047

   ┌──────────avg(Score)─┐
   │ 0.18181818181818182 │
   └─────────────────────┘

1 строка в наборе. Затраченное время: 0.040 сек. Обработано 90.38 миллиона строк, 361.59 МБ (2.25 миллиарда строк/с., 9.01 ГБ/с.)
Максимальное использование памяти: 201.93 МиБ.
```

Этот запрос требует отсканировать все 90 миллионов строк (признаемся, быстро), поскольку `UserId` не является ключом упорядочивания. Ранее мы решили эту проблему, используя материализованное представление, действующее как таблица поиска для `PostId`. Ту же проблему можно решить с помощью проекции. Команда ниже добавляет проекцию для `ORDER BY user_id`.

```sql
ALTER TABLE comments ADD PROJECTION comments_user_id (
SELECT * ORDER BY UserId
)

ALTER TABLE comments MATERIALIZE PROJECTION comments_user_id
```

Обратите внимание, что мы сначала должны создать проекцию, а затем материализовать ее. Эта последняя команда приводит к тому, что данные хранятся дважды на диске в двух разных порядках. Проекция также может быть определена при создании данных, как показано ниже, и будет автоматически поддерживаться по мере вставки данных.

```sql
CREATE TABLE comments
(
        `Id` UInt32,
        `PostId` UInt32,
        `Score` UInt16,
        `Text` String,
        `CreationDate` DateTime64(3, 'UTC'),
        `UserId` Int32,
        `UserDisplayName` LowCardinality(String),
        PROJECTION comments_user_id
        (
        SELECT *
        ORDER BY UserId
        )
)
ENGINE = MergeTree
ORDER BY PostId
```

Если проекция создается через команду `ALTER`, создание происходит асинхронно, когда команда `MATERIALIZE PROJECTION` выдается. Пользователи могут подтвердить ход выполнения этой операции следующим запросом, ожидая `is_done=1`.

```sql
SELECT
        parts_to_do,
        is_done,
        latest_fail_reason
FROM system.mutations
WHERE (`table` = 'comments') AND (command LIKE '%MATERIALIZE%')

   ┌─parts_to_do─┬─is_done─┬─latest_fail_reason─┐
1. │           1 │       0 │                    │
   └─────────────┴─────────┴────────────────────┘

1 строка в наборе. Затраченное время: 0.003 сек.
```

Если мы повторим приведенный выше запрос, мы можем увидеть, что производительность значительно улучшилась за счет дополнительного хранилища.

```sql
SELECT avg(Score)
FROM comments
WHERE UserId = 8592047

   ┌──────────avg(Score)─┐
1. │ 0.18181818181818182 │
   └─────────────────────┘

1 строка в наборе. Затраченное время: 0.008 сек. Обработано 16.36 тысячи строк, 98.17 КБ (2.15 миллиона строк/с., 12.92 МБ/с.)
Максимальное использование памяти: 4.06 МиБ.
```

С помощью команды [`EXPLAIN`](/sql-reference/statements/explain) мы также подтверждаем, что проекция использовалась для выполнения этого запроса:

```sql
EXPLAIN indexes = 1
SELECT avg(Score)
FROM comments
WHERE UserId = 8592047

    ┌─explain─────────────────────────────────────────────┐
 1. │ Expression ((Projection + Before ORDER BY))         │
 2. │   Aggregating                                       │
 3. │   Filter                                            │
 4. │           ReadFromMergeTree (comments_user_id)      │
 5. │           Indexes:                                  │
 6. │           PrimaryKey                                │
 7. │           Keys:                                     │
 8. │           UserId                                    │
 9. │           Condition: (UserId in [8592047, 8592047]) │
10. │           Parts: 2/2                                │
11. │           Granules: 2/11360                         │
    └─────────────────────────────────────────────────────┘

11 строк в наборе. Затраченное время: 0.004 сек.
```
### Когда использовать проекции {#when-to-use-projections}

Проекции являются привлекательной функцией для новых пользователей, так как они автоматически поддерживаются по мере вставки данных. Более того, запросы могут просто быть отправлены в одну таблицу, где проекции используются, когда это возможно, чтобы ускорить время ответа.

<Image img={bigquery_7} size="md" alt="Проекции"/>

Этот подход контрастирует с материализованными представлениями, где пользователю необходимо выбрать подходящую оптимизированную целевую таблицу или переписать свой запрос в зависимости от фильтров. Это создает большую зависимость от приложений пользователей и увеличивает сложность на стороне клиента.

Несмотря на эти преимущества, проекции имеют некоторые встроенные ограничения, о которых пользователям следует знать, и поэтому их следует развертывать с осторожностью:

- Проекции не позволяют использовать разные TTL для исходной таблицы и (скрытой) - целевой таблицы. Материализованные представления позволяют использовать различные TTL.
- Проекции [в настоящее время не поддерживают `optimize_read_in_order`](https://clickhouse.com/blog/clickhouse-faster-queries-with-projections-and-primary-indexes) для (скрытой) целевой таблицы.
- Легковесные обновления и удаления не поддерживаются для таблиц с проекциями.
- Материализованные представления могут быть связаны: целевая таблица одного материализованного представления может быть исходной таблицей другого материализованного представления и так далее. Это невозможно с проекциями.
- Проекции не поддерживают соединения; материализованные представления да.
- Проекции не поддерживают фильтры (оператор `WHERE`); материализованные представления поддерживают.

Мы рекомендуем использовать проекции, когда:

- Потребуется полная переработка данных. Несмотря на то, что выражение в проекции может, теоретически, использовать `GROUP BY`, материализованные представления эффективнее для поддержания агрегатов. Оптимизатор запросов также с большей вероятностью использует проекции, которые используют простую переработку, т.е. `SELECT * ORDER BY x`. Пользователи могут выбрать подмножество столбцов в этом выражении, чтобы уменьшить объем хранилища.
- Пользователи готовы к связанным увеличениям объема хранилища и накладным расходам на запись данных дважды. Протестируйте влияние на скорость вставки и [оцените накладные расходы на хранилище](/data-compression/compression-in-clickhouse).
## Переписывание запросов BigQuery в ClickHouse {#rewriting-bigquery-queries-in-clickhouse}

Следующее предоставляет примеры запросов для сравнения BigQuery и ClickHouse. Этот список нацелен на то, чтобы продемонстрировать, как использовать возможности ClickHouse для значительного упрощения запросов. Примеры здесь используют полный набор данных Stack Overflow (до апреля 2024).

**Пользователи (с более чем 10 вопросами), которые получают больше всего просмотров:**

_BigQuery_

<Image img={bigquery_8} size="sm" alt="Переписывание запросов BigQuery" border/>

_ClickHouse_

```sql
SELECT
    OwnerDisplayName,
    sum(ViewCount) AS total_views
FROM stackoverflow.posts
WHERE (PostTypeId = 'Question') AND (OwnerDisplayName != '')
GROUP BY OwnerDisplayName
HAVING count() > 10
ORDER BY total_views DESC
LIMIT 5

   ┌─OwnerDisplayName─┬─total_views─┐
1. │ Joan Venge       │    25520387 │
2. │ Ray Vega         │    21576470 │
3. │ anon             │    19814224 │
4. │ Tim              │    19028260 │
5. │ John             │    17638812 │
   └──────────────────┴─────────────┘

5 строк в наборе. Затраченное время: 0.076 сек. Обработано 24.35 миллиона строк, 140.21 МБ (320.82 миллиона строк/с., 1.85 ГБ/с.)
Максимальное использование памяти: 323.37 МиБ.
```

**Какие теги получают больше всего просмотров:**

_BigQuery_

<br />

<Image img={bigquery_9} size="sm" alt="BigQuery 1" border/>

_ClickHouse_

```sql
-- ClickHouse
SELECT
    arrayJoin(arrayFilter(t -> (t != ''), splitByChar('|', Tags))) AS tags,
    sum(ViewCount) AS views
FROM stackoverflow.posts
GROUP BY tags
ORDER BY views DESC
LIMIT 5


   ┌─tags───────┬──────views─┐
1. │ javascript │ 8190916894 │
2. │ python     │ 8175132834 │
3. │ java       │ 7258379211 │
4. │ c#         │ 5476932513 │
5. │ android    │ 4258320338 │
   └────────────┴────────────┘

5 строк в наборе. Затраченное время: 0.318 сек. Обработано 59.82 миллиона строк, 1.45 ГБ (188.01 миллиона строк/с., 4.54 ГБ/с.)
Максимальное использование памяти: 567.41 МиБ.
```
## Агрегатные функции {#aggregate-functions}

По возможности пользователям следует использовать агрегатные функции ClickHouse. Ниже мы показываем использование [`argMax` функции](/sql-reference/aggregate-functions/reference/argmax) для вычисления самого просматриваемого вопроса каждого года.

_BigQuery_

<Image img={bigquery_10} border size="sm" alt="Агрегатные функции 1"/>

<Image img={bigquery_11} border size="sm" alt="Агрегатные функции 2"/>

_ClickHouse_

```sql
-- ClickHouse
SELECT
    toYear(CreationDate) AS Year,
    argMax(Title, ViewCount) AS MostViewedQuestionTitle,
    max(ViewCount) AS MaxViewCount
FROM stackoverflow.posts
WHERE PostTypeId = 'Question'
GROUP BY Year
ORDER BY Year ASC
FORMAT Vertical


Row 1:
──────
Year:                    2008
MostViewedQuestionTitle: How to find the index for a given item in a list?
MaxViewCount:            6316987

Row 2:
──────
Year:                    2009
MostViewedQuestionTitle: How do I undo the most recent local commits in Git?
MaxViewCount:            13962748

...

Row 16:
───────
Year:                    2023
MostViewedQuestionTitle: How do I solve "error: externally-managed-environment" every time I use pip 3?
MaxViewCount:            506822

Row 17:
───────
Year:                    2024
MostViewedQuestionTitle: Warning "Third-party cookie will be blocked. Learn more in the Issues tab"
MaxViewCount:            66975

17 строк в наборе. Затраченное время: 0.225 сек. Обработано 24.35 миллиона строк, 1.86 ГБ (107.99 миллиона строк/с., 8.26 ГБ/с.)
Максимальное использование памяти: 377.26 МиБ.
```
## Условные операторы и массивы {#conditionals-and-arrays}

Условные и массивные функции значительно упрощают запросы. Следующий запрос вычисляет теги (с более чем 10000 вхождениями) с наибольшим процентным увеличением с 2022 на 2023 год. Обратите внимание, как следующий запрос ClickHouse краток благодаря условным операторам, массивным функциям и возможности повторного использования псевдонимов в предложениях `HAVING` и `SELECT`.

_BigQuery_

<Image img={bigquery_12} size="sm" border alt="Условные операторы и массивы"/>

_ClickHouse_

```sql
SELECT
    arrayJoin(arrayFilter(t -> (t != ''), splitByChar('|', Tags))) AS tag,
    countIf(toYear(CreationDate) = 2023) AS count_2023,
    countIf(toYear(CreationDate) = 2022) AS count_2022,
    ((count_2023 - count_2022) / count_2022) * 100 AS percent_change
FROM stackoverflow.posts
WHERE toYear(CreationDate) IN (2022, 2023)
GROUP BY tag
HAVING (count_2022 > 10000) AND (count_2023 > 10000)
ORDER BY percent_change DESC
LIMIT 5

┌─tag─────────┬─count_2023─┬─count_2022─┬──────percent_change─┐
│ next.js     │      13788 │      10520 │   31.06463878326996 │
│ spring-boot │      16573 │      17721 │  -6.478189718413183 │
│ .net        │      11458 │      12968 │ -11.644046884639112 │
│ azure       │      11996 │      14049 │ -14.613139725247349 │
│ docker      │      13885 │      16877 │  -17.72826924216389 │
└─────────────┴────────────┴────────────┴─────────────────────┘

5 строк в наборе. Затраченное время: 0.096 сек. Обработано 5.08 миллионов строк, 155.73 MB (53.10 миллионов строк/с., 1.63 GB/с.)
Пиковое использование памяти: 410.37 MiB.
```

На этом мы завершаем наше.basic руководство для пользователей, мигрирующих с BigQuery на ClickHouse. Мы рекомендуем пользователям, мигрирующим с BigQuery, ознакомиться с руководством по [моделированию данных в ClickHouse](/data-modeling/schema-design), чтобы узнать больше о расширенных возможностях ClickHouse.
